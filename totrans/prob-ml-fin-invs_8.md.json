["```py\n# Flatten posterior predictive xdarray into one numpy array of \n# 20,000 simulated samples.\nsimulated_data = target_predicted.flatten()\n\n# Create a pandas dataframe to analyze the simulated data.\ngenerated_data = pd.DataFrame(simulated_data, columns=[\"Values\"])\n\n# Print the summary statistics.\nprint(generated_data.describe().round(2))\n\n# Plot the predicted samples of Apple's excess returns generated by \n# tested linear ensemble.\nplt.hist(simulated_data, bins='auto', density=True)\nplt.title(\"Apple's excess returns predicted by linear ensemble\")\nplt.ylabel('Probability density'), \nplt.xlabel('Simulated excess returns of Apple');\n\n```", "```py\n#Market value of position size in the portfolio\nposition_size = 100000\n\n#The loss function is position size * excess returns of Apple \n#for each prediction. \nlosses = simulated_data/100*position_size\n\n#Expected loss is probability weighted arithmetic mean of all the losses \n#and profits\nexpected_loss = np.mean(losses)\n\n#Range of losses predicted by tested linear ensemble.\nprint(\"Expected loss on investment of $100,000 is ${:.0f}, with max possible \nloss of ${:.0f} and max possible profit of ${:.0f}\"\n.format(expected_loss, np.min(losses), np.max(losses)))\n\nExpected loss on investment of $100,000 is $-237, with max possible loss of \n$-10253 and max possible profit of $8286\n```", "```py\n#Generate a list the 20 worst daily losses predicted \n# by tested linear ensemble.\nsorted_returns = generated['Values'].sort_values()\nsorted_returns.head(20).round(2)\n```", "```py\n# Compute the first percentile of returns. \nprobability = 0.99\ngvar = sorted_returns.quantile(1-probability)\n\nprint(f\"The daily Generative VaR at {probability}% probability is \n{gvar/100:.2%} implying a dollar loss of ${gvar/100*position_size:.0f} \")\n\nThe daily Generative VaR at 0.99% probability is -3.79% implying a dollar\nloss of $-3789 \n\n```", "```py\n# Filter the returns that fall below the first percentile\ngenerated_tail = sorted_returns[sorted_returns <= gvar]\n\n# Expected shortfall is the mean of the tail returns.\nges = generated_tail.mean()\n\n# Generated tail risk is the worst possible loss predicted \n# by the linear ensemble\ngtr = generated_tail.min()\n\n# Plot a histogram of the worst returns or generated tail risk (GTR)\nplt.hist(generated_tail, bins=50)\nplt.axvline(x=gvar, color='green', linestyle='solid', \nlabel='Generative Value at Risk')\nplt.axvline(x=ges, color='black', linestyle='dashed', \nlabel='Generative expected shortfall')\nplt.axvline(x=gtr, color='red', linestyle='dotted', \nlabel='Generative tail risk')\n\nplt.xlabel('Simulated excess returns of Apple')\nplt.ylabel('Frequency of excess returns')\nplt.title('Simulation of the bottom 1% excess returns of Apple')\nplt.legend(loc=0)\nplt.show()\n\nprint(f\"The daily Generative VaR at {probability}% probability is \n{gvar/100:.2%} implying a dollar loss of ${gvar/100*position_size:.0f} \")\nprint(f\"The daily Generative expected shortfall at \n{1-probability:.2}% probability is {ges/100:.2%} implying a dollar loss \nof ${ges/100*position_size:.0f}\")\nprint(f\"The daily Generative tail risk is {gtr/100:.2%} \nimplying a dollar loss of ${gtr/100*position_size:.0f}\")\n\n```", "```py\n#Fix the random seed so numbers can be reproduced\nnp.random.seed(114)\n\n#Number of posterior predictive samples to simulate\nN = 20000\n\n#Draw 100,000 samples from the model's posterior distribution \n#of parameter p\n#Random.choice() selects 100,000 values of p from the \n#earnings_beat['parameter'] column using the probabilities in the \n#earnings_beat['posterior'] column.\nposterior_samples = np.random.choice(earnings_beat['parameter'], \nsize=100000, p=earnings_beat['posterior'])\n\n#Draw a smaller subset of N random samples from the \n#posterior samples of parameter p\nposterior_samples_n = np.random.choice(posterior_samples, size=N)\n\n#Generate N random simulated outcomes by using the model's likelihood\n#function and posterior samples of the parameter p\n#Likelihood function is the Bernoulli distribution, a special case \n#of the binomial distribution where number of trials n=1\n#Simulated data are the data generated from the posterior \n#predictive distribution of the model\nsimulated_data = np.random.binomial(n=1, p=posterior_samples_n)\n\n#Plot the simulated data of earnings outcomes y=0 and y=1\nplt.figure(figsize=(8,6))\nplt.hist(simulated_data)\nplt.xticks([0,1])\nplt.xlabel('Predicted outcomes')\nplt.ylabel('Count')\nplt.title('Simulated outcomes of ZYX beating earnings expectations')\nplt.show()\n\n#Count the number of data points for each outcome\ny_0 = np.sum(simulated_data == 0)\ny_1 = np.sum(simulated_data == 1)\n\n#Compute the posterior predictive distribution\nprint(f\"Probability that ZYX will not beat earnings expectations (y=0) is:\n{y_0/(y_0+y_1):.3f}\")\nprint(f\"Probability that ZYX will beat earnings expectations (y=1) is:\n{y_1/(y_0+y_1):.3f}\")\n\n```", "```py\n#Percentage losses when y=0 and earnings don't beat expectations\nloss = -0.15\n#Percentage profits when y=1 and earnings beat expectations\nprofit = 0.05\n\n#Set the starting capital\nstart_capital = 100000\n\n#Create a list of values for position_size or percentage of total capital \n#invested in ZYX by an investor\nposition_size = np.arange(0.00, 1.00, 0.01)\n\n#Create an empty list to store the final capital values for \n#each position_size of an investor\nfinal_capital_values = []\n\n#Loop over each value of position_size f to calculate \n#terminal wealth for each investor\nfor f in position_size:\n   #Set the initial capital for this simulation\n   capital = start_capital\n\n   #Loop over each simulated data point and calculate the P&L based on y=0 or y=1\n    for y in simulated_data:\n        if y == 0:\n           capital += capital * loss * f\n       else:\n           capital += capital * profit * f\n\n   # Append the final capital value to the list\n   final_capital_values.append(capital)\n\n#Find the value of f that maximizes the final capital of each investor\noptimal_index = np.argmax(final_capital_values)\noptimal_f = f_values[optimal_index]\nmax_capital = final_capital_values[optimal_index]\n\n#Plot the final capital values as a function of position size, f\nplt.figure(figsize=(8,6))\nplt.plot(position_size, final_capital_values)\nplt.xlabel('Position size as a fraction of total capital')\nplt.ylabel('Final capital values')\nplt.title('Growth of total capital as a function of position size in ZYX')\n# Plot a vertical line at the optimal value of f\nplt.axvline(x=optimal_f, color='red', linestyle='--')\nplt.show()\n\n#Print the optimal value of f and the corresponding final capital\nprint(f\"The optimal fraction of total capital is {optimal_f:.2f}\")\nprint(f\"Initial capital of ${start_capital:.0f} grows to a \nfinal capital of ${max_capital:.0f}\")\n\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(101)\n\n# Weighted coin in your favor\np = 0.55\n\n# The Kelly position size (edge/odds) for odds 1:1\nf_star = p - (1 - p)\n\n# Number of series in Monte Carlo simulation\nn_series = 50\n\n# Number of trials per series\nn_trials = 500\n\ndef run_simulation(f):\n#Runs a Monte Carlo simulation of a betting strategy with \n#the given Kelly fraction.\n#Takes f, The Kelly fraction, as the argument and returns a NumPy array \n#of the terminal wealths of the simulation.\n\n    # Array for storing results\n    c = np.zeros((n_trials, n_series))\n\n    # Initial capital of $100\n    c[0] = 100\n\n    for i in range(n_series):\n        for t in range(1, n_trials):\n            # Use binomial random variable because we are tossing \n            # a weighted coin\n            outcome = np.random.binomial(1, p)\n\n            # If we win, we add the Kelly fraction to our accumulated capital\n            if outcome > 0:\n                c[t, i] = (1 + f) * c[t - 1, i]\n\n            # If we lose, we subtract the Kelly fraction from \n            # our accumulated capital\n            else:\n                c[t, i] = (1 - f) * c[t - 1, i]\n\n    return c\n\n# Run simulations for different position sizes\n# The Kelly position size is our optimal betting size\nc_kelly = run_simulation(f_star)\n\n# Half Kelly size reduces the volatility while keeping the gains\nc_half_kelly = run_simulation(f_star / 2)\n\n# Anything more than twice Kelly leads to ruin in the long run\nc_3_kelly = run_simulation(f_star * 3)\n\n# Betting all your capital leads to ruin very quickly\nc_all_in = run_simulation(1)\n\n# Plot the expected value/arithmetic mean of terminal wealth \n# over all the iterations of 500 trials each\nfig, ax = plt.subplots(figsize=(10, 6))\n\n# Overlay multiple plots with different line styles and markers\nax.plot(c_kelly.mean(axis=1), 'b-', lw=2, label='Kelly')\nax.plot(c_half_kelly.mean(axis=1), 'g--', lw=2, label='Half Kelly')\nax.plot(c_3_kelly.mean(axis=1), 'm:', lw=2, label='Three Kelly')\nax.plot(c_all_in.mean(axis=1), 'r-.', lw=2, label='All In')\n\nax.legend(loc=0)\nax.set_title('Expected Wealth of Bettor With Different Position Sizes')\nax.set_ylabel('Terminal wealth')\nax.set_xlabel('Number of Bets')\n\nplt.show()\n```"]