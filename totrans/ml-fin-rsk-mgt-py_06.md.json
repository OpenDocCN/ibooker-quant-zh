["```py\nIn [1]: import numpy as np\n        from scipy.stats import norm\n        import scipy.optimize as opt\n        import yfinance as yf\n        import pandas as pd\n        import datetime\n        import time\n        from arch import arch_model\n        import matplotlib.pyplot as plt\n        from numba import jit\n        from sklearn.metrics import mean_squared_error as mse\n        import warnings\n        warnings.filterwarnings('ignore')\n\nIn [2]: stocks = '^GSPC'\n        start = datetime.datetime(2010, 1, 1)\n        end = datetime.datetime(2021, 8, 1)\n        s_p500 = yf.download(stocks, start=start, end = end, interval='1d')\n        [*********************100%***********************]  1 of 1 completed\n\nIn [3]: ret = 100 * (s_p500.pct_change()[1:]['Adj Close']) ![1](assets/1.png)\n        realized_vol = ret.rolling(5).std()\n\nIn [4]: plt.figure(figsize=(10, 6))\n        plt.plot(realized_vol.index,realized_vol)\n        plt.title('Realized Volatility- S&P-500')\n        plt.ylabel('Volatility')\n        plt.xlabel('Date')\n        plt.show()\n```", "```py\nIn [5]: retv = ret.values ![1](assets/1.png)\n\nIn [6]: plt.figure(figsize=(10, 6))\n        plt.plot(s_p500.index[1:], ret)\n        plt.title('Volatility clustering of S&P-500')\n        plt.ylabel('Daily returns')\n        plt.xlabel('Date')\n        plt.show()\n```", "```py\nIn [7]: n = 252\n        split_date = ret.iloc[-n:].index ![1](assets/1.png)\n\nIn [8]: sgm2 = ret.var() ![2](assets/2.png)\n        K = ret.kurtosis() ![3](assets/3.png)\n        alpha = (-3.0 * sgm2 + np.sqrt(9.0 * sgm2 ** 2 - 12.0 *\n                                     (3.0 * sgm2 - K) * K)) / (6 * K) ![4](assets/4.png)\n        omega = (1 - alpha) * sgm2 ![5](assets/5.png)\n        initial_parameters = [alpha, omega]\n        omega, alpha\nOut[8]: (0.6345749196895419, 0.46656704131150534)\n\nIn [9]: @jit(nopython=True, parallel=True) ![6](assets/6.png)\n        def arch_likelihood(initial_parameters, retv):\n            omega = abs(initial_parameters[0]) ![7](assets/7.png)\n            alpha = abs(initial_parameters[1]) ![7](assets/7.png)\n            T = len(retv)\n            logliks = 0\n            sigma2 = np.zeros(T)\n            sigma2[0] = np.var(retv) ![8](assets/8.png)\n            for t in range(1, T):\n                sigma2[t] = omega + alpha * (retv[t - 1]) ** 2 ![9](assets/9.png)\n            logliks = np.sum(0.5 * (np.log(sigma2)+retv ** 2 / sigma2)) ![10](assets/10.png)\n            return logliks\n\nIn [10]: logliks = arch_likelihood(initial_parameters, retv)\n         logliks\nOut[10]: 1453.127184488521\n\nIn [11]: def opt_params(x0, retv):\n             opt_result = opt.minimize(arch_likelihood, x0=x0, args = (retv),\n                                       method='Nelder-Mead',\n                                       options={'maxiter': 5000}) ![11](assets/11.png)\n             params = opt_result.x ![12](assets/12.png)\n             print('\\nResults of Nelder-Mead minimization\\n{}\\n{}'\n                   .format(''.join(['-'] * 28), opt_result))\n             print('\\nResulting params = {}'.format(params))\n             return params\n\nIn [12]: params = opt_params(initial_parameters, retv)\n\n         Results of Nelder-Mead minimization\n         ----------------------------\n          final_simplex: (array([[0.70168795, 0.39039044],\n                [0.70163494, 0.3904423 ],\n         [0.70163928, 0.39033154]]), array([1385.79241695,\n                1385.792417, 1385.79241907]))\n                    fun: 1385.7924169507244\n                message: 'Optimization terminated successfully.'\n                   nfev: 62\n                    nit: 33\n                 status: 0\n                success: True\n                      x: array([0.70168795, 0.39039044])\n\n         Resulting params = [0.70168795 0.39039044]\n\nIn [13]: def arch_apply(ret):\n                 omega = params[0]\n                 alpha = params[1]\n                 T = len(ret)\n                 sigma2_arch = np.zeros(T + 1)\n                 sigma2_arch[0] = np.var(ret)\n                 for t in range(1, T):\n                     sigma2_arch[t] = omega + alpha * ret[t - 1] ** 2\n                 return sigma2_arch\n\nIn [14]: sigma2_arch = arch_apply(ret)\n```", "```py\nIn [15]: arch = arch_model(ret, mean='zero', vol='ARCH', p=1).fit(disp='off')\n         print(arch.summary())\n\n                 Zero Mean - ARCH Model Results                        \\\n=============================================================================\nDep. Variable:            Adj Close   R-squared:                       0.000\nMean Model:               Zero Mean   Adj. R-squared:                  0.000\nVol Model:                     ARCH   Log-Likelihood:               -4063.63\nDistribution:                Normal   AIC:                           8131.25\nMethod:          Maximum Likelihood   BIC:                           8143.21\nNo. Observations:              2914\n\nDate:                Mon, Sep 13 2021   Df Residuals:                   2914\nTime:                        21:56:56   Df Model:                        0\n\n                        Volatility Model\n========================================================================\n                coef    std err          t      P>|t|  95.0% Conf. Int.\n------------------------------------------------------------------------\nomega          0.7018  5.006e-02     14.018  1.214e-44 [  0.604,  0.800]\nalpha[1]       0.3910  7.016e-02      5.573  2.506e-08 [  0.253,  0.529]\n========================================================================\n\nCovariance estimator: robust\n```", "```py\nIn [16]: bic_arch = []\n\n         for p in range(1, 5): ![1](assets/1.png)\n                 arch = arch_model(ret, mean='zero', vol='ARCH', p=p)\\\n                         .fit(disp='off') ![2](assets/2.png)\n                 bic_arch.append(arch.bic)\n                 if arch.bic == np.min(bic_arch): ![3](assets/3.png)\n                     best_param = p\n         arch = arch_model(ret, mean='zero', vol='ARCH', p=best_param)\\\n                 .fit(disp='off') ![4](assets/4.png)\n         print(arch.summary())\n         forecast = arch.forecast(start=split_date[0]) ![5](assets/5.png)\n         forecast_arch = forecast\n\n         Zero Mean - ARCH Model Results\n==============================================================================\nDep. Variable:              Adj Close   R-squared:                       0.000\nMean Model:                 Zero Mean   Adj. R-squared:                  0.000\nVol Model:                       ARCH   Log-Likelihood:               -3712.38\nDistribution:                  Normal   AIC:                           7434.75\nMethod:            Maximum Likelihood   BIC:                           7464.64\nNo. Observations:                2914\n\nDate:                Mon, Sep 13 2021   Df Residuals:                     2914\nTime:                        21:56:58   Df Model:                          0\n\n         Volatility Model\n\n==========================================================================\n\n                 coef    std err          t      P>|t|    95.0% Conf. Int.\n--------------------------------------------------------------------------\nomega          0.2798  2.584e-02     10.826  2.580e-27   [  0.229,  0.330]\nalpha[1]       0.1519  3.460e-02      4.390  1.136e-05 [8.406e-02,  0.220]\nalpha[2]       0.2329  3.620e-02      6.433  1.249e-10   [  0.162,  0.304]\nalpha[3]       0.1917  3.707e-02      5.170  2.337e-07   [  0.119,  0.264]\nalpha[4]       0.1922  4.158e-02      4.623  3.780e-06   [  0.111,  0.274]\n==========================================================================\n\n         Covariance estimator: robust\n\nIn [17]: rmse_arch = np.sqrt(mse(realized_vol[-n:] / 100,\n                                 np.sqrt(forecast_arch\\\n                                 .variance.iloc[-len(split_date):]\n                                 / 100))) ![6](assets/6.png)\n         print('The RMSE value of ARCH model is {:.4f}'.format(rmse_arch))\n         The RMSE value of ARCH model is 0.0896\n\nIn [18]: plt.figure(figsize=(10, 6))\n         plt.plot(realized_vol / 100, label='Realized Volatility')\n         plt.plot(forecast_arch.variance.iloc[-len(split_date):] / 100,\n                  label='Volatility Prediction-ARCH')\n         plt.title('Volatility Prediction with ARCH', fontsize=12)\n         plt.legend()\n         plt.show()\n```", "```py\nIn [19]: a0 = 0.0001\n         sgm2 = ret.var()\n         K = ret.kurtosis()\n         h = 1 - alpha / sgm2\n         alpha = np.sqrt(K * (1 - h ** 2) / (2.0 * (K + 3)))\n         beta = np.abs(h - omega)\n         omega = (1 - omega) * sgm2\n         initial_parameters = np.array([omega, alpha, beta])\n         print('Initial parameters for omega, alpha, and beta are \\n{}\\n{}\\n{}'\n               .format(omega, alpha, beta))\n         Initial parameters for omega, alpha, and beta  are\n         0.43471178001576827\n         0.512827280537482\n         0.02677799855546381\n\nIn [20]: retv = ret.values\n\nIn [21]: @jit(nopython=True, parallel=True)\n         def garch_likelihood(initial_parameters, retv):\n             omega = initial_parameters[0]\n             alpha = initial_parameters[1]\n             beta = initial_parameters[2]\n             T =  len(retv)\n             logliks = 0\n             sigma2 = np.zeros(T)\n             sigma2[0] = np.var(retv)\n             for t in range(1, T):\n                 sigma2[t] = omega + alpha * (retv[t - 1]) ** 2 +\n                             beta * sigma2[t-1]\n             logliks = np.sum(0.5 * (np.log(sigma2) + retv ** 2 / sigma2))\n             return logliks\n\nIn [22]: logliks = garch_likelihood(initial_parameters, retv)\n         print('The Log likelihood  is {:.4f}'.format(logliks))\n         The Log likelihood  is 1387.7215\n\nIn [23]: def garch_constraint(initial_parameters):\n             alpha = initial_parameters[0]\n             gamma = initial_parameters[1]\n             beta = initial_parameters[2]\n             return np.array([1 - alpha - beta])\n\nIn [24]: bounds = [(0.0, 1.0), (0.0, 1.0), (0.0, 1.0)]\n\nIn [25]: def opt_paramsG(initial_parameters, retv):\n             opt_result = opt.minimize(garch_likelihood,\n                                       x0=initial_parameters,\n                                       constraints=np.array([1 - alpha - beta]),\n                                       bounds=bounds, args = (retv),\n                                       method='Nelder-Mead',\n                                       options={'maxiter': 5000})\n             params = opt_result.x\n             print('\\nResults of Nelder-Mead minimization\\n{}\\n{}'\\\n                   .format('-' * 35, opt_result))\n             print('-' * 35)\n             print('\\nResulting parameters = {}'.format(params))\n             return params\n\nIn [26]: params = opt_paramsG(initial_parameters, retv)\n\n         Results of Nelder-Mead minimization\n         -----------------------------------\n          final_simplex: (array([[0.03918956, 0.17370549, 0.78991502],\n                [0.03920507, 0.17374466, 0.78987403],\n                [0.03916671, 0.17377319, 0.78993078],\n         [0.03917324, 0.17364595, 0.78998753]]), array([979.87109624, 979.8710967 ,\n          979.87109865, 979.8711147 ]))\n                    fun: 979.8710962352685\n                message: 'Optimization terminated successfully.'\n                   nfev: 178\n                    nit: 102\n                 status: 0\n                success: True\n                      x: array([0.03918956, 0.17370549, 0.78991502])\n         -----------------------------------\n\n         Resulting parameters = [0.03918956 0.17370549 0.78991502]\n\nIn [27]: def garch_apply(ret):\n                 omega = params[0]\n                 alpha = params[1]\n                 beta = params[2]\n                 T = len(ret)\n                 sigma2 = np.zeros(T + 1)\n                 sigma2[0] = np.var(ret)\n                 for t in range(1, T):\n                     sigma2[t] = omega + alpha * ret[t - 1] ** 2 +\n                                 beta * sigma2[t-1]\n                 return sigma2\n```", "```py\nIn [28]: garch = arch_model(ret, mean='zero', vol='GARCH', p=1, o=0, q=1)\\\n                 .fit(disp='off')\n         print(garch.summary())\n\n         Zero Mean - GARCH Model Results\n==============================================================================\nDep. Variable:              Adj Close   R-squared:                       0.000\nMean Model:                 Zero Mean   Adj. R-squared:                  0.000\nVol Model:                      GARCH   Log-Likelihood:               -3657.62\nDistribution:                  Normal   AIC:                           7321.23\nMethod:            Maximum Likelihood   BIC:                           7339.16\nNo. Observations:                 2914\n\nDate:                Mon, Sep 13 2021   Df Residuals:                     2914\nTime:                        21:57:08   Df Model:                          0\nVolatility Model\n\n============================================================================\ncoef    std err          t      P>|t|      95.0% Conf. Int.\n\n----------------------------------------------------------------------------\nomega          0.0392  8.422e-03      4.652  3.280e-06 [2.268e-02,5.569e-02]\nalpha[1]       0.1738  2.275e-02      7.637  2.225e-14     [  0.129,  0.218]\nbeta[1]        0.7899  2.275e-02     34.715 4.607e-264     [  0.745,  0.835]\n============================================================================\n\n         Covariance estimator: robust\n```", "```py\nIn [29]: bic_garch = []\n\n         for p in range(1, 5):\n             for q in range(1, 5):\n                 garch = arch_model(ret, mean='zero',vol='GARCH', p=p, o=0, q=q)\\\n                         .fit(disp='off')\n                 bic_garch.append(garch.bic)\n                 if garch.bic == np.min(bic_garch):\n                     best_param = p, q\n         garch = arch_model(ret, mean='zero', vol='GARCH',\n                            p=best_param[0], o=0, q=best_param[1])\\\n                 .fit(disp='off')\n         print(garch.summary())\n         forecast = garch.forecast(start=split_date[0])\n         forecast_garch = forecast\n\n         Zero Mean - GARCH Model Results\n==============================================================================\nDep. Variable:              Adj Close   R-squared:                       0.000\nMean Model:                 Zero Mean   Adj. R-squared:                  0.000\nVol Model:                      GARCH   Log-Likelihood:               -3657.62\nDistribution:                  Normal   AIC:                           7321.23\nMethod:            Maximum Likelihood   BIC:                           7339.16\nNo. Observations:                 2914\n\nDate:                Mon, Sep 13 2021   Df Residuals:                     2914\nTime:                        21:57:10   Df Model:                          0\nVolatility Model\n\n============================================================================\n                  coef    std err          t      P>|t|      95.0% Conf. Int.\n----------------------------------------------------------------------------\nomega          0.0392  8.422e-03      4.652  3.280e-06 [2.268e-02, 5.569e-02]\nalpha[1]       0.1738  2.275e-02      7.637  2.225e-14       [  0.129, 0.218]\nbeta[1]        0.7899  2.275e-02     34.715 4.607e-264       [  0.745, 0.835]\n============================================================================\n\n         Covariance estimator: robust\n\nIn [30]: rmse_garch = np.sqrt(mse(realized_vol[-n:] / 100,\n                                  np.sqrt(forecast_garch\\\n                                  .variance.iloc[-len(split_date):]\n                                  / 100)))\n         print('The RMSE value of GARCH model is {:.4f}'.format(rmse_garch))\n         The RMSE value of GARCH model is 0.0878\n\nIn [31]: plt.figure(figsize=(10,6))\n         plt.plot(realized_vol / 100, label='Realized Volatility')\n         plt.plot(forecast_garch.variance.iloc[-len(split_date):] / 100,\n                  label='Volatility Prediction-GARCH')\n         plt.title('Volatility Prediction with GARCH', fontsize=12)\n         plt.legend()\n         plt.show()\n```", "```py\nIn [32]: bic_gjr_garch = []\n\n         for p in range(1, 5):\n             for q in range(1, 5):\n                 gjrgarch = arch_model(ret, mean='zero', p=p, o=1, q=q)\\\n                            .fit(disp='off')\n                 bic_gjr_garch.append(gjrgarch.bic)\n                 if gjrgarch.bic == np.min(bic_gjr_garch):\n                     best_param = p, q\n         gjrgarch = arch_model(ret,mean='zero', p=best_param[0], o=1,\n                               q=best_param[1]).fit(disp='off')\n         print(gjrgarch.summary())\n         forecast = gjrgarch.forecast(start=split_date[0])\n         forecast_gjrgarch = forecast\n\n         Zero Mean - GJR-GARCH Model Results\n==============================================================================\nDep. Variable:              Adj Close   R-squared:                      0.000\nMean Model:                 Zero Mean   Adj. R-squared:                 0.000\nVol Model:                  GJR-GARCH   Log-Likelihood:              -3593.36\nDistribution:                  Normal   AIC:                          7194.73\nMethod:            Maximum Likelihood   BIC:                          7218.64\nNo. Observations:                 2914\n\nDate:                Mon, Sep 13 2021   Df Residuals:                    2914\nTime:                        21:57:14   Df Model:                         0\nVolatility Model\n\n=============================================================================\n                 coef    std err          t      P>|t|       95.0% Conf. Int.\n-----------------------------------------------------------------------------\nomega          0.0431  7.770e-03      5.542  2.983e-08  [2.784e-02,5.829e-02]\nalpha[1]       0.0386  3.060e-02      1.261      0.207 [-2.139e-02,9.855e-02]\ngamma[1]       0.2806  4.818e-02      5.824  5.740e-09       [  0.186, 0.375]\nbeta[1]        0.7907  2.702e-02     29.263 3.029e-188       [  0.738, 0.844]\n=============================================================================\n\n         Covariance estimator: robust\n\nIn [33]: rmse_gjr_garch = np.sqrt(mse(realized_vol[-n:] / 100,\n                                      np.sqrt(forecast_gjrgarch\\\n                                      .variance.iloc[-len(split_date):]\n                                      / 100)))\n         print('The RMSE value of GJR-GARCH models is {:.4f}'\n               .format(rmse_gjr_garch))\n         The RMSE value of GJR-GARCH models is 0.0882\n\nIn [34]: plt.figure(figsize=(10, 6))\n         plt.plot(realized_vol / 100, label='Realized Volatility')\n         plt.plot(forecast_gjrgarch.variance.iloc[-len(split_date):] / 100,\n                  label='Volatility Prediction-GJR-GARCH')\n         plt.title('Volatility Prediction with GJR-GARCH', fontsize=12)\n         plt.legend()\n         plt.show()\n```", "```py\nIn [35]: bic_egarch = []\n\n         for p in range(1, 5):\n             for q in range(1, 5):\n                 egarch = arch_model(ret, mean='zero', vol='EGARCH', p=p, q=q)\\\n                          .fit(disp='off')\n                 bic_egarch.append(egarch.bic)\n                 if egarch.bic == np.min(bic_egarch):\n                     best_param = p, q\n         egarch = arch_model(ret, mean='zero', vol='EGARCH',\n                             p=best_param[0], q=best_param[1])\\\n                  .fit(disp='off')\n         print(egarch.summary())\n         forecast = egarch.forecast(start=split_date[0])\n         forecast_egarch = forecast\n\n         Zero Mean - EGARCH Model Results\n==============================================================================\nDep. Variable:              Adj Close   R-squared:                      0.000\nMean Model:                 Zero Mean   Adj. R-squared:                 0.000\nVol Model:                     EGARCH   Log-Likelihood:              -3676.18\nDistribution:                  Normal   AIC:                          7358.37\nMethod:            Maximum Likelihood   BIC:                          7376.30\nNo. Observations:                 2914\n\nDate:                Mon, Sep 13 2021   Df Residuals:                    2914\nTime:                        21:57:19   Df Model:                         0\nVolatility Model\n\n=============================================================================\n                 coef    std err          t      P>|t|       95.0% Conf. Int.\n-----------------------------------------------------------------------------\nomega      2.3596e-03  6.747e-03      0.350      0.727  [-1.086e-02,1.558e-02]\nalpha[1]       0.3266  3.427e-02      9.530  1.567e-21        [  0.259, 0.394]\nbeta[1]        0.9456  1.153e-02     82.023      0.000        [  0.923, 0.968]\n=============================================================================\n\n         Covariance estimator: robust\n\nIn [36]: rmse_egarch = np.sqrt(mse(realized_vol[-n:] / 100,\n                                   np.sqrt(forecast_egarch.variance\\\n                                   .iloc[-len(split_date):] / 100)))\n         print('The RMSE value of EGARCH models is {:.4f}'.format(rmse_egarch))\n         The RMSE value of EGARCH models is 0.0904\n\nIn [37]: plt.figure(figsize=(10, 6))\n         plt.plot(realized_vol / 100, label='Realized Volatility')\n         plt.plot(forecast_egarch.variance.iloc[-len(split_date):] / 100,\n                  label='Volatility Prediction-EGARCH')\n         plt.title('Volatility Prediction with EGARCH', fontsize=12)\n         plt.legend()\n         plt.show()\n```", "```py\nIn [38]: from sklearn.svm import SVR\n         from scipy.stats import uniform as sp_rand\n         from sklearn.model_selection import RandomizedSearchCV\n\nIn [39]: realized_vol = ret.rolling(5).std() ![1](assets/1.png)\n         realized_vol = pd.DataFrame(realized_vol)\n         realized_vol.reset_index(drop=True, inplace=True)\n\nIn [40]: returns_svm = ret ** 2\n         returns_svm = returns_svm.reset_index()\n         del returns_svm['Date']\n\nIn [41]: X = pd.concat([realized_vol, returns_svm], axis=1, ignore_index=True)\n         X = X[4:].copy()\n         X = X.reset_index()\n         X.drop('index', axis=1, inplace=True)\n\nIn [42]: realized_vol = realized_vol.dropna().reset_index()\n         realized_vol.drop('index', axis=1, inplace=True)\n\nIn [43]: svr_poly = SVR(kernel='poly', degree=2) ![2](assets/2.png)\n         svr_lin = SVR(kernel='linear') ![2](assets/2.png)\n         svr_rbf = SVR(kernel='rbf') ![2](assets/2.png)\n```", "```py\nIn [44]: para_grid = {'gamma': sp_rand(),\n                      'C': sp_rand(),\n                      'epsilon': sp_rand()} ![1](assets/1.png)\n         clf = RandomizedSearchCV(svr_lin, para_grid) ![2](assets/2.png)\n         clf.fit(X.iloc[:-n].values,\n                 realized_vol.iloc[1:-(n-1)].values.reshape(-1,)) ![3](assets/3.png)\n         predict_svr_lin = clf.predict(X.iloc[-n:]) ![4](assets/4.png)\n\nIn [45]: predict_svr_lin = pd.DataFrame(predict_svr_lin)\n         predict_svr_lin.index = ret.iloc[-n:].index\n\nIn [46]: rmse_svr = np.sqrt(mse(realized_vol.iloc[-n:] / 100,\n                                predict_svr_lin / 100))\n         print('The RMSE value of SVR with Linear Kernel is {:.6f}'\n               .format(rmse_svr))\n         The RMSE value of SVR with Linear Kernel is 0.000462\n\nIn [47]: realized_vol.index = ret.iloc[4:].index\n\nIn [48]: plt.figure(figsize=(10, 6))\n         plt.plot(realized_vol / 100, label='Realized Volatility')\n         plt.plot(predict_svr_lin / 100, label='Volatility Prediction-SVR-GARCH')\n         plt.title('Volatility Prediction with SVR-GARCH (Linear)', fontsize=12)\n         plt.legend()\n         plt.show()\n```", "```py\nIn [49]: para_grid ={'gamma': sp_rand(),\n                     'C': sp_rand(),\n                     'epsilon': sp_rand()}\n         clf = RandomizedSearchCV(svr_rbf, para_grid)\n         clf.fit(X.iloc[:-n].values,\n                 realized_vol.iloc[1:-(n-1)].values.reshape(-1,))\n         predict_svr_rbf = clf.predict(X.iloc[-n:])\n\nIn [50]: predict_svr_rbf = pd.DataFrame(predict_svr_rbf)\n         predict_svr_rbf.index = ret.iloc[-n:].index\n\nIn [51]: rmse_svr_rbf = np.sqrt(mse(realized_vol.iloc[-n:] / 100,\n                                    predict_svr_rbf / 100))\n         print('The RMSE value of SVR with RBF Kernel is  {:.6f}'\n               .format(rmse_svr_rbf))\n         The RMSE value of SVR with RBF Kernel is  0.000970\n\nIn [52]: plt.figure(figsize=(10, 6))\n         plt.plot(realized_vol / 100, label='Realized Volatility')\n         plt.plot(predict_svr_rbf / 100, label='Volatility Prediction-SVR_GARCH')\n         plt.title('Volatility Prediction with SVR-GARCH (RBF)', fontsize=12)\n         plt.legend()\n         plt.show()\n```", "```py\nIn [53]: para_grid = {'gamma': sp_rand(),\n                     'C': sp_rand(),\n                     'epsilon': sp_rand()}\n         clf = RandomizedSearchCV(svr_poly, para_grid)\n         clf.fit(X.iloc[:-n].values,\n                 realized_vol.iloc[1:-(n-1)].values.reshape(-1,))\n         predict_svr_poly = clf.predict(X.iloc[-n:])\n\nIn [54]: predict_svr_poly = pd.DataFrame(predict_svr_poly)\n         predict_svr_poly.index = ret.iloc[-n:].index\n\nIn [55]: rmse_svr_poly = np.sqrt(mse(realized_vol.iloc[-n:] / 100,\n                                     predict_svr_poly / 100))\n         print('The RMSE value of SVR with Polynomial Kernel is {:.6f}'\\\n               .format(rmse_svr_poly))\n         The RMSE value of SVR with Polynomial Kernel is 0.002386\n\nIn [56]: plt.figure(figsize=(10, 6))\n         plt.plot(realized_vol/100, label='Realized Volatility')\n         plt.plot(predict_svr_poly/100, label='Volatility Prediction-SVR-GARCH')\n         plt.title('Volatility Prediction with SVR-GARCH (Polynomial)',\n                   fontsize=12)\n         plt.legend()\n         plt.show()\n```", "```py\nIn [57]: from sklearn.neural_network import MLPRegressor ![1](assets/1.png)\n         NN_vol = MLPRegressor(learning_rate_init=0.001, random_state=1)\n         para_grid_NN = {'hidden_layer_sizes': [(100, 50), (50, 50), (10, 100)],\n                        'max_iter': [500, 1000],\n                        'alpha': [0.00005, 0.0005 ]} ![2](assets/2.png)\n         clf = RandomizedSearchCV(NN_vol, para_grid_NN)\n         clf.fit(X.iloc[:-n].values,\n                 realized_vol.iloc[1:-(n-1)].values.reshape(-1, )) ![3](assets/3.png)\n         NN_predictions = clf.predict(X.iloc[-n:]) ![4](assets/4.png)\n\nIn [58]: NN_predictions = pd.DataFrame(NN_predictions)\n         NN_predictions.index = ret.iloc[-n:].index\n\nIn [59]: rmse_NN = np.sqrt(mse(realized_vol.iloc[-n:] / 100,\n                               NN_predictions / 100))\n         print('The RMSE value of NN is {:.6f}'.format(rmse_NN))\n         The RMSE value of NN is 0.000583\n\nIn [60]: plt.figure(figsize=(10, 6))\n         plt.plot(realized_vol / 100, label='Realized Volatility')\n         plt.plot(NN_predictions / 100, label='Volatility Prediction-NN')\n         plt.title('Volatility Prediction with Neural Network', fontsize=12)\n         plt.legend()\n         plt.show()\n```", "```py\nIn [61]: import tensorflow as tf\n         from tensorflow import keras\n         from tensorflow.keras import layers\n\nIn [62]: model = keras.Sequential(\n             [layers.Dense(256, activation=\"relu\"),\n              layers.Dense(128, activation=\"relu\"),\n              layers.Dense(1, activation=\"linear\"),]) ![1](assets/1.png)\n\nIn [63]: model.compile(loss='mse', optimizer='rmsprop') ![2](assets/2.png)\n\nIn [64]: epochs_trial = np.arange(100, 400, 4) ![3](assets/3.png)\n         batch_trial = np.arange(100, 400, 4) ![3](assets/3.png)\n         DL_pred = []\n         DL_RMSE = []\n         for i, j, k in zip(range(4), epochs_trial, batch_trial):\n             model.fit(X.iloc[:-n].values,\n                       realized_vol.iloc[1:-(n-1)].values.reshape(-1,),\n                       batch_size=k, epochs=j, verbose=False) ![4](assets/4.png)\n             DL_predict = model.predict(np.asarray(X.iloc[-n:])) ![5](assets/5.png)\n             DL_RMSE.append(np.sqrt(mse(realized_vol.iloc[-n:] / 100,\n                                     DL_predict.flatten() / 100))) ![6](assets/6.png)\n             DL_pred.append(DL_predict)\n             print('DL_RMSE_{}:{:.6f}'.format(i+1, DL_RMSE[i]))\n         DL_RMSE_1:0.000551\n         DL_RMSE_2:0.000714\n         DL_RMSE_3:0.000627\n         DL_RMSE_4:0.000739\n\nIn [65]: DL_predict = pd.DataFrame(DL_pred[DL_RMSE.index(min(DL_RMSE))])\n         DL_predict.index = ret.iloc[-n:].index\n\nIn [66]: plt.figure(figsize=(10, 6))\n         plt.plot(realized_vol / 100,label='Realized Volatility')\n         plt.plot(DL_predict / 100,label='Volatility Prediction-DL')\n         plt.title('Volatility Prediction with Deep Learning',  fontsize=12)\n         plt.legend()\n         plt.show()\n```", "```py\nIn [67]: import quantecon as qe\n         from quantecon import MarkovChain\n         import networkx as nx\n         from pprint import pprint\n\nIn [68]: P = [[0.5, 0.2, 0.3],\n              [0.2, 0.3, 0.5],\n              [0.2, 0.2, 0.6]]\n\n         mc = qe.MarkovChain(P, ('studying', 'travelling', 'sleeping'))\n         mc.is_irreducible\nOut[68]: True\n\nIn [69]: states = ['studying', 'travelling', 'sleeping']\n         initial_probs = [0.5, 0.3, 0.6]\n         state_space = pd.Series(initial_probs, index=states, name='states')\n\nIn [70]: q_df = pd.DataFrame(columns=states, index=states)\n         q_df = pd.DataFrame(columns=states, index=states)\n         q_df.loc[states[0]] = [0.5, 0.2, 0.3]\n         q_df.loc[states[1]] = [0.2, 0.3, 0.5]\n         q_df.loc[states[2]] = [0.2, 0.2, 0.6]\n\nIn [71]: def _get_markov_edges(Q):\n             edges = {}\n             for col in Q.columns:\n                 for idx in Q.index:\n                     edges[(idx,col)] = Q.loc[idx,col]\n             return edges\n         edges_wts = _get_markov_edges(q_df)\n         pprint(edges_wts)\n         {('sleeping', 'sleeping'): 0.6,\n          ('sleeping', 'studying'): 0.2,\n          ('sleeping', 'travelling'): 0.2,\n          ('studying', 'sleeping'): 0.3,\n          ('studying', 'studying'): 0.5,\n          ('studying', 'travelling'): 0.2,\n          ('travelling', 'sleeping'): 0.5,\n          ('travelling', 'studying'): 0.2,\n          ('travelling', 'travelling'): 0.3}\n\nIn [72]: G = nx.MultiDiGraph()\n         G.add_nodes_from(states)\n         for k, v in edges_wts.items():\n             tmp_origin, tmp_destination = k[0], k[1]\n             G.add_edge(tmp_origin, tmp_destination, weight=v, label=v)\n\n         pos = nx.drawing.nx_pydot.graphviz_layout(G, prog='dot')\n         nx.draw_networkx(G, pos)\n         edge_labels = {(n1, n2):d['label'] for n1, n2, d in G.edges(data=True)}\n         nx.draw_networkx_edge_labels(G , pos, edge_labels=edge_labels)\n         nx.drawing.nx_pydot.write_dot(G, 'mc_states.dot')\n```", "```py\nIn [73]: import pyflux as pf\n         from scipy.stats import kurtosis\n\nIn [74]: model = pf.GARCH(ret.values, p=1, q=1) ![1](assets/1.png)\n         print(model.latent_variables) ![2](assets/2.png)\n         model.adjust_prior(1, pf.Normal()) ![3](assets/3.png)\n         model.adjust_prior(2, pf.Normal()) ![3](assets/3.png)\n         x = model.fit(method='M-H', iterations='1000') ![4](assets/4.png)\n         print(x.summary())\n\n         Index    Latent Variable           Prior           Prior Hyperparameters\n            V.I. Dist  Transform\n         ======== ========================= ===============\n          ========================= ========== ==========\n         0        Vol Constant              Normal          mu0: 0, sigma0: 3\n            Normal     exp\n         1        q(1)                      Normal          mu0: 0, sigma0: 0.5\n            Normal     logit\n         2        p(1)                      Normal          mu0: 0, sigma0: 0.5\n            Normal     logit\n         3        Returns Constant          Normal          mu0: 0, sigma0: 3\n            Normal     None\n         Acceptance rate of Metropolis-Hastings is 0.0023\n         Acceptance rate of Metropolis-Hastings is 0.23925\n\n         Tuning complete! Now sampling.\n         Acceptance rate of Metropolis-Hastings is 0.239175\n         GARCH(1,1)\n\n         =======================================================\n          ==================================================\n         Dependent Variable: Series                          Method: Metropolis\n          Hastings\n         Start Date: 1                                       Unnormalized Log\n          Posterior: -3635.1348\n         End Date: 2913                                      AIC:\n          7278.269645045323\n         Number of observations: 2913                        BIC:\n          7302.177400073161\n         ======================================================================\n          ====================================\n         Latent Variable                          Median             Mean\n              95% Credibility Interval\n         ======================================== ==================\n          ================== =========================\n         Vol Constant                             0.04               0.0398\n              (0.0315 | 0.0501)\n         q(1)                                     0.1936             0.194\n              (0.1638 | 0.2251)\n         p(1)                                     0.7736             0.7737\n              (0.7438 | 0.8026)\n         Returns Constant                         0.0866             0.0855\n              (0.0646 | 0.1038)\n         ======================================================================\n          ====================================\n         None\n\nIn [75]: model.plot_z([1, 2]) ![5](assets/5.png)\n         model.plot_fit(figsize=(15, 5)) ![6](assets/6.png)\n         model.plot_ppc(T=kurtosis, nsims=1000) ![7](assets/7.png)\n```", "```py\nIn [76]: bayesian_prediction = model.predict_is(n, fit_method='M-H') ![1](assets/1.png)\n         Acceptance rate of Metropolis-Hastings is 0.11515\n         Acceptance rate of Metropolis-Hastings is 0.1787\n         Acceptance rate of Metropolis-Hastings is 0.2675\n\n         Tuning complete! Now sampling.\n         Acceptance rate of Metropolis-Hastings is 0.2579\n\nIn [77]: bayesian_RMSE = np.sqrt(mse(realized_vol.iloc[-n:] / 100,\n                                  bayesian_prediction.values / 100)) ![2](assets/2.png)\n         print('The RMSE of Bayesian model is {:.6f}'.format(bayesian_RMSE))\n         The RMSE of Bayesian model is 0.004047\n\nIn [78]: bayesian_prediction.index = ret.iloc[-n:].index\n```", "```py\nIn [79]: plt.figure(figsize=(10, 6))\n         plt.plot(realized_vol / 100,\n                  label='Realized Volatility')\n         plt.plot(bayesian_prediction['Series'] / 100,\n                  label='Volatility Prediction-Bayesian')\n         plt.title('Volatility Prediction with M-H Approach', fontsize=12)\n         plt.legend()\n         plt.show()\n```"]