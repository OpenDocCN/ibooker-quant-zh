["```py\nIn [1]: import numpy as np\n        import pandas as pd\n        from pylab import plt, mpl\n        plt.style.use('seaborn')\n        mpl.rcParams['savefig.dpi'] = 300\n        mpl.rcParams['font.family'] = 'serif'\n        pd.set_option('precision', 4)\n        np.set_printoptions(suppress=True, precision=4)\n\nIn [2]: url = 'http://hilpisch.com/aiif_eikon_eod_data.csv'  ![1](Images/1.png)\n\nIn [3]: data = pd.read_csv(url, index_col=0, parse_dates=True).dropna()  ![1](Images/1.png)\n\nIn [4]: (data / data.iloc[0]).plot(figsize=(10, 6), cmap='coolwarm');  ![2](Images/2.png)\n```", "```py\nIn [5]: lags = 7  ![1](Images/1.png)\n\nIn [6]: def add_lags(data, ric, lags):\n            cols = []\n            df = pd.DataFrame(data[ric])\n            for lag in range(1, lags + 1):\n                col = 'lag_{}'.format(lag)  ![2](Images/2.png)\n                df[col] = df[ric].shift(lag)  ![3](Images/3.png)\n                cols.append(col)  ![4](Images/4.png)\n            df.dropna(inplace=True)  ![5](Images/5.png)\n            return df, cols\n\nIn [7]: dfs = {}\n        for sym in data.columns:\n            df, cols = add_lags(data, sym, lags)  ![6](Images/6.png)\n            dfs[sym] = df  ![7](Images/7.png)\n\nIn [8]: dfs[sym].head(7)  ![8](Images/8.png)\nOut[8]:                GLD   lag_1   lag_2   lag_3   lag_4   lag_5   lag_6   lag_7\n        Date\n        2010-01-13  111.54  110.49  112.85  111.37  110.82  111.51  109.70  109.80\n        2010-01-14  112.03  111.54  110.49  112.85  111.37  110.82  111.51  109.70\n        2010-01-15  110.86  112.03  111.54  110.49  112.85  111.37  110.82  111.51\n        2010-01-19  111.52  110.86  112.03  111.54  110.49  112.85  111.37  110.82\n        2010-01-20  108.94  111.52  110.86  112.03  111.54  110.49  112.85  111.37\n        2010-01-21  107.37  108.94  111.52  110.86  112.03  111.54  110.49  112.85\n        2010-01-22  107.17  107.37  108.94  111.52  110.86  112.03  111.54  110.49\n```", "```py\nIn [9]: regs = {}\n        for sym in data.columns:\n            df = dfs[sym]  ![1](Images/1.png)\n            reg = np.linalg.lstsq(df[cols], df[sym], rcond=-1)[0]  ![2](Images/2.png)\n            regs[sym] = reg  ![3](Images/3.png)\n\nIn [10]: rega = np.stack(tuple(regs.values()))  ![4](Images/4.png)\n\nIn [11]: regd = pd.DataFrame(rega, columns=cols, index=data.columns)  ![5](Images/5.png)\n\nIn [12]: regd  ![5](Images/5.png)\nOut[12]:          lag_1   lag_2   lag_3   lag_4   lag_5   lag_6   lag_7\n         AAPL.O  1.0106 -0.0592  0.0258  0.0535 -0.0172  0.0060 -0.0184\n         MSFT.O  0.8928  0.0112  0.1175 -0.0832 -0.0258  0.0567  0.0323\n         INTC.O  0.9519  0.0579  0.0490 -0.0772 -0.0373  0.0449  0.0112\n         AMZN.O  0.9799 -0.0134  0.0206  0.0007  0.0525 -0.0452  0.0056\n         GS.N    0.9806  0.0342 -0.0172  0.0042 -0.0387  0.0585 -0.0215\n         SPY     0.9692  0.0067  0.0228 -0.0244 -0.0237  0.0379  0.0121\n         .SPX    0.9672  0.0106  0.0219 -0.0252 -0.0318  0.0515  0.0063\n         .VIX    0.8823  0.0591 -0.0289  0.0284 -0.0256  0.0511  0.0306\n         EUR=    0.9859  0.0239 -0.0484  0.0508 -0.0217  0.0149 -0.0055\n         XAU=    0.9864  0.0069  0.0166 -0.0215  0.0044  0.0198 -0.0125\n         GDX     0.9765  0.0096 -0.0039  0.0223 -0.0364  0.0379 -0.0065\n         GLD     0.9766  0.0246  0.0060 -0.0142 -0.0047  0.0223 -0.0106\n\nIn [13]: regd.mean().plot(kind='bar', figsize=(10, 6));  ![6](Images/6.png)\n```", "```py\nIn [14]: dfs[sym].corr()  ![1](Images/1.png)\nOut[14]:           GLD   lag_1   lag_2   lag_3   lag_4   lag_5   lag_6   lag_7\n         GLD    1.0000  0.9972  0.9946  0.9920  0.9893  0.9867  0.9841  0.9815\n         lag_1  0.9972  1.0000  0.9972  0.9946  0.9920  0.9893  0.9867  0.9842\n         lag_2  0.9946  0.9972  1.0000  0.9972  0.9946  0.9920  0.9893  0.9867\n         lag_3  0.9920  0.9946  0.9972  1.0000  0.9972  0.9946  0.9920  0.9893\n         lag_4  0.9893  0.9920  0.9946  0.9972  1.0000  0.9972  0.9946  0.9920\n         lag_5  0.9867  0.9893  0.9920  0.9946  0.9972  1.0000  0.9972  0.9946\n         lag_6  0.9841  0.9867  0.9893  0.9920  0.9946  0.9972  1.0000  0.9972\n         lag_7  0.9815  0.9842  0.9867  0.9893  0.9920  0.9946  0.9972  1.0000\n\nIn [15]: from statsmodels.tsa.stattools import adfuller  ![2](Images/2.png)\n\nIn [16]: adfuller(data[sym].dropna())  ![2](Images/2.png)\nOut[16]: (-1.9488969577009954,\n          0.3094193074034718,\n          0,\n          2515,\n          {'1%': -3.4329527780962255,\n           '5%': -2.8626898965523724,\n           '10%': -2.567382133955709},\n          8446.683102944744)\n```", "```py\nIn [17]: rets = np.log(data / data.shift(1))  ![1](Images/1.png)\n\nIn [18]: rets.dropna(inplace=True)\n\nIn [19]: dfs = {}\n         for sym in data:\n             df, cols = add_lags(rets, sym, lags)  ![2](Images/2.png)\n             mu, std = df[cols].mean(), df[cols].std()  ![3](Images/3.png)\n             df[cols] = (df[cols] - mu) / std  ![3](Images/3.png)\n             dfs[sym] = df\n\nIn [20]: dfs[sym].head()  ![4](Images/4.png)\nOut[20]:                GLD   lag_1   lag_2   lag_3   lag_4   lag_5   lag_6   lag_7\n         Date\n         2010-01-14  0.0044  0.9570 -2.1692  1.3386  0.4959 -0.6434  1.6613 -0.1028\n         2010-01-15 -0.0105  0.4379  0.9571 -2.1689  1.3388  0.4966 -0.6436  1.6614\n         2010-01-19  0.0059 -1.0842  0.4385  0.9562 -2.1690  1.3395  0.4958 -0.6435\n         2010-01-20 -0.0234  0.5967 -1.0823  0.4378  0.9564 -2.1686  1.3383  0.4958\n         2010-01-21 -0.0145 -2.4045  0.5971 -1.0825  0.4379  0.9571 -2.1680  1.3384\n\nIn [21]: adfuller(dfs[sym]['lag_1'])  ![5](Images/5.png)\nOut[21]: (-51.568251505825536,\n          0.0,\n          0,\n          2507,\n          {'1%': -3.4329610922579095,\n           '5%': -2.8626935681060375,\n           '10%': -2.567384088736619},\n          7017.165474260225)\n\nIn [22]: dfs[sym].corr()  ![6](Images/6.png)\nOut[22]:           GLD   lag_1   lag_2       lag_3   lag_4       lag_5   lag_6   lag_7\n         GLD    1.0000 -0.0297  0.0003  1.2635e-02 -0.0026 -5.9392e-03  0.0099 -0.0013\n         lag_1 -0.0297  1.0000 -0.0305  8.1418e-04  0.0128 -2.8765e-03 -0.0053  0.0098\n         lag_2  0.0003 -0.0305  1.0000 -3.1617e-02  0.0003  1.3234e-02 -0.0043 -0.0052\n         lag_3  0.0126  0.0008 -0.0316  1.0000e+00 -0.0313 -6.8542e-06  0.0141 -0.0044\n         lag_4 -0.0026  0.0128  0.0003 -3.1329e-02  1.0000 -3.1761e-02  0.0002  0.0141\n         lag_5 -0.0059 -0.0029  0.0132 -6.8542e-06 -0.0318  1.0000e+00 -0.0323  0.0002\n         lag_6  0.0099 -0.0053 -0.0043  1.4115e-02  0.0002 -3.2289e-02  1.0000 -0.0324\n         lag_7 -0.0013  0.0098 -0.0052 -4.3869e-03  0.0141  2.1707e-04 -0.0324  1.0000\n```", "```py\nIn [23]: from sklearn.metrics import accuracy_score\n\nIn [24]: %%time\n         for sym in data:\n             df = dfs[sym]\n             reg = np.linalg.lstsq(df[cols], df[sym], rcond=-1)[0]  ![1](Images/1.png)\n             pred = np.dot(df[cols], reg)  ![2](Images/2.png)\n             acc = accuracy_score(np.sign(df[sym]), np.sign(pred))  ![3](Images/3.png)\n             print(f'OLS | {sym:10s} | acc={acc:.4f}')\n         OLS | AAPL.O     | acc=0.5056\n         OLS | MSFT.O     | acc=0.5088\n         OLS | INTC.O     | acc=0.5040\n         OLS | AMZN.O     | acc=0.5048\n         OLS | GS.N       | acc=0.5080\n         OLS | SPY        | acc=0.5080\n         OLS | .SPX       | acc=0.5167\n         OLS | .VIX       | acc=0.5291\n         OLS | EUR=       | acc=0.4984\n         OLS | XAU=       | acc=0.5207\n         OLS | GDX        | acc=0.5307\n         OLS | GLD        | acc=0.5072\n         CPU times: user 201 ms, sys: 65.8 ms, total: 267 ms\n         Wall time: 60.8 ms\n```", "```py\nIn [25]: from sklearn.neural_network import MLPRegressor\n\nIn [26]: %%time\n         for sym in data.columns:\n             df = dfs[sym]\n             model = MLPRegressor(hidden_layer_sizes=[512],\n                                  random_state=100,\n                                  max_iter=1000,\n                                  early_stopping=True,\n                                  validation_fraction=0.15,\n                                  shuffle=False)  ![1](Images/1.png)\n             model.fit(df[cols], df[sym])  ![2](Images/2.png)\n             pred = model.predict(df[cols])  ![3](Images/3.png)\n             acc = accuracy_score(np.sign(df[sym]), np.sign(pred))  ![4](Images/4.png)\n             print(f'MLP | {sym:10s} | acc={acc:.4f}')\n         MLP | AAPL.O     | acc=0.6005\n         MLP | MSFT.O     | acc=0.5853\n         MLP | INTC.O     | acc=0.5766\n         MLP | AMZN.O     | acc=0.5510\n         MLP | GS.N       | acc=0.6527\n         MLP | SPY        | acc=0.5419\n         MLP | .SPX       | acc=0.5399\n         MLP | .VIX       | acc=0.6579\n         MLP | EUR=       | acc=0.5642\n         MLP | XAU=       | acc=0.5522\n         MLP | GDX        | acc=0.6029\n         MLP | GLD        | acc=0.5259\n         CPU times: user 1min 37s, sys: 6.74 s, total: 1min 44s\n         Wall time: 14 s\n```", "```py\nIn [27]: import tensorflow as tf\n         from keras.layers import Dense\n         from keras.models import Sequential\n         Using TensorFlow backend.\n\nIn [28]: np.random.seed(100)\n         tf.random.set_seed(100)\n\nIn [29]: def create_model(problem='regression'):  ![1](Images/1.png)\n             model = Sequential()\n             model.add(Dense(512, input_dim=len(cols),\n                             activation='relu'))\n             if problem == 'regression':\n                 model.add(Dense(1, activation='linear'))\n                 model.compile(loss='mse', optimizer='adam')\n             else:\n                 model.add(Dense(1, activation='sigmoid'))\n                 model.compile(loss='binary_crossentropy', optimizer='adam')\n             return model\n\nIn [30]: %%time\n         for sym in data.columns[:]:\n             df = dfs[sym]\n             model = create_model()  ![2](Images/2.png)\n             model.fit(df[cols], df[sym], epochs=25, verbose=False)  ![3](Images/3.png)\n             pred = model.predict(df[cols])  ![4](Images/4.png)\n             acc = accuracy_score(np.sign(df[sym]), np.sign(pred))  ![5](Images/5.png)\n             print(f'DNN | {sym:10s} | acc={acc:.4f}')\n         DNN | AAPL.O     | acc=0.6292\n         DNN | MSFT.O     | acc=0.5981\n         DNN | INTC.O     | acc=0.6073\n         DNN | AMZN.O     | acc=0.5781\n         DNN | GS.N       | acc=0.6196\n         DNN | SPY        | acc=0.5829\n         DNN | .SPX       | acc=0.6077\n         DNN | .VIX       | acc=0.6392\n         DNN | EUR=       | acc=0.5845\n         DNN | XAU=       | acc=0.5881\n         DNN | GDX        | acc=0.5829\n         DNN | GLD        | acc=0.5666\n         CPU times: user 34.3 s, sys: 5.34 s, total: 39.6 s\n         Wall time: 23.1 s\n```", "```py\nIn [31]: split = int(len(dfs[sym]) * 0.8)\n\nIn [32]: %%time\n         for sym in data.columns:\n             df = dfs[sym]\n             train = df.iloc[:split]  ![1](Images/1.png)\n             reg = np.linalg.lstsq(train[cols], train[sym], rcond=-1)[0]\n             test = df.iloc[split:]  ![2](Images/2.png)\n             pred = np.dot(test[cols], reg)\n             acc = accuracy_score(np.sign(test[sym]), np.sign(pred))\n             print(f'OLS | {sym:10s} | acc={acc:.4f}')\n         OLS | AAPL.O     | acc=0.5219\n         OLS | MSFT.O     | acc=0.4960\n         OLS | INTC.O     | acc=0.5418\n         OLS | AMZN.O     | acc=0.4841\n         OLS | GS.N       | acc=0.4980\n         OLS | SPY        | acc=0.5020\n         OLS | .SPX       | acc=0.5120\n         OLS | .VIX       | acc=0.5458\n         OLS | EUR=       | acc=0.4482\n         OLS | XAU=       | acc=0.5299\n         OLS | GDX        | acc=0.5159\n         OLS | GLD        | acc=0.5100\n         CPU times: user 200 ms, sys: 60.6 ms, total: 261 ms\n         Wall time: 61.7 ms\n```", "```py\nIn [34]: %%time\n         for sym in data.columns:\n             df = dfs[sym]\n             train = df.iloc[:split]\n             model = MLPRegressor(hidden_layer_sizes=[512],\n                                  random_state=100,\n                                  max_iter=1000,\n                                  early_stopping=True,\n                                  validation_fraction=0.15,\n                                  shuffle=False)\n             model.fit(train[cols], train[sym])\n             test = df.iloc[split:]\n             pred = model.predict(test[cols])\n             acc = accuracy_score(np.sign(test[sym]), np.sign(pred))\n             print(f'MLP | {sym:10s} | acc={acc:.4f}')\n         MLP | AAPL.O     | acc=0.4920\n         MLP | MSFT.O     | acc=0.5279\n         MLP | INTC.O     | acc=0.5279\n         MLP | AMZN.O     | acc=0.4641\n         MLP | GS.N       | acc=0.5040\n         MLP | SPY        | acc=0.5259\n         MLP | .SPX       | acc=0.5478\n         MLP | .VIX       | acc=0.5279\n         MLP | EUR=       | acc=0.4980\n         MLP | XAU=       | acc=0.5239\n         MLP | GDX        | acc=0.4880\n         MLP | GLD        | acc=0.5000\n         CPU times: user 1min 39s, sys: 4.98 s, total: 1min 44s\n         Wall time: 13.7 s\n```", "```py\nIn [35]: %%time\n         for sym in data.columns:\n             df = dfs[sym]\n             train = df.iloc[:split]\n             model = create_model()\n             model.fit(train[cols], train[sym], epochs=50, verbose=False)\n             test = df.iloc[split:]\n             pred = model.predict(test[cols])\n             acc = accuracy_score(np.sign(test[sym]), np.sign(pred))\n             print(f'DNN | {sym:10s} | acc={acc:.4f}')\n         DNN | AAPL.O     | acc=0.5179\n         DNN | MSFT.O     | acc=0.5598\n         DNN | INTC.O     | acc=0.4821\n         DNN | AMZN.O     | acc=0.4920\n         DNN | GS.N       | acc=0.5179\n         DNN | SPY        | acc=0.4861\n         DNN | .SPX       | acc=0.5100\n         DNN | .VIX       | acc=0.5378\n         DNN | EUR=       | acc=0.4661\n         DNN | XAU=       | acc=0.4602\n         DNN | GDX        | acc=0.4841\n         DNN | GLD        | acc=0.5378\n         CPU times: user 50.4 s, sys: 7.52 s, total: 57.9 s\n         Wall time: 32.9 s\n```", "```py\nIn [36]: url = 'http://hilpisch.com/aiif_eikon_eod_data.csv'\n\nIn [37]: data = pd.read_csv(url, index_col=0, parse_dates=True).dropna()\n\nIn [38]: def add_lags(data, ric, lags, window=50):\n             cols = []\n             df = pd.DataFrame(data[ric])\n             df.dropna(inplace=True)\n             df['r'] = np.log(df / df.shift())\n             df['sma'] = df[ric].rolling(window).mean()  ![1](Images/1.png)\n             df['min'] = df[ric].rolling(window).min()  ![2](Images/2.png)\n             df['max'] = df[ric].rolling(window).max()  ![3](Images/3.png)\n             df['mom'] = df['r'].rolling(window).mean()  ![4](Images/4.png)\n             df['vol'] = df['r'].rolling(window).std()  ![5](Images/5.png)\n             df.dropna(inplace=True)\n             df['d'] = np.where(df['r'] > 0, 1, 0)  ![6](Images/6.png)\n             features = [ric, 'r', 'd', 'sma', 'min', 'max', 'mom', 'vol']\n             for f in features:\n                 for lag in range(1, lags + 1):\n                     col = f'{f}_lag_{lag}'\n                     df[col] = df[f].shift(lag)\n                     cols.append(col)\n             df.dropna(inplace=True)\n             return df, cols\n\nIn [39]: lags = 5\n\nIn [40]: dfs = {}\n         for ric in data:\n             df, cols = add_lags(data, ric, lags)\n             dfs[ric] = df.dropna(), cols\n```", "```py\nIn [41]: from sklearn.neural_network import MLPClassifier\n\nIn [42]: %%time\n         for ric in data:\n             model = MLPClassifier(hidden_layer_sizes=[512],\n                                   random_state=100,\n                                   max_iter=1000,\n                                   early_stopping=True,\n                                   validation_fraction=0.15,\n                                   shuffle=False)\n             df, cols = dfs[ric]\n             df[cols] = (df[cols] - df[cols].mean()) / df[cols].std()  ![1](Images/1.png)\n             model.fit(df[cols], df['d'])\n             pred = model.predict(df[cols])\n             acc = accuracy_score(df['d'], pred)\n             print(f'IN-SAMPLE | {ric:7s} | acc={acc:.4f}')\n         IN-SAMPLE | AAPL.O  | acc=0.5510\n         IN-SAMPLE | MSFT.O  | acc=0.5376\n         IN-SAMPLE | INTC.O  | acc=0.5607\n         IN-SAMPLE | AMZN.O  | acc=0.5559\n         IN-SAMPLE | GS.N    | acc=0.5794\n         IN-SAMPLE | SPY     | acc=0.5729\n         IN-SAMPLE | .SPX    | acc=0.5941\n         IN-SAMPLE | .VIX    | acc=0.6940\n         IN-SAMPLE | EUR=    | acc=0.5766\n         IN-SAMPLE | XAU=    | acc=0.5672\n         IN-SAMPLE | GDX     | acc=0.5847\n         IN-SAMPLE | GLD     | acc=0.5567\n         CPU times: user 1min 1s, sys: 4.5 s, total: 1min 6s\n         Wall time: 9.05 s\n\nIn [43]: %%time\n         for ric in data:\n             model = create_model('classification')\n             df, cols = dfs[ric]\n             df[cols] = (df[cols] - df[cols].mean()) / df[cols].std()  ![1](Images/1.png)\n             model.fit(df[cols], df['d'], epochs=50, verbose=False)\n             pred = np.where(model.predict(df[cols]) > 0.5, 1, 0)\n             acc = accuracy_score(df['d'], pred)\n             print(f'IN-SAMPLE | {ric:7s} | acc={acc:.4f}')\n         IN-SAMPLE | AAPL.O  | acc=0.7156\n         IN-SAMPLE | MSFT.O  | acc=0.7156\n         IN-SAMPLE | INTC.O  | acc=0.7046\n         IN-SAMPLE | AMZN.O  | acc=0.6640\n         IN-SAMPLE | GS.N    | acc=0.6855\n         IN-SAMPLE | SPY     | acc=0.6696\n         IN-SAMPLE | .SPX    | acc=0.6579\n         IN-SAMPLE | .VIX    | acc=0.7489\n         IN-SAMPLE | EUR=    | acc=0.6737\n         IN-SAMPLE | XAU=    | acc=0.7143\n         IN-SAMPLE | GDX     | acc=0.6826\n         IN-SAMPLE | GLD     | acc=0.7078\n         CPU times: user 1min 5s, sys: 7.06 s, total: 1min 12s\n         Wall time: 44.3 s\n```", "```py\nIn [44]: def train_test_model(model):\n             for ric in data:\n                 df, cols = dfs[ric]\n                 split = int(len(df) * 0.85)\n                 train = df.iloc[:split].copy()\n                 mu, std = train[cols].mean(), train[cols].std()  ![1](Images/1.png)\n                 train[cols] = (train[cols] - mu) / std\n                 model.fit(train[cols], train['d'])\n                 test = df.iloc[split:].copy()\n                 test[cols] = (test[cols] - mu) / std\n                 pred = model.predict(test[cols])\n                 acc = accuracy_score(test['d'], pred)\n                 print(f'OUT-OF-SAMPLE | {ric:7s} | acc={acc:.4f}')\n\nIn [45]: model_mlp = MLPClassifier(hidden_layer_sizes=[512],\n                                   random_state=100,\n                                   max_iter=1000,\n                                   early_stopping=True,\n                                   validation_fraction=0.15,\n                                   shuffle=False)\n\nIn [46]: %time train_test_model(model_mlp)\n         OUT-OF-SAMPLE | AAPL.O  | acc=0.4432\n         OUT-OF-SAMPLE | MSFT.O  | acc=0.4595\n         OUT-OF-SAMPLE | INTC.O  | acc=0.5000\n         OUT-OF-SAMPLE | AMZN.O  | acc=0.5270\n         OUT-OF-SAMPLE | GS.N    | acc=0.4838\n         OUT-OF-SAMPLE | SPY     | acc=0.4811\n         OUT-OF-SAMPLE | .SPX    | acc=0.5027\n         OUT-OF-SAMPLE | .VIX    | acc=0.5676\n         OUT-OF-SAMPLE | EUR=    | acc=0.4649\n         OUT-OF-SAMPLE | XAU=    | acc=0.5514\n         OUT-OF-SAMPLE | GDX     | acc=0.5162\n         OUT-OF-SAMPLE | GLD     | acc=0.4946\n         CPU times: user 44.9 s, sys: 2.64 s, total: 47.5 s\n         Wall time: 6.37 s\n```", "```py\nIn [47]: from sklearn.ensemble import BaggingClassifier\n\nIn [48]: base_estimator = MLPClassifier(hidden_layer_sizes=[256],\n                                   random_state=100,\n                                   max_iter=1000,\n                                   early_stopping=True,\n                                   validation_fraction=0.15,\n                                   shuffle=False)  ![1](Images/1.png)\n\nIn [49]: model_bag = BaggingClassifier(base_estimator=base_estimator,  ![1](Images/1.png)\n                                   n_estimators=35,  ![2](Images/2.png)\n                                   max_samples=0.25,  ![3](Images/3.png)\n                                   max_features=0.5,  ![4](Images/4.png)\n                                   bootstrap=False,  ![5](Images/5.png)\n                                   bootstrap_features=True,  ![6](Images/6.png)\n                                   n_jobs=8,  ![7](Images/7.png)\n                                   random_state=100\n                                  )\n\nIn [50]: %time train_test_model(model_bag)\n         OUT-OF-SAMPLE | AAPL.O  | acc=0.5243\n         OUT-OF-SAMPLE | MSFT.O  | acc=0.5703\n         OUT-OF-SAMPLE | INTC.O  | acc=0.5027\n         OUT-OF-SAMPLE | AMZN.O  | acc=0.5270\n         OUT-OF-SAMPLE | GS.N    | acc=0.5243\n         OUT-OF-SAMPLE | SPY     | acc=0.5595\n         OUT-OF-SAMPLE | .SPX    | acc=0.5514\n         OUT-OF-SAMPLE | .VIX    | acc=0.5649\n         OUT-OF-SAMPLE | EUR=    | acc=0.5108\n         OUT-OF-SAMPLE | XAU=    | acc=0.5378\n         OUT-OF-SAMPLE | GDX     | acc=0.5162\n         OUT-OF-SAMPLE | GLD     | acc=0.5432\n         CPU times: user 2.55 s, sys: 494 ms, total: 3.05 s\n         Wall time: 11.1 s\n```", "```py\nIn [51]: url = 'http://hilpisch.com/aiif_eikon_id_data.csv'\n\nIn [52]: data = pd.read_csv(url, index_col=0, parse_dates=True)\n\nIn [53]: data.info()\n         <class 'pandas.core.frame.DataFrame'>\n         DatetimeIndex: 5529 entries, 2019-03-01 00:00:00 to 2020-01-01 00:00:00\n         Data columns (total 12 columns):\n          #   Column  Non-Null Count  Dtype\n         ---  ------  --------------  -----\n          0   AAPL.O  3384 non-null   float64\n          1   MSFT.O  3378 non-null   float64\n          2   INTC.O  3275 non-null   float64\n          3   AMZN.O  3381 non-null   float64\n          4   GS.N    1686 non-null   float64\n          5   SPY     3388 non-null   float64\n          6   .SPX    1802 non-null   float64\n          7   .VIX    2959 non-null   float64\n          8   EUR=    5429 non-null   float64\n          9   XAU=    5149 non-null   float64\n          10  GDX     3173 non-null   float64\n          11  GLD     3351 non-null   float64\n         dtypes: float64(12)\n         memory usage: 561.5 KB\n\nIn [54]: lags = 5\n\nIn [55]: dfs = {}\n         for ric in data:\n             df, cols = add_lags(data, ric, lags)\n             dfs[ric] = df, cols\n```", "```py\nIn [56]: %time train_test_model(model_mlp)\n         OUT-OF-SAMPLE | AAPL.O  | acc=0.5420\n         OUT-OF-SAMPLE | MSFT.O  | acc=0.4930\n         OUT-OF-SAMPLE | INTC.O  | acc=0.5549\n         OUT-OF-SAMPLE | AMZN.O  | acc=0.4709\n         OUT-OF-SAMPLE | GS.N    | acc=0.5184\n         OUT-OF-SAMPLE | SPY     | acc=0.4860\n         OUT-OF-SAMPLE | .SPX    | acc=0.5019\n         OUT-OF-SAMPLE | .VIX    | acc=0.4885\n         OUT-OF-SAMPLE | EUR=    | acc=0.5130\n         OUT-OF-SAMPLE | XAU=    | acc=0.4824\n         OUT-OF-SAMPLE | GDX     | acc=0.4765\n         OUT-OF-SAMPLE | GLD     | acc=0.5455\n         CPU times: user 1min 4s, sys: 5.05 s, total: 1min 9s\n         Wall time: 9.56 s\n\nIn [57]: %time train_test_model(model_bag)\n         OUT-OF-SAMPLE | AAPL.O  | acc=0.5660\n         OUT-OF-SAMPLE | MSFT.O  | acc=0.5431\n         OUT-OF-SAMPLE | INTC.O  | acc=0.5072\n         OUT-OF-SAMPLE | AMZN.O  | acc=0.5110\n         OUT-OF-SAMPLE | GS.N    | acc=0.5020\n         OUT-OF-SAMPLE | SPY     | acc=0.5120\n         OUT-OF-SAMPLE | .SPX    | acc=0.4677\n         OUT-OF-SAMPLE | .VIX    | acc=0.5092\n         OUT-OF-SAMPLE | EUR=    | acc=0.5242\n         OUT-OF-SAMPLE | XAU=    | acc=0.5255\n         OUT-OF-SAMPLE | GDX     | acc=0.5085\n         OUT-OF-SAMPLE | GLD     | acc=0.5374\n         CPU times: user 2.64 s, sys: 439 ms, total: 3.08 s\n         Wall time: 12.4 s\n```"]