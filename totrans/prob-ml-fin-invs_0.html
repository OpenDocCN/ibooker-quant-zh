<html><head></head><body><section data-pdf-bookmark="Preface" data-type="preface" epub:type="preface"><div class="preface" id="preface">&#13;
<h1>Preface</h1>&#13;
<p>Generative AI, and Chat GPT-4 in particular,<a contenteditable="false" data-primary="generative AI" data-secondary="about probabilistic ML" data-type="indexterm" id="id237"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="about" data-type="indexterm" id="id238"/><a contenteditable="false" data-primary="ChatGPT as deep neural network" data-type="indexterm" id="id239"/><a contenteditable="false" data-primary="deep neural networks" data-secondary="probabilistic ML models versus" data-type="indexterm" id="id240"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="about" data-tertiary="deep neural networks versus" data-type="indexterm" id="id241"/><a contenteditable="false" data-primary="ChatGPT as deep neural network" data-secondary="probabilistic ML versus" data-type="indexterm" id="id242"/><a contenteditable="false" data-primary="decision making" data-secondary="probabilistic versus nonprobabilistic" data-type="indexterm" id="id243"/><a contenteditable="false" data-primary="AI" data-secondary="generative AI" data-tertiary="about probabilistic ML" data-type="indexterm" id="id244"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="about" data-tertiary="generative AI" data-type="indexterm" id="id245"/> is all the rage these days. Probabilistic machine learning (ML) is a type of generative AI that is ideally suited for finance and investing. Unlike deep neural networks, on which ChatGPT is based, probabilistic ML models are not black boxes. These models also enable you to infer causes from effects in a fairly transparent manner. This is important in heavily regulated industries, such as finance and healthcare, where you have to explain the basis of your decisions to many stakeholders.</p>&#13;
<p>Probabilistic ML also enables you to explicitly and systematically encode personal, empirical, and institutional knowledge into ML models to sustain your organization’s competitive advantages. What truly distinguishes probabilistic ML from its conventional counterparts is its capability of seamlessly simulating new data and counterfactual knowledge conditioned on the observed data and model assumptions on which it was trained and tested, regardless of the size of the dataset or the ordering of the data. Probabilistic models are generative models that know their limitations and honestly express their ignorance by widening the ranges of their inferences and predictions. <a contenteditable="false" data-primary="nonprobabilistic ML models described" data-type="indexterm" id="id246"/>You won’t get such quantified doubts from ChatGPT’s confident hallucinations, more commonly known as fibs and lies.</p>&#13;
<p>All ML models are built on<a contenteditable="false" data-primary="machine learning (ML) models" data-secondary="description of" data-type="indexterm" id="id247"/><a contenteditable="false" data-primary="machine learning (ML) models" data-secondary="probabilistic" data-see="probabilistic financial models; probabilistic machine learning" data-type="indexterm" id="id248"/> the assumption that patterns discovered in training or in-sample data will persist in testing or out-of-sample data. However, when nonprobabilistic ML models encounter patterns in data that they have never been trained or tested on, they make egregious inferences and predictions because of the inherent foundational flaws of their statistical models. Furthermore, these ML models do it with complete confidence and without warning decision makers of their <span class="keep-together">uncertainties.</span></p>&#13;
<p>The increasing adoption of nonprobabilistic ML models for decision making in finance and investments can lead to catastrophic consequences for individuals and society at large, including bankruptcies and economic recessions. It is imperative that all ML models quantify the uncertainty of their inferences and predictions on unseen data to support sound decision making in a complex world with three-dimensional uncertainties. Leading companies clearly understand the limitations of standard AI technologies and are developing their probabilistic versions to extend their applicability to more complex problems. Google recently introduced TensorFlow Probability to extend its established TensorFlow platform. Similarly, Facebook and Uber have introduced Pyro to extend their PyTorch platforms. Currently, the most popular open source probabilistic ML technologies are PyMC and Stan. PyMC is written in Python, and Stan is written in C++. This book uses the extensive ecosystem of user-friendly Python libraries.</p>&#13;
<section data-pdf-bookmark="Who Should Read This Book?" data-type="sect1"><div class="sect1" id="who_should_read_this_bookquestion_mark">&#13;
<h1>Who Should Read This Book?</h1>&#13;
<p>The primary audience of this book is the thinking practitioner in the finance and investing discipline. A thinking practitioner is someone who doesn’t merely want to follow instructions from a manual or cookbook. They want to understand the underlying concepts for why they must adopt a process, model, or technology. Generally, they are intellectually curious and enjoy learning for its own sake. At the same time, they are not looking for onerous mathematical proofs or tedious academic tomes. I have provided many scholarly references in each chapter for readers who are looking for the mathematical and technical details underlying the concepts and reasoning presented in this book.</p>&#13;
<p>A thinking practitioner could be an individual investor, analyst, developer, manager, project manager, data scientist, researcher, portfolio manager, or quantitative trader. These thinking practitioners understand that they need to learn new concepts and technologies continually to advance their careers and businesses. A practical depth of understanding gives them the confidence to apply what they learn to develop creative solutions for their unique challenges. It also gives them a framework to explore and learn related technologies and concepts more easily.</p>&#13;
<p>In this book, I am assuming that readers have a basic familiarity with finance, statistics, machine learning, and Python. I am not assuming that they have read any particular book or mastered any particular skill. I am only assuming that they have a willingness to learn, especially when ChatGPT, Bard, and Bing AI can easily explain any code or formula in this book.</p>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Why I Wrote This Book" data-type="sect1"><div class="sect1" id="why_i_wrote_this_book">&#13;
<h1>Why I Wrote This Book</h1>&#13;
<p>There is a paucity of general probabilistic ML books, and none that is dedicated entirely to finance and investing problems. Because of the idiosyncratic complexities of these domains, any naive application of ML in general and probabilistic ML in particular is doomed to failure. A depth of understanding of the foundations of these domains is pivotal to having any chance of succeeding. This book is a primer that endeavors to give the thinking practitioner a solid grounding in the foundational concepts of probabilistic ML and how to apply it to finance and investing problems, using simple math and Python code.</p>&#13;
<p>There is another reason why I wrote this book. <a contenteditable="false" data-primary="financial theory" data-secondary="flaws of" data-type="indexterm" id="id249"/><a contenteditable="false" data-primary="statistical inference" data-secondary="flaws in conventional methodology" data-type="indexterm" id="id250"/><a contenteditable="false" data-primary="goal of financial modeling" data-secondary="flaws of modern financial theory" data-type="indexterm" id="id251"/><a contenteditable="false" data-primary="models" data-secondary="goal of financial modeling" data-tertiary="flaws of modern financial theory" data-type="indexterm" id="id252"/>To this day, books are still a medium for serious discourse. I wanted to remind the readers about the continued grave flaws of modern financial theory and conventional statistical inference methodology. It is outrageous that these pseudoscientific methods are still taught in academia and practiced in industry despite their deep flaws and pathetic performance. They continue to waste billions of research dollars producing junk studies, tarnish the reputation of the scientific enterprise, and contribute significantly to economic disasters and human misery.</p>&#13;
<p>We are at a crossroads in the evolution<a contenteditable="false" data-primary="AI" data-secondary="evolution crossroads of AI" data-type="indexterm" id="id253"/> of AI technologies, with most experts predicting exponential growth in its use, fundamentally transforming the way we live, work, and interact with one another. The danger that AI systems will take over humanity imminently is silly science fiction, because even the most advanced AI system lacks the common sense of a toddler. The real clear and present danger is that fools might end up developing and managing these powerful savants based on the spurious models of conventional finance and statistics. This will most likely lead to catastrophes faster and bigger than we have ever experienced before.</p>&#13;
<p>My criticisms are supported by simple math, common sense, data, and scholarly works that have been published over the past century. Perhaps one added value of this book is in retrieving many of those forgotten academic publications from the dusty archives of history and making readers aware of their insights in plain, unequivocal language using logic, simple math, or code that anyone with a high school degree can understand. Clearly, the conventional mode of expressing these criticisms hasn’t worked at all. The stakes for individuals, society, and the scientific enterprise are too high for us to care if plainly spoken mathematical and scientific truths might offend someone or tarnish a reputation built on authoring or supporting bogus theories.</p>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Navigating This Book" data-type="sect1"><div class="sect1" id="navigating_this_book">&#13;
<h1>Navigating This Book</h1>&#13;
<p>The contents of this book may be divided<a contenteditable="false" data-primary="financial theory" data-secondary="flaws of" data-tertiary="book layout" data-type="indexterm" id="id254"/><a contenteditable="false" data-primary="statistical inference" data-secondary="flaws in conventional methodology" data-tertiary="book layout" data-type="indexterm" id="id255"/> into two logical parts interwoven unevenly throughout each chapter. One part examines the appalling uselessness of the prevailing economics, statistical, and machine learning models for finance and investing domains. The other part examines why probabilistic machine learning is a less wrong, more useful model for these problem domains. The singular focus of this primer is on understanding the foundations of this complex, multidisciplinary field. Only pivotal concepts and applications are covered. Sometimes less is indeed more. The book is organized as follows, with each chapter having at least one of the main concepts in finance and investing applied in a hands-on Python code exercise:</p>&#13;
<ul>&#13;
<li><p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch01.html#the_need_for_probabilistic_machine_lear">Chapter 1, “The Need for Probabilistic <span class="keep-together">Machine Learning</span>”</a> examines some of the woeful inadequacies of theoretical finance, how all financial models are afflicted with a trifecta of errors, and why we need a systematic way of quantifying the uncertainty of our inferences and predictions. The chapter explains why probabilistic ML provides a useful framework for finance and investing.</p></li>&#13;
<li><p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch02.html#analyzing_and_quantifying_uncertainty">Chapter 2, “Analyzing and Quantifying Uncertainty”</a> uses the Monty Hall problem to review the basic rules of probability theory, examine the meanings of probability, and explore the trinity of uncertainties that pervade our world. The chapter also explores the problem of induction and its algorithmic restatement, the no free lunch (NFL) theorems, and how they underpin finance, investing, and probabilistic ML.</p></li>&#13;
<li><p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch03.html#quantifying_output_uncertainty_with_mon">Chapter 3, “Quantifying Output Uncertainty with Monte Carlo Simulation”</a> reviews important statistical concepts to explain why Monte Carlo simulation (MCS), one of the most important numerical techniques, works by generating approximate probabilistic solutions to analytically intractable problems.</p></li>&#13;
<li><p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch04.html#the_dangers_of_conventional_statistical">Chapter 4, “The Dangers of Conventional <span class="keep-together">Statistical Methodologies</span>”</a> exposes the skullduggery of conventional statistical inference methodologies commonly used in research and industry, and explains why they are the main cause of false research findings that plague the social and economic sciences.</p></li>&#13;
<li><p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch05.html#the_probabilistic_machine_learning_fram">Chapter 5, “The Probabilistic Machine Learning Framework”</a> explores the probabilistic machine framework and demonstrates how inference from data and simulation of new data are logically and seamlessly integrated in this type of generative model.</p></li>&#13;
<li><p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch06.html#the_dangers_of_conventional_ai_systems">Chapter 6, “The Dangers of Conventional AI Systems”</a> exposes the dangers of conventional AI systems, especially their lack of basic common sense and how they are unaware of their own limitations, which pose massive risks to all their stakeholders and society at large. Markov chain Monte Carlo simulations are introduced as a dependent sampling method for solving complex problems in finance and investing.</p></li>&#13;
<li><p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch07.html#probabilistic_machine_learning_with_gen">Chapter 7, “Probabilistic Machine Learning with Generative Ensembles”</a> explains how probabilistic machine learning is essentially a form of ensemble machine learning. It shows readers how to develop a prototype of a generative linear ensemble for regression problems in finance and investing using PyMC, Xarray, and ArviZ Python libraries.</p></li>&#13;
<li><p><a data-type="xref" data-xrefstyle="chap-num-title" href="ch08.html#making_probabilistic_decisions_with_gen">Chapter 8, “Making Probabilistic Decisions with Generative Ensembles”</a> shows how to apply generative ensembles to risk management and capital allocation decisions in finance and investing. The implications of ergodicity and the pitfalls of using ensemble averages for financial decision making are explored. The strengths and weaknesses of capital allocation algorithms, including the Kelly criterion, are examined.</p></li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Conventions Used in This Book" data-type="sect1"><div class="sect1" id="_conventions_used_in_this_book">&#13;
<h1>Conventions Used in This Book</h1>&#13;
<p>The following typographical conventions are used in this book:</p>&#13;
<dl>&#13;
<dt><em>Italic</em></dt>&#13;
<dd>&#13;
<p>Indicates new terms, URLs, email addresses, filenames, and file extensions.</p>&#13;
</dd>&#13;
<dt><code>Constant width</code></dt>&#13;
<dd>&#13;
<p>Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements, and keywords.</p>&#13;
</dd>&#13;
<dt><strong><code>Constant width bold</code></strong></dt>&#13;
<dd>&#13;
<p>Shows commands or other text that should be typed literally by the user.</p>&#13;
</dd>&#13;
<dt><em><code>Constant width italic</code></em></dt>&#13;
<dd>&#13;
<p>Shows text that should be replaced with user-supplied values or by values determined by context.</p>&#13;
</dd>&#13;
</dl>&#13;
<div data-type="tip"><h6>Tip</h6>&#13;
<p>This element signifies a tip or suggestion.</p>&#13;
</div>&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>This element signifies a general note.</p>&#13;
</div>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p>This element indicates a warning or caution.</p>&#13;
</div>&#13;
</div></section>&#13;
<section data-pdf-bookmark="Using Code Examples" data-type="sect1"><div class="sect1" id="_using_code_examples">&#13;
<h1>Using Code Examples</h1>&#13;
<!--PROD: Please reach out to author to find out if they will be uploading code examples to oreilly.com or their own site (e.g., GitHub). If there is no code download, delete this whole section. If there is, when you email digidist with the link, let them know what you filled in for title_title (should be as close to book title as possible, i.e., learning_python_2e). This info will determine where digidist loads the files.-->&#13;
<p>Supplemental material (code examples) is available for download at <a href="https://oreil.ly/supp-probabilistic-ML"><em class="hyperlink">https://oreil.ly/supp-probabilistic-ML</em></a>.</p>&#13;
<p>If you have a technical question or a problem using the code examples, please send email to <a class="email" href="mailto:support@oreilly.com"><em>support@oreilly.com</em></a>.</p>&#13;
  <p>This book is here to help you get your job done. In general, if example code is offered with this book, you may use it in your programs and documentation. You do not need to contact us for permission unless you’re reproducing a significant portion of the code. For example, writing a program that uses several chunks of code from this book does not require permission. Selling or distributing examples from O’Reilly books does require permission. Answering a question by citing this book and quoting example code does not require permission. Incorporating a significant amount of example code from this book into your product’s documentation does require permission.</p>&#13;
<p>We appreciate, but generally do not require, attribution. An attribution usually includes the title, author, publisher, and ISBN. For example: “<em>Probabilistic Machine Learning for Finance and Investing</em> by Deepak K. Kanungo (O’Reilly). Copyright 2023 Hedged Capital L.L.C., 978-1-492-09767-9.”</p>&#13;
<p>If you feel your use of code examples falls outside fair use or the permission given above, feel free to contact us at <a class="email" href="mailto:permissions@oreilly.com"><em>permissions@oreilly.com</em></a>.</p>&#13;
</div></section>&#13;
<section data-pdf-bookmark="O’Reilly Online Learning" data-type="sect1"><div class="sect1" id="_safari_books_online">&#13;
<h1>O’Reilly Online Learning</h1>&#13;
<div class="ormenabled" data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>For more than 40 years, <a class="orm:hideurl" href="https://oreilly.com"><em class="hyperlink">O’Reilly Media</em></a> has provided technology and business training, knowledge, and insight to help companies succeed.</p>&#13;
</div>&#13;
<p>Our unique network of experts and innovators share their knowledge and expertise through books, articles, and our online learning platform. O’Reilly’s online learning platform gives you on-demand access to live training courses, in-depth learning paths, interactive coding environments, and a vast collection of text and video from O’Reilly and 200+ other publishers. For more information, visit <a class="orm:hideurl" href="https://oreilly.com"><em>https://oreilly.com</em></a>.</p>&#13;
</div></section>&#13;
<section data-pdf-bookmark="How to Contact Us" data-type="sect1"><div class="sect1" id="_how_to_contact_us">&#13;
<h1>How to Contact Us</h1>&#13;
<p>Please address comments and questions concerning this book to the publisher:</p>&#13;
<ul class="simplelist">&#13;
  <li>O’Reilly Media, Inc.</li>&#13;
  <li>1005 Gravenstein Highway North</li>&#13;
  <li>Sebastopol, CA 95472</li>&#13;
  <li>800-889-8969 (in the United States or Canada)</li>&#13;
  <li>707-829-7019 (international or local)</li>&#13;
  <li>707-829-0104 (fax)</li>&#13;
  <li><a class="email" href="mailto:support@oreilly.com"><em>support@oreilly.com</em></a></li>&#13;
  <li><a href="https://www.oreilly.com/about/contact.html"><em>https://www.oreilly.com/about/contact.html</em></a></li>&#13;
</ul>&#13;
<p class="pagebreak-before">We have a web page<a contenteditable="false" data-primary="book web page" data-type="indexterm" id="id256"/><a contenteditable="false" data-primary="web page for book" data-type="indexterm" id="id257"/> for this book, where we list errata, examples, and any additional information. You can access this page at <a href="https://oreil.ly/Probabilistic_ML"><em class="hyperlink">https://oreil.ly/Probabilistic_ML</em></a>.</p>&#13;
<!--Don't forget to update the link above.-->&#13;
&#13;
<p>For news and information about our books and courses, visit <a href="https://oreilly.com"><em class="hyperlink">https://oreilly.com</em></a>.</p>&#13;
<p>Find us on LinkedIn: <a href="https://linkedin.com/company/oreilly-media"><em class="hyperlink">https://linkedin.com/company/oreilly-media</em></a></p>&#13;
<p>Follow us on Twitter: <a href="https://twitter.com/oreillymedia"><em class="hyperlink">https://twitter.com/oreillymedia</em></a></p>&#13;
<p>Watch us on YouTube: <a href="https://youtube.com/oreillymedia"><em class="hyperlink">https://youtube.com/oreillymedia</em></a></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Acknowledgments" data-type="sect1"><div class="sect1" id="acknowledgments">&#13;
<h1>Acknowledgments</h1>&#13;
<p>I would like to thank Michelle Smith, Jeff Bleiel, and the entire O’Reilly Media team for making this book possible. It was a pleasure working with everyone, especially Jeff, whose honest and insightful feedback helped me improve the contents of this book.</p>&#13;
<p>I would also like to thank the expert reviewers of my book, Abdullah Karasan, Juan Manuel Contreras, and Isaac Rhea, for their valuable comments.</p>&#13;
<p>Furthermore, I would like to thank the following readers of the early releases of the book for their equally valuable feedback: Ian Angell, Bruno Rignel, Jonathan Hugenschmidt, Autumn Peters, and Mike Shwe.</p>&#13;
</div></section>&#13;
</div></section></body></html>