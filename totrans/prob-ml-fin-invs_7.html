<html><head></head><body><section data-pdf-bookmark="Chapter 7. Probabilistic Machine Learning with Generative Ensembles" data-type="chapter" epub:type="chapter"><div class="chapter" id="probabilistic_machine_learning_with_gen">&#13;
<h1><span class="label">Chapter 7. </span>Probabilistic Machine Learning with Generative Ensembles</h1>&#13;
&#13;
<blockquote data-type="epigraph" epub:type="epigraph">&#13;
<p>Don’t look for the needle in the haystack. Just buy the haystack!</p>&#13;
&#13;
<p>— John Bogle, inventor of the index fund and founder of the Vanguard Group</p>&#13;
</blockquote>&#13;
&#13;
<p>Most of us probably didn’t know<a contenteditable="false" data-primary="ordinary least squares (OLS)" data-type="indexterm" id="id1197"/><a contenteditable="false" data-primary="Legendre, Adrien-Marie" data-type="indexterm" id="id1198"/><a contenteditable="false" data-primary="Gaus, Carl" data-type="indexterm" id="id1199"/> we were learning one of the most powerful and robust ML algorithms in high school when we were finding the line of best fit to a scatter of data points. The ordinary least squares (OLS) algorithm that is used to estimate the parameters of linear regression models was developed by Adrien-Marie Legendre and Carl Gauss more than two hundred years ago. These types of models have the longest history and are viewed as the baseline machine learning models in general. Linear regression and classification models are considered to be the most basic artificial neural networks. It is for these reasons that linear models are considered to be the “mother of all parametric models.”</p>&#13;
&#13;
<p>Linear regression models play a pivotal <a contenteditable="false" data-primary="linear regression" data-secondary="capital asset pricing model as" data-type="indexterm" id="id1200"/><a contenteditable="false" data-primary="linear regression" data-secondary="pivotal role in modern finance" data-type="indexterm" id="id1201"/><a contenteditable="false" data-primary="financial theory" data-secondary="linear regression’s pivotal role" data-type="indexterm" id="id1202"/><a contenteditable="false" data-primary="arbitrage pricing model (APT)" data-type="indexterm" id="id1203"/><a contenteditable="false" data-primary="linear regression" data-secondary="pivotal role in modern finance" data-tertiary="arbitrage pricing model" data-type="indexterm" id="id1204"/><a contenteditable="false" data-primary="linear regression" data-secondary="pivotal role in modern finance" data-tertiary="capital asset pricing model" data-type="indexterm" id="id1205"/><a contenteditable="false" data-primary="linear regression" data-secondary="pivotal role in modern finance" data-tertiary="factor models" data-type="indexterm" id="id1206"/>role in modern financial practice, academia, and research. The two foundational models of financial theory are linear regression models: the capital asset pricing model (CAPM) is a simple linear regression model; and the model of arbitrage pricing theory (APT) is a multiple regression model. Factor models used extensively by investment managers are just multiple regression models with public and proprietary factors. A factor is a financial feature such as the inflation rate. <a contenteditable="false" data-primary="high-frequency traders (HFT) using linear regression models" data-type="indexterm" id="id1207"/>Linear models are also the model of choice for many high-frequency traders (HFT), who are some of the most sophisticated algorithmic traders in the industry.</p>&#13;
&#13;
<p>There are many reasons why linear regression models are so popular. These models have a sound mathematical foundation and have been applied extensively in various fields—from astronomy to medicine to economics—for over two centuries. They <span class="keep-together">are viewed</span> as base models and the first approximations for any solution. Linear <span class="keep-together">regression</span> models have a closed-form analytical solution that most people learn in high school. These models are easy to build and interpret. Most spreadsheet software packages have this algorithm already built in with associated statistical analysis. Linear regression models can be trained very quickly and handle noisy financial data well. They are highly scalable to large datasets and become even more powerful in higher-dimensional spaces.</p>&#13;
&#13;
<p>In this chapter, we examine how<a contenteditable="false" data-primary="maximum likelihood estimation (MLE)" data-secondary="probabilistic linear regression model versus" data-type="indexterm" id="id1208"/> a probabilistic linear regression model is fundamentally different from a conventional/frequentist linear regression model that is based on maximum likelihood estimates (MLE) of parameters. Probabilistic models are more useful than MLE models because they are less wrong in their modeling of financial realities. <a contenteditable="false" data-primary="epistemic uncertainty" data-secondary="probabilistic models versus conventional/frequentist" data-type="indexterm" id="id1209"/><a contenteditable="false" data-primary="parameters of a model" data-secondary="parameter inference by ML systems" data-tertiary="probabilistic models" data-type="indexterm" id="id1210"/>As usual, probabilistic models demonstrate this usefulness by including the additional dimension of epistemic uncertainty about the model’s parameters and by explicitly including our prior knowledge or ignorance about them.</p>&#13;
&#13;
<p>The inclusion of epistemic uncertainty in the model transforms probabilistic machine learning into a form of ensemble machine learning since each set of possible parameters generates a different regression model. This also has the desirable effect of increasing the uncertainty of the model’s predictions when the ensemble has to extrapolate beyond the training or test data. As discussed in <a data-type="xref" href="ch06.html#the_dangers_of_conventional_ai_systems">Chapter 6</a>, we want our ML system to be aware of its ignorance. A model should know its limitations.</p>&#13;
&#13;
<p>We demonstrate these fundamental differences in approach by developing a probabilistic market model (MM) that transforms the MLE-based MM that we worked on in <a data-type="xref" href="ch04.html#the_dangers_of_conventional_statistical">Chapter 4</a>. We also use credible intervals instead of flawed confidence intervals. Furthermore, our probabilistic models seamlessly simulate data before and after being trained on in-sample data.</p>&#13;
&#13;
<p>Numerical computations of probabilistic models present a major challenge in applying probabilistic machine learning (PML) models to real-world problems. The grid approximation method that we used in the previous chapter does not scale as the number of parameters increases. In the previous chapter, we introduced the Markov chain Monte Carlo (MCMC) sampling methods. <a contenteditable="false" data-primary="probabilistic financial models" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-tertiary="about PyMC library" data-type="indexterm" id="id1211"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="generative ensembles" data-tertiary="PyMC library" data-type="indexterm" id="id1212"/><a contenteditable="false" data-primary="generative AI" data-secondary="generative ensembles" data-tertiary="PyMC library" data-type="indexterm" id="id1213"/><a contenteditable="false" data-primary="AI" data-secondary="generative AI" data-tertiary="PyMC library" data-type="indexterm" id="id1214"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-tertiary="about PyMC library" data-type="indexterm" id="id1215"/><a contenteditable="false" data-primary="PyMC library" data-secondary="about" data-type="indexterm" id="id1216"/><a contenteditable="false" data-primary="probabilistic linear ensembles" data-secondary="assembling with PyMC and ArviZ" data-tertiary="about PyMC library" data-type="indexterm" id="id1217"/>In this chapter, we will build our PML model using the PyMC library, the most popular open source probabilistic machine learning library in Python. PyMC has a syntax that is close to how probabilistic models are developed in practice. It has several advanced MCMC and other probabilistic algorithms, such as Hamiltonian Monte Carlo (HMC) and automatic differentiation variational inference (ADVI), which are arguably some of the most sophisticated algorithms in machine learning. These advanced MCMC sampling algorithms can be applied to problems with a basic understanding of the complex mathematics underpinning them, as discussed in <a data-type="xref" href="ch06.html#the_dangers_of_conventional_ai_systems">Chapter 6</a>.</p>&#13;
&#13;
<section data-pdf-bookmark="MLE Regression Models" data-type="sect1"><div class="sect1" id="mle_regression_models">&#13;
<h1>MLE Regression Models</h1>&#13;
&#13;
<p>Deterministic linear models, such<a contenteditable="false" data-primary="probabilistic financial models" data-secondary="as generative models" data-secondary-sortas="generative models" data-tertiary="MLE regression models" data-type="indexterm" id="ch07-mlereg"/><a contenteditable="false" data-primary="generative AI" data-secondary="generative ensembles" data-tertiary="MLE regression models" data-type="indexterm" id="ch07-mlereg2"/><a contenteditable="false" data-primary="AI" data-secondary="generative AI" data-tertiary="MLE regression models" data-type="indexterm" id="ch07-mlereg3"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="generative ensembles" data-tertiary="MLE regression models" data-type="indexterm" id="ch07-mlereg4"/><a contenteditable="false" data-primary="linear regression" data-secondary="MLE regression models" data-type="indexterm" id="ch07-mlereg5"/><a contenteditable="false" data-primary="maximum likelihood estimation (MLE)" data-secondary="regression models" data-type="indexterm" id="ch07-mlereg6"/><a contenteditable="false" data-primary="regression" data-see="linear regression" data-type="indexterm" id="id1218"/> as those found in physics and engineering, make mind-blowingly precise estimates and predictions that market participants can only dream about for their financial models. <a contenteditable="false" data-primary="maximum likelihood estimation (MLE)" data-secondary="regression models" data-tertiary="residual" data-type="indexterm" id="id1219"/><a contenteditable="false" data-primary="probabilistic financial models" data-secondary="as generative models" data-secondary-sortas="generative models" data-tertiary="residual" data-type="indexterm" id="id1220"/><a contenteditable="false" data-primary="generative AI" data-secondary="generative ensembles" data-tertiary="residual" data-type="indexterm" id="id1221"/><a contenteditable="false" data-primary="AI" data-secondary="generative AI" data-tertiary="residual" data-type="indexterm" id="id1222"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="generative ensembles" data-tertiary="residual" data-type="indexterm" id="id1223"/><a contenteditable="false" data-primary="residual" data-type="indexterm" id="id1224"/><a contenteditable="false" data-primary="linear regression" data-secondary="MLE regression models" data-tertiary="residual" data-type="indexterm" id="id1225"/>On the other hand, all nondeterministic or statistical linear models include a random component that captures the difference between a model’s prediction (Y) and its observed value (Y′). This difference is called the residual and is depicted in <a data-type="xref" href="#the_line_of_best_fit_of_a_linear_regres">Figure 7-1</a> by the vertical lines that go from the line of best fit to the observed data points. The goal of training the model is to learn the optimal parameters that minimize some average of the residuals.</p>&#13;
&#13;
<figure><div class="figure" id="the_line_of_best_fit_of_a_linear_regres"><img alt="The line of best fit of a linear regression model. The residuals are the vertical lines between the observed data and the fitted line." src="assets/pmlf_0701.png"/>&#13;
<h6><span class="label">Figure 7-1. </span>The line of best fit of a linear regression model. The residuals are the vertical lines between the observed data and the fitted line.<sup><a data-type="noteref" href="ch07.html#ch07fn1" id="ch07fn1-marker">1</a></sup></h6>&#13;
</div></figure>&#13;
&#13;
<p>As shown in <a data-type="xref" href="#the_line_of_best_fit_of_a_linear_regres">Figure 7-1</a>, the target (Y) of a simple linear regression model has only one feature (X) and is expressed as:</p>&#13;
<ul class="simplelist">&#13;
<li>Y = a + b × X + e, where a and b are constants to be learned from training data by minimizing the residual, e = Y − Y′.</li>&#13;
</ul>&#13;
<p>A multiple linear regression model uses a linear combination of more than one feature for predicting the target. The general form of linear regression is expressed as:</p>&#13;
<ul class="simplelist">&#13;
<li>Y = b<sub>0</sub> + b<sub>1</sub> × X<sub>1</sub> + b<sub>2</sub> × X<sub>2</sub> + …+ b<sub>n</sub> × X<sub>n</sub> + e, where b<sub>0</sub> − b<sub>n</sub> are constants to be learned from training data by minimizing the residual, e = Y − Y′.</li>&#13;
</ul>&#13;
<p>It is important to note that in a linear model, it is the coefficients (b<sub>0</sub> – b<sub>n</sub>) that have to be linear, and not the features. Recall from <a data-type="xref" href="ch04.html#the_dangers_of_conventional_statistical">Chapter 4</a> that a financial analyst, relying on modern portfolio theory and the practice of the frequentist statistical approach, incorrectly assumes that there is an underlying, time-invariant, stochastic process generating the price data of an asset such as a stock.</p>&#13;
&#13;
<section data-pdf-bookmark="Market Model" data-type="sect2"><div class="sect2" id="market_model">&#13;
<h2>Market Model</h2>&#13;
&#13;
<p>This stochastic process can be<a contenteditable="false" data-primary="linear regression" data-secondary="MLE regression models" data-tertiary="market model" data-type="indexterm" id="id1226"/><a contenteditable="false" data-primary="probabilistic financial models" data-secondary="as generative models" data-secondary-sortas="generative models" data-tertiary="market model" data-type="indexterm" id="id1227"/><a contenteditable="false" data-primary="generative AI" data-secondary="generative ensembles" data-tertiary="market model" data-type="indexterm" id="id1228"/><a contenteditable="false" data-primary="AI" data-secondary="generative AI" data-tertiary="market model" data-type="indexterm" id="id1229"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="generative ensembles" data-tertiary="market model" data-type="indexterm" id="id1230"/><a contenteditable="false" data-primary="market model for equities (MM)" data-secondary="linear regression model" data-type="indexterm" id="id1231"/><a contenteditable="false" data-primary="maximum likelihood estimation (MLE)" data-secondary="regression models" data-tertiary="market model" data-type="indexterm" id="id1232"/> modeled as an MM, which is basically a simple linear regression model of the realized excess returns of the stock (target) regressed on the realized excess returns of the overall market (feature), as formulated here:</p>&#13;
<ul class="simplelist">&#13;
<li>(R − F) = a + b (M − F) + e                      <em>(Equation 7.1)</em></li>&#13;
</ul>&#13;
<ul>&#13;
	<li>&#13;
	<p>Y = (R – F) is the target, X = (M − F) is the feature.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>R is the realized return of the stock.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>F is the return on a risk-free asset (such as the 10-year US Treasury note).</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>M is the realized return of a market portfolio (such as the S&amp;P 500 index).</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>a (alpha) is the expected stock-specific return.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>b (beta) is the level of systematic risk exposure to the market.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>e (residual) is the unexpected stock-specific return.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Even though the alpha and beta parameters of this underlying random process may be unknown or unknowable, the analyst is made to believe that these parameters are constant and have “true” values. The assumed time-invariant nature of this stochastic process implies that model parameters can be estimated from any random sample of price data of the various securities involved over a reasonably long amount of time. This implicit assumption is known as the stationary ergodic condition. It is the randomness of sample-to-sample data that creates aleatory uncertainty in the estimates of the true, fixed parameters, according to frequentists. The aleatory uncertainty of the parameters is captured by the residual, e = (Y – Y′).</p>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Model Assumptions" data-type="sect2"><div class="sect2" id="model_assumptions">&#13;
<h2>Model Assumptions</h2>&#13;
&#13;
<p>Many analysts are generally <a contenteditable="false" data-primary="linear regression" data-secondary="MLE regression models" data-tertiary="market model assumptions" data-type="indexterm" id="id1233"/><a contenteditable="false" data-primary="maximum likelihood estimation (MLE)" data-secondary="regression models" data-tertiary="market model assumptions" data-type="indexterm" id="id1234"/><a contenteditable="false" data-primary="market model for equities (MM)" data-secondary="linear regression model" data-tertiary="assumptions" data-type="indexterm" id="id1235"/><a contenteditable="false" data-primary="probabilistic financial models" data-secondary="as generative models" data-secondary-sortas="generative models" data-tertiary="market model assumptions" data-type="indexterm" id="id1236"/><a contenteditable="false" data-primary="generative AI" data-secondary="generative ensembles" data-tertiary="market model assumptions" data-type="indexterm" id="id1237"/><a contenteditable="false" data-primary="AI" data-secondary="generative AI" data-tertiary="market model assumptions" data-type="indexterm" id="id1238"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="generative ensembles" data-tertiary="market model assumptions" data-type="indexterm" id="id1239"/><a contenteditable="false" data-primary="Gaus-Markov theorem assumptions" data-type="indexterm" id="id1240"/>not aware that in order to make sound inferences about the model parameters, they have to make further assumptions about the residuals based on the Gauss-Markov theorem, namely:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>The residuals are independent and identically distributed.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>The expected mean of the residuals is zero.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>The variance of the residuals is constant and finite.</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Learning Parameters Using MLE" data-type="sect2"><div class="sect2" id="learning_parameters_using_mle">&#13;
<h2>Learning Parameters Using MLE</h2>&#13;
&#13;
<p>If the analyst assumes that the<a contenteditable="false" data-primary="linear regression" data-secondary="MLE regression models" data-tertiary="learning parameters using MLE" data-type="indexterm" id="id1241"/><a contenteditable="false" data-primary="maximum likelihood estimation (MLE)" data-secondary="regression models" data-tertiary="learning parameters using MLE" data-type="indexterm" id="id1242"/><a contenteditable="false" data-primary="parameters of a model" data-secondary="learning using MLE" data-type="indexterm" id="id1243"/> residuals are normally distributed, then it can be shown with basic calculus that the maximum likelihood estimate (MLE) for both parameters, alpha and beta, have the same values as those obtained using the OLS algorithm we learned in high school and applied in <a data-type="xref" href="ch04.html#the_dangers_of_conventional_statistical">Chapter 4</a> using the Statsmodels library. This is because both algorithms are minimizing the mean squared error or the expected value of the square of the residuals E[(Y − Y′)<sup>2</sup>)]. However, the MLE algorithm is preferred over the OLS algorithm because it can be applied to many different types of likelihood functions.<sup><a data-type="noteref" href="ch07.html#ch07fn2" id="ch07fn2-marker">2</a></sup></p>&#13;
&#13;
<p>It is common knowledge that while<a contenteditable="false" data-primary="financial data signal-to-noise ratios" data-type="indexterm" id="id1244"/><a contenteditable="false" data-primary="machine learning (ML) models" data-secondary="risks of overfitting data" data-type="indexterm" id="id1245"/><a contenteditable="false" data-primary="variance" data-secondary="financial data signal-to-noise ratios" data-type="indexterm" id="id1246"/><a contenteditable="false" data-primary="financial data signal-to-noise ratios" data-secondary="variance risks" data-type="indexterm" id="id1247"/> financial data are abundant, they have very low signal-to-noise ratios. One of the biggest risks in financial ML is that of variance or overfitting of data. When the model is trained on data, the algorithm learns the noise instead of the signal. This results in model parameter estimates that vary wildly from sample to sample. Consequently, the model performs poorly in out-of-sample testing.</p>&#13;
&#13;
<p>In multiple linear regression, overfitting<a contenteditable="false" data-primary="linear regression" data-secondary="overfitting of data" data-type="indexterm" id="id1248"/><a contenteditable="false" data-primary="multicollinearity" data-type="indexterm" id="id1249"/> of the data also occurs because the model might have highly correlated features. This is also called multicollinearity and is common in the financial and business world, where most features are interconnected, especially in times of financial distress.</p>&#13;
&#13;
<p>Conventional statisticians have developed<a contenteditable="false" data-primary="financial data signal-to-noise ratios" data-secondary="variance risks" data-tertiary="regularizations to reduce" data-type="indexterm" id="id1250"/><a contenteditable="false" data-primary="machine learning (ML) models" data-secondary="risks of overfitting data" data-tertiary="regularizations to reduce" data-type="indexterm" id="id1251"/><a contenteditable="false" data-primary="variance" data-secondary="financial data signal-to-noise ratios" data-tertiary="regularizations to reduce overfitting" data-type="indexterm" id="id1252"/><a contenteditable="false" data-primary="linear regression" data-secondary="overfitting of data" data-tertiary="regularizations to reduce" data-type="indexterm" id="id1253"/><a contenteditable="false" data-primary="regularizations to reduce variance" data-type="indexterm" id="id1254"/><a contenteditable="false" data-primary="frequentist view of probability" data-secondary="regularizations to reduce variance" data-type="indexterm" id="id1255"/><a contenteditable="false" data-primary="probability" data-secondary="frequentist conventional view" data-tertiary="regularizations to reduce variance" data-type="indexterm" id="id1256"/> two ad hoc methods called regularizations to reduce this overfitting of noisy data by creating a penalty term in the optimization algorithm for reducing the impact of any one parameter. Never mind that this is the antithesis of the frequentist decree of letting “only the data speak for themselves.”</p>&#13;
&#13;
<p>There are two types of regularization methods that penalize model complexity:<a contenteditable="false" data-primary="lasso regularization" data-type="indexterm" id="id1257"/><a contenteditable="false" data-primary="regularizations to reduce variance" data-secondary="lasso regularization" data-type="indexterm" id="id1258"/><a contenteditable="false" data-primary="L1 regularization" data-type="indexterm" id="id1259"/><a contenteditable="false" data-primary="ridge regularization" data-type="indexterm" id="id1260"/><a contenteditable="false" data-primary="regularizations to reduce variance" data-secondary="ridge regularization" data-type="indexterm" id="id1261"/><a contenteditable="false" data-primary="L2 regularization" data-type="indexterm" id="id1262"/></p>&#13;
&#13;
<dl>&#13;
	<dt>Lasso or L1 regularization</dt>&#13;
	<dd>Penalizes the sum of the absolute values of the parameters. In Lasso regression, many of the parameters are shrunk to zero. Lasso is also used to eliminate correlated features and improve the interpretation of complex models.</dd>&#13;
	<dt>Ridge or L2 regularization</dt>&#13;
	<dd>Penalizes the sum of the coefficients squared of the parameters. In ridge regression, all parameters are shrunk to near zero, which reduces the impact of any one feature on the target variable.</dd>&#13;
</dl>&#13;
&#13;
<p>In other words, instead of “only letting the data speak for themselves,” L2 regularization stifles all the voices, while L1 regularization silences many of them. Of course, models are regularized to make them useful in finance and investing, where data are extremely noisy, and the following Fisher’s dictum results in regression models failing abysmally and losing money.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Quantifying Parameter Uncertainty with Confidence Intervals" data-type="sect2"><div class="sect2" id="quantifying_parameter_uncertainty_with">&#13;
<h2>Quantifying Parameter Uncertainty with Confidence Intervals</h2>&#13;
&#13;
<p>After estimating the model parameters<a contenteditable="false" data-primary="linear regression" data-secondary="MLE regression models" data-tertiary="quantifying parameter uncertainty with confidence intervals" data-type="indexterm" id="id1263"/><a contenteditable="false" data-primary="maximum likelihood estimation (MLE)" data-secondary="regression models" data-tertiary="quantifying parameter uncertainty with confidence intervals" data-type="indexterm" id="id1264"/><a contenteditable="false" data-primary="confidence intervals (CIs)" data-secondary="quantifying parameter uncertainty with" data-type="indexterm" id="id1265"/><a contenteditable="false" data-primary="parameters of a model" data-secondary="learning using MLE" data-tertiary="quantifying uncertainty with confidence intervals" data-type="indexterm" id="id1266"/><a contenteditable="false" data-primary="parameters of a model" data-secondary="parameter uncertainty" data-tertiary="quantifying with confidence intervals" data-type="indexterm" id="id1267"/> from training data, the analyst computes the confidence intervals for alpha and beta to quantify their aleatory uncertainty. Most analysts are unaware about the three types of errors of using confidence intervals and don’t understand their flaws, as was discussed in <a data-type="xref" href="ch04.html#the_dangers_of_conventional_statistical">Chapter 4</a>. If they did, they would never use confidence intervals in financial analysis except in special cases when the central limit theorem applies.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Predicting and Simulating Model Outputs" data-type="sect2"><div class="sect2" id="predicting_and_simulating_model_outputs">&#13;
<h2>Predicting and Simulating Model Outputs</h2>&#13;
&#13;
<p>Now that the linear model has been built,<a contenteditable="false" data-primary="maximum likelihood estimation (MLE)" data-secondary="regression models" data-tertiary="predicting and simulating model outputs" data-type="indexterm" id="id1268"/><a contenteditable="false" data-primary="linear regression" data-secondary="MLE regression models" data-tertiary="predicting and simulating model outputs" data-type="indexterm" id="id1269"/><a contenteditable="false" data-primary="predictions" data-secondary="MLE regression models" data-type="indexterm" id="id1270"/> it is tested on unseen data to evaluate its usefulness for estimating and predicting. The same type of scoring algorithms that are used to evaluate the performance of the model on training data are used on testing data to compute its usefulness. However, to simulate data, the analyst will have to set up a separate Monte Carlo simulation (MCS) model, as discussed in <a data-type="xref" href="ch03.html#quantifying_output_uncertainty_with_mon">Chapter 3</a>. This is because MLE models are not generative models. They do not learn the underlying statistical structure of the data and so are unable to simulate data.<a contenteditable="false" data-primary="" data-startref="ch07-mlereg" data-type="indexterm" id="id1271"/><a contenteditable="false" data-primary="" data-startref="ch07-mlereg2" data-type="indexterm" id="id1272"/><a contenteditable="false" data-primary="" data-startref="ch07-mlereg3" data-type="indexterm" id="id1273"/><a contenteditable="false" data-primary="" data-startref="ch07-mlereg4" data-type="indexterm" id="id1274"/><a contenteditable="false" data-primary="" data-startref="ch07-mlereg5" data-type="indexterm" id="id1275"/><a contenteditable="false" data-primary="" data-startref="ch07-mlereg6" data-type="indexterm" id="id1276"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Probabilistic Linear Ensembles" data-type="sect1"><div class="sect1" id="probabilistic_linear_ensembles">&#13;
<h1>Probabilistic Linear Ensembles</h1>&#13;
&#13;
<p>In MLE modeling, the financial analyst<a contenteditable="false" data-primary="probabilistic financial models" data-secondary="as generative models" data-secondary-sortas="generative models" data-tertiary="probabilistic linear ensembles" data-type="indexterm" id="ch07-proben"/><a contenteditable="false" data-primary="generative AI" data-secondary="generative ensembles" data-tertiary="probabilistic linear ensembles" data-type="indexterm" id="ch07-proben2"/><a contenteditable="false" data-primary="AI" data-secondary="generative AI" data-tertiary="probabilistic linear ensembles" data-type="indexterm" id="ch07-proben3"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="generative ensembles" data-tertiary="probabilistic linear ensembles" data-type="indexterm" id="ch07-proben4"/><a contenteditable="false" data-primary="probabilistic financial models" data-secondary="probabilistic linear ensembles" data-type="indexterm" id="ch07-proben5"/><a contenteditable="false" data-primary="probabilistic financial models" data-secondary="probabilistic linear ensembles" data-tertiary="about" data-type="indexterm" id="id1277"/> tries to build models that are expected to emulate a “true” model that is supposedly optimal, elegant, and eternal. In probabilistic modeling, the financial analyst is freed from such ideological burdens. They don’t have to apologize for their financial models being approximate, messy, and transient because they merely reflect mathematical and market realities. We know that all models are wrong regardless of whether they are treated as prophetic or pathetic. We only evaluate them on their usefulness in achieving our financial goals.</p>&#13;
&#13;
<p>The financial analyst using the probabilistic framework not only applies the inverse probability rule, but also inverts the MLE modeling paradigm. Spurning ideological dictums of orthodox statistics in favor of common sense and the principles of the scientific method, they invert the conventional treatment of data and parameters:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Training data of excess returns, such as Y = (R − F) and X = (M − F), are treated as constants because their values have already been realized and recorded and will never change. That is the epitome of what a constant means.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Model parameters, such as alpha (a), beta (b), and the residual (e), are treated as variables with probability distributions since their values are unknown and uncertain. Financial model parameters have aleatory, epistemic, and ontological uncertainty. Their estimates keep changing depending on the sample used, assumptions applied, and the time period involved. That is the quintessence of what a variable means.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>The analyst understands that the search for any “true” constant parameter value of a financial model is a fool’s errand. This is because the dynamic randomness of markets and their participants ensure that probability distributions are never stationary ergodic. These analysts are painfully aware that creative, free-willed, emotional human beings make a mockery of theoretical, MLE-based “absolutist” financial models almost every day. The frequentist claim that financial model parameters have “true” values is simply unscientific, ideological drivel.</p>&#13;
&#13;
<p>We will use the probabilistic framework to explicitly state our assumptions and assign specific probability distributions to all the terms of the probabilistic framework so far discussed. Each probability distribution has additional parameters that will have to be estimated by the analyst. The analyst will have to specify the reasons for their choices. If the models fail during the testing phase, the analysts will change any and all probability distributions, including their parameters. All financial models are developed based on the most fundamental of heuristic techniques: trial and error.</p>&#13;
&#13;
<p>In a probabilistic framework, we apply the inverse probability rule to estimate our model parameters, as developed in <a data-type="xref" href="ch05.html#the_probabilistic_machine_learning_fram">Chapter 5</a>. After we have designed our model, we will develop it in Python using the PyMC library. Based on the terms defined for the MM, the probabilistic linear ensemble (PLE) is formulated as:</p>&#13;
<ul class="simplelist">&#13;
<li>P(a, b, e| X, Y) = P(Y| a, b, e, X) P(a, b, e) / P(Y|X) where</li></ul>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Y = a + b × X + e, as expressed in the MLE linear model, but without its explicit or implicit assumptions. These will be specified explicitly in the PLE.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>P(a, b, e) are the prior probabilities of all model parameters before observing the training data (X, Y).</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>P(Y| a, b, e, X) is the likelihood of observing the target training data Y given the parameters a, b, e, and feature training data X.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>P(Y|X) is the marginal likelihood of observing the training values of target Y given the training values of feature X averaged over all possible prior values of the parameters (a, b, e).</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>P(a, b, e| X, Y) is the posterior probabilities of the parameters a, b, e given the training data (X,Y).</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>We now discuss each component of the PLE model in more detail.</p>&#13;
&#13;
<section data-pdf-bookmark="Prior Probability Distributions P(a, b, e)" data-type="sect2"><div class="sect2" id="prior_probability_distributions_pleft_p">&#13;
<h2>Prior Probability Distributions P(a, b, e)</h2>&#13;
&#13;
<p>Before the analyst sees any<a contenteditable="false" data-primary="prior probability distributions P(a, b, e)" data-type="indexterm" id="id1278"/><a contenteditable="false" data-primary="probabilistic financial models" data-secondary="probabilistic linear ensembles" data-tertiary="prior probability distributions P(a, b, e)" data-type="indexterm" id="id1279"/><a contenteditable="false" data-primary="probabilistic linear ensembles" data-secondary="prior probability distributions P(a, b, e)" data-type="indexterm" id="id1280"/> training data (X,Y), they may specify the prior probability distributions of the PLE parameters (a, b, e) and quantify their epistemic uncertainty. All prior distributions are assumed to be independent of one another. These prior distributions may be based on personal, institutional, experiential, or common knowledge. If the analyst does not have any prior knowledge about the parameters, they can express their ignorance with uniform distributions that consider each value between the upper and lower limits equally likely. Remember that having bounds of 0 and 1 should be avoided unless you are absolutely certain that a parameter can take these values. The main objective is to specify one of the most important model assumptions explicitly and quantitatively.</p>&#13;
&#13;
<p>Given the tendency of models to overfit noisy financial data that don’t have any persistent structural unity, the analyst is aware that it is foolish to follow the orthodox dictum of “only letting the data speak for themselves.” The ad hoc use of regularization methods in MLE models to manage this overfitting risk are merely prior probability distributions in disguise. It can be shown mathematically that L1 regularization is equivalent to using a Laplacian prior, and L2 regularization is equivalent to using a Gaussian prior.<sup><a data-type="noteref" href="ch07.html#ch07fn3" id="ch07fn3-marker">3</a></sup></p>&#13;
&#13;
<p>The analyst systematically follows the probabilistic framework and explicitly quantifies their knowledge, or ignorance, about the model parameters with prior probability distributions. This makes the model transparent so it can be changed and critiqued by anyone, especially the portfolio manager. For instance, the analyst could assume that:</p>&#13;
&#13;
<ul class="pagebreak-before">&#13;
	<li>&#13;
	<p>alpha is normally distributed: a ~Normal()</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>beta is normally distributed: b ~Normal()</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Residual is Half-Student’s t-distributed: e ~HalfStudentT()</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Likelihood Function P(Y| a, b, e, X)" data-type="sect2"><div class="sect2" id="likelihood_function_pleft_parenthesisyv">&#13;
<h2>Likelihood Function P(Y| a, b, e, X)</h2>&#13;
&#13;
<p>After the analyst observes the<a contenteditable="false" data-primary="likelihood function P(D|H)" data-secondary="probabilistic linear ensembles P(Y|a, b, e, X)" data-type="indexterm" id="id1281"/><a contenteditable="false" data-primary="probabilistic financial models" data-secondary="probabilistic linear ensembles" data-tertiary="likelihood function P(Y|a, b, e, X)" data-type="indexterm" id="id1282"/><a contenteditable="false" data-primary="probabilistic linear ensembles" data-secondary="likelihood function P(Y|a, b, e, X)" data-type="indexterm" id="id1283"/> training data (X,Y), they need to formulate a likelihood function that best fits that data and quantifies the aleatory uncertainty of the model parameters (a, b, e). This is the same likelihood function that was used in the MLE linear model. In standard linear regression, the likelihood function for the residuals (e) is assumed to be a Gaussian or normal distribution. However, instead of using a normal probability distribution, the analyst uses Student’s t-distribution to model the financial realities of fat-tailed asset price returns. Also, if the likelihood function can accommodate outliers as well as the Student’s t-distribution does, the linear regression is termed a robust linear regression.</p>&#13;
&#13;
<p>Student’s t-distribution is a family of distributions that can approximate a range of other probability distributions based on its degrees of freedom parameter, v, which is a real number that can range from 0 to infinity. Student’s t-distributions are fat-tailed for lower values of v and get more normally distributed as v gets larger. It is important to note that for:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>v ≤ 1, t-distributions have no defined mean and variance</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>1 &lt; v ≤ 2, t-distributions have a defined mean but no defined variance</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>v &gt; 30, t-distributions are approximately normally distributed</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Say the analyst assigns a Student’s t-distribution with v = 6 to the likelihood function. Why v = 6? Financial research and practice has shown that this t-distribution does a good job of describing the fat-tailed stock price returns. So we are applying prior common knowledge to the choice of the likelihood function. The specific likelihood function can be expressed mathematically as:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Y ~StudentT(u, e, v = 6) where u = a + b × X and (a, b, e) are as defined by their prior probability distributions</p>&#13;
	</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Marginal Likelihood Function P(Y|X)" data-type="sect2"><div class="sect2" id="marginal_likelihood_function_pleft_pare">&#13;
<h2>Marginal Likelihood Function P(Y|X)</h2>&#13;
&#13;
<p>This is the hardest function to compute<a contenteditable="false" data-primary="marginal likelihood function P(D)" data-secondary="probabilistic linear ensembles P(Y|X)" data-type="indexterm" id="id1284"/><a contenteditable="false" data-primary="probabilistic financial models" data-secondary="probabilistic linear ensembles" data-tertiary="marginal likelihood function P(Y|X)" data-type="indexterm" id="id1285"/><a contenteditable="false" data-primary="probabilistic linear ensembles" data-secondary="marginal likelihood function P(Y|X)" data-type="indexterm" id="id1286"/> given it is averaging the likelihood functions over all the model’s parameters. The complexity increases as the types of probability distributions and number of parameters increase. As was mentioned earlier, we need groundbreaking algorithms to approximate this function numerically.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Posterior Probability Distributions P(a, b, e| X, Y)" data-type="sect2"><div class="sect2" id="posterior_probability_distributions_ple">&#13;
<h2>Posterior Probability Distributions P(a, b, e| X, Y)</h2>&#13;
&#13;
<p>Now that we have our model specified,<a contenteditable="false" data-primary="posterior probability distribution P(H|D)" data-secondary="probabilistic linear ensembles P(a, b, e|X, Y)" data-type="indexterm" id="id1287"/><a contenteditable="false" data-primary="probabilistic financial models" data-secondary="probabilistic linear ensembles" data-tertiary="posterior probability distributions P(a, b, e|X, Y)" data-type="indexterm" id="id1288"/><a contenteditable="false" data-primary="probabilistic linear ensembles" data-secondary="posterior probability distributions P(a, b, e|X, Y)" data-type="indexterm" id="id1289"/> we can compute the posterior probabilities for all our model’s parameters (a, b, e) given our training data (X,Y). To recap, our model is specified as follows:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Y ~StudentT(u, e, v = 6)</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>u = a + b × X</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>a ~Normal(), b ~Normal(), e ~HalfStudentT()</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>X,Y are training data pairs in a sample time period that reflect the current market conditions.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Model parameters, their probability distributions, and their relationships are displayed in <a data-type="xref" href="#probabilistic_market_model_showing_prio">Figure 7-2</a>.</p>&#13;
&#13;
<figure><div class="figure" id="probabilistic_market_model_showing_prio"><img alt="Probabilistic market model showing prior distributions used for parameters and the likelihood function used to fit training data" src="assets/pmlf_0702.png"/>&#13;
<h6><span class="label">Figure 7-2. </span>Probabilistic market model showing prior distributions used for parameters and the likelihood function used to fit training data</h6>&#13;
</div></figure>&#13;
&#13;
<p class="pagebreak-before">Because of the complexity of any realistic model, especially the marginal likelihood function, we can only approximate the posterior distributions of each of its parameters. PyMC uses the appropriate state-of-the-art MCMC algorithm to simulate the posterior distribution by sampling from it as discussed in Chapter 6. We then use the ArviZ library to explore these samples, enabling us to draw inferences and make predictions from them.<a contenteditable="false" data-primary="" data-startref="ch07-proben" data-type="indexterm" id="id1290"/><a contenteditable="false" data-primary="" data-startref="ch07-proben2" data-type="indexterm" id="id1291"/><a contenteditable="false" data-primary="" data-startref="ch07-proben3" data-type="indexterm" id="id1292"/><a contenteditable="false" data-primary="" data-startref="ch07-proben4" data-type="indexterm" id="id1293"/><a contenteditable="false" data-primary="" data-startref="ch07-proben5" data-type="indexterm" id="id1294"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Assembling PLEs with PyMC and ArviZ" data-type="sect1"><div class="sect1" id="assembling_ples_with_pymc_and_arviz">&#13;
<h1>Assembling PLEs with PyMC and ArviZ</h1>&#13;
&#13;
<p>Let’s now build our PLE in Python<a contenteditable="false" data-primary="probabilistic financial models" data-secondary="probabilistic linear ensembles" data-tertiary="assembling with PyMC and ArviZ" data-type="indexterm" id="ch07-assem"/><a contenteditable="false" data-primary="probabilistic linear ensembles" data-secondary="assembling with PyMC and ArviZ" data-type="indexterm" id="ch07-assem2"/><a contenteditable="false" data-primary="AI" data-secondary="generative AI" data-tertiary="PyMC library" data-type="indexterm" id="ch07-assem3"/><a contenteditable="false" data-primary="generative AI" data-secondary="generative ensembles" data-tertiary="PyMC library" data-type="indexterm" id="ch07-assem4"/><a contenteditable="false" data-primary="PyMC library" data-secondary="assembling probabilistic linear ensembles" data-type="indexterm" id="ch07-assem5"/><a contenteditable="false" data-primary="probabilistic financial models" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-type="indexterm" id="ch07-assem6"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-type="indexterm" id="ch07-assem7"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="generative ensembles" data-tertiary="PyMC library" data-type="indexterm" id="ch07-assem8"/> by leveraging its extensive ecosystem of powerful libraries. In addition to the standard Python stack of NumPy, pandas, and Matplotlib, we will also be using PyMC, ArviZ, and Xarray libraries. As mentioned earlier, PyMC is the most popular probabilistic machine learning library in Python. ArviZ is a probabilistic language-agnostic tool for analyzing and visualizing probabilistic ensembles. It converts inference data of probabilistic ensembles into Xarray objects, which are labeled, multidimensional arrays. You can search the web for links to the relevant documentation of the previously mentioned libraries.</p>&#13;
&#13;
<p>Building an ensemble of any kind requires a systematic process, and our PLE is no exception. We will follow the high-level ensemble-building process outlined in <a data-type="xref" href="#high_level_process_for_assembling_proba">Figure 7-3</a>. Each phase and its constituent parts will be explained along with the relevant code. It is important to note that even though we will go through our ensemble building process sequentially, this is an iterative, nonlinear process in practice. For instance, you could easily go back and forth from the training phase to the analyze features and target data phase. With that nonlinearity in mind, let’s go to the first phase.</p>&#13;
&#13;
<figure><div class="figure" id="high_level_process_for_assembling_proba"><img alt="High-level process for assembling probabilistic learning ensembles" src="assets/pmlf_0703.png"/>&#13;
<h6><span class="label">Figure 7-3. </span>High-level process for assembling probabilistic learning ensembles</h6>&#13;
</div></figure>&#13;
&#13;
<section data-pdf-bookmark="Define Ensemble Performance Metrics" data-type="sect2"><div class="sect2" id="define_ensemble_performance_metrics">&#13;
<h2>Define Ensemble Performance Metrics</h2>&#13;
&#13;
<p>Our financial objectives and activities<a contenteditable="false" data-primary="probabilistic financial models" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-tertiary="defining ensemble performance metrics" data-type="indexterm" id="ch07-def"/><a contenteditable="false" data-primary="probabilistic linear ensembles" data-secondary="assembling with PyMC and ArviZ" data-tertiary="defining ensemble performance metrics" data-type="indexterm" id="ch07-def2"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-tertiary="defining ensemble performance metrics" data-type="indexterm" id="ch07-def3"/><a contenteditable="false" data-primary="PyMC library" data-secondary="assembling probabilistic linear ensembles" data-tertiary="defining ensemble performance metrics" data-type="indexterm" id="ch07-def4"/> should drive the effort of building our PLE. Consequently, this influences the metrics we use to evaluate its performance. Our financial tasks are generally to estimate the parameters of a financial model or to forecast its outputs or both. As you know by now, probabilistic machine learning systems are ideally suited to both these tasks because they do inverse propagation and forward propagation seamlessly. More importantly, these generative ensembles direct us to consider the aleatory and epistemic uncertainties of the problem we are addressing and its possible solutions.</p>&#13;
&#13;
<section data-pdf-bookmark="Financial activities" data-type="sect3"><div class="sect3" id="financial_activities">&#13;
<h3>Financial activities</h3>&#13;
&#13;
<p>Plausible estimates of the regression parameters alpha and beta in Equation 7.1 are required for several financial activities that are practiced in the industry:<a contenteditable="false" data-primary="Jensen’s alpha" data-type="indexterm" id="id1295"/><a contenteditable="false" data-primary="market neutral strategies" data-type="indexterm" id="id1296"/><a contenteditable="false" data-primary="cross-hedging" data-type="indexterm" id="id1297"/><a contenteditable="false" data-primary="cost of equity capital" data-type="indexterm" id="id1298"/></p>&#13;
&#13;
<dl>&#13;
	<dt>Jensen’s alpha</dt>&#13;
	<dd>By regressing the returns of a fund against the returns of its benchmark portfolio, investors evaluate the skill of the fund’s manager by estimating the regression’s alpha parameter. This metric is known as Jensen’s alpha in the industry.</dd>&#13;
	<dt>Market neutral strategies</dt>&#13;
	<dd>Alpha can also be viewed as the asset-specific expected return regardless of the movements of the market. If a fund manager finds this return significantly attractive, they can try to isolate it and capture it by hedging out the asset’s exposure to market movements. This also involves estimating the asset’s beta, or sensitivity to the market. The portfolio consisting of the asset and the hedge becomes indifferent or neutral to the vagaries of the market.</dd>&#13;
	<dt>Cross-hedging</dt>&#13;
	<dd>By assuming constant variance of the residuals in Equation 7.1, the beta parameter can also be shown mathematically to correlate the volatility of one asset (Y) with the volatility of another related asset (X). Cross-hedging programs in corporate treasury departments use this beta-related correlation to hedge a commodity required by their company, say jet fuel, with another related commodity, such as oil. Treasury departments buy or sell financial instruments, such as futures, in the open market to hedge their input costs.</dd>&#13;
	<dt>Cost of equity capital</dt>&#13;
	<dd>Corporate financial analysts estimate the cost of their company’s equity capital by estimating the realized return, R, in the regression Equation 7.1. This is supposedly the expected return on their stock that their public shareholders are demanding. Many analysts still use their stock’s CAPM model and estimate R by making alpha = 0 in Equation 7.1.</dd>&#13;
</dl>&#13;
&#13;
<p>In this chapter, we will focus on estimating Apple’s equity price returns by using its MM, and not its CAPM, for the reasons detailed in <a data-type="xref" href="ch04.html#the_dangers_of_conventional_statistical">Chapter 4</a>. We will estimate the posterior probability distribution of Apple’s excess returns (R - F) given the current market regime. The generative linear ensemble can be applied to all the financial activities discussed earlier.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Objective function" data-type="sect3"><div class="sect3" id="objective_function">&#13;
<h3>Objective function</h3>&#13;
&#13;
<p>A rule that is formulated to measure<a contenteditable="false" data-primary="objective function" data-type="indexterm" id="id1299"/> the performance of a model or ensemble is called an objective function. This function generally measures the difference between the ensemble’s estimates or predictions compared with the corresponding realized or observed values. Common objective functions that measure the difference between predicted and observed values in machine learning regression models are mean squared error (MSE) and median absolute errors (MAE). The choice of an objective function depends on the business problem we are trying to solve. An objective function that reduces losses/costs is called a loss/cost function.</p>&#13;
&#13;
<p>Another regression objective function is R-squared. In frequentist statistics, it is defined as the variance of the predicted values divided by the total variance of the data. Note that R-squared can be interpreted mathematically as a standardized MSE objective function that needs to be maximized:</p>&#13;
<ul class="simplelist">&#13;
	<li>R-squared(Y) = 1 – MSE(Y)/Var(Y)</li>&#13;
</ul>&#13;
&#13;
<p>Since we are dealing with aleatory and epistemic uncertainties in our probabilistic models, this R-squared formula has to be modified so that its value does not exceed 1. The probabilistic version of R-squared is modified to equal the variance of the predicted values divided by the variance of predicted values plus the expected variance of the errors. It can be interpreted as a variance decomposition.<sup><a data-type="noteref" href="ch07.html#ch07fn4" id="ch07fn4-marker">4</a></sup> We will call this version of the R-squared objective function <em>probabilistic R-squared</em>.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Performance metrics" data-type="sect3"><div class="sect3" id="performance_metrics">&#13;
<h3>Performance metrics</h3>&#13;
&#13;
<p>As mentioned earlier, financial data<a contenteditable="false" data-primary="performance of a model" data-secondary="performance metrics" data-type="indexterm" id="id1300"/> are very noisy, which implies that we need to be realistic about the performance metrics we establish for each development phase. At a minimum, we want our model to do better than random guessing, i.e., we want performance scores greater than 50%. We would like our PLE to meet or exceed the following performance metrics:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>Probabilistic R-squared prior score &gt; 55%</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Probabilistic R-squared training score &gt; 60%</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Probabilistic R-squared test score &gt; 65%</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Highest-density intervals (HDIs): 90% HDI to include almost all training and test data (HDI will be explained shortly)</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>Keep in mind that all these metrics will be based on personal and organization preferences and are imperfect, as are the models used to produce them. It requires judgment and domain expertise. Regardless, we will use these metrics as another input to help us to evaluate our PLE, critique it, and revise it. In practice, we revise our PLE until we are confident that it will give us a high enough positive expected value in the financial activity we want to apply it to. Only then do we deploy our PLE out of the lab.<a contenteditable="false" data-primary="" data-startref="ch07-def" data-type="indexterm" id="id1301"/><a contenteditable="false" data-primary="" data-startref="ch07-def2" data-type="indexterm" id="id1302"/><a contenteditable="false" data-primary="" data-startref="ch07-def3" data-type="indexterm" id="id1303"/><a contenteditable="false" data-primary="" data-startref="ch07-def4" data-type="indexterm" id="id1304"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Analyze Data and Engineer Features" data-type="sect2"><div class="sect2" id="analyze_data_and_engineer_features">&#13;
<h2>Analyze Data and Engineer Features</h2>&#13;
&#13;
<p>We have already done data analysis<a contenteditable="false" data-primary="probabilistic financial models" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-tertiary="analyzing data and engineering features" data-type="indexterm" id="ch07-analy"/><a contenteditable="false" data-primary="probabilistic linear ensembles" data-secondary="assembling with PyMC and ArviZ" data-tertiary="analyzing data and engineering features" data-type="indexterm" id="ch07-analy2"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-tertiary="analyzing data and engineering features" data-type="indexterm" id="ch07-analy3"/><a contenteditable="false" data-primary="PyMC library" data-secondary="assembling probabilistic linear ensembles" data-tertiary="analyzing data and engineering features" data-type="indexterm" id="ch07-analy4"/> of the target and features in <a data-type="xref" href="ch04.html#the_dangers_of_conventional_statistical">Chapter 4</a> and in rewriting Equation 7.1.</p>&#13;
&#13;
<section data-pdf-bookmark="Data exploration" data-type="sect3"><div class="sect3" id="data_exploration">&#13;
<h3>Data exploration</h3>&#13;
&#13;
<p>In general, in this phase you would define your target of interest, such as predicting asset price returns or estimating volatility. These target variables are real valued numbers and are termed as regression targets. Alternatively, a target of interest could also be classification of a company’s creditworthiness based on predictions of whether it will default or not. These are classification targets that take on discrete numbers like 0 or 1.</p>&#13;
&#13;
<p>You would then identify various sources of data that will enable you to analyze your target and features in sufficient detail. Data sources can be expensive, and you will have to figure out how to get them in a cost-effective manner. Cleaning and processing data from various sources is generally quite time-consuming.</p>&#13;
&#13;
<section data-pdf-bookmark="Feature engineering" data-type="sect3"><div class="sect3" id="feature_engineering">&#13;
<h3>Feature engineering</h3>&#13;
&#13;
<p>Recall that a feature is some representation of data that serves as an independent variable enabling inference or prediction of a model’s target variable. Feature engineering is the practice of selecting, designing, and developing a useful set of features that work together to enable reliable inferences or predictions of the target variable(s) in out-of-sample data.</p>&#13;
&#13;
<p>To predict a target variable, such as price returns, a model can have many different types of features. Here are examples of various types of features:</p>&#13;
&#13;
<dl>&#13;
	<dt>Fundamental</dt>&#13;
	<dd>Company sales, interest rates, exchange rates, GDP growth rate</dd>&#13;
	<dt>Technical</dt>&#13;
	<dd>Momentum indicators, fund flows, liquidity</dd>&#13;
	<dt>Sentiment</dt>&#13;
	<dd>Consumer sentiment, investor sentiment</dd>&#13;
	<dt>Other</dt>&#13;
	<dd>Proprietary mathematical or statistical indicators</dd>&#13;
</dl>&#13;
&#13;
<p>After you have selected and developed a possible set of features, it is generally a good idea to use relative changes in feature levels, rather than absolute levels, as inputs into your features’ dataframe. This reduces the serial autocorrelation endemic in financial time series. Serial correlation occurs when a variable is correlated with past values of itself over time. Traders and investors are generally interested in understanding if a good or bad condition is getting better or worse. So market participants are continually reacting to relative changes in levels in terms of percentages or differences.</p>&#13;
&#13;
<p>If we have more than one feature, we need to check if some of them are highly correlated with one another. Recall that this issue is called multicollinearity. Highly correlated features can unduly amplify the same signal in data, leading to invalid inferences and predictions. Ideally, there should be zero correlation or no multicollinearity among features. Unfortunately, that almost never happens in practice. Coming up with a threshold variance above which you would remove redundant features is a judgment call based on the business context.</p>&#13;
&#13;
<p>Feature engineering is critical to the performance of all ML systems. It requires domain expertise, judgment, experience, common sense, and a lot of trial and error. These are the qualities that enable human intelligence to distinguish correlation from causation, which AI-enabled agents cannot do to this day.</p>&#13;
&#13;
<p>We are going to keep our feature engineering simple in this primer and leverage a vast body of financial knowledge and experience on market models. Our PLE has a single feature: the market as represented by the S&amp;P 500 index.</p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Data analysis" data-type="sect3"><div class="sect3" id="data_analysis">&#13;
<h3>Data analysis</h3>&#13;
&#13;
<p>PLEs demonstrate their strengths when we have small datasets, such that a weak or flat prior is not overwhelmed by the likelihood function. Here we will look at 31 days of data in the last two months of last year, from 11/15/2022 to 12/31/22. This period covers two Federal Reserve meetings and was exceptionally volatile. We will train our PLE on the first 21 days of data and test it on the last 10 days of data. This is called the time series split method of cross-validation. Because financial time series have strong serial correlation, we cannot use the standard cross-validation method, since it assumes that each data sample is independent and identically distributed.</p>&#13;
&#13;
<p>Let’s actually download price data for Apple Inc., S&amp;P 500, and the 10-year treasury note, and compute the daily price returns as we did for our linear MM in <a data-type="xref" href="ch04.html#the_dangers_of_conventional_statistical">Chapter 4</a>:<a contenteditable="false" data-primary="" data-startref="ch07-analy" data-type="indexterm" id="id1305"/><a contenteditable="false" data-primary="" data-startref="ch07-analy2" data-type="indexterm" id="id1306"/><a contenteditable="false" data-primary="" data-startref="ch07-analy3" data-type="indexterm" id="id1307"/><a contenteditable="false" data-primary="" data-startref="ch07-analy4" data-type="indexterm" id="id1308"/></p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Import standard Python libraries.</code>&#13;
<code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>&#13;
<code class="kn">import</code> <code class="nn">pandas</code> <code class="k">as</code> <code class="nn">pd</code>&#13;
<code class="kn">from</code> <code class="nn">datetime</code> <code class="kn">import</code> <code class="n">datetime</code>&#13;
<code class="kn">import</code> <code class="nn">xarray</code> <code class="k">as</code> <code class="nn">xr</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="k">as</code> <code class="nn">plt</code>&#13;
&#13;
<code class="c1"># Install and import PyMC and Arviz libraries.</code>&#13;
<code class="err">!</code><code class="n">pip</code> <code class="n">install</code> <code class="n">pymc</code> <code class="o">-</code><code class="n">q</code>&#13;
<code class="kn">import</code> <code class="nn">pymc</code> <code class="k">as</code> <code class="nn">pm</code>&#13;
<code class="kn">import</code> <code class="nn">arviz</code> <code class="k">as</code> <code class="nn">az</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">style</code><code class="o">.</code><code class="n">use</code><code class="p">(</code><code class="s1">'arviz-darkgrid'</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Install and import Yahoo Finance web scraper.</code>&#13;
<code class="err">!</code><code class="n">pip</code> <code class="n">install</code> <code class="n">yfinance</code> <code class="o">-</code><code class="n">q</code>&#13;
<code class="kn">import</code> <code class="nn">yfinance</code> <code class="k">as</code> <code class="nn">yf</code>&#13;
&#13;
<code class="c1"># Fix random seed so that numerical results can be reproduced.</code>&#13;
<code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">(</code><code class="mi">101</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Import financial data.</code>&#13;
<code class="n">start</code> <code class="o">=</code> <code class="n">datetime</code><code class="p">(</code><code class="mi">2022</code><code class="p">,</code> <code class="mi">11</code><code class="p">,</code> <code class="mi">15</code><code class="p">)</code>&#13;
<code class="n">end</code> <code class="o">=</code> <code class="n">datetime</code><code class="p">(</code><code class="mi">2022</code><code class="p">,</code> <code class="mi">12</code><code class="p">,</code> <code class="mi">31</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># S&amp;P 500 index is a proxy for the market factor.</code>&#13;
<code class="n">market</code> <code class="o">=</code> <code class="n">yf</code><code class="o">.</code><code class="n">Ticker</code><code class="p">(</code><code class="s1">'SPY'</code><code class="p">)</code><code class="o">.</code><code class="n">history</code><code class="p">(</code><code class="n">start</code><code class="o">=</code><code class="n">start</code><code class="p">,</code> <code class="n">end</code><code class="o">=</code><code class="n">end</code><code class="p">)</code>&#13;
<code class="c1"># Ticker symbol for Apple, the largest company in the world </code>&#13;
<code class="c1"># by market capitalization.</code>&#13;
<code class="n">stock</code> <code class="o">=</code> <code class="n">yf</code><code class="o">.</code><code class="n">Ticker</code><code class="p">(</code><code class="s1">'AAPL'</code><code class="p">)</code><code class="o">.</code><code class="n">history</code><code class="p">(</code><code class="n">start</code><code class="o">=</code><code class="n">start</code><code class="p">,</code> <code class="n">end</code><code class="o">=</code><code class="n">end</code><code class="p">)</code>&#13;
<code class="c1"># 10 year US treasury note is the proxy for risk free rate.</code>&#13;
<code class="n">riskfree_rate</code> <code class="o">=</code> <code class="n">yf</code><code class="o">.</code><code class="n">Ticker</code><code class="p">(</code><code class="s1">'^TNX'</code><code class="p">)</code><code class="o">.</code><code class="n">history</code><code class="p">(</code><code class="n">start</code><code class="o">=</code><code class="n">start</code><code class="p">,</code> <code class="n">end</code><code class="o">=</code><code class="n">end</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Create a dataframe to hold the daily returns of securities.</code>&#13;
<code class="n">daily_returns</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">()</code>&#13;
<code class="c1"># Compute daily percentage returns based on closing prices for Apple and </code>&#13;
<code class="c1"># S&amp;P 500 index.</code>&#13;
<code class="n">daily_returns</code><code class="p">[</code><code class="s1">'market'</code><code class="p">]</code> <code class="o">=</code> <code class="n">market</code><code class="p">[</code><code class="s1">'Close'</code><code class="p">]</code><code class="o">.</code><code class="n">pct_change</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code><code class="o">*</code><code class="mi">100</code>&#13;
<code class="n">daily_returns</code><code class="p">[</code><code class="s1">'stock'</code><code class="p">]</code> <code class="o">=</code> <code class="n">stock</code><code class="p">[</code><code class="s1">'Close'</code><code class="p">]</code><code class="o">.</code><code class="n">pct_change</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code><code class="o">*</code><code class="mi">100</code>&#13;
<code class="c1"># Compounded daily risk free rate based on 360 days for the calendar year </code>&#13;
<code class="c1"># used in the bond market.</code>&#13;
<code class="n">daily_returns</code><code class="p">[</code><code class="s1">'riskfree'</code><code class="p">]</code> <code class="o">=</code> <code class="p">(</code><code class="mi">1</code> <code class="o">+</code> <code class="n">riskfree_rate</code><code class="p">[</code><code class="s1">'Close'</code><code class="p">])</code> <code class="o">**</code> <code class="p">(</code><code class="mi">1</code><code class="o">/</code><code class="mi">360</code><code class="p">)</code> <code class="o">-</code> <code class="mi">1</code>&#13;
&#13;
<code class="c1"># Check for missing data in the dataframe.</code>&#13;
<code class="n">market</code><code class="o">.</code><code class="n">index</code><code class="o">.</code><code class="n">difference</code><code class="p">(</code><code class="n">riskfree_rate</code><code class="o">.</code><code class="n">index</code><code class="p">)</code>&#13;
<code class="c1"># Fill rows with previous day's risk-free rate since </code>&#13;
<code class="c1"># daily rates are generally stable.</code>&#13;
<code class="n">daily_returns</code> <code class="o">=</code> <code class="n">daily_returns</code><code class="o">.</code><code class="n">ffill</code><code class="p">()</code>&#13;
<code class="c1"># Drop NaNs in first row because of percentage calculations </code>&#13;
<code class="c1"># are based on previous day's closing price.</code>&#13;
<code class="n">daily_returns</code> <code class="o">=</code> <code class="n">daily_returns</code><code class="o">.</code><code class="n">dropna</code><code class="p">()</code>&#13;
<code class="c1"># Check dataframe for null values.</code>&#13;
<code class="n">daily_returns</code><code class="o">.</code><code class="n">isnull</code><code class="p">()</code><code class="o">.</code><code class="n">sum</code><code class="p">()</code>&#13;
<code class="c1"># Check first five rows of dataframe.</code>&#13;
<code class="n">daily_returns</code><code class="o">.</code><code class="n">head</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># Daily excess returns of AAPL are returns in excess of </code>&#13;
<code class="c1"># the daily risk free rate.</code>&#13;
<code class="n">y</code> <code class="o">=</code> <code class="n">daily_returns</code><code class="p">[</code><code class="s1">'stock'</code><code class="p">]</code> <code class="o">-</code> <code class="n">daily_returns</code><code class="p">[</code><code class="s1">'riskfree'</code><code class="p">]</code>&#13;
<code class="c1"># Daily excess returns of the market are returns in excess of </code>&#13;
<code class="c1"># the daily risk free rate.</code>&#13;
<code class="n">x</code> <code class="o">=</code> <code class="n">daily_returns</code><code class="p">[</code><code class="s1">'market'</code><code class="p">]</code> <code class="o">-</code> <code class="n">daily_returns</code><code class="p">[</code><code class="s1">'riskfree'</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># Plot the excess returns of Apple and S&amp;P 500.</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">scatter</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code class="n">y</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">ylabel</code><code class="p">(</code><code class="s1">'Excess returns of Apple'</code><code class="p">),</code> &#13;
<code class="n">plt</code><code class="o">.</code><code class="n">xlabel</code><code class="p">(</code><code class="s1">'Excess returns of S&amp;P 500'</code><code class="p">);</code>&#13;
&#13;
<code class="c1"># Plot histogram of Apple's excess returns during the period.</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">hist</code><code class="p">(</code><code class="n">y</code><code class="p">,</code> <code class="n">density</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> <code class="n">color</code><code class="o">=</code><code class="s1">'blue'</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">ylabel</code><code class="p">(</code><code class="s1">'Probability density'</code><code class="p">),</code> <code class="n">plt</code><code class="o">.</code><code class="n">xlabel</code><code class="p">(</code><code class="s1">'Excess returns of Apple'</code><code class="p">);</code>&#13;
&#13;
<code class="c1"># Analyze daily returns of all securities.</code>&#13;
<code class="n">daily_returns</code><code class="o">.</code><code class="n">describe</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># Split time series sequentially because of serial correlation </code>&#13;
<code class="c1"># in financial data.</code>&#13;
<code class="n">test_size</code> <code class="o">=</code> <code class="mi">10</code>&#13;
&#13;
<code class="n">x_train</code> <code class="o">=</code> <code class="n">x</code><code class="p">[:</code><code class="o">-</code><code class="n">test_size</code><code class="p">]</code>&#13;
<code class="n">y_train</code> <code class="o">=</code> <code class="n">y</code><code class="p">[:</code><code class="o">-</code><code class="n">test_size</code><code class="p">]</code>&#13;
&#13;
<code class="n">x_test</code> <code class="o">=</code> <code class="n">x</code><code class="p">[</code><code class="o">-</code><code class="n">test_size</code><code class="p">:]</code>&#13;
<code class="n">y_test</code> <code class="o">=</code> <code class="n">y</code><code class="p">[</code><code class="o">-</code><code class="n">test_size</code><code class="p">:]</code>&#13;
</pre>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Develop and Retrodict Prior Ensemble" data-type="sect2"><div class="sect2" id="develop_and_retrodict_prior_ensemble">&#13;
<h2>Develop and Retrodict Prior Ensemble</h2>&#13;
&#13;
<p>Let’s start developing our PLE using<a contenteditable="false" data-primary="probabilistic financial models" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-tertiary="developing and retrodicting prior ensemble" data-type="indexterm" id="ch07-prior"/><a contenteditable="false" data-primary="probabilistic linear ensembles" data-secondary="assembling with PyMC and ArviZ" data-tertiary="developing and retrodicting prior ensemble" data-type="indexterm" id="ch07-prior2"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-tertiary="developing and retrodicting prior ensemble" data-type="indexterm" id="ch07-prior3"/><a contenteditable="false" data-primary="PyMC library" data-secondary="assembling probabilistic linear ensembles" data-tertiary="developing and retrodicting prior ensemble" data-type="indexterm" id="ch07-prior4"/> the PyMC library. At this point, we explicitly state the assumptions of our ensemble in the prior probability distributions of the parameters and the likelihood function. This also includes our hypothesis about the functional form of the underlying data-generating process, i.e., linear with some noise.</p>&#13;
&#13;
<p>After that, we check to see if the ensemble’s prior predictive distribution generates data that is plausible and may have occurred in the past, and are now in our training data sample. A prediction of a past event is called retrodiction and is used as a model check, before and after it is trained. If the data generated by the prior ensemble are implausible, because they don’t fall within our highest density interval, we revise all of our model assumptions.</p>&#13;
&#13;
<section data-pdf-bookmark="Specify distributions and their parameters" data-type="sect3"><div class="sect3" id="specify_distributions_and_their_paramet">&#13;
<h3>Specify distributions and their parameters</h3>&#13;
&#13;
<p>We incorporate our prior knowledge into the ensemble by specifying the prior probability distributions of its parameters, P(a), P(b), and P(e). After that, we specify the likelihood of observing our data given the parameters, P(D | a, b, e).</p>&#13;
&#13;
<p>In the following Python code block, we have chosen a Student’s t-distribution with <span class="keep-together">nu = 6</span> for the likelihood function of our ensemble. Of course, we could also add nu as another unknown parameter that needs to be inferred. However, that would merely increase the complexity without adding much in terms of increasing your understanding of the development process. </p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Create a probabilistic model by instantiating the PyMC model class.</code>&#13;
<code class="n">model</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">Model</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># The with statement creates a context manager for the model object.</code>&#13;
<code class="c1"># All variables and constants inside the with-block are part of the model.</code>&#13;
&#13;
<code class="k">with</code> <code class="n">model</code><code class="p">:</code>&#13;
  <code class="c1"># Define the prior probability distributions of the model's parameters. </code>&#13;
  <code class="c1"># Use prior domain knowledge.</code>&#13;
&#13;
  <code class="c1"># Alpha quantifies the idiosyncratic, daily excess return of Apple </code>&#13;
  <code class="c1"># ​unaffected by market movements.</code>&#13;
  <code class="c1"># Assume that alpha is normally distributed. The values of mu and </code>&#13;
  <code class="c1"># sigma are based on previous data analysis and trial and error.</code>&#13;
  <code class="n">alpha</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">Normal</code><code class="p">(</code><code class="s1">'alpha'</code><code class="p">,</code> <code class="n">mu</code><code class="o">=</code><code class="mf">0.02</code><code class="p">,</code> <code class="n">sigma</code><code class="o">=</code><code class="mf">0.10</code><code class="p">)</code>&#13;
&#13;
  <code class="c1"># Beta quantifies the sensitivity of Apple to the movements </code>&#13;
  <code class="c1"># of the market/S&amp;P 500.</code>&#13;
  <code class="c1"># Assume that beta is normally distributed. The values of mu and </code>&#13;
  <code class="c1"># sigma are based on previous data analysis and trial and error.</code>&#13;
  <code class="n">beta</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">Normal</code><code class="p">(</code><code class="s1">'beta'</code><code class="p">,</code> <code class="n">mu</code><code class="o">=</code><code class="mf">1.2</code><code class="p">,</code> <code class="n">sigma</code><code class="o">=</code><code class="mf">0.15</code><code class="p">)</code>&#13;
&#13;
  <code class="c1"># Residual quantifies the unexpected returns of Apple </code>&#13;
  <code class="c1"># i.e returns not predicted by the linear model.</code>&#13;
  <code class="c1"># Assume residuals are Half Student's t-distribution with nu=6. </code>&#13;
  <code class="c1"># Value of nu=6 is based on research studies and trial and error.</code>&#13;
  <code class="n">residual</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">HalfStudentT</code><code class="p">(</code><code class="s1">'residual'</code><code class="p">,</code> <code class="n">sigma</code><code class="o">=</code><code class="mf">0.20</code><code class="p">,</code> <code class="n">nu</code><code class="o">=</code><code class="mi">6</code><code class="p">)</code>&#13;
&#13;
  <code class="c1"># Mutatable data containers are used so that we can swap out </code>&#13;
  <code class="c1"># training data for test data later.</code>&#13;
  <code class="n">feature</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">MutableData</code><code class="p">(</code><code class="s1">'feature'</code><code class="p">,</code> <code class="n">x_train</code><code class="p">,</code> <code class="n">dims</code><code class="o">=</code><code class="s1">'feature_data'</code><code class="p">)</code>&#13;
  <code class="n">target</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">MutableData</code><code class="p">(</code><code class="s1">'target'</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">dims</code><code class="o">=</code><code class="s1">'target_data'</code><code class="p">)</code>&#13;
&#13;
  <code class="c1"># Expected daily excess returns of Apple are approximately </code>&#13;
  <code class="c1"># linearly related to daily excess returns of S&amp;P 500.</code>&#13;
  <code class="c1"># The function specifies the linear model and the expected return. </code>&#13;
  <code class="c1"># It creates a deterministic variable in the trace object.</code>&#13;
  <code class="n">target_expected</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">Deterministic</code><code class="p">(</code><code class="s1">'target_expected'</code><code class="p">,</code> &#13;
  <code class="n">alpha</code> <code class="o">+</code> <code class="n">beta</code> <code class="o">*</code> <code class="n">feature</code><code class="p">,</code> <code class="n">dims</code><code class="o">=</code><code class="s1">'feature_data'</code><code class="p">)</code>&#13;
&#13;
  <code class="c1"># Assign the training data sample to the likelihood function.</code>&#13;
  <code class="c1"># Daily excess stock price returns are assumed to be T-distributed, nu=6.</code>&#13;
  <code class="n">target_likelihood</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">StudentT</code><code class="p">(</code><code class="s1">'target_likelihood'</code><code class="p">,</code> <code class="n">mu</code><code class="o">=</code><code class="n">target_expected</code><code class="p">,</code> &#13;
  <code class="n">sigma</code><code class="o">=</code><code class="n">residual</code><code class="p">,</code> <code class="n">nu</code><code class="o">=</code><code class="mi">6</code><code class="p">,</code> <code class="n">observed</code><code class="o">=</code><code class="n">target</code><code class="p">,</code> <code class="n">dims</code><code class="o">=</code><code class="s1">'target_data'</code><code class="p">)</code>&#13;
 </pre>&#13;
&#13;
<p><a data-type="xref" href="#probabilistic_market_model_showing_prio">Figure 7-2</a> was generated by the <code>graphviz</code> method shown in the following code:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Use the graphviz method to visualize the probabilistic model's data, </code>&#13;
<code class="c1"># parameters, distributions and dependencies</code>&#13;
<code class="n">pm</code><code class="o">.</code><code class="n">model_to_graphviz</code><code class="p">(</code><code class="n">model</code><code class="p">)</code></pre>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Sample distributions and simulate data" data-type="sect3"><div class="sect3" id="sample_distributions_and_simulate_data">&#13;
<h3>Sample distributions and simulate data</h3>&#13;
&#13;
<p>Before we train our model, we should check the usefulness of the assumptions of our prior ensemble. The goal is to make sure that the ensemble is good enough for the training phase. This is done by conducting what is called a prior predictive check. We use the ensemble’s prior predictive distribution to simulate a data distribution that may have been realized in the past. Recall that this is called a retrodiction as opposed to a prediction, which simulates a data distribution that is most likely to occur in the future.</p>&#13;
&#13;
<p>In the following code block, we simulate 21,000 data samples from the prior predictive distribution. We let ArviZ return the <code>InferenceData</code> object so that we can visualize and analyze the generated data samples. Expand the display after the inference object is returned to examine the structure of the various groups. We will need them for analysis and inference:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Sample from the prior distributions and the likelihood function </code>&#13;
<code class="c1"># to generate prior predictive distribution of the model.</code>&#13;
<code class="c1"># Take 1000 draws from the prior predictive distribution </code>&#13;
<code class="c1"># to simulate (1000*21) target values based on our prior assumptions.</code>&#13;
<code class="n">idata</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">sample_prior_predictive</code><code class="p">(</code><code class="n">samples</code><code class="o">=</code><code class="mi">1000</code><code class="p">,</code> <code class="n">model</code><code class="o">=</code><code class="n">model</code><code class="p">,</code> &#13;
<code class="n">return_inferencedata</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> <code class="n">random_seed</code><code class="o">=</code><code class="mi">101</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># PyMC/Arviz returns an xarray - a labeled, multidimensional array </code>&#13;
<code class="c1"># containing inference data samples structured into groups. Note the </code>&#13;
<code class="c1"># dimensions of the prior predictive group to see how we got (1*1000*21) </code>&#13;
<code class="c1"># simulated target data of the prior predictive distribution.</code>&#13;
<code class="n">idata</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in01.png"/>&#13;
</div></figure>&#13;
&#13;
<p>Let’s plot the marginal prior distributions of each parameter before we conduct prior predictive checks. Note that a kernel density estimate is a smoothed-out histogram of a continuous variable:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Subplots on the left show the kernel density estimates (KDE) of </code>&#13;
<code class="c1"># the marginal prior probability distributions of model parameters </code>&#13;
<code class="c1"># from the 1000 samples drawn. Subplots on the right show the parameter </code>&#13;
<code class="c1"># values from a single Markov chain that were sampled sequentially </code>&#13;
<code class="c1"># by the NUTS sampler, the default regression sampler.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_trace</code><code class="p">(</code><code class="n">idata</code><code class="o">.</code><code class="n">prior</code><code class="p">,</code> <code class="n">kind</code><code class="o">=</code><code class="s1">'trace'</code><code class="p">,</code> &#13;
<code class="n">var_names</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'alpha'</code><code class="p">,</code> <code class="s1">'beta'</code><code class="p">,</code> <code class="s1">'residual'</code><code class="p">],</code> <code class="n">legend</code><code class="o">=</code><code class="kc">True</code><code class="p">);</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in02.png"/>&#13;
</div></figure>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Plot the marginal prior distributions of each parameter with 94% </code>&#13;
<code class="c1"># highest density intervals (HDI).</code>&#13;
<code class="c1"># Note the residual subplot shows the majority of probability density function</code>&#13;
<code class="c1"># within 3 percentage points and the rest extending out into a long tail.</code>&#13;
<code class="c1"># In Arviz, there is no method to plot the prior marginal distributions but we </code>&#13;
<code class="c1"># can hack the plot posterior method and use the prior group instead.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_posterior</code><code class="p">(</code><code class="n">idata</code><code class="o">.</code><code class="n">prior</code><code class="p">,</code> &#13;
<code class="n">var_names</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'alpha'</code><code class="p">,</code> <code class="s1">'beta'</code><code class="p">,</code> <code class="s1">'residual'</code><code class="p">],</code> <code class="n">round_to</code><code class="o">=</code><code class="mi">2</code><code class="p">);</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in03.png"/>&#13;
</div></figure>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Plot the joint prior probability distribution of alpha and beta with their </code>&#13;
<code class="c1"># respective means and marginal distributions on the side.</code>&#13;
<code class="c1"># Hexabin plot below shows little or no linear correlation with the high </code>&#13;
<code class="c1"># concentration areas in the heat map forming a cloud.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_pair</code><code class="p">(</code><code class="n">idata</code><code class="o">.</code><code class="n">prior</code><code class="p">,</code> <code class="n">var_names</code><code class="o">=</code><code class="p">[</code><code class="s1">'alpha'</code><code class="p">,</code> <code class="s1">'beta'</code><code class="p">],</code> <code class="n">kind</code><code class="o">=</code><code class="s1">'hexbin'</code><code class="p">,</code> &#13;
<code class="n">marginals</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> <code class="n">point_estimate</code><code class="o">=</code><code class="s1">'mean'</code><code class="p">,</code> <code class="n">colorbar</code><code class="o">=</code><code class="kc">True</code><code class="p">);</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in04.png"/>&#13;
</div></figure>&#13;
&#13;
<p>Let’s create a prior ensemble of 1000 regression lines, one for each value of the ensemble’s parameters (a, b) sampled from its prior distributions, and plot the epistemic uncertainty around the prior mean of the untrained linear ensemble. We also use the prior predictive distribution of the ensemble to simulate data. This displays the epistemic and aleatory uncertainties of the data distributions. Note that the training data is plotted to give us some context and a baseline for the ensemble’s retrodictions:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Plot the retrodictions of prior predictive ensemble.</code>&#13;
&#13;
<code class="c1"># Retrieve feature and target training data from the constant_data group.</code>&#13;
<code class="c1"># Feature is now an Xarray instead of a panda's series, </code>&#13;
<code class="c1"># a requirement for ArviZ data analysis.</code>&#13;
<code class="n">feature_train</code> <code class="o">=</code> <code class="n">idata</code><code class="o">.</code><code class="n">constant_data</code><code class="p">[</code><code class="s1">'feature'</code><code class="p">]</code>&#13;
<code class="n">target_train</code> <code class="o">=</code> <code class="n">idata</code><code class="o">.</code><code class="n">constant_data</code><code class="p">[</code><code class="s1">'target'</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># Generate 1000 linear regression lines based on 1000 draws from one  </code>&#13;
<code class="c1"># Markov chain of the prior distributions of alpha and beta.</code>&#13;
<code class="c1"># Prior target values are in 1000 arrays with each array having 21 samples,</code>&#13;
<code class="c1"># the same number of samples as our training data set.</code>&#13;
<code class="n">prior_target</code> <code class="o">=</code> <code class="n">idata</code><code class="o">.</code><code class="n">prior</code><code class="p">[</code><code class="s2">"alpha"</code><code class="p">]</code> <code class="o">+</code> <code class="n">idata</code><code class="o">.</code><code class="n">prior</code><code class="p">[</code><code class="s2">"beta"</code><code class="p">]</code> <code class="o">*</code> <code class="n">feature_train</code>&#13;
&#13;
<code class="c1"># Prior_predictive is the data generating distribution of the untrained ensemble.</code>&#13;
<code class="n">prior_predictive</code> <code class="o">=</code> <code class="n">idata</code><code class="o">.</code><code class="n">prior_predictive</code><code class="p">[</code><code class="s1">'target_likelihood'</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># Create figure of subplots</code>&#13;
<code class="n">fig</code><code class="p">,</code> <code class="n">ax</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># Plot epistemic and aleatory uncertainties of untrained </code>&#13;
<code class="c1"># ensemble's retrodictions.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_lm</code><code class="p">(</code><code class="n">idata</code><code class="o">=</code><code class="n">idata</code><code class="p">,</code> <code class="n">x</code><code class="o">=</code><code class="n">feature_train</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="n">target_train</code><code class="p">,</code> &#13;
<code class="n">num_samples</code><code class="o">=</code><code class="mi">1000</code><code class="p">,</code> <code class="n">y_model</code> <code class="o">=</code> <code class="n">prior_target</code><code class="p">,</code> &#13;
<code class="n">y_hat</code> <code class="o">=</code> <code class="n">prior_predictive</code><code class="p">,</code> <code class="n">axes</code><code class="o">=</code><code class="n">ax</code><code class="p">)</code>&#13;
&#13;
<code class="c1">#Label the figure.</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_xlabel</code><code class="p">(</code><code class="s2">"Excess returns of S&amp;</code><code class="w"/>&#13;
<code class="n">P</code> <code class="mi">500</code><code class="s2">")</code><code class="w"/>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_ylabel</code><code class="p">(</code><code class="s2">"Excess returns of Apple"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_title</code><code class="p">(</code><code class="s2">"Retrodictions of untrained linear ensemble"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s1">'upper left'</code><code class="p">);</code></pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in05.png"/>&#13;
</div></figure>&#13;
&#13;
<p>It is very important to observe that the linear ensemble’s epistemic uncertainty increases as we move away from the center of the plot. Confessions of ignorance is what we are seeking in any model: it should become increasingly unsure about its expected values as it moves into regions where it has no data and must extrapolate. Our ensemble knows its limitations.</p>&#13;
&#13;
<p>This is seen more clearly in the next plot where we generate and distribute the prior predictive data samples into a 90% high-density interval (HDI) and then conduct a prior predictive check:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Plot 90% HDI of untrained ensemble.</code>&#13;
<code class="c1"># This will show the aleatory (data related) and epistemic </code>&#13;
<code class="c1"># (parameter related) uncertainty of model output before it is trained.</code>&#13;
&#13;
<code class="c1"># Create figure of subplots.</code>&#13;
<code class="n">fig</code><code class="p">,</code> <code class="n">ax</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># Plot the ensemble of 1000 regression lines to show the </code>&#13;
<code class="c1"># epistemic uncertainty around the mean regression line.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_lm</code><code class="p">(</code><code class="n">idata</code><code class="o">=</code><code class="n">idata</code><code class="p">,</code> <code class="n">x</code><code class="o">=</code><code class="n">feature_train</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="n">target_train</code><code class="p">,</code> &#13;
<code class="n">num_samples</code><code class="o">=</code><code class="mi">1000</code><code class="p">,</code> <code class="n">y_model</code> <code class="o">=</code> <code class="n">prior_target</code><code class="p">,</code> <code class="n">axes</code><code class="o">=</code><code class="n">ax</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Plot the prior predictive data within the 90% HDI band to </code>&#13;
<code class="c1"># show both epistemic and aleatory uncertainties.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_hdi</code><code class="p">(</code><code class="n">feature_train</code><code class="p">,</code> <code class="n">prior_predictive</code><code class="p">,</code> <code class="n">hdi_prob</code><code class="o">=</code><code class="mf">0.90</code><code class="p">,</code> <code class="n">smooth</code><code class="o">=</code><code class="kc">False</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Label figure.</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_xlabel</code><code class="p">(</code><code class="s2">"Excess returns of S&amp;P 500"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_ylabel</code><code class="p">(</code><code class="s2">"Excess returns of Apple"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_title</code><code class="p">(</code><code class="s2">"90% HDI for simulated samples of untrained linear ensemble"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">legend</code><code class="p">();</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in06.png"/>&#13;
</div></figure>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Conduct a prior predictive check of the untrained linear ensemble.</code>&#13;
<code class="c1"># Create figure of subplots.</code>&#13;
<code class="n">fig</code><code class="p">,</code> <code class="n">ax</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">()</code>&#13;
<code class="c1"># Plot the prior predictive check</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_ppc</code><code class="p">(</code><code class="n">idata</code><code class="p">,</code> <code class="n">group</code><code class="o">=</code><code class="s1">'prior'</code><code class="p">,</code> <code class="n">kind</code><code class="o">=</code><code class="s1">'cumulative'</code><code class="p">,</code> &#13;
<code class="n">num_pp_samples</code><code class="o">=</code><code class="mi">1000</code><code class="p">,</code> <code class="n">alpha</code><code class="o">=</code><code class="mf">0.1</code><code class="p">,</code> <code class="n">ax</code><code class="o">=</code><code class="n">ax</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Label the figure.</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_xlabel</code><code class="p">(</code><code class="s2">"Simulated Apple excess returns"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_ylabel</code><code class="p">(</code><code class="s2">"Cumulative Probability"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_title</code><code class="p">(</code><code class="s2">"Prior predictive check of untrained linear ensemble"</code><code class="p">);</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in07.png"/>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Evaluate and revise untrained model" data-type="sect3"><div class="sect3" id="evaluate_and_revise_untrained_model">&#13;
<h3>Evaluate and revise untrained model</h3>&#13;
&#13;
<p>Specifying a probabilistic model is never easy, and requires many revisions. Let’s use qualitative and quantitative prior predictive checks to see if our prior model is plausible and ready for training. From the recent plots, we can see that our ensemble has simulated all the training data within the 90% HDI band. However, the prior predictive check shows some low probability, extreme returns that have not occurred in the recent past. Let’s now compute the probabilistic R-squared measure to evaluate the ensemble’s retrodictions before it has been trained:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Evaluate untrained ensemble's retrodictions by comparing simulated </code>&#13;
<code class="c1"># data with training data.</code>&#13;
&#13;
<code class="c1"># Extract target values of our training data.</code>&#13;
<code class="n">target_actual</code> <code class="o">=</code> <code class="n">target_train</code><code class="o">.</code><code class="n">values</code>&#13;
&#13;
<code class="c1"># Sample the prior predictive distribution to simulate </code>&#13;
<code class="c1"># expected target training values.</code>&#13;
<code class="n">target_predicted</code> <code class="o">=</code> <code class="n">idata</code><code class="o">.</code><code class="n">prior_predictive</code><code class="o">.</code><code class="n">stack</code><code class="p">(</code><code class="n">sample</code><code class="o">=</code><code class="p">(</code><code class="s2">"chain"</code><code class="p">,</code> <code class="s2">"draw"</code><code class="p">))</code>&#13;
<code class="p">[</code><code class="s1">'target_likelihood'</code><code class="p">]</code><code class="o">.</code><code class="n">values</code><code class="o">.</code><code class="n">T</code>&#13;
&#13;
<code class="c1"># Use the probabilistic R-squared metric.</code>&#13;
<code class="n">prior_score</code> <code class="o">=</code> <code class="n">az</code><code class="o">.</code><code class="n">r2_score</code><code class="p">(</code><code class="n">target_actual</code><code class="p">,</code> <code class="n">target_predicted</code><code class="p">)</code>&#13;
<code class="n">prior_score</code><code class="o">.</code><code class="n">round</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>The probabilistic R-squared metric of the prior ensemble is 61%, with a standard deviation of 10%. This exceeds our performance benchmark of 55% for the prior model.</p>&#13;
&#13;
<p>Please note that this performance is a result of many revisions to the prior model I made by changing the values of the various parameters of the prior distributions. I also experimented with different distributions, including a uniform prior for the alpha parameter. All the prior scores were greater than 55%, and the one you see here is closer to the median score. Feel free to make your own revisions to the prior model until you are satisfied that your ensemble is plausible and ready to be trained by in-sample data.<a contenteditable="false" data-primary="" data-startref="ch07-prior" data-type="indexterm" id="id1309"/><a contenteditable="false" data-primary="" data-startref="ch07-prior2" data-type="indexterm" id="id1310"/><a contenteditable="false" data-primary="" data-startref="ch07-prior3" data-type="indexterm" id="id1311"/><a contenteditable="false" data-primary="" data-startref="ch07-prior4" data-type="indexterm" id="id1312"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Train and Retrodict Posterior Model" data-type="sect2"><div class="sect2" id="train_and_retrodict_posterior_model">&#13;
<h2>Train and Retrodict Posterior Model</h2>&#13;
&#13;
<p>We now have an ensemble<a contenteditable="false" data-primary="probabilistic financial models" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-tertiary="training and retrodicting posterior model" data-type="indexterm" id="ch07-trai"/><a contenteditable="false" data-primary="probabilistic linear ensembles" data-secondary="assembling with PyMC and ArviZ" data-tertiary="training and retrodicting posterior model" data-type="indexterm" id="ch07-trai2"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-tertiary="training and retrodicting posterior model" data-type="indexterm" id="ch07-trai3"/><a contenteditable="false" data-primary="PyMC library" data-secondary="assembling probabilistic linear ensembles" data-tertiary="training and retrodicting posterior model" data-type="indexterm" id="ch07-trai4"/> that is ready to be trained, and we are confident it reflects our prior knowledge, including the epistemic uncertainty of its parameters and the aleatory uncertainty of the data it might generate. Let’s train it with actual in-sample data our ensemble has been anticipating by computing the posterior distribution.</p>&#13;
&#13;
<section data-pdf-bookmark="Train and sample posterior" data-type="sect3"><div class="sect3" id="train_and_sample_posterior">&#13;
<h3>Train and sample posterior</h3>&#13;
&#13;
<p>We execute the default sampler of PyMC, the Hamiltonian Monte Carlo (HMC) algorithm, a second-generation MCMC algorithm. PyMC directs HMC to generate dependent random samples from the joint posterior distribution of all the <span class="keep-together">parameters:</span></p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Draw 1000 samples from two Markov chains resulting in 2000 values of each</code>&#13;
<code class="c1"># parameter to analyze the joint posterior distribution.</code>&#13;
<code class="c1"># Check for any divergences in the progress bar. We want 0 divergences for a </code>&#13;
<code class="c1"># reliable sampling of the posterior distribution.</code>&#13;
<code class="n">idata</code><code class="o">.</code><code class="n">extend</code><code class="p">(</code><code class="n">pm</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">draws</code><code class="o">=</code><code class="mi">1000</code><code class="p">,</code> <code class="n">chains</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">model</code><code class="o">=</code><code class="n">model</code><code class="p">,</code> <code class="n">random_seed</code><code class="o">=</code><code class="mi">101</code><code class="p">))</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in08.png"/>&#13;
</div></figure>&#13;
&#13;
<p class="pagebreak-before">Evaluating the quality of the MCMC sampling is an advanced topic and will not be covered in this primer. Since we have no divergences in the Markov chains, let’s analyze the marginal distribution of each parameter and make inferences about each of them:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Subplots on the left show the kernel density estimates (KDE)</code>&#13;
<code class="c1"># of the marginal posterior probability distributions of each parameter.</code>&#13;
<code class="c1"># Subplots on the right show the parameter values </code>&#13;
<code class="c1"># that were sampled sequentially in two chains by the NUTS sampler</code>&#13;
<code class="k">with</code> <code class="n">model</code><code class="p">:</code>&#13;
  <code class="n">az</code><code class="o">.</code><code class="n">plot_trace</code><code class="p">(</code><code class="n">idata</code><code class="o">.</code><code class="n">posterior</code><code class="p">,</code> <code class="n">kind</code><code class="o">=</code><code class="s1">'trace'</code><code class="p">,</code>&#13;
  <code class="n">var_names</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'alpha'</code><code class="p">,</code> <code class="s1">'beta'</code><code class="p">,</code> <code class="s1">'residual'</code><code class="p">],</code> <code class="n">legend</code><code class="o">=</code><code class="kc">True</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in09.png"/>&#13;
</div></figure>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Plot the joint posterior probability distribution of alpha and beta </code>&#13;
<code class="c1"># with their respective means and marginal distributions on the side.</code>&#13;
<code class="c1"># Hexabin plot below shows little or no linear correlation with the </code>&#13;
<code class="c1"># high concentration areas in the heat map forming a cloud.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_pair</code><code class="p">(</code><code class="n">idata</code><code class="o">.</code><code class="n">posterior</code><code class="p">,</code> <code class="n">var_names</code><code class="o">=</code><code class="p">[</code><code class="s1">'alpha'</code><code class="p">,</code> <code class="s1">'beta'</code><code class="p">],</code> <code class="n">kind</code><code class="o">=</code><code class="s1">'hexbin'</code><code class="p">,</code>&#13;
<code class="n">marginals</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> <code class="n">point_estimate</code><code class="o">=</code><code class="s1">'mean'</code><code class="p">,</code> <code class="n">colorbar</code><code class="o">=</code><code class="kc">True</code><code class="p">);</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in10.png"/>&#13;
</div></figure>&#13;
&#13;
<p>We can summarize the posterior distributions in a pandas DataFrame as follows:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Examine sample statistics of each parameter's posterior marginal distribution, </code>&#13;
<code class="c1"># including it's 94% highest density interval (HDI).</code>&#13;
<code class="n">display</code><code class="p">(</code><code class="n">az</code><code class="o">.</code><code class="n">summary</code><code class="p">(</code><code class="n">idata</code><code class="p">,</code> <code class="n">kind</code><code class="o">=</code><code class="s1">'stats'</code><code class="p">,</code> &#13;
<code class="n">var_names</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'alpha'</code><code class="p">,</code> <code class="s1">'beta'</code><code class="p">,</code> <code class="s1">'residual'</code><code class="p">],</code> <code class="n">round_to</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">hdi_prob</code><code class="o">=</code><code class="mf">0.94</code><code class="p">))</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in11.png"/>&#13;
</div></figure>&#13;
&#13;
<p>This statistical summary gives you the mean, standard deviation, and a 94% credible interval for all our parameters. Note that the 94% credible intervals are computed as the differences between the highest density intervals (HDI): hdi_97% – hdi_3% = hdi_94%.</p>&#13;
&#13;
<p>Unlike the shenanigans of frequentist confidence intervals discussed in <a data-type="xref" href="ch04.html#the_dangers_of_conventional_statistical">Chapter 4</a>, a credible interval is exactly what a confidence interval pretends to be but is not. Credible intervals are a postdata methodology for making valid statistical inferences from a single experiment. This is exactly what we want as researchers, scientists, and <span class="keep-together">practitioners</span> in any field. For instance, the 94% credible interval for beta in the summary table means the following:</p>&#13;
&#13;
<ul>&#13;
	<li>&#13;
	<p>There is a 94% probability that beta is in the <em>specific interval [1.12 and 1.55].</em> It is as simple as that. Unlike confidence intervals, we don’t have to deal with some warped definition that defies any semblance of common sense to interpret credible intervals.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>There are no assumptions of asymptotic normality of any distribution.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>There are no underhanded invocations to the central limit theorem.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Beta is not a point estimate with only aleatory uncertainty.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>We are ignorant of the exact value of beta. It is highly unlikely that we will ever know the exact values of any model parameter for any realistic scenario in the social and economic sciences.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Parameters like beta are better interpreted as probability distributions with both aleatory and epistemic uncertainties.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>It is much more realistic to model and interpret parameters like beta as unknowable variables rather than as unknowable constants.</p>&#13;
	</li>&#13;
</ul>&#13;
&#13;
<p>It is important to note that credible intervals are not unique within a posterior distribution. Our preferred way is to choose the narrowest interval with the highest probability density within the posterior distribution. Such an interval is also known as the highest-density interval (HDI) and is the method we have been following in this chapter.</p>&#13;
&#13;
<p>You might be wondering why PyMC/ArviZ developers have chosen the default credible interval to be 94%. It is a reminder that there are no physical or socioeconomic laws that dictate that we choose 95% or any other specific percentage. I believe it is a subtle dig at the conventional statistical community for sanctifying the 95% significance level in the social and economic sciences. At any rate, ArviZ provides a method for changing the default interval, as shown in the following code block:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Change the default highest density interval to 90%</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">rcParams</code><code class="p">[</code><code class="s1">'stats.hdi_prob'</code><code class="p">]</code> <code class="o">=</code> <code class="mf">0.90</code></pre>&#13;
&#13;
<p>It helps to visualize the posterior distributions of our model parameters for credible intervals with different probabilities. The following plot shows 70% credible intervals for all three parameters:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Plot the marginal posterior distribution of each parameter displaying </code>&#13;
<code class="c1"># the above statistics but now within a 70% HDI</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_posterior</code><code class="p">(</code><code class="n">idata</code><code class="p">,</code> <code class="n">var_names</code> <code class="o">=</code> <code class="p">[</code><code class="s1">'alpha'</code><code class="p">,</code> <code class="s1">'beta'</code><code class="p">,</code> <code class="s1">'residual'</code><code class="p">],</code> &#13;
<code class="n">hdi_prob</code><code class="o">=</code><code class="mf">0.70</code><code class="p">,</code> <code class="n">round_to</code><code class="o">=</code><code class="mi">3</code><code class="p">);</code></pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in12.png"/>&#13;
</div></figure>&#13;
&#13;
<p>More often than not, we have to evaluate point estimates in making our financial and investment decisions. We can estimate how plausible any point estimate of a parameter is based on where it lies within its posterior probability distribution. For instance, if we want to evaluate the point estimate = 1.15 for beta, we can use it as a reference value and compare it to an HDI, as shown in the following code:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Evaluate a point estimate for a single parameter using its </code>&#13;
<code class="c1"># posterior distribution.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_posterior</code><code class="p">(</code><code class="n">idata</code><code class="p">,</code> <code class="s1">'beta'</code><code class="p">,</code> <code class="n">ref_val</code><code class="o">=</code><code class="mf">1.15</code><code class="p">,</code> <code class="n">hdi_prob</code><code class="o">=</code><code class="mf">0.80</code><code class="p">,</code> &#13;
<code class="n">point_estimate</code><code class="o">=</code><code class="s1">'mode'</code><code class="p">,</code> <code class="n">round_to</code><code class="o">=</code><code class="mi">3</code><code class="p">);</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in13.png"/>&#13;
</div></figure>&#13;
&#13;
<p>This plot implies that 94.5% of the distribution is above beta = 1.15. Beta = 1.15 is in the left tail of the distribution since only 5.5% of the distribution is below it. Note that the two percentages may not add up to 100% because of rounding errors. So, it is reasonable to conclude that beta = 1.15 is not the best estimate.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Retrodict and simulate training data" data-type="sect3"><div class="sect3" id="retrodict_and_simulate_training_data">&#13;
<h3>Retrodict and simulate training data</h3>&#13;
&#13;
<p>We now use the posterior predictive distribution (PPD) to simulate data from the trained ensemble and follow the same steps we did with the ensemble’s prior predictive distribution. This will help us to evaluate how well the ensemble has been trained:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Draw 1000 samples each from two Markov chains of the </code>&#13;
<code class="c1"># posterior predictive distribution.</code>&#13;
<code class="k">with</code> <code class="n">model</code><code class="p">:</code>&#13;
  <code class="n">pm</code><code class="o">.</code><code class="n">sample_posterior_predictive</code><code class="p">(</code><code class="n">idata</code><code class="p">,</code> <code class="n">extend_inferencedata</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> &#13;
  <code class="n">random_seed</code><code class="o">=</code><code class="mi">101</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Generate 2000 linear regression lines based on 1000 draws each from </code>&#13;
<code class="c1"># two chains of the posterior distributions of alpha and beta.</code>&#13;
<code class="c1"># Posterior target values are in 2000 arrays, each with 21 samples, </code>&#13;
<code class="c1"># the same number of samples as our training data set.</code>&#13;
<code class="n">posterior</code> <code class="o">=</code> <code class="n">idata</code><code class="o">.</code><code class="n">posterior</code>&#13;
<code class="n">posterior_target</code> <code class="o">=</code> <code class="n">posterior</code><code class="p">[</code><code class="s2">"alpha"</code><code class="p">]</code> <code class="o">+</code> <code class="n">posterior</code><code class="p">[</code><code class="s2">"beta"</code><code class="p">]</code> <code class="o">*</code> <code class="n">feature_train</code>&#13;
&#13;
<code class="c1"># Posterior_predictive is the data generating distribution of the </code>&#13;
<code class="c1"># trained ensemble.</code>&#13;
<code class="n">posterior_predictive</code> <code class="o">=</code> <code class="n">idata</code><code class="o">.</code><code class="n">posterior_predictive</code><code class="p">[</code><code class="s1">'target_likelihood'</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># Create figure of subplots.</code>&#13;
<code class="n">fig</code><code class="p">,</code> <code class="n">ax</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># Plot epistemic and aleatory uncertainties of trained </code>&#13;
<code class="c1"># ensemble's retrodictions.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_lm</code><code class="p">(</code><code class="n">idata</code><code class="o">=</code><code class="n">idata</code><code class="p">,</code> <code class="n">x</code><code class="o">=</code><code class="n">feature_train</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="n">target_train</code><code class="p">,</code> <code class="n">num_samples</code><code class="o">=</code><code class="mi">2000</code><code class="p">,</code>&#13;
<code class="n">y_model</code> <code class="o">=</code> <code class="n">posterior_target</code><code class="p">,</code> <code class="n">y_hat</code><code class="o">=</code><code class="n">posterior_predictive</code><code class="p">,</code> <code class="n">axes</code><code class="o">=</code><code class="n">ax</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Label the figure.</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_xlabel</code><code class="p">(</code><code class="s2">"Excess returns of S&amp;P 500"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_ylabel</code><code class="p">(</code><code class="s2">"Excess returns of Apple"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_title</code><code class="p">(</code><code class="s2">"Retrodictions of the trained linear ensemble"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s1">'upper left'</code><code class="p">);</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in14.png"/>&#13;
</div></figure>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Plot 90% HDI of trained ensemble.</code>&#13;
<code class="c1"># This will show the aleatory (data related) and epistemic </code>&#13;
<code class="c1"># (parameter related) uncertainty of model output after it is trained.</code>&#13;
&#13;
<code class="c1"># Create figure of subplots.</code>&#13;
<code class="n">fig</code><code class="p">,</code> <code class="n">ax</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># Plot the ensemble of 2000 regression lines to show the epistemic </code>&#13;
<code class="c1"># uncertainty around the mean regression line.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_lm</code><code class="p">(</code><code class="n">idata</code><code class="o">=</code><code class="n">idata</code><code class="p">,</code> <code class="n">x</code><code class="o">=</code><code class="n">feature_train</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="n">target_train</code><code class="p">,</code> <code class="n">num_samples</code><code class="o">=</code><code class="mi">1000</code><code class="p">,</code>&#13;
<code class="n">y_model</code> <code class="o">=</code> <code class="n">posterior_target</code><code class="p">,</code> <code class="n">axes</code><code class="o">=</code><code class="n">ax</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Plot the posterior predictive data within the 90% HDI band to show both </code>&#13;
<code class="c1"># epistemic and aleatory uncertainties.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_hdi</code><code class="p">(</code><code class="n">feature_train</code><code class="p">,</code> <code class="n">posterior_predictive</code><code class="p">,</code> <code class="n">hdi_prob</code><code class="o">=</code><code class="mf">0.90</code><code class="p">,</code> <code class="n">smooth</code><code class="o">=</code><code class="kc">False</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Label the figure</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_xlabel</code><code class="p">(</code><code class="s2">"Excess returns of S&amp;P 500"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_ylabel</code><code class="p">(</code><code class="s2">"Excess returns of Apple"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_title</code><code class="p">(</code><code class="s2">"90% HDI for simulated samples of trained linear ensemble"</code><code class="p">);</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in15.png"/>&#13;
</div></figure>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Conduct a posterior predictive check of the trained linear ensemble.</code>&#13;
&#13;
<code class="c1"># Create a figure of subplots.</code>&#13;
<code class="n">fig</code><code class="p">,</code> <code class="n">ax</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># Plot the posterior predictive check.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_ppc</code><code class="p">(</code><code class="n">idata</code><code class="p">,</code> <code class="n">group</code><code class="o">=</code><code class="s1">'posterior'</code><code class="p">,</code> <code class="n">kind</code><code class="o">=</code><code class="s1">'cumulative'</code><code class="p">,</code> &#13;
<code class="n">num_pp_samples</code><code class="o">=</code><code class="mi">2000</code><code class="p">,</code> <code class="n">alpha</code><code class="o">=</code><code class="mf">0.1</code><code class="p">,</code> <code class="n">ax</code><code class="o">=</code><code class="n">ax</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Label the figure.</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_xlabel</code><code class="p">(</code><code class="s2">"Simulated Apple excess returns given training data"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_ylabel</code><code class="p">(</code><code class="s2">"Cumulative Probability"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_title</code><code class="p">(</code><code class="s2">"Posterior predictive check of trained ensemble"</code><code class="p">);</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in16.png"/>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Evaluate and revise trained model" data-type="sect3"><div class="sect3" id="evaluate_and_revise_trained_model">&#13;
<h3>Evaluate and revise trained model</h3>&#13;
&#13;
<p>As we did earlier, let’s use qualitative and quantitative checks to see if our posterior model is plausible and ready for testing. The posterior predictive check shows us a range of returns that are more consistent with the recent historical returns of Apple. From its retrodictions, we can see that our ensemble has simulated most of the training data it has been trained on within the 90% HDI band. Let’s now compute the probabilistic R-squared measure to evaluate the trained  ensemble’s performance:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Evaluate trained ensemble's retrodictions by comparing</code>&#13;
<code class="c1"># simulated data with training data.</code>&#13;
&#13;
<code class="c1"># Get target values of our training data</code>&#13;
<code class="n">target_actual</code> <code class="o">=</code> <code class="n">target_train</code><code class="o">.</code><code class="n">values</code>&#13;
&#13;
<code class="c1"># Sample the posterior predictive distribution </code>&#13;
<code class="c1"># conditioned on training data.</code>&#13;
<code class="n">target_predicted</code> <code class="o">=</code> <code class="n">idata</code><code class="o">.</code><code class="n">posterior_predictive</code><code class="o">.</code><code class="n">stack</code><code class="p">(</code><code class="n">sample</code><code class="o">=</code><code class="p">(</code><code class="s2">"chain"</code><code class="p">,</code> <code class="s2">"draw"</code><code class="p">))</code>&#13;
<code class="p">[</code><code class="s1">'target_likelihood'</code><code class="p">]</code><code class="o">.</code><code class="n">values</code><code class="o">.</code><code class="n">T</code>&#13;
&#13;
<code class="c1"># Compute probabilistic R-squared performance metric.</code>&#13;
<code class="n">training_score</code> <code class="o">=</code> <code class="n">az</code><code class="o">.</code><code class="n">r2_score</code><code class="p">(</code><code class="n">target_actual</code><code class="p">,</code> <code class="n">target_predicted</code><code class="p">)</code>&#13;
<code class="n">training_score</code><code class="o">.</code><code class="n">round</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p class="pagebreak-before">The probabilistic R-squared metric of the posterior ensemble is 65%, with a standard deviation of 8%. This is a performance improvement compared to that of the untrained ensemble. We can make this comparison because we are using the same dataset to make the performance comparison. It also exceeds the training score benchmark of 60%. Our ensemble is ready for its main test: predictions based on out-of-sample or unseen test data.<a contenteditable="false" data-primary="" data-startref="ch07-trai" data-type="indexterm" id="id1313"/><a contenteditable="false" data-primary="" data-startref="ch07-trai2" data-type="indexterm" id="id1314"/><a contenteditable="false" data-primary="" data-startref="ch07-trai3" data-type="indexterm" id="id1315"/><a contenteditable="false" data-primary="" data-startref="ch07-trai4" data-type="indexterm" id="id1316"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Test and Evaluate Ensemble Predictions" data-type="sect2"><div class="sect2" id="test_and_evaluate_ensemble_predictions">&#13;
<h2>Test and Evaluate Ensemble Predictions</h2>&#13;
&#13;
<p>We are now confident that<a contenteditable="false" data-primary="probabilistic financial models" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-tertiary="testing and evaluating ensemble predictions" data-type="indexterm" id="ch07-test"/><a contenteditable="false" data-primary="probabilistic linear ensembles" data-secondary="assembling with PyMC and ArviZ" data-tertiary="testing and evaluating ensemble predictions" data-type="indexterm" id="ch07-test2"/><a contenteditable="false" data-primary="probabilistic machine learning (PML)" data-secondary="PyMC library for assembling probabilistic linear ensembles" data-tertiary="testing and evaluating ensemble predictions" data-type="indexterm" id="ch07-test3"/><a contenteditable="false" data-primary="PyMC library" data-secondary="assembling probabilistic linear ensembles" data-tertiary="testing and evaluating ensemble predictions" data-type="indexterm" id="ch07-test4"/> our trained ensemble reflects both our prior knowledge and new learnings from the in-sample data that were observed. Moreover, the ensemble has updated its parameter probability distributions in light of the training data, including their epistemic uncertainties. Consequently, the data distributions that the ensemble will generate have also been updated, including their aleatory uncertainties.</p>&#13;
&#13;
<p>The various steps that led us here are all necessary but not sufficient for us to decide if we are going to commit hard-earned capital to the predictions of our ensemble. One of the most important tests for any ML system is how well it performs on previously unseen, out-of-sample test data.</p>&#13;
&#13;
<section data-pdf-bookmark="Swap data and resample posterior predictive distribution" data-type="sect3"><div class="sect3" id="swap_data_and_resample_posterior_predic">&#13;
<h3>Swap data and resample posterior predictive distribution</h3>&#13;
&#13;
<p>PyMC provides mutable data containers that enable the swapping of training data for test data without any other changes to the ensemble. We now have to resample the posterior predictive distribution with the new test data for our target and features.</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Now we use our trained model to make predictions based on test data. </code>&#13;
<code class="c1"># This is the reason we created mutable data containers earlier.</code>&#13;
<code class="k">with</code> <code class="n">model</code><code class="p">:</code>&#13;
    <code class="c1">#Swap feature and target training data for their respective test data.</code>&#13;
    <code class="n">pm</code><code class="o">.</code><code class="n">set_data</code><code class="p">({</code><code class="s1">'feature'</code><code class="p">:</code> <code class="n">x_test</code><code class="p">,</code> <code class="s1">'target'</code><code class="p">:</code> <code class="n">y_test</code><code class="p">})</code>&#13;
    <code class="c1">#Create two new inference groups, predictions and predictions_constant_data </code>&#13;
    <code class="c1">#for making predictions based on features in the test data.</code>&#13;
    <code class="n">pm</code><code class="o">.</code><code class="n">sample_posterior_predictive</code><code class="p">(</code><code class="n">idata</code><code class="p">,</code> <code class="n">return_inferencedata</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> &#13;
    <code class="n">predictions</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> <code class="n">extend_inferencedata</code><code class="o">=</code><code class="kc">True</code><code class="p">,</code> <code class="n">random_seed</code><code class="o">=</code><code class="mi">101</code><code class="p">)</code>&#13;
</pre>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Predict and simulate test data" data-type="sect3"><div class="sect3" id="predict_and_simulate_test_data">&#13;
<h3>Predict and simulate test data</h3>&#13;
&#13;
<p>This creates a new inference group called predictions. We repeat the same steps as we did in the training phase but use test data instead:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Get feature and target test data.</code>&#13;
<code class="n">feature_test</code> <code class="o">=</code> <code class="n">idata</code><code class="o">.</code><code class="n">predictions_constant_data</code><code class="p">[</code><code class="s1">'feature'</code><code class="p">]</code>&#13;
<code class="n">target_test</code> <code class="o">=</code> <code class="n">idata</code><code class="o">.</code><code class="n">predictions_constant_data</code><code class="p">[</code><code class="s1">'target'</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># Prediction target values are in 2000 arrays, each with 10 samples,</code>&#13;
<code class="c1"># the same number of samples as our test data set. Predict target values </code>&#13;
<code class="c1"># based on posterior values of regression parameters and feature test data.</code>&#13;
<code class="n">prediction_target</code> <code class="o">=</code> <code class="n">posterior</code><code class="p">[</code><code class="s2">"alpha"</code><code class="p">]</code> <code class="o">+</code> <code class="n">posterior</code><code class="p">[</code><code class="s2">"beta"</code><code class="p">]</code> <code class="o">*</code> <code class="n">feature_test</code>&#13;
&#13;
<code class="c1"># Predictions is the data generating posterior predictive distribution </code>&#13;
<code class="c1"># of the trained ensemble based on test data.</code>&#13;
<code class="n">simulate_predictions</code> <code class="o">=</code> <code class="n">idata</code><code class="o">.</code><code class="n">predictions</code><code class="p">[</code><code class="s1">'target_likelihood'</code><code class="p">]</code>&#13;
&#13;
<code class="c1"># Create figure of subplots.</code>&#13;
<code class="n">fig</code><code class="p">,</code> <code class="n">ax</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># Plot the 2000 regression lines showing the epistemic and </code>&#13;
<code class="c1"># aleatory uncertainties of out-of-sample predictions.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_lm</code><code class="p">(</code><code class="n">idata</code><code class="o">=</code><code class="n">idata</code><code class="p">,</code> <code class="n">x</code><code class="o">=</code><code class="n">feature_test</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="n">target_test</code><code class="p">,</code> <code class="n">num_samples</code><code class="o">=</code><code class="mi">2000</code><code class="p">,</code> &#13;
<code class="n">y_model</code> <code class="o">=</code> <code class="n">prediction_target</code><code class="p">,</code> <code class="n">y_hat</code><code class="o">=</code><code class="n">simulate_predictions</code><code class="p">,</code> <code class="n">axes</code><code class="o">=</code><code class="n">ax</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Label figure</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_xlabel</code><code class="p">(</code><code class="s2">"Excess returns of S&amp;P 500"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_ylabel</code><code class="p">(</code><code class="s2">"Excess returns of Apple"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_title</code><code class="p">(</code><code class="s2">"Predictions of trained linear ensemble"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s1">'upper left'</code><code class="p">);</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in17.png"/>&#13;
</div></figure>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Plot 90% HDI of trained ensemble. This will show the aleatory </code>&#13;
<code class="c1"># (data related) and epistemic (parameter related) uncertainty </code>&#13;
<code class="c1"># of trained model's predictions based on test data.</code>&#13;
&#13;
<code class="c1"># Create figure of subplots.</code>&#13;
<code class="n">fig</code><code class="p">,</code> <code class="n">ax</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">()</code>&#13;
&#13;
<code class="c1"># Plot the ensemble of 2000 regression lines to show the epistemic uncertainty </code>&#13;
<code class="c1"># around the mean regression line.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_lm</code><code class="p">(</code><code class="n">idata</code><code class="o">=</code><code class="n">idata</code><code class="p">,</code> <code class="n">x</code><code class="o">=</code><code class="n">feature_test</code><code class="p">,</code> <code class="n">y</code><code class="o">=</code><code class="n">target_test</code><code class="p">,</code> &#13;
<code class="n">num_samples</code><code class="o">=</code><code class="mi">2000</code><code class="p">,</code> <code class="n">y_model</code> <code class="o">=</code> <code class="n">prediction_target</code><code class="p">,</code> <code class="n">axes</code><code class="o">=</code><code class="n">ax</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Plot the posterior predictive data within the 90% HDI band </code>&#13;
<code class="c1"># to show both epistemic and aleatory uncertainties.</code>&#13;
<code class="n">az</code><code class="o">.</code><code class="n">plot_hdi</code><code class="p">(</code><code class="n">feature_test</code><code class="p">,</code> <code class="n">simulate_predictions</code><code class="p">,</code> &#13;
<code class="n">hdi_prob</code><code class="o">=</code><code class="mf">0.90</code><code class="p">,</code> <code class="n">smooth</code><code class="o">=</code><code class="kc">False</code><code class="p">)</code>&#13;
&#13;
<code class="c1"># Label the figure.</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_xlabel</code><code class="p">(</code><code class="s2">"Excess returns of S&amp;P 500"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_ylabel</code><code class="p">(</code><code class="s2">"Excess returns of Apple"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">set_title</code><code class="p">(</code><code class="s2">"90% HDI for predictions of trained linear ensemble"</code><code class="p">)</code>&#13;
<code class="n">ax</code><code class="o">.</code><code class="n">legend</code><code class="p">();</code>&#13;
</pre>&#13;
&#13;
<figure class="informal"><div class="figure"><img alt="Image" src="assets/pmlf_07in18.png"/>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Evaluate, revise, or deploy ensemble" data-type="sect3"><div class="sect3" id="evaluatecomma_revisecomma_or_deploy_ens">&#13;
<h3>Evaluate, revise, or deploy ensemble</h3>&#13;
&#13;
<p>From the recent plot we can see that our ensemble has simulated all of the test data within the 90% HDI band. Let’s also compute the probabilistic R-squared measure to evaluate the ensemble’s predictive performance:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting">&#13;
<code class="c1"># Evaluate out-of-sample predictions of trained </code>&#13;
<code class="c1"># ensemble by comparing simulated data with test data.</code>&#13;
&#13;
<code class="c1"># Get target values of the test data.</code>&#13;
<code class="n">target_actual</code> <code class="o">=</code> <code class="n">target_test</code><code class="o">.</code><code class="n">values</code>&#13;
&#13;
<code class="c1"># Sample ensemble's predictions based on test data.</code>&#13;
<code class="n">target_predicted</code> <code class="o">=</code> <code class="n">idata</code><code class="o">.</code><code class="n">predictions</code><code class="o">.</code><code class="n">stack</code><code class="p">(</code><code class="n">sample</code><code class="o">=</code><code class="p">(</code><code class="s2">"chain"</code><code class="p">,</code> <code class="s2">"draw"</code><code class="p">))</code>&#13;
<code class="p">[</code><code class="s1">'target_likelihood'</code><code class="p">]</code><code class="o">.</code><code class="n">values</code><code class="o">.</code><code class="n">T</code>&#13;
&#13;
<code class="c1"># Compute the probabilistic R-squared performance metric.</code>&#13;
<code class="n">test_score</code> <code class="o">=</code> <code class="n">az</code><code class="o">.</code><code class="n">r2_score</code><code class="p">(</code><code class="n">target_actual</code><code class="p">,</code> <code class="n">target_predicted</code><code class="p">)</code>&#13;
<code class="n">test_score</code><code class="o">.</code><code class="n">round</code><code class="p">(</code><code class="mi">2</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>The probabilistic R-squared metric of the tested ensemble is 69%, with a standard deviation of 13%. It is better than our training score and exceeds the test score benchmark of 65%. We are ready to deploy our tested ensemble into our paper trading system or other simulated financial system that uses real-time data feeds with fictitious capital. This enables us to evaluate how our ensemble performs in real time before we are ready to deploy it into production and commit real hard-earned capital to our system.<a contenteditable="false" data-primary="" data-startref="ch07-assem" data-type="indexterm" id="id1317"/><a contenteditable="false" data-primary="" data-startref="ch07-assem2" data-type="indexterm" id="id1318"/><a contenteditable="false" data-primary="" data-startref="ch07-assem3" data-type="indexterm" id="id1319"/><a contenteditable="false" data-primary="" data-startref="ch07-assem4" data-type="indexterm" id="id1320"/><a contenteditable="false" data-primary="" data-startref="ch07-assem5" data-type="indexterm" id="id1321"/><a contenteditable="false" data-primary="" data-startref="ch07-assem6" data-type="indexterm" id="id1322"/><a contenteditable="false" data-primary="" data-startref="ch07-assem7" data-type="indexterm" id="id1323"/><a contenteditable="false" data-primary="" data-startref="ch07-assem8" data-type="indexterm" id="id1324"/><a contenteditable="false" data-primary="" data-startref="ch07-test" data-type="indexterm" id="id1325"/><a contenteditable="false" data-primary="" data-startref="ch07-test2" data-type="indexterm" id="id1326"/><a contenteditable="false" data-primary="" data-startref="ch07-test3" data-type="indexterm" id="id1327"/><a contenteditable="false" data-primary="" data-startref="ch07-test4" data-type="indexterm" id="id1328"/></p>&#13;
</div></section>&#13;
</div></section>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="summary-id00027">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>In this chapter, we saw how probabilistic linear regression (PLE) modeling is fundamentally different from conventional linear regression (MLE) modeling. The probabilistic framework provides a systematic method for modeling physical phenomena in general and financial realities in particular.</p>&#13;
&#13;
<p>Conventional financial models use the MLE method to compute the optimal values of parameters that fit the data. That would be appropriate if we were dealing with time-invariant statistical distributions. It is inappropriate in finance because we don’t have such time-invariant distributions. Learning optimal parameter values from noisy financial data is suboptimal and risky. Instead of relying on one expert in such a situation, we are better off relying on a council of experts for the many possible scenarios that are plausible and synthesize their expertise. This is exactly what a probabilistic ensemble does for us. It gives us the weighted average of all the estimates of model parameters.</p>&#13;
&#13;
<p class="pagebreak-before">In probabilistic regression modeling, as opposed to conventional linear modeling, data are treated as fixed and parameters are treated as variables because common sense and facts support such an approach. There is no need for the conventional use of ad hoc methods like L1 and L2 regularization, which are merely prior probability distributions in disguise. Most importantly, in the probabilistic paradigm, we are freed from ideological dictums like “let only the data speak for themselves” and unscientific claims of the existence of “true models” or “true parameters.”</p>&#13;
&#13;
<p>Probabilistic ensembles make no pretense to analytical elegance. They do not lull us into a false sense of security about our financial activities with point estimates and bogus analytical solutions fit only for toy problems. Probabilistic ensembles are numerical and messy models that quantify aleatory and epistemic uncertainties. These models are suited for endemic uncertainties of finance and investing. Most importantly, it reminds us of the uncertainty of our knowledge, inferences, and <span class="keep-together">predictions.</span></p>&#13;
&#13;
<p>In the next chapter, we will explore how to apply our probabilistic estimates and predictions to decision making in the face of three-dimensional uncertainty and incomplete information.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="References" data-type="sect1"><div class="sect1" id="references-id00017">&#13;
<h1>References</h1>&#13;
&#13;
<p>Dürr, Oliver, and Beate Sick. <em>Probabilistic Deep Learning with Python, Keras, and TensorFlow Probability</em>. Manning Publications, 2020.</p>&#13;
&#13;
<p>Gelman Andrew, Ben Goodrich, Jonah Gabry, and Aki Vehtari. “R-Squared for Bayesian Regression Models.” <em>The American Statistician</em> 73, no. 3 (2019): 307–309. <a href="https://doi.org/10.1080/00031305.2018.1549100"><em class="hyperlink">https://doi.org/10.1080/00031305.2018.1549100</em></a>.</p>&#13;
&#13;
<p>Murphy, Kevin P. <em>Machine Learning: A Probabilistic Perspective</em>. Cambridge, MA: The MIT Press, 2012.</p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Further Reading" data-type="sect1"><div class="sect1" id="further_reading-id00009">&#13;
<h1>Further Reading</h1>&#13;
&#13;
<p>Martin, Osvaldo A., Ravin Kumar, and Junpeng Lao. <em>Bayesian Modeling and Computation in Python</em>. 1st ed. Boca Raton, FL: CRC Press, 2021.</p>&#13;
</div></section>&#13;
<div data-type="footnotes"><p data-type="footnote" id="ch07fn1"><sup><a href="ch07.html#ch07fn1-marker">1</a></sup> Adapted from an image on Wikimedia Commons.</p><p data-type="footnote" id="ch07fn2"><sup><a href="ch07.html#ch07fn2-marker">2</a></sup> Oliver Dürr and Beate Sick, “Building Loss Functions with the Likelihood Approach,” in <em>Probabilistic Deep Learning with Python, Keras, and TensorFlow Probability</em> (Manning Publications, 2020), 93–127.</p><p data-type="footnote" id="ch07fn3"><sup><a href="ch07.html#ch07fn3-marker">3</a></sup> Kevin P. Murphy, “Sparse Linear Models,” in <em>Machine Learning: A Probabilistic Perspective</em> (Cambridge, MA: The MIT Press, 2012), 421–78.</p><p data-type="footnote" id="ch07fn4"><sup><a href="ch07.html#ch07fn4-marker">4</a></sup> Andrew Gelman et al., “R-Squared for Bayesian Regression Models,” <em>The American Statistician</em> 73, no. 3 (2019): 307–309, <a href="https://doi.org/10.1080/00031305.2018.1549100"><em class="hyperlink">https://doi.org/10.1080/00031305.2018.1549100</em></a>.</p></div></div></section></body></html>