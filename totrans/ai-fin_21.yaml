- en: Appendix A. Interactive Neural Networks
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 附录 A. 交互式神经网络
- en: This appendix explores fundamental notions of neural networks with basic Python
    code—on the basis of both simple and shallow neural networks. The goal is to provide
    a good grasp and intuition for important concepts that often disappear behind
    high-level, abstract APIs when working with standard machine and deep learning
    packages.
  id: totrans-1
  prefs: []
  type: TYPE_NORMAL
  zh: 本附录通过基础的 Python 代码探讨了神经网络的基本概念，涵盖了简单和浅层神经网络。其目标是帮助读者对重要概念有一个深入的理解和直观感受，这些概念在使用标准机器学习和深度学习包时往往被高级抽象的
    API 所掩盖。
- en: 'The appendix has the following sections:'
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 本附录包含以下部分：
- en: '[“Tensors and Tensor Operations”](#app_inn_tensors) covers the basics of *tensors*
    and the operations implemented on them.'
  id: totrans-3
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“张量和张量操作”](#app_inn_tensors)介绍了*张量*的基础知识和在其上实施的操作。'
- en: '[“Simple Neural Networks”](#app_inn_sinn) discusses *simple neural networks*,
    or neural networks that only have an input and an output layer.'
  id: totrans-4
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“简单神经网络”](#app_inn_sinn)讨论*简单神经网络*，即只有输入层和输出层的神经网络。'
- en: '[“Shallow Neural Networks”](#app_inn_shnn) focuses on *shallow neural networks*,
    or neural networks with one hidden layer.'
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '[“浅层神经网络”](#app_inn_shnn)关注*浅层神经网络*，即只有一个隐藏层的神经网络。'
- en: Tensors and Tensor Operations
  id: totrans-6
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 张量和张量操作
- en: 'In addition to implementing several imports and configurations, the following
    Python code shows the four types of tensors relevant for the purposes of this
    appendix: scalar, vector, matrix, and cube tensors. Tensors are generally represented
    as potentially multidimensional `ndarray` objects in Python. For more details
    and examples, see Chollet (2017, ch. 2):'
  id: totrans-7
  prefs: []
  type: TYPE_NORMAL
  zh: 除了实现多个导入和配置外，以下 Python 代码展示了本附录目的上相关的四种张量类型：标量、向量、矩阵和立方体张量。在 Python 中，张量通常表示为可能是多维
    `ndarray` 对象。有关更多详细信息和示例，请参阅 Chollet（2017，第 2 章）：
- en: '[PRE0]'
  id: totrans-8
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: '[![1](Images/1.png)](#co_interactive_neural_networks_CO1-1)'
  id: totrans-9
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_interactive_neural_networks_CO1-1)'
- en: Scalar tensor
  id: totrans-10
  prefs: []
  type: TYPE_NORMAL
  zh: 标量张量
- en: '[![2](Images/2.png)](#co_interactive_neural_networks_CO1-3)'
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_interactive_neural_networks_CO1-3)'
- en: Vector tensor
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 向量张量
- en: '[![3](Images/3.png)](#co_interactive_neural_networks_CO1-5)'
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_interactive_neural_networks_CO1-5)'
- en: Matrix tensor
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 矩阵张量
- en: '[![4](Images/4.png)](#co_interactive_neural_networks_CO1-7)'
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_interactive_neural_networks_CO1-7)'
- en: Cube tensor
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 立方体张量
- en: 'In a neural network context, several mathematical operations on tensors are
    of importance, such as element-wise operations or the dot product:'
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 在神经网络的背景下，张量上的几种数学操作非常重要，例如逐元素操作或点积：
- en: '[PRE1]'
  id: totrans-18
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: '[![1](Images/1.png)](#co_interactive_neural_networks_CO2-1)'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_interactive_neural_networks_CO2-1)'
- en: Broadcasting operation
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 广播操作
- en: '[![2](Images/2.png)](#co_interactive_neural_networks_CO2-2)'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_interactive_neural_networks_CO2-2)'
- en: Element-wise operation
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 逐元素操作
- en: '[![3](Images/3.png)](#co_interactive_neural_networks_CO2-3)'
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_interactive_neural_networks_CO2-3)'
- en: Dot product with `NumPy` function
  id: totrans-24
  prefs: []
  type: TYPE_NORMAL
  zh: 用 `NumPy` 函数进行点积
- en: '[![4](Images/4.png)](#co_interactive_neural_networks_CO2-4)'
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_interactive_neural_networks_CO2-4)'
- en: Dot product in explicit notation
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: 显式符号中的点积
- en: Simple Neural Networks
  id: totrans-27
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 简单神经网络
- en: Equipped with the basics of tensors, consider simple neural networks, which
    only have an input layer and an output layer.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 理解张量的基础后，考虑仅有输入层和输出层的简单神经网络。
- en: Estimation
  id: totrans-29
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 估计
- en: 'The first problem is an *estimation problem* for which the labels are real-valued:'
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 第一个问题是一个*估计问题*，其标签是实值的：
- en: '[PRE2]'
  id: totrans-31
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: '[![1](Images/1.png)](#co_interactive_neural_networks_CO3-1)'
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_interactive_neural_networks_CO3-1)'
- en: Number of features
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 特征数量
- en: '[![2](Images/2.png)](#co_interactive_neural_networks_CO3-2)'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_interactive_neural_networks_CO3-2)'
- en: Number of samples
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 样本数量
- en: '[![3](Images/3.png)](#co_interactive_neural_networks_CO3-3)'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_interactive_neural_networks_CO3-3)'
- en: Random input layer
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 随机输入层
- en: '[![4](Images/4.png)](#co_interactive_neural_networks_CO3-5)'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_interactive_neural_networks_CO3-5)'
- en: Random weights
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 随机权重
- en: '[![5](Images/5.png)](#co_interactive_neural_networks_CO3-7)'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_interactive_neural_networks_CO3-7)'
- en: Output layer via dot product
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 通过点积的输出层
- en: '[![6](Images/6.png)](#co_interactive_neural_networks_CO3-9)'
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#co_interactive_neural_networks_CO3-9)'
- en: Labels to be learned
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 待学习的标签
- en: 'The following Python code goes step by step through a learning episode, from
    the calculation of the errors to the calculation of the mean-squared error (MSE)
    after the weights have been updated:'
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 下面的 Python 代码逐步展示了一个学习过程，从计算误差到在更新权重后计算均方误差（MSE）：
- en: '[PRE3]'
  id: totrans-45
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '[![1](Images/1.png)](#co_interactive_neural_networks_CO4-1)'
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_interactive_neural_networks_CO4-1)'
- en: Errors in estimation
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 估计误差
- en: '[![2](Images/2.png)](#co_interactive_neural_networks_CO4-3)'
  id: totrans-48
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_interactive_neural_networks_CO4-3)'
- en: MSE value given the estimation
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 给定估计的均方误差值
- en: '[![3](Images/3.png)](#co_interactive_neural_networks_CO4-5)'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_interactive_neural_networks_CO4-5)'
- en: Backward propagation (here `d = e`)^([1](app01.xhtml#idm45625236964232))
  id: totrans-51
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播（这里 `d = e`）^([1](app01.xhtml#idm45625236964232))
- en: '[![4](Images/4.png)](#co_interactive_neural_networks_CO4-7)'
  id: totrans-52
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_interactive_neural_networks_CO4-7)'
- en: The learning rate
  id: totrans-53
  prefs: []
  type: TYPE_NORMAL
  zh: 学习率
- en: '[![5](Images/5.png)](#co_interactive_neural_networks_CO4-8)'
  id: totrans-54
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_interactive_neural_networks_CO4-8)'
- en: The update values
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 更新值
- en: '[![6](Images/6.png)](#co_interactive_neural_networks_CO4-10)'
  id: totrans-56
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#co_interactive_neural_networks_CO4-10)'
- en: Weights before and after update
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: 更新前后的权重
- en: '[![7](Images/7.png)](#co_interactive_neural_networks_CO4-13)'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](Images/7.png)](#co_interactive_neural_networks_CO4-13)'
- en: New output layer (estimation) after update
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 更新后的新输出层（估计）
- en: '[![8](Images/8.png)](#co_interactive_neural_networks_CO4-14)'
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: '[![8](Images/8.png)](#co_interactive_neural_networks_CO4-14)'
- en: New error values after update
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 更新后的新误差值
- en: '[![9](Images/9.png)](#co_interactive_neural_networks_CO4-15)'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: '[![9](Images/9.png)](#co_interactive_neural_networks_CO4-15)'
- en: New MSE values after update
  id: totrans-63
  prefs: []
  type: TYPE_NORMAL
  zh: 更新后的新均方误差值
- en: 'To improve the estimation, the same procedure needs to be repeated in general
    a larger number of times. In the following code, the learning rate is increased
    and the procedure is executed a few hundred times. The final MSE value is quite
    low and the estimation quite good:'
  id: totrans-64
  prefs: []
  type: TYPE_NORMAL
  zh: 为了提高估计精度，通常需要重复相同的步骤多次。在下面的代码中，学习率增加，并且该过程执行了数百次。最终的均方误差值非常低，估计非常好：
- en: '[PRE4]'
  id: totrans-65
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: '[![1](Images/1.png)](#co_interactive_neural_networks_CO5-1)'
  id: totrans-66
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_interactive_neural_networks_CO5-1)'
- en: Adjusted learning rate
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 调整后的学习率
- en: '[![2](Images/2.png)](#co_interactive_neural_networks_CO5-2)'
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_interactive_neural_networks_CO5-2)'
- en: Initial random weights
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 初始随机权重
- en: '[![3](Images/3.png)](#co_interactive_neural_networks_CO5-4)'
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_interactive_neural_networks_CO5-4)'
- en: Number of learning steps
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 学习步骤的数量
- en: '[![4](Images/4.png)](#co_interactive_neural_networks_CO5-5)'
  id: totrans-72
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_interactive_neural_networks_CO5-5)'
- en: Residual errors of the estimation
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 估计的残差误差
- en: '[![5](Images/5.png)](#co_interactive_neural_networks_CO5-6)'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_interactive_neural_networks_CO5-6)'
- en: Final weights of the network
  id: totrans-75
  prefs: []
  type: TYPE_NORMAL
  zh: 神经网络的最终权重
- en: Classification
  id: totrans-76
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类
- en: 'The second problem is a *classification problem* for which the labels are binary
    and integer-valued. To improve the performance of the learning algorithm, a *sigmoid
    function* is used for activation (of the output layer). [Figure A-1](#figure_inn_01)
    shows the sigmoid function with its first derivative and compares it to a simple
    step function:'
  id: totrans-77
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个问题是一个二元整数值标签的*分类问题*。为了改善学习算法的性能，输出层的激活采用了*sigmoid 函数*。[图 A-1](#figure_inn_01)展示了sigmoid函数及其一阶导数，并将其与简单的阶跃函数进行了比较：
- en: '[PRE5]'
  id: totrans-78
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: '![aiif 1601](Images/aiif_1601.png)'
  id: totrans-79
  prefs: []
  type: TYPE_IMG
  zh: '![aiif 1601](Images/aiif_1601.png)'
- en: Figure A-1\. Step function, sigmoid function, and its first derivative
  id: totrans-80
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
  zh: 图 A-1\. 阶跃函数、sigmoid 函数及其一阶导数
- en: 'To keep things simple, the classification problem is based on random binary
    features and binary labels data. Apart from the different features and labels
    data, only the activation for the output layer is different from the estimation
    problem. The learning algorithm for the updating of the neural networks’ weights
    is basically the same:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 为了简化问题，分类问题基于随机二进制特征和二进制标签数据。除了不同的特征和标签数据外，只有输出层的激活与估计问题有所不同。更新神经网络权重的学习算法基本相同：
- en: '[PRE6]'
  id: totrans-82
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: '[![1](Images/1.png)](#co_interactive_neural_networks_CO6-1)'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_interactive_neural_networks_CO6-1)'
- en: Input layer with binary features
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 具有二进制特征的输入层
- en: '[![2](Images/2.png)](#co_interactive_neural_networks_CO6-3)'
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_interactive_neural_networks_CO6-3)'
- en: Sigmoid activated output layer
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: sigmoid 激活的输出层
- en: '[![3](Images/3.png)](#co_interactive_neural_networks_CO6-4)'
  id: totrans-87
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_interactive_neural_networks_CO6-4)'
- en: Binary labels data
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制标签数据
- en: '[![4](Images/4.png)](#co_interactive_neural_networks_CO6-7)'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_interactive_neural_networks_CO6-7)'
- en: Backward propagation via the first derivative
  id: totrans-90
  prefs: []
  type: TYPE_NORMAL
  zh: 通过一阶导数进行反向传播
- en: 'As before, a loop with a larger number of iterations for the learning step
    is required to get to accurate classification results. Depending on the random
    numbers drawn, an accuracy of 100% is possible, as in the following example:'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 与之前一样，需要进行更多次迭代的循环来获得准确的分类结果。根据随机数的选择，像下面的例子中可能会达到100%的准确率：
- en: '[PRE7]'
  id: totrans-92
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: Shallow Neural Networks
  id: totrans-93
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 浅层神经网络
- en: The neural network of the previous section consists only of an input layer and
    an output layer. In other words, input and output layers are directly connected.
    A *shallow neural network* has one hidden layer that is between the input and
    output layer. Given this structure, two sets of weights are required to connect
    the total of three layers in the neural network. This section analyzes shallow
    neural networks for estimation and classification.
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 前一节的神经网络仅由输入层和输出层组成。换句话说，输入层和输出层直接相连。*浅层神经网络*在输入层和输出层之间有一个隐藏层。考虑到这种结构，需要两组权重来连接神经网络中的三层。本节分析了用于估计和分类的浅层神经网络。
- en: Estimation
  id: totrans-95
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 估计
- en: 'As in the previous section, let’s take the estimation problem first. The following
    Python code builds the neural network with the three layers and the two sets of
    weights. This first sequence of steps is usually called *forward propagation*.
    The input layer matrix in this context is in general of full rank, indicating
    that a perfect estimation result is possible:'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 如同前一节，首先解决估计问题。以下Python代码构建了具有三层和两组权重的神经网络。这第一个步骤序列通常称为*前向传播*。在这种情况下，输入层矩阵通常具有满秩，表明可以实现完美的估计结果：
- en: '[PRE8]'
  id: totrans-97
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: '[![1](Images/1.png)](#co_interactive_neural_networks_CO7-1)'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_interactive_neural_networks_CO7-1)'
- en: The random input layer
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 随机输入层
- en: '[![2](Images/2.png)](#co_interactive_neural_networks_CO7-3)'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_interactive_neural_networks_CO7-3)'
- en: The rank of the input layer matrix
  id: totrans-101
  prefs: []
  type: TYPE_NORMAL
  zh: 输入层矩阵的秩
- en: '[![3](Images/3.png)](#co_interactive_neural_networks_CO7-4)'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_interactive_neural_networks_CO7-4)'
- en: The number of hidden units
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: 隐藏单元的数量
- en: '[![4](Images/4.png)](#co_interactive_neural_networks_CO7-5)'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: '[![4](Images/4.png)](#co_interactive_neural_networks_CO7-5)'
- en: The first set of random weights, given the `features` and `units` parameters
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 给定`features`和`units`参数的第一组随机权重
- en: '[![5](Images/5.png)](#co_interactive_neural_networks_CO7-7)'
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: '[![5](Images/5.png)](#co_interactive_neural_networks_CO7-7)'
- en: The hidden layer, given the input layer and the weights
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: 给定输入层和权重的隐藏层
- en: '[![6](Images/6.png)](#co_interactive_neural_networks_CO7-9)'
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: '[![6](Images/6.png)](#co_interactive_neural_networks_CO7-9)'
- en: The second set of random weights
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 第二组随机权重
- en: '[![7](Images/7.png)](#co_interactive_neural_networks_CO7-11)'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
  zh: '[![7](Images/7.png)](#co_interactive_neural_networks_CO7-11)'
- en: The output layer, given the hidden layer and the weights
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 给定隐藏层和权重的输出层
- en: '[![8](Images/8.png)](#co_interactive_neural_networks_CO7-13)'
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
  zh: '[![8](Images/8.png)](#co_interactive_neural_networks_CO7-13)'
- en: The random labels data
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 随机标签数据
- en: 'The second sequence of steps is usually called *backward propagation*—with
    respect to the estimation errors. The two sets of weights are updated, starting
    at the output layer and updating the set of weights `w1` between the hidden layer
    and the output layer. Afterwards, taking the updated weights `w1` into account,
    the set of weights `w0` between the input layer and the hidden layer is updated:'
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 第二个步骤序列通常称为*反向传播*，与估计误差相关。两组权重将被更新，从输出层开始更新连接隐藏层和输出层之间的权重`w1`。随后，在考虑更新后的权重`w1`之后，将更新连接输入层和隐藏层之间的权重`w0`：
- en: '[PRE9]'
  id: totrans-115
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: '[![1](Images/1.png)](#co_interactive_neural_networks_CO8-1)'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_interactive_neural_networks_CO8-1)'
- en: Update procedure for the set of weights `w1`
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: 更新过程的权重集`w1`
- en: '[![2](Images/2.png)](#co_interactive_neural_networks_CO8-10)'
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_interactive_neural_networks_CO8-10)'
- en: Update procedure for the set of weights `w0`
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
  zh: 更新过程的权重集`w0`
- en: 'The following Python code implements the learning (that is, the updating of
    the network weights) as a `for` loop with a larger number of iterations. By increasing
    the number of iterations, the estimation results can be made arbitrarily precise:'
  id: totrans-120
  prefs: []
  type: TYPE_NORMAL
  zh: 以下Python代码实现了学习（即网络权重的更新）作为一个`for`循环，迭代次数更多。通过增加迭代次数，可以使估计结果任意精确：
- en: '[PRE10]'
  id: totrans-121
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: Classification
  id: totrans-122
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 分类
- en: 'Next is the classification problem. The implementation in this context is pretty
    close to the estimation problem. However, the sigmoid function is used again for
    activation. The following Python code generates the random sample data first:'
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
  zh: 接下来是分类问题。在这种情况下，实现与估计问题非常接近。但是，再次使用Sigmoid函数进行激活。以下Python代码首先生成随机样本数据：
- en: '[PRE11]'
  id: totrans-124
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: '[![1](Images/1.png)](#co_interactive_neural_networks_CO9-1)'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_interactive_neural_networks_CO9-1)'
- en: Binary features data (input layer)
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制特征数据（输入层）
- en: '[![2](Images/2.png)](#co_interactive_neural_networks_CO9-2)'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_interactive_neural_networks_CO9-2)'
- en: Binary labels data
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 二进制标签数据
- en: 'The implementation of the learning algorithm again makes use of a `for` loop
    to repeat the weights-updating step as often as necessary. Depending on the random
    numbers generated for the features and labels data, an accuracy of 100% can be
    achieved after enough learning steps:'
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
  zh: 学习算法的实现再次利用`for`循环来重复权重更新步骤，直到必要的次数。根据为特征和标签数据生成的随机数，经过足够的学习步骤后可以达到100%的准确率：
- en: '[PRE12]'
  id: totrans-130
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: '[![1](Images/1.png)](#co_interactive_neural_networks_CO10-1)'
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: '[![1](Images/1.png)](#co_interactive_neural_networks_CO10-1)'
- en: Forward propagation
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 前向传播
- en: '[![2](Images/2.png)](#co_interactive_neural_networks_CO10-3)'
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
  zh: '[![2](Images/2.png)](#co_interactive_neural_networks_CO10-3)'
- en: Backward propagation
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 反向传播
- en: '[![3](Images/3.png)](#co_interactive_neural_networks_CO10-11)'
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
  zh: '[![3](Images/3.png)](#co_interactive_neural_networks_CO10-11)'
- en: Accuracy of the classification
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: 分类的准确性
- en: References
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 参考资料
- en: 'Books cited in this appendix:'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 附录中引用的书籍：
- en: 'Chollet, Francois. 2017\. *Deep Learning with Python*. Shelter Island: Manning.'
  id: totrans-139
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Chollet, Francois. 2017\. *Python深度学习*. Shelter Island: Manning.'
- en: ^([1](app01.xhtml#idm45625236964232-marker)) Since there is no hidden layer,
    backward propagation does take place with a factor of 1 as the value of the derivative.
    Output and input layers are directly connected.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
  zh: ^([1](app01.xhtml#idm45625236964232-marker)) 由于没有隐藏层，反向传播的导数值为1。输出层和输入层直接连接。
