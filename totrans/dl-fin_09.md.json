["```py\npip install fracdiff\n```", "```py\nfrom fracdiff.sklearn import Fracdiff\nimport pandas_datareader as pdr\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n```", "```py\n# Set the start and end dates for the data\nstart_date = '1990-01-01'\nend_date   = '2023-06-01'\n# Fetch S&P 500 price data\ndata = np.array((pdr.get_data_fred('SP500', start = start_date, \n                                   end = end_date)).dropna())\n# Calculate the fractional differentiation\nwindow = 100\nf = Fracdiff(0.48, mode = 'valid', window = window)\nfrac_data = f.fit_transform(data)\n# Calculate a simple differencing function for comparison\ndiff_data = np.reshape(np.diff(data[:, 0]), (–1, 1))\n# Harmonizing time indices\ndata = data[window – 1:, ]\ndiff_data = diff_data[window – 2:, ]\n\n```", "```py\nfig, axes = plt.subplots(nrows = 3, ncols = 1)\naxes[0].plot(data[5:,], label = 'S&P 500', color = 'blue', linewidth = 1)\naxes[1].plot(frac_data[5:,], label = \n             'Fractionally Differentiated S&P 500 (0.48)', \n             color = 'orange', linewidth = 1)\naxes[2].plot(diff_data[5:,], label = \n             'Differenced S&P 500', color = 'green', linewidth = 1)\naxes[0].legend()\naxes[1].legend()\naxes[2].legend()\naxes[0].grid()\naxes[1].grid()\naxes[2].grid()   \naxes[1].axhline(y = 0, color = 'black', linestyle = 'dashed') \naxes[2].axhline(y = 0, color = 'black', linestyle = 'dashed')  \n\n```", "```py\nfrom statsmodels.tsa.stattools import adfuller\nprint('p-value: %f' % adfuller(data)[1])\nprint('p-value: %f' % adfuller(frac_data)[1])\nprint('p-value: %f' % adfuller(diff_data)[1])\n\n```", "```py\n# The original S&P 500 dataset is nonstationary\np-value: 0.842099 \n# The fractionally differentiated S&P 500 dataset is stationary\np-value: 0.038829\n# The normally differenced S&P 500 dataset is stationary\np-value: 0.000000\n\n```", "```py\ndata = np.array((pdr.get_data_fred('DEXUSEU', start = start_date, \n                                   end = end_date)).dropna())\n```", "```py\n# The original EURUSD dataset is nonstationary\np-value: 0.397494\n# The fractionally differentiated EURUSD  dataset is stationary\np-value: 0.043214\n# The normally differenced EURUSD  dataset is stationary\np-value: 0.000000 \n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom master_function import data_preprocessing, mass_import\nfrom master_function import plot_train_test_values, forecasting_threshold\n\n```", "```py\nnum_lags = 500\ntrain_test_split = 0.80 \nnum_neurons_in_hidden_layers = 256 \nnum_epochs = 100 \nbatch_size = 10\nthreshold = 0.0015\n\n```", "```py\n# Fetching the historical price data\ndata = np.diff(mass_import(0, 'D1')[:, 3])\n# Creating the training and test sets\nx_train, y_train, x_test, y_test = data_preprocessing(data, num_lags, \n                                                      train_test_split)\n# Designing the architecture of the model\nmodel = Sequential()\n# First hidden layer\nmodel.add(Dense(num_neurons_in_hidden_layers, input_dim = num_lags, \n                activation = 'relu'))  \n# Second hidden layer\nmodel.add(Dense(num_neurons_in_hidden_layers, activation = 'relu'))\n# Output layer\nmodel.add(Dense(1))\n# Compiling\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n\n```", "```py\n# Fitting\nmodel.fit(x_train, y_train, epochs = num_epochs, batch_size = batch_size)\n# Predicting\ny_predicted = model.predict(x_test)\n# Threshold function\ny_predicted = forecasting_threshold(y_predicted, threshold)\n# Plotting\nplot_train_test_values(100, 50, y_train, y_test, y_predicted)\n\n```", "```py\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.linear_model import LinearRegression\nfrom master_function import data_preprocessing, mass_import\nfrom master_function import plot_train_test_values, \nfrom master_function import calculate_accuracy, model_bias\nfrom sklearn.metrics import mean_squared_error\n\n```", "```py\n# Importing the time series\ndata = np.diff(mass_import(0, 'D1')[:, 3])\n# Setting the hyperparameters\nnum_lags = 15\ntrain_test_split = 0.80 \n# Creating the training and test sets\nx_train, y_train, x_test, y_test = data_preprocessing(data, num_lags, \n                                                      train_test_split)\n# Fitting the model\nmodel = LinearRegression()\nmodel.fit(x_train, y_train)\n# Predicting in-sample\ny_predicted_train = np.reshape(model.predict(x_train), (–1, 1))\n\n```", "```py\n# Store the new forecasts\ny_predicted = []\n# Reshape x_test to forecast one period\nlatest_values = np.transpose(np.reshape(x_test[0], (–1, 1)))\n# Isolate the real values for comparison\ny_test_store = y_test\ny_train_store = y_train\nfor i in range(len(y_test)):\n    try: \n        # Predict over the first x_test data\n        predicted_value = model.predict(latest_values)\n        # Store the prediction in an array\n        y_predicted = np.append(y_predicted, predicted_value)\n        # Add the first test values to the last training values\n        x_train = np.concatenate((x_train, latest_values), axis = 0)\n        y_train = np.append(y_train, y_test[0])\n        # Remove the first test values from the test arrays\n        y_test = y_test[1:]\n        x_test = x_test[1:, ]\n        # Retrain\n        model.fit(x_train, y_train)\n        # Select the first values of the test set\n        latest_values = np.transpose(np.reshape(x_test[0], (–1, 1)))\n    except IndexError:\n        pass\n\n```", "```py\nplot_train_test_values(100, 50, y_train, y_test_store, y_predicted)\n\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport keras\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom master_function import data_preprocessing, plot_train_test_values, \nfrom master_function import recursive_mpf\nfrom master_function import calculate_directional_accuracy\nfrom sklearn.metrics import mean_squared_error\n\n```", "```py\n# Importing the data\ndata = np.reshape(np.array(pd.read_excel('Temperature_Basel.xlsx').dropna()\n                  ), (–1))\n# Setting the hyperparameters\nnum_lags = 500\ntrain_test_split = 0.8\nnum_neurons_in_hidden_layers = 100\nnum_epochs = 200\nbatch_size = 12\n# Creating the training and test sets\nx_train, y_train, x_test, y_test = data_preprocessing(data, num_lags, \n                                                      train_test_split)\n\n```", "```py\n# Designing the architecture of the model\nmodel = Sequential()\n# First hidden layer\nmodel.add(Dense(num_neurons_in_hidden_layers, input_dim = num_lags, \n          activation = 'relu'))  \n# Second hidden layer\nmodel.add(Dense(num_neurons_in_hidden_layers, activation = 'relu'))  \n# Third hidden layer\nmodel.add(Dense(num_neurons_in_hidden_layers, activation = 'relu'))  \n# Fourth hidden layer\nmodel.add(Dense(num_neurons_in_hidden_layers, activation = 'relu')) \n# Output layer\nmodel.add(Dense(1))\n# Compiling\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n# Fitting the model\nmodel.fit(x_train, np.reshape(y_train, (–1, 1)), epochs = num_epochs, \n          batch_size = batch_size)\n# Predicting in-sample\ny_predicted_train = np.reshape(model.predict(x_train), (–1, 1))\n# Predicting in the test set on a recursive basis\nx_test, y_predicted = recursive_mpf(x_test, y_test, num_lags, \n                                    model, architecture = 'MLP')\n\n```", "```py\ndata = np.reshape(np.array(pd.read_excel('ISM_PMI.xlsx').dropna()), (–1))\n\n```", "```py\nnum_lags = 200\ntrain_test_split = 0.8\nnum_neurons_in_hidden_layers = 500\nnum_epochs = 400\nbatch_size = 100\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport keras\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom master_function import direct_mpf\nfrom master_function import calculate_directional_accuracy\nfrom sklearn.metrics import mean_squared_error\n\n```", "```py\n# Importing the data\ndata = np.reshape(np.array(pd.read_excel('ISM_PMI.xlsx').dropna()), (–1))\n# Setting the hyperparameters\nnum_lags = 10\ntrain_test_split = 0.80\nnum_neurons_in_hidden_layers = 200\nnum_epochs = 200\nbatch_size = 10\nforecast_horizon = 18 # This means eighteen months\nx_train, y_train, x_test, y_test = direct_mpf(data, num_lags, \n                                              train_test_split, \n                                              forecast_horizon)\n\n```", "```py\n# Designing the architecture of the model\nmodel = Sequential()\n# First hidden layer\nmodel.add(Dense(num_neurons_in_hidden_layers, input_dim = num_lags, \n                activation = 'relu'))  \n# Second hidden layer\nmodel.add(Dense(num_neurons_in_hidden_layers, activation = 'relu'))  \n# Output layer\nmodel.add(Dense(forecast_horizon))\n# Compiling\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n# Fitting (training) the model\nmodel.fit(x_train, y_train, epochs = num_epochs, batch_size = batch_size)\n# Make predictions\ny_predicted = model.predict(x_test)\n# Plotting\nplt.plot(y_predicted[–1], label = 'Predicted data', color = 'red', \n         linewidth = 1)\nplt.plot(y_test[–1], label = 'Test data', color = 'black', \n         linestyle = 'dashed', linewidth = 2)\nplt.grid()\nplt.legend()\n\n```", "```py\nnum_lags = 1\ntrain_test_split = 0.80\nnum_neurons_in_hidden_layers = 2\nnum_epochs = 10\nbatch_size = 1\nforecast_horizon = 18\n```", "```py\nnum_lags = 500\ntrain_test_split = 0.80\nnum_neurons_in_hidden_layers = 128\nnum_epochs = 50\nbatch_size = 12\nforecast_horizon = 500\n```", "```py\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport pandas_datareader as pdr\nfrom master_function import data_preprocessing, plot_train_test_values\nfrom master_function import calculate_directional_accuracy\nfrom sklearn.metrics import mean_squared_error\n```", "```py\n# Set the start and end dates for the data\nstart_date = '1990-01-01'\nend_date   = '2023-06-01'\n# Fetch S&P 500 price data\ndata = np.array((pdr.get_data_fred('SP500', start = start_date, \n                                   end = end_date)).dropna())\n\n```", "```py\nrolling_autocorr = pd.DataFrame(data).rolling(window = \n                                              20).apply(lambda x: \n                                              x.autocorr(lag=1)).dropna()\nrolling_autocorr = np.reshape(np.array(rolling_autocorr), (–1))\n```", "```py\n# Create an anonymous function to divide two variables\ndivide = lambda x, y: x / y\n# Call the function\nresult = divide(10, 2)\n```", "```py\nfig, axes = plt.subplots(nrows = 2, ncols = 1)\naxes[0].plot(data[-350:,], label = 'S&P 500', linewidth = 1.5)\naxes[1].plot(rolling_autocorr[-350:,], label = '20-Day Autocorrelation', \n             color = 'orange', linewidth = 1.5)\naxes[0].legend()\naxes[1].legend()\naxes[0].grid()\naxes[1].grid()\naxes[1].axhline(y = 0.95, color = 'black', linestyle = 'dashed')\n\n```", "```py\nnum_lags = 500 \ntrain_test_split = 0.80 \nnum_neurons_in_hidden_layers = 128 \nnum_epochs = 100 \nbatch_size = 20\n# Creating the training and test sets\nx_train, y_train, x_test, y_test = data_preprocessing(rolling_autocorr, \n                                                      num_lags, \n                                                      train_test_split)\n\n```", "```py\nx_train = x_train.reshape((–1, num_lags, 1))\nx_test = x_test.reshape((–1, num_lags, 1))\n\n```", "```py\n# Create the LSTM model\nmodel = Sequential()\nmodel.add(LSTM(units = num_neurons_in_hidden_layers, input_shape = \n               (num_lags, 1)))\n# Adding batch normalization and a dropout of 10%\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.1)) \n# Adding the output layer\nmodel.add(Dense(units = 1))\n# Compile the model\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n# Early stopping implementation\nearly_stopping = EarlyStopping(monitor = 'loss', patience = 15, \n restore_best_weights = True)\n# Train the model\nmodel.fit(x_train, y_train, epochs = num_epochs, \n          batch_size = batch_size, callbacks = [early_stopping])\n\n```", "```py\n# Predicting in-sample\ny_predicted_train = np.reshape(model.predict(x_train), (–1, 1))\n# Predicting out-of-sample\ny_predicted = np.reshape(model.predict(x_test), (–1, 1))\n# Plotting\nplot_train_test_values(300, 50, y_train, y_test, y_predicted)\n\n```", "```py\nAccuracy Train =  70.37 %\nAccuracy Test =  68.12 %\nRMSE Train =  0.0658945761\nRMSE Test =  0.0585669847\nCorrelation In-Sample Predicted/Train =  0.945\nCorrelation Out-of-Sample Predicted/Test =  0.936\n```", "```py\ndata = np.reshape(data, (–1))\n```", "```py\ndata = np.reshape(data, (–1, 1))\n```"]