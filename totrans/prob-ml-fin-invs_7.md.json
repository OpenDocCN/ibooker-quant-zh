["```py\n# Import standard Python libraries.\nimport numpy as np\nimport pandas as pd\nfrom datetime import datetime\nimport xarray as xr\nimport matplotlib.pyplot as plt\n\n# Install and import PyMC and Arviz libraries.\n!pip install pymc -q\nimport pymc as pm\nimport arviz as az\naz.style.use('arviz-darkgrid')\n\n# Install and import Yahoo Finance web scraper.\n!pip install yfinance -q\nimport yfinance as yf\n\n# Fix random seed so that numerical results can be reproduced.\nnp.random.seed(101)\n\n# Import financial data.\nstart = datetime(2022, 11, 15)\nend = datetime(2022, 12, 31)\n\n# S&P 500 index is a proxy for the market factor.\nmarket = yf.Ticker('SPY').history(start=start, end=end)\n# Ticker symbol for Apple, the largest company in the world \n# by market capitalization.\nstock = yf.Ticker('AAPL').history(start=start, end=end)\n# 10 year US treasury note is the proxy for risk free rate.\nriskfree_rate = yf.Ticker('^TNX').history(start=start, end=end)\n\n# Create a dataframe to hold the daily returns of securities.\ndaily_returns = pd.DataFrame()\n# Compute daily percentage returns based on closing prices for Apple and \n# S&P 500 index.\ndaily_returns['market'] = market['Close'].pct_change(1)*100\ndaily_returns['stock'] = stock['Close'].pct_change(1)*100\n# Compounded daily risk free rate based on 360 days for the calendar year \n# used in the bond market.\ndaily_returns['riskfree'] = (1 + riskfree_rate['Close']) ** (1/360) - 1\n\n# Check for missing data in the dataframe.\nmarket.index.difference(riskfree_rate.index)\n# Fill rows with previous day's risk-free rate since \n# daily rates are generally stable.\ndaily_returns = daily_returns.ffill()\n# Drop NaNs in first row because of percentage calculations \n# are based on previous day's closing price.\ndaily_returns = daily_returns.dropna()\n# Check dataframe for null values.\ndaily_returns.isnull().sum()\n# Check first five rows of dataframe.\ndaily_returns.head()\n\n# Daily excess returns of AAPL are returns in excess of \n# the daily risk free rate.\ny = daily_returns['stock'] - daily_returns['riskfree']\n# Daily excess returns of the market are returns in excess of \n# the daily risk free rate.\nx = daily_returns['market'] - daily_returns['riskfree']\n\n# Plot the excess returns of Apple and S&P 500.\nplt.scatter(x,y)\nplt.ylabel('Excess returns of Apple'), \nplt.xlabel('Excess returns of S&P 500');\n\n# Plot histogram of Apple's excess returns during the period.\nplt.hist(y, density=True, color='blue')\nplt.ylabel('Probability density'), plt.xlabel('Excess returns of Apple');\n\n# Analyze daily returns of all securities.\ndaily_returns.describe()\n\n# Split time series sequentially because of serial correlation \n# in financial data.\ntest_size = 10\n\nx_train = x[:-test_size]\ny_train = y[:-test_size]\n\nx_test = x[-test_size:]\ny_test = y[-test_size:]\n\n```", "```py\n# Create a probabilistic model by instantiating the PyMC model class.\nmodel = pm.Model()\n\n# The with statement creates a context manager for the model object.\n# All variables and constants inside the with-block are part of the model.\n\nwith model:\n  # Define the prior probability distributions of the model's parameters. \n  # Use prior domain knowledge.\n\n  # Alpha quantifies the idiosyncratic, daily excess return of Apple \n  # ​unaffected by market movements.\n  # Assume that alpha is normally distributed. The values of mu and \n  # sigma are based on previous data analysis and trial and error.\n  alpha = pm.Normal('alpha', mu=0.02, sigma=0.10)\n\n  # Beta quantifies the sensitivity of Apple to the movements \n  # of the market/S&P 500.\n  # Assume that beta is normally distributed. The values of mu and \n  # sigma are based on previous data analysis and trial and error.\n  beta = pm.Normal('beta', mu=1.2, sigma=0.15)\n\n  # Residual quantifies the unexpected returns of Apple \n  # i.e returns not predicted by the linear model.\n  # Assume residuals are Half Student's t-distribution with nu=6\\. \n  # Value of nu=6 is based on research studies and trial and error.\n  residual = pm.HalfStudentT('residual', sigma=0.20, nu=6)\n\n  # Mutatable data containers are used so that we can swap out \n  # training data for test data later.\n  feature = pm.MutableData('feature', x_train, dims='feature_data')\n  target = pm.MutableData('target', y_train, dims='target_data')\n\n  # Expected daily excess returns of Apple are approximately \n  # linearly related to daily excess returns of S&P 500.\n  # The function specifies the linear model and the expected return. \n  # It creates a deterministic variable in the trace object.\n  target_expected = pm.Deterministic('target_expected', \n  alpha + beta * feature, dims='feature_data')\n\n  # Assign the training data sample to the likelihood function.\n  # Daily excess stock price returns are assumed to be T-distributed, nu=6.\n  target_likelihood = pm.StudentT('target_likelihood', mu=target_expected, \n  sigma=residual, nu=6, observed=target, dims='target_data')\n\n```", "```py\n# Use the graphviz method to visualize the probabilistic model's data, \n# parameters, distributions and dependencies\npm.model_to_graphviz(model)\n```", "```py\n# Sample from the prior distributions and the likelihood function \n# to generate prior predictive distribution of the model.\n# Take 1000 draws from the prior predictive distribution \n# to simulate (1000*21) target values based on our prior assumptions.\nidata = pm.sample_prior_predictive(samples=1000, model=model, \nreturn_inferencedata=True, random_seed=101)\n\n# PyMC/Arviz returns an xarray - a labeled, multidimensional array \n# containing inference data samples structured into groups. Note the \n# dimensions of the prior predictive group to see how we got (1*1000*21) \n# simulated target data of the prior predictive distribution.\nidata\n\n```", "```py\n# Subplots on the left show the kernel density estimates (KDE) of \n# the marginal prior probability distributions of model parameters \n# from the 1000 samples drawn. Subplots on the right show the parameter \n# values from a single Markov chain that were sampled sequentially \n# by the NUTS sampler, the default regression sampler.\naz.plot_trace(idata.prior, kind='trace', \nvar_names = ['alpha', 'beta', 'residual'], legend=True);\n\n```", "```py\n# Plot the marginal prior distributions of each parameter with 94% \n# highest density intervals (HDI).\n# Note the residual subplot shows the majority of probability density function\n# within 3 percentage points and the rest extending out into a long tail.\n# In Arviz, there is no method to plot the prior marginal distributions but we \n# can hack the plot posterior method and use the prior group instead.\naz.plot_posterior(idata.prior, \nvar_names = ['alpha', 'beta', 'residual'], round_to=2);\n\n```", "```py\n# Plot the joint prior probability distribution of alpha and beta with their \n# respective means and marginal distributions on the side.\n# Hexabin plot below shows little or no linear correlation with the high \n# concentration areas in the heat map forming a cloud.\naz.plot_pair(idata.prior, var_names=['alpha', 'beta'], kind='hexbin', \nmarginals=True, point_estimate='mean', colorbar=True);\n\n```", "```py\n# Plot the retrodictions of prior predictive ensemble.\n\n# Retrieve feature and target training data from the constant_data group.\n# Feature is now an Xarray instead of a panda's series, \n# a requirement for ArviZ data analysis.\nfeature_train = idata.constant_data['feature']\ntarget_train = idata.constant_data['target']\n\n# Generate 1000 linear regression lines based on 1000 draws from one \n# Markov chain of the prior distributions of alpha and beta.\n# Prior target values are in 1000 arrays with each array having 21 samples,\n# the same number of samples as our training data set.\nprior_target = idata.prior[\"alpha\"] + idata.prior[\"beta\"] * feature_train\n\n# Prior_predictive is the data generating distribution of the untrained ensemble.\nprior_predictive = idata.prior_predictive['target_likelihood']\n\n# Create figure of subplots\nfig, ax = plt.subplots()\n\n# Plot epistemic and aleatory uncertainties of untrained \n# ensemble's retrodictions.\naz.plot_lm(idata=idata, x=feature_train, y=target_train, \nnum_samples=1000, y_model = prior_target, \ny_hat = prior_predictive, axes=ax)\n\n#Label the figure.\nax.set_xlabel(\"Excess returns of S&\nP 500\")\nax.set_ylabel(\"Excess returns of Apple\")\nax.set_title(\"Retrodictions of untrained linear ensemble\")\nax.legend(loc='upper left');\n```", "```py\n# Plot 90% HDI of untrained ensemble.\n# This will show the aleatory (data related) and epistemic \n# (parameter related) uncertainty of model output before it is trained.\n\n# Create figure of subplots.\nfig, ax = plt.subplots()\n\n# Plot the ensemble of 1000 regression lines to show the \n# epistemic uncertainty around the mean regression line.\naz.plot_lm(idata=idata, x=feature_train, y=target_train, \nnum_samples=1000, y_model = prior_target, axes=ax)\n\n# Plot the prior predictive data within the 90% HDI band to \n# show both epistemic and aleatory uncertainties.\naz.plot_hdi(feature_train, prior_predictive, hdi_prob=0.90, smooth=False)\n\n# Label figure.\nax.set_xlabel(\"Excess returns of S&P 500\")\nax.set_ylabel(\"Excess returns of Apple\")\nax.set_title(\"90% HDI for simulated samples of untrained linear ensemble\")\nax.legend();\n\n```", "```py\n# Conduct a prior predictive check of the untrained linear ensemble.\n# Create figure of subplots.\nfig, ax = plt.subplots()\n# Plot the prior predictive check\naz.plot_ppc(idata, group='prior', kind='cumulative', \nnum_pp_samples=1000, alpha=0.1, ax=ax)\n\n# Label the figure.\nax.set_xlabel(\"Simulated Apple excess returns\")\nax.set_ylabel(\"Cumulative Probability\")\nax.set_title(\"Prior predictive check of untrained linear ensemble\");\n\n```", "```py\n# Evaluate untrained ensemble's retrodictions by comparing simulated \n# data with training data.\n\n# Extract target values of our training data.\ntarget_actual = target_train.values\n\n# Sample the prior predictive distribution to simulate \n# expected target training values.\ntarget_predicted = idata.prior_predictive.stack(sample=(\"chain\", \"draw\"))\n['target_likelihood'].values.T\n\n# Use the probabilistic R-squared metric.\nprior_score = az.r2_score(target_actual, target_predicted)\nprior_score.round(2)\n\n```", "```py\n# Draw 1000 samples from two Markov chains resulting in 2000 values of each\n# parameter to analyze the joint posterior distribution.\n# Check for any divergences in the progress bar. We want 0 divergences for a \n# reliable sampling of the posterior distribution.\nidata.extend(pm.sample(draws=1000, chains=2, model=model, random_seed=101))\n\n```", "```py\n# Subplots on the left show the kernel density estimates (KDE)\n# of the marginal posterior probability distributions of each parameter.\n# Subplots on the right show the parameter values \n# that were sampled sequentially in two chains by the NUTS sampler\nwith model:\n  az.plot_trace(idata.posterior, kind='trace',\n  var_names = ['alpha', 'beta', 'residual'], legend=True)\n\n```", "```py\n# Plot the joint posterior probability distribution of alpha and beta \n# with their respective means and marginal distributions on the side.\n# Hexabin plot below shows little or no linear correlation with the \n# high concentration areas in the heat map forming a cloud.\naz.plot_pair(idata.posterior, var_names=['alpha', 'beta'], kind='hexbin',\nmarginals=True, point_estimate='mean', colorbar=True);\n\n```", "```py\n# Examine sample statistics of each parameter's posterior marginal distribution, \n# including it's 94% highest density interval (HDI).\ndisplay(az.summary(idata, kind='stats', \nvar_names = ['alpha', 'beta', 'residual'], round_to=2, hdi_prob=0.94))\n\n```", "```py\n# Change the default highest density interval to 90%\naz.rcParams['stats.hdi_prob'] = 0.90\n```", "```py\n# Plot the marginal posterior distribution of each parameter displaying \n# the above statistics but now within a 70% HDI\naz.plot_posterior(idata, var_names = ['alpha', 'beta', 'residual'], \nhdi_prob=0.70, round_to=3);\n```", "```py\n# Evaluate a point estimate for a single parameter using its \n# posterior distribution.\naz.plot_posterior(idata, 'beta', ref_val=1.15, hdi_prob=0.80, \npoint_estimate='mode', round_to=3);\n\n```", "```py\n# Draw 1000 samples each from two Markov chains of the \n# posterior predictive distribution.\nwith model:\n  pm.sample_posterior_predictive(idata, extend_inferencedata=True, \n  random_seed=101)\n\n```", "```py\n# Generate 2000 linear regression lines based on 1000 draws each from \n# two chains of the posterior distributions of alpha and beta.\n# Posterior target values are in 2000 arrays, each with 21 samples, \n# the same number of samples as our training data set.\nposterior = idata.posterior\nposterior_target = posterior[\"alpha\"] + posterior[\"beta\"] * feature_train\n\n# Posterior_predictive is the data generating distribution of the \n# trained ensemble.\nposterior_predictive = idata.posterior_predictive['target_likelihood']\n\n# Create figure of subplots.\nfig, ax = plt.subplots()\n\n# Plot epistemic and aleatory uncertainties of trained \n# ensemble's retrodictions.\naz.plot_lm(idata=idata, x=feature_train, y=target_train, num_samples=2000,\ny_model = posterior_target, y_hat=posterior_predictive, axes=ax)\n\n# Label the figure.\nax.set_xlabel(\"Excess returns of S&P 500\")\nax.set_ylabel(\"Excess returns of Apple\")\nax.set_title(\"Retrodictions of the trained linear ensemble\")\nax.legend(loc='upper left');\n\n```", "```py\n# Plot 90% HDI of trained ensemble.\n# This will show the aleatory (data related) and epistemic \n# (parameter related) uncertainty of model output after it is trained.\n\n# Create figure of subplots.\nfig, ax = plt.subplots()\n\n# Plot the ensemble of 2000 regression lines to show the epistemic \n# uncertainty around the mean regression line.\naz.plot_lm(idata=idata, x=feature_train, y=target_train, num_samples=1000,\ny_model = posterior_target, axes=ax)\n\n# Plot the posterior predictive data within the 90% HDI band to show both \n# epistemic and aleatory uncertainties.\naz.plot_hdi(feature_train, posterior_predictive, hdi_prob=0.90, smooth=False)\n\n# Label the figure\nax.set_xlabel(\"Excess returns of S&P 500\")\nax.set_ylabel(\"Excess returns of Apple\")\nax.set_title(\"90% HDI for simulated samples of trained linear ensemble\");\n\n```", "```py\n# Conduct a posterior predictive check of the trained linear ensemble.\n\n# Create a figure of subplots.\nfig, ax = plt.subplots()\n\n# Plot the posterior predictive check.\naz.plot_ppc(idata, group='posterior', kind='cumulative', \nnum_pp_samples=2000, alpha=0.1, ax=ax)\n\n# Label the figure.\nax.set_xlabel(\"Simulated Apple excess returns given training data\")\nax.set_ylabel(\"Cumulative Probability\")\nax.set_title(\"Posterior predictive check of trained ensemble\");\n\n```", "```py\n# Evaluate trained ensemble's retrodictions by comparing\n# simulated data with training data.\n\n# Get target values of our training data\ntarget_actual = target_train.values\n\n# Sample the posterior predictive distribution \n# conditioned on training data.\ntarget_predicted = idata.posterior_predictive.stack(sample=(\"chain\", \"draw\"))\n['target_likelihood'].values.T\n\n# Compute probabilistic R-squared performance metric.\ntraining_score = az.r2_score(target_actual, target_predicted)\ntraining_score.round(2)\n\n```", "```py\n# Now we use our trained model to make predictions based on test data. \n# This is the reason we created mutable data containers earlier.\nwith model:\n    #Swap feature and target training data for their respective test data.\n    pm.set_data({'feature': x_test, 'target': y_test})\n    #Create two new inference groups, predictions and predictions_constant_data \n    #for making predictions based on features in the test data.\n    pm.sample_posterior_predictive(idata, return_inferencedata=True, \n    predictions=True, extend_inferencedata=True, random_seed=101)\n\n```", "```py\n# Get feature and target test data.\nfeature_test = idata.predictions_constant_data['feature']\ntarget_test = idata.predictions_constant_data['target']\n\n# Prediction target values are in 2000 arrays, each with 10 samples,\n# the same number of samples as our test data set. Predict target values \n# based on posterior values of regression parameters and feature test data.\nprediction_target = posterior[\"alpha\"] + posterior[\"beta\"] * feature_test\n\n# Predictions is the data generating posterior predictive distribution \n# of the trained ensemble based on test data.\nsimulate_predictions = idata.predictions['target_likelihood']\n\n# Create figure of subplots.\nfig, ax = plt.subplots()\n\n# Plot the 2000 regression lines showing the epistemic and \n# aleatory uncertainties of out-of-sample predictions.\naz.plot_lm(idata=idata, x=feature_test, y=target_test, num_samples=2000, \ny_model = prediction_target, y_hat=simulate_predictions, axes=ax)\n\n# Label figure\nax.set_xlabel(\"Excess returns of S&P 500\")\nax.set_ylabel(\"Excess returns of Apple\")\nax.set_title(\"Predictions of trained linear ensemble\")\nax.legend(loc='upper left');\n\n```", "```py\n# Plot 90% HDI of trained ensemble. This will show the aleatory \n# (data related) and epistemic (parameter related) uncertainty \n# of trained model's predictions based on test data.\n\n# Create figure of subplots.\nfig, ax = plt.subplots()\n\n# Plot the ensemble of 2000 regression lines to show the epistemic uncertainty \n# around the mean regression line.\naz.plot_lm(idata=idata, x=feature_test, y=target_test, \nnum_samples=2000, y_model = prediction_target, axes=ax)\n\n# Plot the posterior predictive data within the 90% HDI band \n# to show both epistemic and aleatory uncertainties.\naz.plot_hdi(feature_test, simulate_predictions, \nhdi_prob=0.90, smooth=False)\n\n# Label the figure.\nax.set_xlabel(\"Excess returns of S&P 500\")\nax.set_ylabel(\"Excess returns of Apple\")\nax.set_title(\"90% HDI for predictions of trained linear ensemble\")\nax.legend();\n\n```", "```py\n# Evaluate out-of-sample predictions of trained \n# ensemble by comparing simulated data with test data.\n\n# Get target values of the test data.\ntarget_actual = target_test.values\n\n# Sample ensemble's predictions based on test data.\ntarget_predicted = idata.predictions.stack(sample=(\"chain\", \"draw\"))\n['target_likelihood'].values.T\n\n# Compute the probabilistic R-squared performance metric.\ntest_score = az.r2_score(target_actual, target_predicted)\ntest_score.round(2)\n\n```"]