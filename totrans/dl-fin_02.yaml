- en: Chapter 2\. Essential Probabilistic Methods for Deep Learning
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The rise and accessibility of technology have made it possible for everyone
    to deploy machine learning and deep learning algorithms for data analysis and
    optimization. But unfortunately, a large number of users do not understand the
    basics of the different learning models. This makes machine learning nothing short
    of a mystery box to them, which is a recipe for disaster.
  prefs: []
  type: TYPE_NORMAL
- en: Understanding fundamental concepts in probability, statistics, and math is essential
    for understanding and mastering data as well as for creating models that seek
    to interpret and forecast data. This chapter presents the basics of probability
    that are either directly or indirectly related to the algorithms. Note that you
    are unlikely to use these probability concepts in your everyday life, but it’s
    important to know where some algorithms draw their assumptions from.
  prefs: []
  type: TYPE_NORMAL
- en: A Primer on Probability
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Probability* is all about describing random variables and random events. The
    world is filled with randomness, and the best way to find your way through chaos
    is to try to explain it using probabilistic methods. Granted, the phrase *explain
    chaos* may be an oxymoron, as chaos cannot really be explained, but we humans
    cannot relinquish control over uncertain events. This is why we have developed
    tools to make sense out of our scary world.'
  prefs: []
  type: TYPE_NORMAL
- en: You may wonder what is the use of understanding the basics of probability when
    trying to develop machine learning algorithms for financial trading. This is a
    reasonable question, and you must know that the foundations of a discipline do
    not necessarily resemble it.
  prefs: []
  type: TYPE_NORMAL
- en: For example, to become a pilot you have to study aerodynamics, which is filled
    with technical concepts that do not resemble the final skill. This is similar
    to what is being done in this chapter; by studying probabilistic essentials, you
    give your brain a proper warm-up for what’s to come.
  prefs: []
  type: TYPE_NORMAL
- en: 'Knowing the utility of what you are learning should give you a motivation boost.
    Here are some key probability topics that are important for machine learning:'
  prefs: []
  type: TYPE_NORMAL
- en: Probability distribution functions
  prefs: []
  type: TYPE_NORMAL
- en: The possibility of seeing various outcomes of a random variable is described
    by a *probability distribution*. For many machine learning techniques, it is essential
    to comprehend the features and attributes of typical probability distributions.
    Probability distribution functions also describe different types of time series
    data, which in turn helps in choosing the right algorithm. For simplicity and
    coherence, this topic is discussed in [Chapter 3](ch03.html#ch03).
  prefs: []
  type: TYPE_NORMAL
- en: Hypothesis testing
  prefs: []
  type: TYPE_NORMAL
- en: '*Hypothesis testing* is used to establish whether a population-based assertion
    is more likely to be correct or incorrect based on a sample of data. Stationarity
    tests use hypothesis testing and are discussed in [Chapter 3](ch03.html#ch03).'
  prefs: []
  type: TYPE_NORMAL
- en: Decision trees
  prefs: []
  type: TYPE_NORMAL
- en: '*Decision trees* are a type of machine learning algorithm that borrows from
    probabilistic concepts such as conditional probability, a concept covered in this
    chapter. For more detail on decision trees, see [Chapter 7](ch07.html#ch07).'
  prefs: []
  type: TYPE_NORMAL
- en: Information theory
  prefs: []
  type: TYPE_NORMAL
- en: '*Information theory* is the complex study of how information is quantified,
    stored, and transmitted. It is incorporated into numerous machine learning techniques,
    including decision trees. It is also used in a type of nonlinear correlation measure
    called the maximal information coefficient, which is discussed in [Chapter 3](ch03.html#ch03).'
  prefs: []
  type: TYPE_NORMAL
- en: Introduction to Probabilistic Concepts
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The most basic piece of probabilistic information is a *random variable,* which
    is an uncertain number or outcome. Random variables are used to model events that
    are considered uncertain, such as the future return of a currency pair.
  prefs: []
  type: TYPE_NORMAL
- en: 'A random variable is either discrete or continuous. A *discrete random variable*
    has a finite set of values, while a *continuous random variable* has values within
    a certain interval. Consider the following examples to clarify things:'
  prefs: []
  type: TYPE_NORMAL
- en: 'An example of a discrete random variable would be the result of rolling a die.
    The outcomes are limited by the following set: {1, 2, 3, 4, 5, 6}.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: An example of a continuous random variable would be the daily price returns
    of EURUSD (the exchange rate of one euro expressed in US dollars).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Random variables are described by *probability distributions,* which are functions
    that give the probability of every possible value of these random variables. Generally,
    a histogram is used to show the probability. Histogram plotting is discussed in
    [Chapter 3](ch03.html#ch03).
  prefs: []
  type: TYPE_NORMAL
- en: At any moment, the probability that a certain event will unfold is between 0
    and 1\. This means that probability is assigned to random variables on a scale
    between 0 and 1 such that a probability of 0 represents zero chance of occurrence
    and a probability of 1 represents a certainty of occurrence.
  prefs: []
  type: TYPE_NORMAL
- en: You can also think of this in percentage terms, which range from 0% to 100%.
    Values within the two numbers are valid, which means that you can have a 0.5133
    (51.33%) probability of a certain event occurring. Consider rolling a die that
    has six sides. What is the probability of getting a 3 knowing that the die is
    not manipulated in any way?
  prefs: []
  type: TYPE_NORMAL
- en: 'As the die has six sides, there are six equal probabilities for every outcome,
    which means that for any outcome, the probability is found as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis x right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle displaystyle="false" scriptlevel="0"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'with *P(x)* designating the probability of event *x*. This gives the answer
    to the question:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 3 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>3</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle displaystyle="false" scriptlevel="0"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: When a die is rolled, there can only be one result. It cannot give a 3 and a
    4 simultaneously, since one side has to dominate the other. This is the concept
    of *mutual exclusivity*. Mutually exclusive events (such as getting a 3 or getting
    a 4 in a die roll) eventually sum to 1.
  prefs: []
  type: TYPE_NORMAL
- en: 'Take a look at the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 1 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>1</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle displaystyle="false" scriptlevel="0"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 2 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>2</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle displaystyle="false" scriptlevel="0"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 3 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>3</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle displaystyle="false" scriptlevel="0"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 4 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>4</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle displaystyle="false" scriptlevel="0"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 5 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>5</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle displaystyle="false" scriptlevel="0"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 6 right-parenthesis equals one-sixth
    equals 0.167"><mrow><mi>P</mi> <mrow><mo>(</mo> <mn>6</mn> <mo>)</mo></mrow> <mo>=</mo>
    <mstyle displaystyle="false" scriptlevel="0"><mfrac><mn>1</mn> <mn>6</mn></mfrac></mstyle>
    <mo>=</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>167</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Summing all these mutually exclusive events gives 1, which means that the sum
    of the possible probabilities in a six-sided die is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis 1 right-parenthesis plus upper P left-parenthesis
    2 right-parenthesis plus upper P left-parenthesis 3 right-parenthesis plus upper
    P left-parenthesis 4 right-parenthesis plus upper P left-parenthesis 5 right-parenthesis
    plus upper P left-parenthesis 6 right-parenthesis equals 1"><mrow><mi>P</mi> <mo>(</mo>
    <mn>1</mn> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mn>2</mn> <mo>)</mo> <mo>+</mo>
    <mi>P</mi> <mo>(</mo> <mn>3</mn> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mn>4</mn>
    <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mn>5</mn> <mo>)</mo> <mo>+</mo> <mi>P</mi>
    <mo>(</mo> <mn>6</mn> <mo>)</mo> <mo>=</mo> <mn>1</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Stating that a random variable has a 0.8 probability of occurring is the same
    as stating that the same variable has a 0.2 probability of not occurring.
  prefs: []
  type: TYPE_NORMAL
- en: Probability measures can be conditional or unconditional. A *conditional probability*
    is when the occurrence of an event impacts the probability that another event
    occurs. For example, the probability of a sovereign interest rate hike given positive
    employment data is an example of a conditional probability. The probability of
    event A given the occurrence of event B is denoted by the mathematical notation
    *P(A|B)*.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, *unconditional probability* is not dependent on other events. Taking
    the example of conditional probability, you can formulate an unconditional probability
    calculation that measures the probability of an interest rate hike regardless
    of other economic events.
  prefs: []
  type: TYPE_NORMAL
- en: 'Probabilities have specific addition and multiplication rules with their own
    interpretations. Let’s take a look at the formulas before seeing an example. The
    *joint probability* of the realization of two events is the probability that they
    will both occur. It is calculated using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A upper B right-parenthesis equals
    upper P left-parenthesis upper A vertical-bar upper B right-parenthesis times
    upper P left-parenthesis upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo>
    <mi>A</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>|</mo>
    <mi>B</mi> <mo>)</mo> <mo>×</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: That formula says the probability of occurrence for both A and B is the probability
    that A occurs given B occurs multiplied by the probability that B occurs. Therefore,
    the right side of the equation multiplies a conditional probability by an unconditional
    probability.
  prefs: []
  type: TYPE_NORMAL
- en: 'The *addition rule* is used to determine the probability that at least one
    of the two outcomes will occur. This works in two ways: one deals with mutually
    exclusive events, and the other deals with events that are not mutually exclusive.'
  prefs: []
  type: TYPE_NORMAL
- en: 'If the events are not mutually exclusive, then to avoid double counting, the
    formula is:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A o r upper B right-parenthesis
    equals upper P left-parenthesis upper A right-parenthesis plus upper P left-parenthesis
    upper B right-parenthesis minus upper P left-parenthesis upper A upper B right-parenthesis"><mrow><mi>P</mi>
    <mo>(</mo> <mi>A</mi> <mi>o</mi> <mi>r</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi>
    <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>+</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo>
    <mo>-</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>B</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'If the events are mutually exclusive, then the formula is simplified to the
    following:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A upper B right-parenthesis equals
    0"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A o r upper B right-parenthesis
    equals upper P left-parenthesis upper A right-parenthesis plus upper P left-parenthesis
    upper B right-parenthesis minus 0"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>o</mi>
    <mi>r</mi> <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo>
    <mo>+</mo> <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo> <mo>-</mo> <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A o r upper B right-parenthesis
    equals upper P left-parenthesis upper A right-parenthesis plus upper P left-parenthesis
    upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>o</mi> <mi>r</mi>
    <mi>B</mi> <mo>)</mo> <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>+</mo>
    <mi>P</mi> <mo>(</mo> <mi>B</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Notice how in mutually exclusive events, it’s either A or B that can be realized,
    and therefore, the probability that both of them will occur is zero. To understand
    why you need to subtract the joint probability of A and B, take a look at [Figure 2-1](#figure-2-1).
  prefs: []
  type: TYPE_NORMAL
- en: '![](assets/dlff_0201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. The addition rule of probability
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Notice how the probability of either A or B occurring while they are mutually
    exclusive must not include their joint probability. Let’s now look at the concept
    of independent events.
  prefs: []
  type: TYPE_NORMAL
- en: '*Independent events* are not tied to one another (e.g., rolling the die twice).
    In this case, the joint probability is calculated as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis upper A upper B right-parenthesis equals
    upper P left-parenthesis upper A right-parenthesis times upper P left-parenthesis
    upper B right-parenthesis"><mrow><mi>P</mi> <mo>(</mo> <mi>A</mi> <mi>B</mi> <mo>)</mo>
    <mo>=</mo> <mi>P</mi> <mo>(</mo> <mi>A</mi> <mo>)</mo> <mo>×</mo> <mi>P</mi> <mo>(</mo>
    <mi>B</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Independent events therefore refer to instances where the occurrence of one
    event has absolutely zero impact on the occurrence of the other event(s). Let’s
    see an example to validate this concept. Consider a simple coin toss. The probability
    of getting heads does not depend on what you got in the previous coin toss. Therefore,
    the probability of getting heads is always 0.50 (50%). To take things further,
    what is the probability of getting only heads after five coin tosses?
  prefs: []
  type: TYPE_NORMAL
- en: 'As the probability of each event is independent from the previous or the next
    one, the formula is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper P left-parenthesis x right-parenthesis equals 0.50 times
    0.50 times 0.50 times 0.50 times 0.50 equals 0.03125 equals 3.125 percent-sign"><mrow><mi>P</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo> <mo>=</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo>
    <mn>50</mn> <mo>×</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>50</mn>
    <mo>×</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>50</mn> <mo>×</mo>
    <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>50</mn> <mo>×</mo> <mn>0</mn>
    <mo lspace="0%" rspace="0%">.</mo> <mn>50</mn> <mo>=</mo> <mn>0</mn> <mo lspace="0%"
    rspace="0%">.</mo> <mn>03125</mn> <mo>=</mo> <mn>3</mn> <mo lspace="0%" rspace="0%">.</mo>
    <mn>125</mn> <mo lspace="0%" rspace="0%">%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The *expected value* of a random variable is the weighted average of the different
    outcomes. Therefore, the expected value is really another way of referring to
    the mean. Mathematically, the expected value is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper E left-parenthesis upper X right-parenthesis equals sigma-summation
    Underscript i equals 1 Overscript n Endscripts left-parenthesis upper P left-parenthesis
    x Subscript i Baseline right-parenthesis x Subscript i Baseline right-parenthesis"><mrow><mi>E</mi>
    <mrow><mo>(</mo> <mi>X</mi> <mo>)</mo></mrow> <mo>=</mo> <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>n</mi></msubsup> <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow> <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Take a look at [Table 2-1](#table-2-1) and try to calculate the expected value
    of the next employment numbers in a certain month of the year.
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-1\. Employment numbers
  prefs: []
  type: TYPE_NORMAL
- en: '| Nonfarm payrolls | Probability |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 300,000 | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '| 400,000 | 0.3 |'
  prefs: []
  type: TYPE_TB
- en: '| 500,000 | 0.5 |'
  prefs: []
  type: TYPE_TB
- en: '| 600,000 | 0.1 |'
  prefs: []
  type: TYPE_TB
- en: '*Nonfarm payrolls* refer to a monthly report issued by the US Department of
    Labor that gives information on the total number of paid employees in the nation,
    excluding those employed in the agriculture sector, as well as those employed
    by the government and nonprofit organizations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'From [Table 2-1](#table-2-1), economists assume there is a 50% probability
    that there will be a 500,000 increase in the total number of paid employees and
    a 30% probability that there will be a 400,000 increase in the total number of
    paid employees. The expected value is therefore:'
  prefs: []
  type: TYPE_NORMAL
- en: <math><mtable displaystyle="true"><mtr><mtd columnalign="right"><mrow><mi>E</mi>
    <mo>(</mo> <mi>X</mi> <mo>)</mo></mrow></mtd> <mtd columnalign="left"><mrow><mo>=</mo>
    <mo>(</mo> <mn>300</mn> <mo>,</mo> <mn>000</mn> <mo>×</mo> <mn>0</mn> <mo lspace="0%"
    rspace="0%">.</mo> <mn>1</mn> <mo>)</mo> <mo>+</mo> <mo>(</mo> <mn>400</mn> <mo>,</mo>
    <mn>000</mn> <mo>×</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>3</mn>
    <mo>)</mo> <mo>+</mo> <mo>(</mo> <mn>500</mn> <mo>,</mo> <mn>000</mn> <mo>×</mo>
    <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>5</mn> <mo>)</mo> <mo>+</mo>
    <mo>(</mo> <mn>600</mn> <mo>,</mo> <mn>000</mn> <mo>×</mo> <mn>0</mn> <mo lspace="0%"
    rspace="0%">.</mo> <mn>1</mn> <mo>)</mo></mrow></mtd></mtr> <mtr><mtd columnalign="left"><mrow><mo>=</mo>
    <mn>460</mn> <mo>,</mo> <mn>000</mn></mrow></mtd></mtr></mtable></math>
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, the number that represents the economists’ consensus is 460,000,
    as it is the closest weighted value to most forecasts. It is the value that represents
    the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The main takeaways from this section are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Probabilitydescribes random variables and random events. It is a value between
    0 and 1.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Probabilities of events may be grouped together to form more complex scenarios.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The expected outcome is the weighted average of every probability in the designated
    universe.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Sampling and Hypothesis Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When populations are large, representative samples are taken so that they become
    the main describers of data. Take the United States. Its democratic system means
    that the people hold the right to decide their own fate, but it’s not possible
    to go to every person and ask them for their detailed opinions on every topic
    out there. This is why elections are held and representatives are elected to act
    in the people’s name.
  prefs: []
  type: TYPE_NORMAL
- en: '*Sampling* refers to the act of selecting samples of data within a larger population
    and making conclusions about the statistical properties of the population. There
    are a few different methods of sampling. The best-known ones are the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Simple random sampling
  prefs: []
  type: TYPE_NORMAL
- en: With simple random sampling, each element in the population has an equal chance
    of being selected for the sample. This can be a random number generated on a labeled
    population where each individual has the same probability of being selected.
  prefs: []
  type: TYPE_NORMAL
- en: Stratified sampling
  prefs: []
  type: TYPE_NORMAL
- en: With stratified sampling, the population is divided into groups based on some
    characteristic, and then a simple random sample is taken from each group in proportion
    to its size.
  prefs: []
  type: TYPE_NORMAL
- en: Cluster sampling
  prefs: []
  type: TYPE_NORMAL
- en: With cluster sampling, the population is divided into clusters, and a random
    sample of clusters is selected. Then, all elements within the selected clusters
    are included in the sample.
  prefs: []
  type: TYPE_NORMAL
- en: Systematic sampling
  prefs: []
  type: TYPE_NORMAL
- en: With systematic sampling, an element is selected by choosing every *n*th individual
    from the population, where *n* is a fixed number. This means that it is not random
    but specified in advance.
  prefs: []
  type: TYPE_NORMAL
- en: A rule of thumb is that the more data you acquire, the better the metrics reflect
    the population. Sampling is extremely important in the world of machine learning,
    as quite often you are taking samples of data to represent the true population.
    For example, when performing a backtest on a trading strategy, you will be required
    to split the whole dataset into a *training sample* and a *testing sample* where
    the first is the sample of data on which the algorithm understands its structure
    (also known as the *in-sample set*), and the second is the sample of data on which
    the algorithm tests its predictive power (also known as the *out-of-sample set*).
  prefs: []
  type: TYPE_NORMAL
- en: Another example of using sampling is *cross validation*. With this technique,
    a dataset is divided into two or more subsets. The model is trained using one
    subset, and its results are tested using the other subset(s). For various subsets
    of the data, this procedure is repeated numerous times, and then the model’s average
    performance is determined.
  prefs: []
  type: TYPE_NORMAL
- en: These terms are discussed in more depth in the coming chapters. For now, you
    should understand that the concept of sampling is very important in machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Sampling is not perfect, and errors may be possible, just as in any other estimation
    method. *Sampling error* refers to the difference between the statistic of the
    sample and the statistic of the population (if it’s known). A *statistic* is a
    metric that describes the analyzed dataset (an example of this would be the mean,
    a statistic you will see in greater detail in [Chapter 3](ch03.html#ch03)). Now,
    what is the minimum sample size you should have to be able to make inferences
    about the population? The rule of thumb is to have a minimum of 30 observations,
    and the more the merrier. This brings the discussion to the *central limit theorem*,
    which states that random samples drawn from a population will approach a normal
    distribution (a probability distribution that is symmetric and bell shaped) as
    the sample gets larger.
  prefs: []
  type: TYPE_NORMAL
- en: 'The central limit theorem makes it simple to apply inferences and conclusions
    as hypothesis testing goes well with a normal distribution. Before proceeding
    to hypothesis testing, let’s look at *confidence intervals*, which are ranges
    of values where the population parameter is expected to be. Confidence intervals
    are generally constructed by adding or subtracting a factor from the point estimate.
    For example, given a sample mean x̄, a confidence interval can be constructed
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="x overbar plus-or-minus left-parenthesis reliability factor times
    standard error right-parenthesis"><mrow><mover accent="true"><mi>x</mi> <mo>¯</mo></mover>
    <mo>±</mo> <mrow><mo>(</mo> <mtext>reliability</mtext> <mtext>factor</mtext> <mo>×</mo>
    <mtext>standard</mtext> <mtext>error</mtext> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Let’s try to understand the calculation step by step. The sample mean is an
    estimate of the population and is calculated because it is not possible to calculate
    the population mean. Therefore, by performing a random sample, the assumption
    is that the sample mean should be equal to the population mean. However, in real
    life, things may differ, and this is why you should construct a confidence interval
    using probabilistic methods.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: The *significance level* is the threshold of the confidence interval. For example,
    a confidence interval of 95% means that with 95% confidence, the estimate should
    lie within a certain range. The remaining 5% probability that it does not is the
    significance level (generally marked with the letter alpha, α).
  prefs: []
  type: TYPE_NORMAL
- en: A *reliability f**actor* is a statistical measure that depends on the distribution
    of the estimate and the probability that it falls within the confidence interval.
    For the sake of simplicity, let’s assume that the variance of the population is
    normal and the population is normally distributed. For a significance level of
    5% (thus, a confidence interval of 95%), the reliability factor is 1.96 in this
    case (the way you get this number is less relevant to the discussion).
  prefs: []
  type: TYPE_NORMAL
- en: 'The *standard error* is the standard deviation of the sample. *Standard deviation*
    is discussed in greater depth in [Chapter 3](ch03.html#ch03); for now, just know
    that it represents the degree of fluctuation of the different values around the
    mean. Standard error is found using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="s equals StartFraction sigma Over StartRoot n EndRoot EndFraction"><mrow><mi>s</mi>
    <mo>=</mo> <mfrac><mi>σ</mi> <msqrt><mi>n</mi></msqrt></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="sigma is the population standard deviation"><mrow><mi>σ</mi>
    <mtext>is</mtext> <mtext>the</mtext> <mtext>population</mtext> <mtext>standard</mtext>
    <mtext>deviation</mtext></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="StartRoot n EndRoot is the square root of the population number"><mrow><msqrt><mi>n</mi></msqrt>
    <mtext>is</mtext> <mtext>the</mtext> <mtext>square</mtext> <mtext>root</mtext>
    <mtext>of</mtext> <mtext>the</mtext> <mtext>population</mtext> <mtext>number</mtext></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: It is also worth knowing that for a 1% significance level, the reliability factor
    is 2.575, and for a 10% significance level, the reliability factor is 1.645\.
    Let’s take a look at a practical example to make sense of all this math.
  prefs: []
  type: TYPE_NORMAL
- en: Consider a population of 100 financial instruments (bonds, currency pairs, stocks,
    structured products, etc.). The mean annual return of these instruments is 1.4%.
    Assuming a population standard deviation of 4.34%, what is the confidence interval
    at a 1% significance level (99% confidence interval) of the mean?
  prefs: []
  type: TYPE_NORMAL
- en: 'The answer is determined by just plugging the values into the formula as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="1.4 percent-sign plus-or-minus 2.575 times StartFraction 4.34
    percent-sign Over StartRoot 100 EndRoot EndFraction equals 1.4 percent-sign plus-or-minus
    1.11 percent-sign"><mrow><mn>1</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>4</mn>
    <mo lspace="0%" rspace="0%">%</mo> <mo>±</mo> <mn>2</mn> <mo lspace="0%" rspace="0%">.</mo>
    <mn>575</mn> <mo>×</mo> <mfrac><mrow><mn>4</mn><mo lspace="0%" rspace="0%">.</mo><mn>34</mn><mo
    lspace="0%" rspace="0%">%</mo></mrow> <msqrt><mn>100</mn></msqrt></mfrac> <mo>=</mo>
    <mn>1</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>4</mn> <mo lspace="0%" rspace="0%">%</mo>
    <mo>±</mo> <mn>1</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>11</mn> <mo lspace="0%"
    rspace="0%">%</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: This means that the confidence interval is between (0.29%, 2.51%).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: If the sample size is small and/or the population standard deviation is unknown,
    a t-distribution may be a better choice than a normal distribution.
  prefs: []
  type: TYPE_NORMAL
- en: The *t-distribution* is a type of probability distribution used to model the
    distribution of a sample mean when the sample size is small and/or when the population
    standard deviation is unknown. It resembles the normal distribution in shape but
    with heavier tails, which represents the uncertainty associated with smaller sample
    sizes.
  prefs: []
  type: TYPE_NORMAL
- en: The next stop is hypothesis testing, a key probabilistic technique of getting
    conclusions on samples of data. This part is extremely important, as it’s used
    in a lot of statistical analyses and models.
  prefs: []
  type: TYPE_NORMAL
- en: In statistics, *hypothesis testing* is a technique for drawing conclusions about
    a population from a small sample of data. It entails developing two competing
    hypotheses, the *null hypothesis* and the *alternative hypothesis*, about a population
    parameter and then figuring out which is more likely to be accurate using sample
    data.
  prefs: []
  type: TYPE_NORMAL
- en: 'For example, say that a financial analyst is evaluating two portfolios from
    a risk perspective. They formulate two hypotheses:'
  prefs: []
  type: TYPE_NORMAL
- en: The null hypothesis states that there is no significant difference in the volatility
    of the two portfolios.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The alternative hypothesis states that there is a significant difference in
    the volatility of the two portfolios.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The hypothesis is then tested using statistical analysis to determine whether
    the difference in volatility is statistically significant or due to pure chance.
  prefs: []
  type: TYPE_NORMAL
- en: Following the definition of null and alternative hypotheses, a test statistic
    is computed using the sample data. To assess the result’s significance, the test
    statistic is then compared to a critical value drawn from a standard distribution.
    The null hypothesis is rejected and the alternative hypothesis is accepted if
    the test statistic is inside the crucial zone. The null hypothesis is not rejected
    and the conclusion that there is insufficient evidence to support the alternative
    hypothesis is reached if the test statistic does not fall inside the crucial zone.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is all a fancy way of saying that hypothesis testing basically involves
    creating two opposing scenarios, running a probability check, and then deciding
    which scenario is more likely true. Hypothesis testing can take two forms:'
  prefs: []
  type: TYPE_NORMAL
- en: One-tailed test
  prefs: []
  type: TYPE_NORMAL
- en: An example of this would be to test if the return on certain financial instruments
    is greater than zero.
  prefs: []
  type: TYPE_NORMAL
- en: Two-tailed test
  prefs: []
  type: TYPE_NORMAL
- en: An example of this would be to test if the return on certain financial instruments
    is different from zero (meaning that it can be either greater than or less than
    zero). Hypothesis tests are generally two-tailed tests.
  prefs: []
  type: TYPE_NORMAL
- en: 'The null hypothesis is the one that you want to reject and therefore is tested
    in the hopes of getting rejected and accepting the alternative scenario. A two-tailed
    test takes the following general form:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H 0 colon x equals x 0"><mrow><msub><mi>H</mi> <mn>0</mn></msub>
    <mo>:</mo> <mi>x</mi> <mo>=</mo> <msub><mi>x</mi> <mn>0</mn></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H Subscript a Baseline colon x not-equals x 0"><mrow><msub><mi>H</mi>
    <mi>a</mi></msub> <mo>:</mo> <mi>x</mi> <mo>≠</mo> <msub><mi>x</mi> <mn>0</mn></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: As the alternative scenario allows for values above and below zero (which is
    the stated level in the null hypothesis), there should be two critical values.
    Therefore, the rule of a two-tailed test is to reject the null hypothesis if the
    test statistic is greater than the upper critical value or less than the lower
    critical value. For instance, for a normally distributed dataset, the test statistic
    is compared with the critical values (at 5% significance level) at +1.96 and –1.96\.
    The null hypothesis is rejected if the test statistic falls outside the range
    of +1.96 and –1.96.
  prefs: []
  type: TYPE_NORMAL
- en: 'The process of hypothesis testing entails the calculation of the test statistic.
    This is done by comparing the point estimate of the population parameter with
    the hypothesized value of the null hypothesis. Both are then scaled by the standard
    error of the sample. The mathematical representation is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="Test statistic equals StartFraction Sample statistic minus Hypothesized
    value Over Standard error EndFraction"><mrow><mtext>Test</mtext> <mtext>statistic</mtext>
    <mo>=</mo> <mstyle displaystyle="false" scriptlevel="0"><mfrac><mrow><mtext>Sample</mtext><mtext>statistic</mtext><mo>-</mo><mtext>Hypothesized</mtext><mtext>value</mtext></mrow>
    <mrow><mtext>Standard</mtext><mtext>error</mtext></mrow></mfrac></mstyle></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'An important consideration in hypothesis testing is that the sample may not
    be representative, which leads to errors in describing the population. This gives
    rise to two types of errors:'
  prefs: []
  type: TYPE_NORMAL
- en: '*Type I error*'
  prefs: []
  type: TYPE_NORMAL
- en: This error occurs when rejecting the null hypothesis even though it is true.
  prefs: []
  type: TYPE_NORMAL
- en: '*Type II error*'
  prefs: []
  type: TYPE_NORMAL
- en: This error occurs when failing to reject the null hypothesis even though it
    is false.
  prefs: []
  type: TYPE_NORMAL
- en: Intuitively, the significance level is the probability of making a type I error.
    Remember that if α = 5%, then there is a 5% chance of rejecting a true null hypothesis
    by mistake. An example would make things clearer.
  prefs: []
  type: TYPE_NORMAL
- en: 'Consider an analyst doing research on the annual returns of a long–short portfolio
    over a period of 20 years. The mean annual return was 1% with a standard deviation
    of 2%. The analyst’s opinion is that the mean annual return is not equal to zero,
    and they want to construct a 95% confidence interval for this and then construct
    a hypothesis test. You would proceed as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: State the variables. The size of the sample is 20, the standard deviation is
    2%, and the mean is 1%.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Calculate the standard error, which in this case is 0.44% as per the formula.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Define the critical values for the 95% confidence interval. The critical values
    are +1.96 and –1.96\. To find the confidence interval, add and subtract the margin
    of error from the sample mean. The confidence interval is therefore (0.13%, 1.86%).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Specify the null hypothesis, which is, according to the analyst’s opinion, a
    two-tailed test. The null hypothesis is that the annual return equals zero. You
    should reject it if the test statistic is less than –1.96 or greater than +1.96.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Using the formula to find the test statistic gives 2.27\. Therefore, the null
    hypothesis is rejected.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: One more important metric to discuss is the p-value. The *p-value* is the probability
    of seeing a test statistic more extreme than the one seen in the statistical test
    given that the null hypothesis is true. Comparing a p-value to a significance
    level—typically 0.05—allows you to understand it. The result is deemed statistically
    significant, and the null hypothesis is rejected in favor of the alternative hypothesis
    if the p-value is less than or equal to the significance level.
  prefs: []
  type: TYPE_NORMAL
- en: If the p-value is less than the significance level of 5%, it means that there
    is a 5% chance you will see a test statistic as extreme as the current one if
    the null hypothesis is true. Another way of defining the p-value is to consider
    it as being the smallest significance level for which the null hypothesis can
    be rejected.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The main takeaways from this section are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: Sampling refers to the collection of data within a population, with the aim
    of making conclusions about the statistical properties of the aforementioned population.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hypothesis testing is a technique for drawing conclusions about a population
    from a small sample of data.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A Primer on Information Theory
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*Information theory* is a complex field in abstract mathematics that is closely
    related to probability. It is the study of how information is quantified, stored,
    and transmitted. There are three conditions of occurrence when it comes to an
    event:'
  prefs: []
  type: TYPE_NORMAL
- en: Uncertainty
  prefs: []
  type: TYPE_NORMAL
- en: If the event has not occurred yet
  prefs: []
  type: TYPE_NORMAL
- en: Surprise
  prefs: []
  type: TYPE_NORMAL
- en: If the event has just occurred
  prefs: []
  type: TYPE_NORMAL
- en: Information
  prefs: []
  type: TYPE_NORMAL
- en: If the event has occurred in the past
  prefs: []
  type: TYPE_NORMAL
- en: One of the key concepts in information theory is *entropy*, which is the level
    of uncertainty or randomness in a message or information source and describes
    the degree to which an event or message is unexpected. In contrast, *information
    gain* measures the reduction in entropy (surprise) when receiving new information.
  prefs: []
  type: TYPE_NORMAL
- en: Basically, information theory describes the surprise of events. When an event
    has a low probability of occurrence, it has more surprise and hence more information
    to provide. Similarly, when an event has a high probability of occurrence, it
    has less surprise and therefore less information. What you should retain from
    this is that the amount of information learned from an unlikely event is greater
    than the amount of information learned from a likely event.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before starting to dig a little deeper into the field of information theory,
    it is important to understand what a logarithm is and, for that matter, what an
    exponent is. A general exponential function takes a certain constant or a variable
    to a certain power:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="f left-parenthesis x right-parenthesis equals a Superscript x"><mrow><mi>f</mi>
    <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <msup><mi>a</mi> <mi>x</mi></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'In other words, the *exponent of a number* is the number of times you will
    multiply it by itself:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="4 cubed equals 4 times 4 times 4 equals 64"><mrow><msup><mn>4</mn>
    <mn>3</mn></msup> <mo>=</mo> <mn>4</mn> <mo>×</mo> <mn>4</mn> <mo>×</mo> <mn>4</mn>
    <mo>=</mo> <mn>64</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'A logarithm is the opposite of an exponent, and its aim is to find the exponent—knowing
    4 and 64 from the previous example and finding 3:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="log Subscript 4 Baseline left-parenthesis 64 right-parenthesis
    equals 3"><mrow><msub><mo form="prefix">log</mo> <mn>4</mn></msub> <mrow><mo>(</mo>
    <mn>64</mn> <mo>)</mo></mrow> <mo>=</mo> <mn>3</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'A logarithm therefore is the answer to how many of one number to multiply to
    get another number. Since they are literally inverse functions, you can use them
    together to simplify or even solve for *x*. Take the following example:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="log Subscript 4 Baseline left-parenthesis x right-parenthesis
    equals 3"><mrow><msub><mo form="prefix">log</mo> <mn>4</mn></msub> <mrow><mo>(</mo>
    <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo> <mn>3</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'The objective here is to find *x* given the logarithmic function. The first
    step is simply to use the exponential function on one side as you want it to cancel
    out the logarithm on the right (inverse functions cancel each other out). This
    gives us the following result:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="4 Superscript l o g 4 left-parenthesis x right-parenthesis Baseline
    equals 4 cubed"><mrow><msup><mn>4</mn> <mrow><mi>l</mi><mi>o</mi><msub><mi>g</mi>
    <mn>4</mn></msub> <mrow><mo>(</mo><mi>x</mi><mo>)</mo></mrow></mrow></msup> <mo>=</mo>
    <msup><mn>4</mn> <mn>3</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="x equals 4 cubed"><mrow><mi>x</mi> <mo>=</mo> <msup><mn>4</mn>
    <mn>3</mn></msup></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="x equals 64"><mrow><mi>x</mi> <mo>=</mo> <mn>64</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Logarithms can have different bases. However, the most used logarithm has a
    base of 10\. In computer science, base 2 logarithms represent bits (binary digits).
    Therefore, information is represented as bits. The formula of information gain
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H left-parenthesis x Subscript i Baseline right-parenthesis
    equals minus l o g 2 left-parenthesis upper P left-parenthesis x Subscript i Baseline
    right-parenthesis right-parenthesis"><mrow><mi>H</mi> <mrow><mo>(</mo> <msub><mi>x</mi>
    <mi>i</mi></msub> <mo>)</mo></mrow> <mo>=</mo> <mo>-</mo> <mi>l</mi> <mi>o</mi>
    <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo>
    <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s assume two variables *x* and *y*, where *x* has a probability of 1 (100%
    and therefore certain) and *y* has a probability of 0.5 (50% and therefore mostly
    random). What would be the information value in these two cases? The answer is
    as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H left-parenthesis x right-parenthesis equals minus l o
    g 2 left-parenthesis upper P left-parenthesis 1 right-parenthesis right-parenthesis
    equals 0"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>x</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mn>1</mn> <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo>
    <mn>0</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H left-parenthesis y right-parenthesis equals minus l o
    g 2 left-parenthesis upper P left-parenthesis 0.5 right-parenthesis right-parenthesis
    equals 1"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>y</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>5</mn>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mn>1</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: So the certain event has an information value of zero, and the one that has
    a 50-50 chance of realizing has an information value of 1\. What about the very
    unlikely event *z* that has a probability of 0.05 (5%)?
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper H left-parenthesis z right-parenthesis equals minus l o
    g 2 left-parenthesis upper P left-parenthesis 0.05 right-parenthesis right-parenthesis
    equals 4.32"><mrow><mi>H</mi> <mrow><mo>(</mo> <mi>z</mi> <mo>)</mo></mrow> <mo>=</mo>
    <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <mn>0</mn> <mo lspace="0%" rspace="0%">.</mo> <mn>05</mn>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo>=</mo> <mn>4</mn> <mo lspace="0%" rspace="0%">.</mo>
    <mn>32</mn></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: A negative relationship between probability and information is one of the principles
    of information theory. Entropy and information are related concepts, but they
    have different meanings and applications.
  prefs: []
  type: TYPE_NORMAL
- en: '*Entropy* is a metric used to assess how chaotic or random a system is. Entropy
    describes how uncertain or unpredictable a signal is. The degree of disorder or
    unpredictability in the system or communication increases as entropy increases.'
  prefs: []
  type: TYPE_NORMAL
- en: '*Information* is the decrease in entropy or uncertainty that happens as a result
    of receiving a signal. A signal’s ability to lessen the receiver’s uncertainty
    or entropy increases with its informational content.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Entropy is maximized whenever all the events are equally likely.
  prefs: []
  type: TYPE_NORMAL
- en: 'Entropy is calculated using the following formula:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper S left-parenthesis x Subscript n Baseline right-parenthesis
    equals sigma-summation Underscript i equals 1 Overscript n Endscripts left-parenthesis
    minus l o g 2 left-parenthesis upper P left-parenthesis x Subscript i Baseline
    right-parenthesis right-parenthesis period left-parenthesis upper P left-parenthesis
    x Subscript i Baseline right-parenthesis right-parenthesis right-parenthesis"><mrow><mi>S</mi>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>n</mi></msub> <mo>)</mo></mrow> <mo>=</mo>
    <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi></msubsup>
    <mrow><mo>(</mo> <mo>-</mo> <mi>l</mi> <mi>o</mi> <msub><mi>g</mi> <mn>2</mn></msub>
    <mrow><mo>(</mo> <mi>P</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub>
    <mo>)</mo></mrow> <mo>)</mo></mrow> <mo lspace="0%" rspace="0%">.</mo> <mrow><mo>(</mo>
    <mi>P</mi> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow>
    <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: Therefore, entropy is the average of the sum of logarithms times their respective
    probabilities.
  prefs: []
  type: TYPE_NORMAL
- en: Now let’s discuss the final concept of the section, *information gain*. The
    reduction in entropy caused by changing a dataset is calculated via information
    gain.
  prefs: []
  type: TYPE_NORMAL
- en: Tip
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Information gain is one of the key concepts you will see in [Chapter 7](ch07.html#ch07)
    with decision trees, and therefore, you may want to refer back to this section
    after reading that chapter.
  prefs: []
  type: TYPE_NORMAL
- en: The typical way to calculate information gain is by comparing the entropy of
    a dataset before and after a transformation. Recall that entropy is maximized
    when all the outcomes of a random event have the same probability. This can also
    be presented as a distribution, where a symmetrical distribution (such as the
    normal distribution) has high entropy and a skewed distribution has low entropy.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Minimizing entropy is related to maximizing information gain.
  prefs: []
  type: TYPE_NORMAL
- en: 'Before closing this introductory section on information theory, let’s look
    at the concept of *mutual information*. This measure is calculated between two
    variables, hence the name *mutual*, and it measures the reduction in uncertainty
    of a variable given another variable. The formula for mutual information is as
    follows:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper M upper I left-parenthesis x comma y right-parenthesis
    equals upper S left-parenthesis x right-parenthesis minus upper S left-parenthesis
    x vertical-bar y right-parenthesis"><mrow><mi>M</mi> <mi>I</mi> <mo>(</mo> <mi>x</mi>
    <mo>,</mo> <mi>y</mi> <mo>)</mo> <mo>=</mo> <mi>S</mi> <mo>(</mo> <mi>x</mi> <mo>)</mo>
    <mo>-</mo> <mi>S</mi> <mo>(</mo> <mi>x</mi> <mo>|</mo> <mi>y</mi> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: '*MI*(*x*, *y*) is the mutual information of *x* and *y*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*S*(*x*) is the entropy of *x*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*S*(*x*|*y*) is the conditional entropy of *x* and *y*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mutual information therefore measures the dependence between variables. The
    greater the mutual information, the bigger the relationship between the variables
    (a value of zero represents independent variables). Keep this concept in mind,
    as you will see it in [“Correlation”](ch03.html#correlation). This is because
    mutual information can also be a measure of nonlinear correlation between variables.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'To summarize, here is what you need to retain in information theory to have
    a basic knowledge of what’s to come:'
  prefs: []
  type: TYPE_NORMAL
- en: Information theory uses concepts from probability to calculate information and
    entropy, which are used in machine learning models and other calculations (such
    as correlation).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Information is the decrease in entropy or uncertainty that happens as a result
    of receiving a signal. Entropy is a metric used to assess how chaotic or random
    a system is.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mutual information is a measure of dependence between two random variables.
    It can also be used to calculate the correlation between the two.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Tools from information theory are used in some machine learning models such
    as decision trees.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: An understanding of probability presents a basic framework before moving to
    more advanced topics. This chapter skimmed over the concepts that you may encounter
    when dealing with machine and deep learning models. It is important to understand
    how probability is calculated and how hypothesis testing is performed (even though,
    in reality, algorithms will do this for you).
  prefs: []
  type: TYPE_NORMAL
- en: The next chapter is extremely important and presents the statistical knowledge
    you need, not just for machine learning but also for financial trading and even
    complex data analysis.
  prefs: []
  type: TYPE_NORMAL
