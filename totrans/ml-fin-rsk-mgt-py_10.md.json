["```py\nIn [1]: import pandas as pd\n        import numpy as np\n        import matplotlib.pyplot as plt\n        import seaborn as sns\n        from scipy.stats import zscore\n        import warnings\n        warnings.filterwarnings('ignore')\n\nIn [2]: fraud_data = pd.read_csv('fraudTrain.csv')\n        del fraud_data['Unnamed: 0']\n\nIn [3]: fraud_data.info()\n        <class 'pandas.core.frame.DataFrame'>\n        RangeIndex: 1296675 entries, 0 to 1296674\n        Data columns (total 22 columns):\n         #   Column                 Non-Null Count    Dtype\n        ---  ------                 --------------    -----\n         0   trans_date_trans_time  1296675 non-null  object\n         1   cc_num                 1296675 non-null  int64\n         2   merchant               1296675 non-null  object\n         3   category               1296675 non-null  object\n         4   amt                    1296675 non-null  float64\n         5   first                  1296675 non-null  object\n         6   last                   1296675 non-null  object\n         7   gender                 1296675 non-null  object\n         8   street                 1296675 non-null  object\n         9   city                   1296675 non-null  object\n         10  state                  1296675 non-null  object\n         11  zip                    1296675 non-null  int64\n         12  lat                    1296675 non-null  float64\n         13  long                   1296675 non-null  float64\n         14  city_pop               1296675 non-null  int64\n         15  job                    1296675 non-null  object\n         16  dob                    1296675 non-null  object\n         17  trans_num              1296675 non-null  object\n         18  unix_time              1296675 non-null  int64\n         19  merch_lat              1296675 non-null  float64\n         20  merch_long             1296675 non-null  float64\n         21  is_fraud               1296675 non-null  int64\n        dtypes: float64(5), int64(5), object(12)\n        memory usage: 217.6+ MB\n```", "```py\nIn [4]: plt.pie(fraud_data['is_fraud'].value_counts(), labels=[0, 1])\n        plt.title('Pie Chart for Dependent Variable');\n        print(fraud_data['is_fraud'].value_counts())\n        plt.show()\n        0    1289169\n        1       7506\n        Name: is_fraud, dtype: int64\n```", "```py\nIn [5]: import missingno as msno ![1](assets/1.png)\n\n        msno.bar(fraud_data) ![2](assets/2.png)\n```", "```py\nIn [6]: fraud_data['time'] = pd.to_datetime(fraud_data['trans_date_trans_time'])\n        del fraud_data['trans_date_trans_time']\n\nIn [7]: fraud_data['days'] = fraud_data['time'].dt.day_name()\n        fraud_data['hour'] = fraud_data['time'].dt.hour\n\nIn [8]: def fraud_cat(cols):\n            k = 1\n            plt.figure(figsize=(20, 40))\n            for i in cols:\n                categ = fraud_data.loc[fraud_data['is_fraud'] == 1, i].\\\n                        value_counts().sort_values(ascending=False).\\\n                        reset_index().head(10) ![1](assets/1.png)\n                plt.subplot(len(cols) / 2, len(cols) / 2, k)\n                bar_plot = plt.bar(categ.iloc[:, 0], categ[i])\n                plt.title(f'Cases per {i} Categories')\n                plt.xticks(rotation='45')\n                k+= 1\n            return categ, bar_plot\n\nIn [9]: cols = ['job', 'state', 'gender', 'category', 'days', 'hour']\n        _, bar_plot = fraud_cat(cols)\n        bar_plot\n```", "```py\nIn [10]: cols=['amt','gender','state','category',\n               'city_pop','job','is_fraud','days','hour']\n         fraud_data_df=fraud_data[cols]\n\nIn [11]: cat_cols=fraud_data[cols].select_dtypes(include='object').columns\n\nIn [12]: def one_hot_encoded_cat(data, cat_cols):\n             for i in cat_cols:\n                 df1 = pd.get_dummies(data[str(i)],\n                                      prefix=i, drop_first=True)\n                 data.drop(str(i), axis=1, inplace=True)\n                 data = pd.concat([data, df1], axis=1)\n             return data\n\nIn [13]: fraud_df = one_hot_encoded_cat(fraud_data_df, cat_cols)\n```", "```py\nIn [14]: num_col = fraud_data_df.select_dtypes(exclude='object').columns\n         fraud_data_df = fraud_data_df[num_col]\n         del fraud_data_df['is_fraud']\n\nIn [15]: plt.figure(figsize=(10,6))\n         corrmat = fraud_data_df.corr()\n         top_corr_features = corrmat.index\n         heat_map = sns.heatmap(corrmat, annot=True, cmap=\"viridis\")\n```", "```py\nIn [16]: from sklearn.model_selection import train_test_split\n         from sklearn.linear_model import LogisticRegression\n         from sklearn.model_selection import train_test_split\n         from sklearn.model_selection import GridSearchCV\n         from sklearn.model_selection import RandomizedSearchCV\n         from sklearn.metrics import (classification_report,\n                                     confusion_matrix, f1_score)\n\nIn [17]: non_fraud_class = fraud_df[fraud_df['is_fraud'] == 0]\n         fraud_class = fraud_df[fraud_df['is_fraud'] == 1]\n\nIn [18]: non_fraud_count,fraud_count=fraud_df['is_fraud'].value_counts()\n         print('The number of observations in non_fraud_class:', non_fraud_count)\n         print('The number of observations in fraud_class:', fraud_count)\n         The number of observations in non_fraud_class: 1289169\n         The number of observations in fraud_class: 7506\n\nIn [19]: non_fraud_under = non_fraud_class.sample(fraud_count) ![1](assets/1.png)\n         under_sampled = pd.concat([non_fraud_under, fraud_class], axis=0) ![2](assets/2.png)\n         X_under = under_sampled.drop('is_fraud',axis=1) ![3](assets/3.png)\n         y_under = under_sampled['is_fraud'] ![4](assets/4.png)\n\nIn [20]: X_train_under, X_test_under, y_train_under, y_test_under =\\\n                 train_test_split(X_under, y_under, random_state=0)\n```", "```py\nIn [21]: param_log = {'C': np.logspace(-4, 4, 4), 'penalty': ['l1', 'l2']}\n         log_grid = GridSearchCV(LogisticRegression(),\n                                 param_grid=param_log, n_jobs=-1)\n         log_grid.fit(X_train_under, y_train_under)\n         prediction_log = log_grid.predict(X_test_under)\n\nIn [22]: conf_mat_log = confusion_matrix(y_true=y_test_under,\n                                         y_pred=prediction_log)\n         print('Confusion matrix:\\n', conf_mat_log)\n         print('--' * 25)\n         print('Classification report:\\n',\n               classification_report(y_test_under, prediction_log))\n         Confusion matrix:\n          [[1534  310]\n          [ 486 1423]]\n         --------------------------------------------------\n         Classification report:\n                        precision    recall  f1-score   support\n\n                    0       0.76      0.83      0.79      1844\n                    1       0.82      0.75      0.78      1909\n\n             accuracy                           0.79      3753\n            macro avg       0.79      0.79      0.79      3753\n         weighted avg       0.79      0.79      0.79      3753\n```", "```py\nIn [23]: from sklearn.tree import DecisionTreeClassifier\n\nIn [24]: param_dt = {'max_depth': [3, 5, 10],\n                     'min_samples_split': [2, 4, 6],\n                     'criterion': ['gini', 'entropy']}\n         dt_grid = GridSearchCV(DecisionTreeClassifier(),\n                                param_grid=param_dt, n_jobs=-1)\n         dt_grid.fit(X_train_under, y_train_under)\n         prediction_dt = dt_grid.predict(X_test_under)\n\nIn [25]: conf_mat_dt = confusion_matrix(y_true=y_test_under,\n                                        y_pred=prediction_dt)\n         print('Confusion matrix:\\n', conf_mat_dt)\n         print('--' * 25)\n         print('Classification report:\\n',\n               classification_report(y_test_under, prediction_dt))\n         Confusion matrix:\n          [[1795   49]\n          [  84 1825]]\n         --------------------------------------------------\n         Classification report:\n                        precision    recall  f1-score   support\n\n                    0       0.96      0.97      0.96      1844\n                    1       0.97      0.96      0.96      1909\n\n             accuracy                           0.96      3753\n            macro avg       0.96      0.96      0.96      3753\n         weighted avg       0.96      0.96      0.96      3753\n```", "```py\nIn [26]: from sklearn.ensemble import RandomForestClassifier\n\nIn [27]: param_rf = {'n_estimators':[20,50,100] ,\n                  'max_depth':[3,5,10],\n                  'min_samples_split':[2,4,6],\n                  'max_features':['auto', 'sqrt', 'log2']}\n         rf_grid = GridSearchCV(RandomForestClassifier(),\n                               param_grid=param_rf, n_jobs=-1)\n         rf_grid.fit(X_train_under, y_train_under)\n         prediction_rf = rf_grid.predict(X_test_under)\n\nIn [28]: conf_mat_rf = confusion_matrix(y_true=y_test_under,\n                                        y_pred=prediction_rf)\n         print('Confusion matrix:\\n', conf_mat_rf)\n         print('--' * 25)\n         print('Classification report:\\n',\n               classification_report(y_test_under, prediction_rf))\n         Confusion matrix:\n          [[1763   81]\n          [ 416 1493]]\n         --------------------------------------------------\n         Classification report:\n                        precision    recall  f1-score   support\n\n                    0       0.81      0.96      0.88      1844\n                    1       0.95      0.78      0.86      1909\n\n             accuracy                           0.87      3753\n            macro avg       0.88      0.87      0.87      3753\n         weighted avg       0.88      0.87      0.87      3753\n```", "```py\nIn [29]: from xgboost import XGBClassifier\n\nIn [30]: param_boost = {'learning_rate': [0.01, 0.1],\n                        'max_depth': [3, 5, 7],\n                        'subsample': [0.5, 0.7],\n                        'colsample_bytree': [0.5, 0.7],\n                        'n_estimators': [10, 20, 30]}\n         boost_grid = RandomizedSearchCV(XGBClassifier(),\n                                         param_boost, n_jobs=-1)\n         boost_grid.fit(X_train_under, y_train_under)\n         prediction_boost = boost_grid.predict(X_test_under)\n\nIn [31]: conf_mat_boost = confusion_matrix(y_true=y_test_under,\n                                           y_pred=prediction_boost)\n         print('Confusion matrix:\\n', conf_mat_boost)\n         print('--' * 25)\n         print('Classification report:\\n',\n               classification_report(y_test_under, prediction_boost))\n         Confusion matrix:\n          [[1791   53]\n          [  75 1834]]\n         --------------------------------------------------\n         Classification report:\n                        precision    recall  f1-score   support\n\n                    0       0.96      0.97      0.97      1844\n                    1       0.97      0.96      0.97      1909\n\n             accuracy                           0.97      3753\n            macro avg       0.97      0.97      0.97      3753\n         weighted avg       0.97      0.97      0.97      3753\n```", "```py\nIn [32]: fraud_df_sampled = fraud_df.sample(int(len(fraud_df) * 0.2)) ![1](assets/1.png)\n\nIn [33]: cost_fp = 2\n         cost_fn = fraud_df_sampled['amt']\n         cost_tp = 2\n         cost_tn = 0\n         cost_mat = np.array([cost_fp * np.ones(fraud_df_sampled.shape[0]),\n                              cost_fn,\n                              cost_tp * np.ones(fraud_df_sampled.shape[0]),\n                              cost_tn * np.ones(fraud_df_sampled.shape[0])]).T ![2](assets/2.png)\n\nIn [34]: cost_log = conf_mat_log[0][1] * cost_fp + conf_mat_boost[1][0] * \\\n                     cost_fn.mean() + conf_mat_log[1][1] * cost_tp ![3](assets/3.png)\n         cost_dt = conf_mat_dt[0][1] * cost_fp + conf_mat_boost[1][0] * \\\n                   cost_fn.mean() + conf_mat_dt[1][1] * cost_tp ![3](assets/3.png)\n         cost_rf = conf_mat_rf[0][1] * cost_fp + conf_mat_boost[1][0] * \\\n                   cost_fn.mean() + conf_mat_rf[1][1] * cost_tp ![3](assets/3.png)\n         cost_boost = conf_mat_boost[0][1] * cost_fp + conf_mat_boost[1][0] * \\\n                      cost_fn.mean() + conf_mat_boost[1][1] * cost_tp ![3](assets/3.png)\n```", "```py\nIn [35]: import joblib\n         import sys\n         sys.modules['sklearn.externals.joblib'] = joblib\n         from costcla.metrics import cost_loss, savings_score\n         from costcla.models import BayesMinimumRiskClassifier\n\nIn [36]: X_train, X_test, y_train, y_test, cost_mat_train, cost_mat_test = \\\n         train_test_split(fraud_df_sampled.drop('is_fraud', axis=1),\n                                    fraud_df_sampled.is_fraud, cost_mat,\n                                    test_size=0.2, random_state=0)\n\nIn [37]: saving_models = []\n         saving_models.append(('Log. Reg.',\n                               LogisticRegression()))\n         saving_models.append(('Dec. Tree',\n                               DecisionTreeClassifier()))\n         saving_models.append(('Random Forest',\n                               RandomForestClassifier()))\n\nIn [38]: saving_score_base_all = []\n\n         for name, save_model in saving_models:\n             sv_model = save_model\n             sv_model.fit(X_train, y_train)\n             y_pred = sv_model.predict(X_test)\n             saving_score_base = savings_score(y_test, y_pred, cost_mat_test) ![1](assets/1.png)\n             saving_score_base_all.append(saving_score_base)\n             print('The saving score for {} is {:.4f}'.\n                   format(name, saving_score_base))\n             print('--' * 20)\n         The saving score for Log. Reg. is -0.5602\n         ----------------------------------------\n         The saving score for Dec. Tree is 0.6557\n         ----------------------------------------\n         The saving score for Random Forest is 0.4789\n         ----------------------------------------\n\nIn [39]: f1_score_base_all = []\n\n         for name, save_model in saving_models:\n             sv_model = save_model\n             sv_model.fit(X_train, y_train)\n             y_pred = sv_model.predict(X_test)\n             f1_score_base = f1_score(y_test, y_pred, cost_mat_test) ![2](assets/2.png)\n             f1_score_base_all.append(f1_score_base)\n             print('The F1 score for {} is {:.4f}'.\n                   format(name, f1_score_base))\n             print('--' * 20)\n         The F1 score for Log. Reg. is 0.0000\n         ----------------------------------------\n         The F1 score for Dec. Tree is 0.7383\n         ----------------------------------------\n         The F1 score for Random Forest is 0.7068\n         ----------------------------------------\n```", "```py\nIn [40]: from costcla.models import CostSensitiveLogisticRegression\n         from costcla.models import CostSensitiveDecisionTreeClassifier\n         from costcla.models import CostSensitiveRandomForestClassifier\n\nIn [41]: cost_sen_models = []\n         cost_sen_models.append(('Log. Reg. CS',\n                                 CostSensitiveLogisticRegression()))\n         cost_sen_models.append(('Dec. Tree CS',\n                                 CostSensitiveDecisionTreeClassifier()))\n         cost_sen_models.append(('Random Forest CS',\n                                 CostSensitiveRandomForestClassifier()))\n\nIn [42]: saving_cost_all = []\n\n         for name, cost_model in cost_sen_models:\n             cs_model = cost_model\n             cs_model.fit(np.array(X_train), np.array(y_train),\n                          cost_mat_train) ![1](assets/1.png)\n             y_pred = cs_model.predict(np.array(X_test))\n             saving_score_cost = savings_score(np.array(y_test),\n                                               np.array(y_pred), cost_mat_test)\n             saving_cost_all.append(saving_score_cost)\n             print('The saving score for {} is {:.4f}'.\n                   format(name, saving_score_cost))\n             print('--'*20)\n         The saving score for Log. Reg. CS is -0.5906\n         ----------------------------------------\n         The saving score for Dec. Tree CS is 0.8419\n         ----------------------------------------\n         The saving score for Random Forest CS is 0.8903\n         ----------------------------------------\n\nIn [43]: f1_score_cost_all = []\n\n         for name, cost_model in cost_sen_models:\n             cs_model = cost_model\n             cs_model.fit(np.array(X_train), np.array(y_train),\n                          cost_mat_train)\n             y_pred = cs_model.predict(np.array(X_test))\n             f1_score_cost = f1_score(np.array(y_test),\n                                      np.array(y_pred), cost_mat_test)\n             f1_score_cost_all.append(f1_score_cost)\n             print('The F1 score for {} is {:.4f}'. format(name,\n                                                           f1_score_cost))\n             print('--'*20)\n         The F1 score for Log. Reg. CS is 0.0000\n         ----------------------------------------\n         The F1 score for Dec. Tree CS is 0.3281\n         ----------------------------------------\n         The F1 score for Random Forest CS is 0.4012\n         ----------------------------------------\n```", "```py\nIn [44]: saving_score_bmr_all = []\n\n         for name, bmr_model in saving_models:\n             f = bmr_model.fit(X_train, y_train)\n             y_prob_test = f.predict_proba(np.array(X_test))\n             f_bmr = BayesMinimumRiskClassifier() ![1](assets/1.png)\n             f_bmr.fit(np.array(y_test), y_prob_test)\n             y_pred_test = f_bmr.predict(np.array(y_prob_test),\n                                         cost_mat_test)\n             saving_score_bmr = savings_score(y_test, y_pred_test,\n                                              cost_mat_test)\n             saving_score_bmr_all.append(saving_score_bmr)\n             print('The saving score for {} is {:.4f}'.\\\n                   format(name, saving_score_bmr))\n             print('--' * 20)\n         The saving score for Log. Reg. is 0.8064\n         ----------------------------------------\n         The saving score for Dec. Tree is 0.7343\n         ----------------------------------------\n         The saving score for Random Forest is 0.9624\n         ----------------------------------------\n\nIn [45]: f1_score_bmr_all = []\n\n         for name, bmr_model in saving_models:\n             f = bmr_model.fit(X_train, y_train)\n             y_prob_test = f.predict_proba(np.array(X_test))\n             f_bmr = BayesMinimumRiskClassifier()\n             f_bmr.fit(np.array(y_test), y_prob_test)\n             y_pred_test = f_bmr.predict(np.array(y_prob_test),\n                                         cost_mat_test)\n             f1_score_bmr = f1_score(y_test, y_pred_test)\n             f1_score_bmr_all.append(f1_score_bmr)\n             print('The F1 score for {} is {:.4f}'.\\\n                   format(name, f1_score_bmr))\n             print('--'*20)\n         The F1 score for Log. Reg. is 0.1709\n         ----------------------------------------\n         The F1 score for Dec. Tree is 0.6381\n         ----------------------------------------\n         The F1 score for Random Forest is 0.4367\n         ----------------------------------------\n```", "```py\nIn [46]: savings = [saving_score_base_all, saving_cost_all, saving_score_bmr_all]\n         f1 = [f1_score_base_all, f1_score_cost_all, f1_score_bmr_all]\n         saving_scores = pd.concat([pd.Series(x) for x in savings])\n         f1_scores = pd.concat([pd.Series(x) for x in f1])\n         scores = pd.concat([saving_scores, f1_scores], axis=1)\n         scores.columns = ['saving_scores', 'F1_scores']\n\nIn [47]: model_names = ['Log. Reg_base', 'Dec. Tree_base', 'Random Forest_base',\n                        'Log. Reg_cs', 'Dec. Tree_cs', 'Random Forest_cs',\n                       'Log. Reg_bayes', 'Dec. Tree_bayes',\n                        'Random Forest_bayes']\n\nIn [48]: plt.figure(figsize=(10, 6))\n         plt.plot(range(scores.shape[0]), scores[\"F1_scores\"],\n                  \"--\", label='F1Score') ![1](assets/1.png)\n         plt.bar(np.arange(scores.shape[0]), scores['saving_scores'],\n                 0.6, label='Savings') ![2](assets/2.png)\n         _ = np.arange(len(model_names))\n         plt.xticks(_, model_names)\n         plt.legend(loc='best')\n         plt.xticks(rotation='vertical')\n         plt.show()\n```", "```py\nIn [49]: from sklearn.preprocessing import StandardScaler\n         standard = StandardScaler()\n         scaled_fraud = standard.fit_transform(X_under)\n\nIn [50]: from sklearn_som.som import SOM\n         som = SOM(m=2, n=1, dim=scaled_fraud.shape[1]) ![1](assets/1.png)\n         som.fit(scaled_fraud)\n         predictions_som = som.predict(np.array(scaled_fraud))\n\nIn [51]: predictions_som = np.where(predictions_som == 1, 0, 1)\n\nIn [52]: print('Classification report:\\n',\n               classification_report(y_under, predictions_som))\n         Classification report:\n                        precision    recall  f1-score   support\n\n                    0       0.56      0.40      0.47      7506\n                    1       0.53      0.68      0.60      7506\n\n             accuracy                           0.54     15012\n            macro avg       0.54      0.54      0.53     15012\n         weighted avg       0.54      0.54      0.53     15012\n```", "```py\nIn [53]: fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 6))\n         x = X_under.iloc[:,0]\n         y = X_under.iloc[:,1]\n\n         ax[0].scatter(x, y, alpha=0.1, cmap='Greys', c=y_under)\n         ax[0].title.set_text('Actual Classes')\n         ax[1].scatter(x, y, alpha=0.1, cmap='Greys', c=predictions_som)\n         ax[1].title.set_text('SOM Predictions')\n```", "```py\nIn [54]: from sklearn.preprocessing import StandardScaler\n         from tensorflow import keras\n         from tensorflow.keras.layers import Dense, Dropout\n         from keras import regularizers\n\nIn [55]: fraud_df[['amt','city_pop','hour']] = StandardScaler().\\\n         fit_transform(fraud_df[['amt','city_pop','hour']])\n\nIn [56]: X_train, X_test = train_test_split(fraud_df,\n                                            test_size=0.2, random_state=123)\n         X_train[X_train['is_fraud'] == 0]\n         X_train = X_train.drop(['is_fraud'], axis=1).values\n         y_test = X_test['is_fraud']\n         X_test = X_test.drop(['is_fraud'], axis=1).values\n\nIn [57]: autoencoder = keras.Sequential()\n         autoencoder.add(Dense(X_train_under.shape[1], activation='tanh',\n                               activity_regularizer=regularizers.l1(10e-5),\n                               input_dim= X_train_under.shape[1]))\n         #encoder\n         autoencoder.add(Dense(64, activation='tanh')) ![1](assets/1.png)\n         autoencoder.add(Dense(32, activation='relu')) ![2](assets/2.png)\n         #decoder\n         autoencoder.add(Dense(32, activation='elu')) ![1](assets/1.png)\n         autoencoder.add(Dense(64,activation='tanh')) ![2](assets/2.png)\n         autoencoder.add(Dense(X_train_under.shape[1], activation='elu'))\n         autoencoder.compile(loss='mse',\n                             optimizer='adam')\n         autoencoder.summary();\n         Model: \"sequential\"\n         _________________________________________________________________\n         Layer (type)                 Output Shape              Param #\n         =================================================================\n         dense (Dense)                (None, 566)               320922\n         _________________________________________________________________\n         dense_1 (Dense)              (None, 64)                36288\n         _________________________________________________________________\n         dense_2 (Dense)              (None, 32)                2080\n         _________________________________________________________________\n         dense_3 (Dense)              (None, 32)                1056\n         _________________________________________________________________\n         dense_4 (Dense)              (None, 64)                2112\n         _________________________________________________________________\n         dense_5 (Dense)              (None, 566)               36790\n         =================================================================\n         Total params: 399,248\n         Trainable params: 399,248\n         Non-trainable params: 0\n         _________________________________________________________________\n```", "```py\nIn [58]: batch_size = 200\n         epochs = 100\n\nIn [59]: history = autoencoder.fit(X_train, X_train,\n                                   shuffle=True,\n                                   epochs=epochs,\n                                   batch_size=batch_size,\n                                   validation_data=(X_test, X_test),\n                                   verbose=0).history\n\nIn [60]: autoencoder_pred = autoencoder.predict(X_test)\n         mse = np.mean(np.power(X_test - autoencoder_pred, 2), axis=1)\n         error_df = pd.DataFrame({'reconstruction_error': mse,\n                                 'true_class': y_test}) ![1](assets/1.png)\n         error_df.describe()\nOut[60]:        reconstruction_error     true_class\n         count         259335.000000  259335.000000\n         mean               0.002491       0.005668\n         std                0.007758       0.075075\n         min                0.000174       0.000000\n         25%                0.001790       0.000000\n         50%                0.001993       0.000000\n         75%                0.003368       0.000000\n         max                2.582811       1.000000\n```", "```py\nIn [61]: plt.figure(figsize=(10, 6))\n         plt.plot(history['loss'], linewidth=2, label='Train')\n         plt.plot(history['val_loss'], linewidth=2, label='Test')\n         plt.legend(loc='upper right')\n         plt.title('Model loss')\n         plt.ylabel('Loss')\n         plt.xlabel('Epoch')\n         plt.show()\n```"]