<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 7. Dense Neural Networks"><div class="chapter" id="dense_networks">
<h1><span class="label">Chapter 7. </span>Dense Neural Networks</h1>

<blockquote>
<p class="align_me_right">[I]f you’re trying to predict the movements of a stock on the stock market given its recent price history, you’re unlikely to succeed, because price history doesn’t contain much predictive information.</p>
<p data-type="attribution">François Chollet (2017)</p>
</blockquote>

<p><a data-type="indexterm" data-primary="statistical inefficiencies" data-secondary="DNNs" id="ix_stat_ineffic_DNNs_ch7"/><a data-type="indexterm" data-primary="market prediction" data-secondary="DNN with FX data" id="ix_market_predict_DNNs_ch7"/><a data-type="indexterm" data-primary="DNNs (dense neural networks)" id="ix_DNNs_ch7"/>This chapter is about important aspects of <em>dense neural networks</em>. Previous chapters have already made use of this type of neural network. In particular, the 
<span class="keep-together"><code>MLPClassifier</code></span> and <code>MLPRegressor</code> models from <code>scikit-learn</code> and the <code>Sequential</code> model from <code>Keras</code> for classification and estimation are dense neural networks (DNNs). This chapter exclusively focuses on <code>Keras</code> since it gives more freedom and flexibility in modeling DNNs.<sup><a data-type="noteref" id="idm45625297582184-marker" href="ch07.xhtml#idm45625297582184">1</a></sup></p>

<p><a data-type="xref" href="#dnn_data">“The Data”</a> introduces the foreign exchange (FX) data set that the other sections in this chapter use. <a data-type="xref" href="#dnn_baseline">“Baseline Prediction”</a> generates a baseline, in-sample prediction on the new data set. Normalization of training and test data is introduced in <a data-type="xref" href="#dnn_normalization">“Normalization”</a>. As means to avoid overfitting, <a data-type="xref" href="#dnn_dropouts">“Dropout”</a> and <a data-type="xref" href="#dnn_regularization">“Regularization”</a> discuss dropout and regularization as popular methods. Bagging, as another method to avoid overfitting and already used in <a data-type="xref" href="ch06.xhtml#ai_first_finance">Chapter 6</a>, is revisited in <a data-type="xref" href="#dnn_bagging">“Bagging”</a>. Finally, <a data-type="xref" href="#dnn_optimizers">“Optimizers”</a> compares the performance of different optimizers that can be used with <code>Keras</code> DNN models.</p>

<p>Although the introductory quote for the chapter might give little reason for hope, the main goal for this chapter—as well as for <a data-type="xref" href="part03.xhtml#part_statistical_inefficiencies">Part III</a> as a whole—is to discover statistical inefficiencies in financial markets (time series) by applying neural networks. The numerical results presented in this chapter, such as prediction accuracies of 60% and more in certain cases, indicate that at least some hope is justified.</p>






<section data-type="sect1" data-pdf-bookmark="The Data"><div class="sect1" id="dnn_data">
<h1>The Data</h1>

<p><a data-type="xref" href="ch06.xhtml#ai_first_finance">Chapter 6</a> discovers hints for statistical inefficiencies for, among other time series, the intraday price series of the EUR/USD currency pair. <a data-type="indexterm" data-primary="FX (foreign exchange)" id="ix_FX_DNNs_ch7"/><a data-type="indexterm" data-primary="DNNs (dense neural networks)" data-secondary="data for example" id="ix_DNNs_data_example"/>This chapter and the following ones focus on foreign exchange (FX) as an asset class and specifically on the EUR/USD currency pair. Among other reasons, economically exploiting statistical inefficiencies for FX is in general not as involved as for other asset classes, such as for volatility products like the VIX volatility index. Free and comprehensive data availability is also often given for FX. The following data set is from the <a data-type="indexterm" data-primary="Eikon Data API" id="idm45625297566376"/><a data-type="indexterm" data-primary="Refinitiv Workspace" id="idm45625297565704"/>Refinitiv Eikon Data API. The data set has been retrieved via the API. The data set contains open, high, low, and close values. <a data-type="xref" href="#figure_dnn_01">Figure 7-1</a> visualizes the closing prices:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">import</code><code> </code><code class="nn">os</code><code>
</code><code>        </code><code class="kn">import</code><code> </code><code class="nn">numpy</code><code> </code><code class="kn">as</code><code> </code><code class="nn">np</code><code>
</code><code>        </code><code class="kn">import</code><code> </code><code class="nn">pandas</code><code> </code><code class="kn">as</code><code> </code><code class="nn">pd</code><code>
</code><code>        </code><code class="kn">from</code><code> </code><code class="nn">pylab</code><code> </code><code class="kn">import</code><code> </code><code class="n">plt</code><code class="p">,</code><code> </code><code class="n">mpl</code><code>
</code><code>        </code><code class="n">plt</code><code class="o">.</code><code class="n">style</code><code class="o">.</code><code class="n">use</code><code class="p">(</code><code class="s1">'</code><code class="s1">seaborn</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>        </code><code class="n">mpl</code><code class="o">.</code><code class="n">rcParams</code><code class="p">[</code><code class="s1">'</code><code class="s1">savefig.dpi</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="mi">300</code><code>
</code><code>        </code><code class="n">mpl</code><code class="o">.</code><code class="n">rcParams</code><code class="p">[</code><code class="s1">'</code><code class="s1">font.family</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">serif</code><code class="s1">'</code><code>
</code><code>        </code><code class="n">pd</code><code class="o">.</code><code class="n">set_option</code><code class="p">(</code><code class="s1">'</code><code class="s1">precision</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="mi">4</code><code class="p">)</code><code>
</code><code>        </code><code class="n">np</code><code class="o">.</code><code class="n">set_printoptions</code><code class="p">(</code><code class="n">suppress</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code> </code><code class="n">precision</code><code class="o">=</code><code class="mi">4</code><code class="p">)</code><code>
</code><code>        </code><code class="n">os</code><code class="o">.</code><code class="n">environ</code><code class="p">[</code><code class="s1">'</code><code class="s1">PYTHONHASHSEED</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">0</code><code class="s1">'</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">2</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">url</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">http://hilpisch.com/aiif_eikon_id_eur_usd.csv</code><code class="s1">'</code><code>  </code><a class="co" id="co_dense_neural_networks_CO1-1" href="#callout_dense_neural_networks_CO1-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">3</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">symbol</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">EUR_USD</code><code class="s1">'</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">4</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">raw</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="n">url</code><code class="p">,</code><code> </code><code class="n">index_col</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="n">parse_dates</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO1-2" href="#callout_dense_neural_networks_CO1-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">5</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">raw</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">5</code><code class="p">]</code><code class="p">:</code><code>                        </code><code class="n">HIGH</code><code>     </code><code class="n">LOW</code><code>    </code><code class="n">OPEN</code><code>   </code><code class="n">CLOSE</code><code>
</code><code>        </code><code class="n">Date</code><code>
</code><code>        </code><code class="mi">2019</code><code class="o">-</code><code class="mi">10</code><code class="o">-</code><code class="mo">01</code><code> </code><code class="mo">00</code><code class="p">:</code><code class="mo">00</code><code class="p">:</code><code class="mo">00</code><code>  </code><code class="mf">1.0899</code><code>  </code><code class="mf">1.0897</code><code>  </code><code class="mf">1.0897</code><code>  </code><code class="mf">1.0899</code><code>
</code><code>        </code><code class="mi">2019</code><code class="o">-</code><code class="mi">10</code><code class="o">-</code><code class="mo">01</code><code> </code><code class="mo">00</code><code class="p">:</code><code class="mo">01</code><code class="p">:</code><code class="mo">00</code><code>  </code><code class="mf">1.0899</code><code>  </code><code class="mf">1.0896</code><code>  </code><code class="mf">1.0899</code><code>  </code><code class="mf">1.0898</code><code>
</code><code>        </code><code class="mi">2019</code><code class="o">-</code><code class="mi">10</code><code class="o">-</code><code class="mo">01</code><code> </code><code class="mo">00</code><code class="p">:</code><code class="mo">02</code><code class="p">:</code><code class="mo">00</code><code>  </code><code class="mf">1.0898</code><code>  </code><code class="mf">1.0896</code><code>  </code><code class="mf">1.0898</code><code>  </code><code class="mf">1.0896</code><code>
</code><code>        </code><code class="mi">2019</code><code class="o">-</code><code class="mi">10</code><code class="o">-</code><code class="mo">01</code><code> </code><code class="mo">00</code><code class="p">:</code><code class="mo">03</code><code class="p">:</code><code class="mo">00</code><code>  </code><code class="mf">1.0898</code><code>  </code><code class="mf">1.0896</code><code>  </code><code class="mf">1.0897</code><code>  </code><code class="mf">1.0898</code><code>
</code><code>        </code><code class="mi">2019</code><code class="o">-</code><code class="mi">10</code><code class="o">-</code><code class="mo">01</code><code> </code><code class="mo">00</code><code class="p">:</code><code class="mo">04</code><code class="p">:</code><code class="mo">00</code><code>  </code><code class="mf">1.0898</code><code>  </code><code class="mf">1.0896</code><code>  </code><code class="mf">1.0897</code><code>  </code><code class="mf">1.0898</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">6</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">raw</code><code class="o">.</code><code class="n">info</code><code class="p">(</code><code class="p">)</code><code>
</code><code>        </code><code class="o">&lt;</code><code class="k">class</code><code> </code><code class="err">'</code><code class="nc">pandas</code><code class="o">.</code><code class="n">core</code><code class="o">.</code><code class="n">frame</code><code class="o">.</code><code class="n">DataFrame</code><code class="s1">'</code><code class="s1">&gt;</code><code>
</code><code>        </code><code class="n">DatetimeIndex</code><code class="p">:</code><code> </code><code class="mi">96526</code><code> </code><code class="n">entries</code><code class="p">,</code><code> </code><code class="mi">2019</code><code class="o">-</code><code class="mi">10</code><code class="o">-</code><code class="mo">01</code><code> </code><code class="mo">00</code><code class="p">:</code><code class="mo">00</code><code class="p">:</code><code class="mo">00</code><code> </code><code class="n">to</code><code> </code><code class="mi">2019</code><code class="o">-</code><code class="mi">12</code><code class="o">-</code><code class="mi">31</code><code> </code><code class="mi">23</code><code class="p">:</code><code class="mo">06</code><code class="p">:</code><code class="mo">00</code><code>
</code><code>        </code><code class="n">Data</code><code> </code><code class="n">columns</code><code> </code><code class="p">(</code><code class="n">total</code><code> </code><code class="mi">4</code><code> </code><code class="n">columns</code><code class="p">)</code><code class="p">:</code><code>
</code><code>         </code><code class="c1">#   Column  Non-Null Count  Dtype</code><code>
</code><code>        </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>  </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>  </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>  </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>
</code><code>         </code><code class="mi">0</code><code>   </code><code class="n">HIGH</code><code>    </code><code class="mi">96526</code><code> </code><code class="n">non</code><code class="o">-</code><code class="n">null</code><code>  </code><code class="n">float64</code><code>
</code><code>         </code><code class="mi">1</code><code>   </code><code class="n">LOW</code><code>     </code><code class="mi">96526</code><code> </code><code class="n">non</code><code class="o">-</code><code class="n">null</code><code>  </code><code class="n">float64</code><code>
</code><code>         </code><code class="mi">2</code><code>   </code><code class="n">OPEN</code><code>    </code><code class="mi">96526</code><code> </code><code class="n">non</code><code class="o">-</code><code class="n">null</code><code>  </code><code class="n">float64</code><code>
</code><code>         </code><code class="mi">3</code><code>   </code><code class="n">CLOSE</code><code>   </code><code class="mi">96526</code><code> </code><code class="n">non</code><code class="o">-</code><code class="n">null</code><code>  </code><code class="n">float64</code><code>
</code><code>        </code><code class="n">dtypes</code><code class="p">:</code><code> </code><code class="n">float64</code><code class="p">(</code><code class="mi">4</code><code class="p">)</code><code>
</code><code>        </code><code class="n">memory</code><code> </code><code class="n">usage</code><code class="p">:</code><code> </code><code class="mf">3.7</code><code> </code><code class="n">MB</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">7</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">raw</code><code class="p">[</code><code class="s1">'</code><code class="s1">CLOSE</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="p">:</code><code class="p">]</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO1-3" href="#callout_dense_neural_networks_CO1-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>        </code><code class="n">data</code><code class="o">.</code><code class="n">columns</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="n">symbol</code><code class="p">]</code><code>  </code><a class="co" id="co_dense_neural_networks_CO1-4" href="#callout_dense_neural_networks_CO1-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">8</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">data</code><code> </code><code class="o">=</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">resample</code><code class="p">(</code><code class="s1">'</code><code class="s1">1h</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">label</code><code class="o">=</code><code class="s1">'</code><code class="s1">right</code><code class="s1">'</code><code class="p">)</code><code class="o">.</code><code class="n">last</code><code class="p">(</code><code class="p">)</code><code class="o">.</code><code class="n">ffill</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO1-5" href="#callout_dense_neural_networks_CO1-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">9</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">info</code><code class="p">(</code><code class="p">)</code><code>
</code><code>        </code><code class="o">&lt;</code><code class="k">class</code><code> </code><code class="err">'</code><code class="nc">pandas</code><code class="o">.</code><code class="n">core</code><code class="o">.</code><code class="n">frame</code><code class="o">.</code><code class="n">DataFrame</code><code class="s1">'</code><code class="s1">&gt;</code><code>
</code><code>        </code><code class="n">DatetimeIndex</code><code class="p">:</code><code> </code><code class="mi">2208</code><code> </code><code class="n">entries</code><code class="p">,</code><code> </code><code class="mi">2019</code><code class="o">-</code><code class="mi">10</code><code class="o">-</code><code class="mo">01</code><code> </code><code class="mo">01</code><code class="p">:</code><code class="mo">00</code><code class="p">:</code><code class="mo">00</code><code> </code><code class="n">to</code><code> </code><code class="mi">2020</code><code class="o">-</code><code class="mo">01</code><code class="o">-</code><code class="mo">01</code><code> </code><code class="mo">00</code><code class="p">:</code><code class="mo">00</code><code class="p">:</code><code class="mo">00</code><code>
</code><code>        </code><code class="n">Freq</code><code class="p">:</code><code> </code><code class="n">H</code><code>
</code><code>        </code><code class="n">Data</code><code> </code><code class="n">columns</code><code> </code><code class="p">(</code><code class="n">total</code><code> </code><code class="mi">1</code><code> </code><code class="n">columns</code><code class="p">)</code><code class="p">:</code><code>
</code><code>         </code><code class="c1">#   Column   Non-Null Count  Dtype</code><code>
</code><code>        </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>  </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>   </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>  </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>
</code><code>         </code><code class="mi">0</code><code>   </code><code class="n">EUR_USD</code><code>  </code><code class="mi">2208</code><code> </code><code class="n">non</code><code class="o">-</code><code class="n">null</code><code>   </code><code class="n">float64</code><code>
</code><code>        </code><code class="n">dtypes</code><code class="p">:</code><code> </code><code class="n">float64</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code><code>
</code><code>        </code><code class="n">memory</code><code> </code><code class="n">usage</code><code class="p">:</code><code> </code><code class="mf">34.5</code><code> </code><code class="n">KB</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">10</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code> </code><code class="mi">6</code><code class="p">)</code><code class="p">)</code><code class="p">;</code><code>  </code><a class="co" id="co_dense_neural_networks_CO1-6" href="#callout_dense_neural_networks_CO1-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_dense_neural_networks_CO1-1" href="#co_dense_neural_networks_CO1-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Reads the data into a <code>DataFrame</code> object</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO1-2" href="#co_dense_neural_networks_CO1-3"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Selects, resamples, and plots the closing prices<a data-type="indexterm" data-primary="" data-startref="ix_DNNs_data_example" id="idm45625294689176"/><a data-type="indexterm" data-primary="" data-startref="ix_FX_DNNs_ch7" id="idm45625294688200"/></p></dd>
</dl>

<figure class="thumb"><div id="figure_dnn_01" class="figure">
<img src="Images/aiif_0701.png" alt="aiif 0701" width="2519" height="1528"/>
<h6><span class="label">Figure 7-1. </span>Mid-closing prices for EUR/USD (intraday)</h6>
</div></figure>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Baseline Prediction"><div class="sect1" id="dnn_baseline">
<h1>Baseline Prediction</h1>

<p><a data-type="indexterm" data-primary="DNNs (dense neural networks)" data-secondary="baseline prediction" id="ix_DNNs_baseline_predict"/>Based on the new data set, the prediction approach from <a data-type="xref" href="ch06.xhtml#ai_first_finance">Chapter 6</a> is repeated. First is the creation of the lagged features:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">11</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">lags</code><code> </code><code class="o">=</code><code> </code><code class="mi">5</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">12</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">add_lags</code><code class="p">(</code><code class="n">data</code><code class="p">,</code><code> </code><code class="n">symbol</code><code class="p">,</code><code> </code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">window</code><code class="o">=</code><code class="mi">20</code><code class="p">)</code><code class="p">:</code><code>  </code><a class="co" id="co_dense_neural_networks_CO2-1" href="#callout_dense_neural_networks_CO2-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">cols</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>
</code><code>             </code><code class="n">df</code><code> </code><code class="o">=</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">copy</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="n">df</code><code class="o">.</code><code class="n">dropna</code><code class="p">(</code><code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code>
</code><code>             </code><code class="n">df</code><code class="p">[</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">log</code><code class="p">(</code><code class="n">df</code><code> </code><code class="o">/</code><code> </code><code class="n">df</code><code class="o">.</code><code class="n">shift</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>
</code><code>             </code><code class="n">df</code><code class="p">[</code><code class="s1">'</code><code class="s1">sma</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">df</code><code class="p">[</code><code class="n">symbol</code><code class="p">]</code><code class="o">.</code><code class="n">rolling</code><code class="p">(</code><code class="n">window</code><code class="p">)</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="n">df</code><code class="p">[</code><code class="s1">'</code><code class="s1">min</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">df</code><code class="p">[</code><code class="n">symbol</code><code class="p">]</code><code class="o">.</code><code class="n">rolling</code><code class="p">(</code><code class="n">window</code><code class="p">)</code><code class="o">.</code><code class="n">min</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="n">df</code><code class="p">[</code><code class="s1">'</code><code class="s1">max</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">df</code><code class="p">[</code><code class="n">symbol</code><code class="p">]</code><code class="o">.</code><code class="n">rolling</code><code class="p">(</code><code class="n">window</code><code class="p">)</code><code class="o">.</code><code class="n">max</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="n">df</code><code class="p">[</code><code class="s1">'</code><code class="s1">mom</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">df</code><code class="p">[</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">rolling</code><code class="p">(</code><code class="n">window</code><code class="p">)</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="n">df</code><code class="p">[</code><code class="s1">'</code><code class="s1">vol</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">df</code><code class="p">[</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">rolling</code><code class="p">(</code><code class="n">window</code><code class="p">)</code><code class="o">.</code><code class="n">std</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="n">df</code><code class="o">.</code><code class="n">dropna</code><code class="p">(</code><code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code>
</code><code>             </code><code class="n">df</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">df</code><code class="p">[</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">&gt;</code><code> </code><code class="mi">0</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">)</code><code>
</code><code>             </code><code class="n">features</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="n">symbol</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">sma</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">min</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">max</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">mom</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">vol</code><code class="s1">'</code><code class="p">]</code><code>
</code><code>             </code><code class="k">for</code><code> </code><code class="n">f</code><code> </code><code class="ow">in</code><code> </code><code class="n">features</code><code class="p">:</code><code>
</code><code>                 </code><code class="k">for</code><code> </code><code class="n">lag</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">lags</code><code> </code><code class="o">+</code><code> </code><code class="mi">1</code><code class="p">)</code><code class="p">:</code><code>
</code><code>                     </code><code class="n">col</code><code> </code><code class="o">=</code><code> </code><code class="n">f</code><code class="s1">'</code><code class="s1">{f}_lag_{lag}</code><code class="s1">'</code><code>
</code><code>                     </code><code class="n">df</code><code class="p">[</code><code class="n">col</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">df</code><code class="p">[</code><code class="n">f</code><code class="p">]</code><code class="o">.</code><code class="n">shift</code><code class="p">(</code><code class="n">lag</code><code class="p">)</code><code>
</code><code>                     </code><code class="n">cols</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">col</code><code class="p">)</code><code>
</code><code>             </code><code class="n">df</code><code class="o">.</code><code class="n">dropna</code><code class="p">(</code><code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code>
</code><code>             </code><code class="k">return</code><code> </code><code class="n">df</code><code class="p">,</code><code> </code><code class="n">cols</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">13</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">data</code><code class="p">,</code><code> </code><code class="n">cols</code><code> </code><code class="o">=</code><code> </code><code class="n">add_lags</code><code class="p">(</code><code class="n">data</code><code class="p">,</code><code> </code><code class="n">symbol</code><code class="p">,</code><code> </code><code class="n">lags</code><code class="p">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_dense_neural_networks_CO2-1" href="#co_dense_neural_networks_CO2-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Slightly adjusted function from <a data-type="xref" href="ch06.xhtml#ai_first_finance">Chapter 6</a></p></dd>
</dl>

<p><a data-type="indexterm" data-primary="classification task" data-secondary="neural networks applied to" id="idm45625295125672"/><a data-type="indexterm" data-primary="neural networks" data-secondary="in classification task" data-secondary-sortas="classification task" id="idm45625295094664"/>Second, a look at the labels data. A major problem in classification that can arise depending on the data set available is <em>class imbalance</em>. This means, in the context of binary labels, that the frequency of one particular class compared to the other class might be higher. This might lead to situations in which the neural network simply predicts the class with the higher frequency since this already can lead to low loss and high accuracy values. Applying appropriate weights, one can make sure that both classes gain equal importance during the DNN training step:<sup><a data-type="noteref" id="idm45625295132152-marker" href="ch07.xhtml#idm45625295132152">2</a></sup></p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">14</code><code class="p">]</code><code class="p">:</code><code> </code><code class="nb">len</code><code class="p">(</code><code class="n">data</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">14</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mi">2183</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">15</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">c</code><code> </code><code class="o">=</code><code> </code><code class="n">data</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO3-1" href="#callout_dense_neural_networks_CO3-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>         </code><code class="n">c</code><code>  </code><a class="co" id="co_dense_neural_networks_CO3-2" href="#callout_dense_neural_networks_CO3-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">15</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mi">0</code><code>    </code><code class="mi">1445</code><code>
</code><code>         </code><code class="mi">1</code><code>     </code><code class="mi">738</code><code>
</code><code>         </code><code class="n">Name</code><code class="p">:</code><code> </code><code class="n">d</code><code class="p">,</code><code> </code><code class="n">dtype</code><code class="p">:</code><code> </code><code class="n">int64</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">16</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">cw</code><code class="p">(</code><code class="n">df</code><code class="p">)</code><code class="p">:</code><code>  </code><a class="co" id="co_dense_neural_networks_CO3-3" href="#callout_dense_neural_networks_CO3-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">c0</code><code class="p">,</code><code> </code><code class="n">c1</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">bincount</code><code class="p">(</code><code class="n">df</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>             </code><code class="n">w0</code><code> </code><code class="o">=</code><code> </code><code class="p">(</code><code class="mi">1</code><code> </code><code class="o">/</code><code> </code><code class="n">c0</code><code class="p">)</code><code> </code><code class="o">*</code><code> </code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">df</code><code class="p">)</code><code class="p">)</code><code> </code><code class="o">/</code><code> </code><code class="mi">2</code><code>
</code><code>             </code><code class="n">w1</code><code> </code><code class="o">=</code><code> </code><code class="p">(</code><code class="mi">1</code><code> </code><code class="o">/</code><code> </code><code class="n">c1</code><code class="p">)</code><code> </code><code class="o">*</code><code> </code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">df</code><code class="p">)</code><code class="p">)</code><code> </code><code class="o">/</code><code> </code><code class="mi">2</code><code>
</code><code>             </code><code class="k">return</code><code> </code><code class="p">{</code><code class="mi">0</code><code class="p">:</code><code> </code><code class="n">w0</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">:</code><code> </code><code class="n">w1</code><code class="p">}</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">17</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">class_weight</code><code> </code><code class="o">=</code><code> </code><code class="n">cw</code><code class="p">(</code><code class="n">data</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO3-4" href="#callout_dense_neural_networks_CO3-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">18</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">class_weight</code><code>  </code><a class="co" id="co_dense_neural_networks_CO3-5" href="#callout_dense_neural_networks_CO3-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">18</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">{</code><code class="mi">0</code><code class="p">:</code><code> </code><code class="mf">0.755363321799308</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">:</code><code> </code><code class="mf">1.4789972899728998</code><code class="p">}</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">19</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">class_weight</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code class="n">c</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code>  </code><a class="co" id="co_dense_neural_networks_CO3-6" href="#callout_dense_neural_networks_CO3-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">19</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">1091.5</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">20</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">class_weight</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code class="n">c</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code>  </code><a class="co" id="co_dense_neural_networks_CO3-7" href="#callout_dense_neural_networks_CO3-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">20</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">1091.5</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_dense_neural_networks_CO3-1" href="#co_dense_neural_networks_CO3-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Shows the frequency of the two classes</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO3-2" href="#co_dense_neural_networks_CO3-3"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Calculates appropriate weights to reach an equal weighting</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO3-3" href="#co_dense_neural_networks_CO3-6"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>With the calculated weights, both classes gain equal weight</p></dd>
</dl>

<p>Third is the creation of the DNN model with <code>Keras</code> and the training of the model on the complete data set. The baseline performance in-sample is around 60%:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">21</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">import</code><code> </code><code class="nn">random</code><code>
</code><code>         </code><code class="kn">import</code><code> </code><code class="nn">tensorflow</code><code> </code><code class="kn">as</code><code> </code><code class="nn">tf</code><code>
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">keras.layers</code><code> </code><code class="kn">import</code><code> </code><code class="n">Dense</code><code>
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">keras.models</code><code> </code><code class="kn">import</code><code> </code><code class="n">Sequential</code><code>
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">keras.optimizers</code><code> </code><code class="kn">import</code><code> </code><code class="n">Adam</code><code>
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">sklearn.metrics</code><code> </code><code class="kn">import</code><code> </code><code class="n">accuracy_score</code><code>
</code><code>         </code><code class="n">Using</code><code> </code><code class="n">TensorFlow</code><code> </code><code class="n">backend</code><code class="o">.</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">22</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">set_seeds</code><code class="p">(</code><code class="n">seed</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code><code class="p">:</code><code>
</code><code>             </code><code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">(</code><code class="n">seed</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO4-1" href="#callout_dense_neural_networks_CO4-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">(</code><code class="n">seed</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO4-2" href="#callout_dense_neural_networks_CO4-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">tf</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">set_seed</code><code class="p">(</code><code class="n">seed</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO4-3" href="#callout_dense_neural_networks_CO4-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">23</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">optimizer</code><code> </code><code class="o">=</code><code> </code><code class="n">Adam</code><code class="p">(</code><code class="n">lr</code><code class="o">=</code><code class="mf">0.001</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO4-4" href="#callout_dense_neural_networks_CO4-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">24</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">create_model</code><code class="p">(</code><code class="n">hl</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">128</code><code class="p">,</code><code> </code><code class="n">optimizer</code><code class="o">=</code><code class="n">optimizer</code><code class="p">)</code><code class="p">:</code><code>
</code><code>             </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">Sequential</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">hu</code><code class="p">,</code><code> </code><code class="n">input_dim</code><code class="o">=</code><code class="nb">len</code><code class="p">(</code><code class="n">cols</code><code class="p">)</code><code class="p">,</code><code>
</code><code>                             </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO4-5" href="#callout_dense_neural_networks_CO4-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a><code>
</code><code>             </code><code class="k">for</code><code> </code><code class="n">_</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="n">hl</code><code class="p">)</code><code class="p">:</code><code>
</code><code>                 </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">hu</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO4-6" href="#callout_dense_neural_networks_CO4-6"><img src="Images/6.png" alt="6" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">sigmoid</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO4-7" href="#callout_dense_neural_networks_CO4-7"><img src="Images/7.png" alt="7" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code><code class="o">=</code><code class="s1">'</code><code class="s1">binary_crossentropy</code><code class="s1">'</code><code class="p">,</code><code>  </code><a class="co" id="co_dense_neural_networks_CO4-8" href="#callout_dense_neural_networks_CO4-8"><img src="Images/8.png" alt="8" width="12" height="12"/></a><code>
</code><code>                           </code><code class="n">optimizer</code><code class="o">=</code><code class="n">optimizer</code><code class="p">,</code><code>  </code><a class="co" id="co_dense_neural_networks_CO4-9" href="#callout_dense_neural_networks_CO4-9"><img src="Images/9.png" alt="9" width="12" height="12"/></a><code>
</code><code>                           </code><code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="s1">'</code><code class="s1">accuracy</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO4-10" href="#callout_dense_neural_networks_CO4-10"><img src="Images/10.png" alt="10" width="12" height="12"/></a><code>
</code><code>             </code><code class="k">return</code><code> </code><code class="n">model</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">25</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>
</code><code>         </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">create_model</code><code class="p">(</code><code class="n">hl</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">128</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">26</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">data</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">epochs</code><code class="o">=</code><code class="mi">50</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code> </code><code class="n">class_weight</code><code class="o">=</code><code class="n">cw</code><code class="p">(</code><code class="n">data</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">6.44</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mi">939</code><code> </code><code class="n">ms</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">7.38</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">4.07</code><code> </code><code class="n">s</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">26</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7fbfc2ee6690</code><code class="o">&gt;</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">27</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">data</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>         </code><code class="mi">2183</code><code class="o">/</code><code class="mi">2183</code><code> </code><code class="p">[</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="p">]</code><code> </code><code class="o">-</code><code> </code><code class="mi">0</code><code class="n">s</code><code> </code><code class="mi">24</code><code class="n">us</code><code class="o">/</code><code class="n">step</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">27</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">[</code><code class="mf">0.582192026280068</code><code class="p">,</code><code> </code><code class="mf">0.6087952256202698</code><code class="p">]</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">28</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">data</code><code class="p">[</code><code class="s1">'</code><code class="s1">p</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">)</code><code> </code><code class="o">&gt;</code><code> </code><code class="mf">0.5</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">29</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">data</code><code class="p">[</code><code class="s1">'</code><code class="s1">p</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">29</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mi">1</code><code>    </code><code class="mi">1340</code><code>
</code><code>         </code><code class="mi">0</code><code>     </code><code class="mi">843</code><code>
</code><code>         </code><code class="n">Name</code><code class="p">:</code><code> </code><code class="n">p</code><code class="p">,</code><code> </code><code class="n">dtype</code><code class="p">:</code><code> </code><code class="n">int64</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_dense_neural_networks_CO4-1" href="#co_dense_neural_networks_CO4-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Python random number seed</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO4-2" href="#co_dense_neural_networks_CO4-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p><code>NumPy</code> random number seed</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO4-3" href="#co_dense_neural_networks_CO4-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p><code>TensorFlow</code> random number seed</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO4-4" href="#co_dense_neural_networks_CO4-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a></dt>
<dd><p>Default optimizer (see <a href="https://oreil.ly/atpu8"><em class="hyperlink">https://oreil.ly/atpu8</em></a>)</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO4-5" href="#co_dense_neural_networks_CO4-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a></dt>
<dd><p>First layer</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO4-6" href="#co_dense_neural_networks_CO4-6"><img src="Images/6.png" alt="6" width="12" height="12"/></a></dt>
<dd><p>Additional layers</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO4-7" href="#co_dense_neural_networks_CO4-7"><img src="Images/7.png" alt="7" width="12" height="12"/></a></dt>
<dd><p>Output layer</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO4-8" href="#co_dense_neural_networks_CO4-8"><img src="Images/8.png" alt="8" width="12" height="12"/></a></dt>
<dd><p>Loss function (see <a href="https://oreil.ly/cVGVf"><em class="hyperlink">https://oreil.ly/cVGVf</em></a>)</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO4-9" href="#co_dense_neural_networks_CO4-9"><img src="Images/9.png" alt="9" width="12" height="12"/></a></dt>
<dd><p>Optimizer to be used</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO4-10" href="#co_dense_neural_networks_CO4-10"><img src="Images/10.png" alt="10" width="12" height="12"/></a></dt>
<dd><p>Additional metrics to be collected</p></dd>
</dl>
<div style="page-break-after: always;"/>

<p>The same holds true for the performance of the model out-of-sample. It is still well above 60%. This can be considered already quite good:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">30</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">split</code><code> </code><code class="o">=</code><code> </code><code class="nb">int</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">data</code><code class="p">)</code><code> </code><code class="o">*</code><code> </code><code class="mf">0.8</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO5-1" href="#callout_dense_neural_networks_CO5-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">31</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">train</code><code> </code><code class="o">=</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="p">:</code><code class="n">split</code><code class="p">]</code><code class="o">.</code><code class="n">copy</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO5-2" href="#callout_dense_neural_networks_CO5-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">32</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">test</code><code> </code><code class="o">=</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">split</code><code class="p">:</code><code class="p">]</code><code class="o">.</code><code class="n">copy</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO5-3" href="#callout_dense_neural_networks_CO5-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">33</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>
</code><code>         </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">create_model</code><code class="p">(</code><code class="n">hl</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">128</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">34</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">train</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">epochs</code><code class="o">=</code><code class="mi">50</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">validation_split</code><code class="o">=</code><code class="mf">0.2</code><code class="p">,</code><code> </code><code class="n">shuffle</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">class_weight</code><code class="o">=</code><code class="n">cw</code><code class="p">(</code><code class="n">train</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">4.72</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mi">686</code><code> </code><code class="n">ms</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">5.41</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">3.14</code><code> </code><code class="n">s</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">34</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7fbfc3231250</code><code class="o">&gt;</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">35</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">train</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO5-4" href="#callout_dense_neural_networks_CO5-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code>
</code><code>         </code><code class="mi">1746</code><code class="o">/</code><code class="mi">1746</code><code> </code><code class="p">[</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="p">]</code><code> </code><code class="o">-</code><code> </code><code class="mi">0</code><code class="n">s</code><code> </code><code class="mi">13</code><code class="n">us</code><code class="o">/</code><code class="n">step</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">35</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">[</code><code class="mf">0.612861613500842</code><code class="p">,</code><code> </code><code class="mf">0.5853379368782043</code><code class="p">]</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">36</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">test</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO5-5" href="#callout_dense_neural_networks_CO5-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a><code>
</code><code>         </code><code class="mi">437</code><code class="o">/</code><code class="mi">437</code><code> </code><code class="p">[</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="p">]</code><code> </code><code class="o">-</code><code> </code><code class="mi">0</code><code class="n">s</code><code> </code><code class="mi">16</code><code class="n">us</code><code class="o">/</code><code class="n">step</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">36</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">[</code><code class="mf">0.5946959675858714</code><code class="p">,</code><code> </code><code class="mf">0.6247139573097229</code><code class="p">]</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">37</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">p</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">test</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">)</code><code> </code><code class="o">&gt;</code><code> </code><code class="mf">0.5</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">38</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">p</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">38</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mi">1</code><code>    </code><code class="mi">291</code><code>
</code><code>         </code><code class="mi">0</code><code>    </code><code class="mi">146</code><code>
</code><code>         </code><code class="n">Name</code><code class="p">:</code><code> </code><code class="n">p</code><code class="p">,</code><code> </code><code class="n">dtype</code><code class="p">:</code><code> </code><code class="n">int64</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_dense_neural_networks_CO5-1" href="#co_dense_neural_networks_CO5-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Splits the whole data set…</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO5-2" href="#co_dense_neural_networks_CO5-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>…into the training data set…</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO5-3" href="#co_dense_neural_networks_CO5-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>…and the test data set.</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO5-4" href="#co_dense_neural_networks_CO5-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a></dt>
<dd><p>Evaluates the <em>in-sample</em> performance.</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO5-5" href="#co_dense_neural_networks_CO5-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a></dt>
<dd><p>Evaluates the <em>out-of-sample</em> performance.</p></dd>
</dl>
<div style="page-break-after: always;"/>

<p><a data-type="xref" href="#figure_dnn_02">Figure 7-2</a> shows how the accuracy on the training and validation data sub-sets changes over the training epochs:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">39</code><code class="p">]:</code> <code class="n">res</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">history</code><code class="o">.</code><code class="n">history</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">40</code><code class="p">]:</code> <code class="n">res</code><code class="p">[[</code><code class="s1">'accuracy'</code><code class="p">,</code> <code class="s1">'val_accuracy'</code><code class="p">]]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code> <code class="n">style</code><code class="o">=</code><code class="s1">'--'</code><code class="p">);</code></pre>

<figure class="thumb"><div id="figure_dnn_02" class="figure">
<img src="Images/aiif_0702.png" alt="aiif 0702" width="2471" height="1421"/>
<h6><span class="label">Figure 7-2. </span>Training and validation accuracy values</h6>
</div></figure>

<p>The analysis in this section sets the stage for the more elaborate use of DNNs with <code>Keras</code>. It presents a baseline market prediction approach. The following sections add different elements that are primarily supposed to improve the out-of-sample model performance and to avoid overfitting of the model to the training data.<a data-type="indexterm" data-primary="" data-startref="ix_DNNs_baseline_predict" id="idm45625293695416"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Normalization"><div class="sect1" id="dnn_normalization">
<h1>Normalization</h1>

<p><a data-type="indexterm" data-primary="Gaussian normalization" id="ix_Gauss_normaliz"/><a data-type="indexterm" data-primary="normalization, DNNs" id="ix_normaliz_DNNs"/><a data-type="indexterm" data-primary="DNNs (dense neural networks)" data-secondary="normalization" id="ix_DNNs_normaliz"/>The baseline prediction in <a data-type="xref" href="#dnn_baseline">“Baseline Prediction”</a> takes the lagged features as they are. In <a data-type="xref" href="ch06.xhtml#ai_first_finance">Chapter 6</a>, the features data is normalized by subtracting the mean of the training data for every feature and dividing it by the standard deviation of the training data. This normalization technique is called <em>Gaussian normalization</em> and proves often, if not always, to be an important aspect when training a neural network. As the following Python code and its results illustrate, the in-sample performance increases significantly when working with normalized features data. The out-of-sample performance also slightly increases. However, there is no guarantee that the out-of-sample performance increases through features normalization:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">41</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">mu</code><code class="p">,</code><code> </code><code class="n">std</code><code> </code><code class="o">=</code><code> </code><code class="n">train</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">train</code><code class="o">.</code><code class="n">std</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO6-1" href="#callout_dense_neural_networks_CO6-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">42</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">train_</code><code> </code><code class="o">=</code><code> </code><code class="p">(</code><code class="n">train</code><code> </code><code class="o">-</code><code> </code><code class="n">mu</code><code class="p">)</code><code> </code><code class="o">/</code><code> </code><code class="n">std</code><code>  </code><a class="co" id="co_dense_neural_networks_CO6-2" href="#callout_dense_neural_networks_CO6-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">43</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>
</code><code>         </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">create_model</code><code class="p">(</code><code class="n">hl</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">128</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">44</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">train_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">epochs</code><code class="o">=</code><code class="mi">50</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">validation_split</code><code class="o">=</code><code class="mf">0.2</code><code class="p">,</code><code> </code><code class="n">shuffle</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">class_weight</code><code class="o">=</code><code class="n">cw</code><code class="p">(</code><code class="n">train</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">5.81</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mi">879</code><code> </code><code class="n">ms</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">6.69</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">3.53</code><code> </code><code class="n">s</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">44</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7fbfa51353d0</code><code class="o">&gt;</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">45</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">train_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO6-3" href="#callout_dense_neural_networks_CO6-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>         </code><code class="mi">1746</code><code class="o">/</code><code class="mi">1746</code><code> </code><code class="p">[</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="p">]</code><code> </code><code class="o">-</code><code> </code><code class="mi">0</code><code class="n">s</code><code> </code><code class="mi">14</code><code class="n">us</code><code class="o">/</code><code class="n">step</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">45</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">[</code><code class="mf">0.4253406366728084</code><code class="p">,</code><code> </code><code class="mf">0.887170672416687</code><code class="p">]</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">46</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">test_</code><code> </code><code class="o">=</code><code> </code><code class="p">(</code><code class="n">test</code><code> </code><code class="o">-</code><code> </code><code class="n">mu</code><code class="p">)</code><code> </code><code class="o">/</code><code> </code><code class="n">std</code><code>  </code><a class="co" id="co_dense_neural_networks_CO6-4" href="#callout_dense_neural_networks_CO6-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">47</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">test_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO6-5" href="#callout_dense_neural_networks_CO6-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a><code>
</code><code>         </code><code class="mi">437</code><code class="o">/</code><code class="mi">437</code><code> </code><code class="p">[</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="p">]</code><code> </code><code class="o">-</code><code> </code><code class="mi">0</code><code class="n">s</code><code> </code><code class="mi">24</code><code class="n">us</code><code class="o">/</code><code class="n">step</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">47</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">[</code><code class="mf">1.1377735263422917</code><code class="p">,</code><code> </code><code class="mf">0.681922197341919</code><code class="p">]</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">48</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">p</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">test_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">)</code><code> </code><code class="o">&gt;</code><code> </code><code class="mf">0.5</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">49</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">p</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">49</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mi">0</code><code>    </code><code class="mi">281</code><code>
</code><code>         </code><code class="mi">1</code><code>    </code><code class="mi">156</code><code>
</code><code>         </code><code class="n">Name</code><code class="p">:</code><code> </code><code class="n">p</code><code class="p">,</code><code> </code><code class="n">dtype</code><code class="p">:</code><code> </code><code class="n">int64</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_dense_neural_networks_CO6-1" href="#co_dense_neural_networks_CO6-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Calculates the mean and standard deviation for all <em>training features</em></p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO6-2" href="#co_dense_neural_networks_CO6-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Normalizes the <em>training data</em> set based on Gaussian normalization</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO6-3" href="#co_dense_neural_networks_CO6-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>Evaluates the <em>in-sample</em> performance</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO6-4" href="#co_dense_neural_networks_CO6-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a></dt>
<dd><p>Normalizes the <em>test data</em> set based on Gaussian normalization</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO6-5" href="#co_dense_neural_networks_CO6-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a></dt>
<dd><p>Evaluates the <em>out-of-sample</em> performance</p></dd>
</dl>

<p><a data-type="indexterm" data-primary="overfitting of data, avoiding" id="ix_overfit_avoid_ch7"/>A major problem that often arises is <em>overfitting</em>. It is impressively visualized in <a data-type="xref" href="#figure_dnn_03">Figure 7-3</a>, which shows a steadily improving training accuracy while the validation accuracy decreases slowly:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">50</code><code class="p">]:</code> <code class="n">res</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">history</code><code class="o">.</code><code class="n">history</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">51</code><code class="p">]:</code> <code class="n">res</code><code class="p">[[</code><code class="s1">'accuracy'</code><code class="p">,</code> <code class="s1">'val_accuracy'</code><code class="p">]]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code> <code class="n">style</code><code class="o">=</code><code class="s1">'--'</code><code class="p">);</code></pre>

<figure class="thumb"><div id="figure_dnn_03" class="figure">
<img src="Images/aiif_0703.png" alt="aiif 0703" width="2418" height="1421"/>
<h6><span class="label">Figure 7-3. </span>Training and validation accuracy values (normalized features data)</h6>
</div></figure>

<p>Three candidate methods to avoid overfitting are <em>dropout</em>, <em>regularization</em>, and <em>bagging</em>. The following sections discuss these methods. The impact of the chosen optimizer is also discussed later in this chapter.<a data-type="indexterm" data-primary="" data-startref="ix_DNNs_normaliz" id="idm45625293576152"/><a data-type="indexterm" data-primary="" data-startref="ix_Gauss_normaliz" id="idm45625293575176"/><a data-type="indexterm" data-primary="" data-startref="ix_normaliz_DNNs" id="idm45625293574232"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Dropout"><div class="sect1" id="dnn_dropouts">
<h1>Dropout</h1>

<p><a data-type="indexterm" data-primary="dropout, managing" data-secondary="DNNs" id="ix_dropout_DNNs"/><a data-type="indexterm" data-primary="DNNs (dense neural networks)" data-secondary="dropout" id="ix_DNNs_dropout"/>The idea of <em>dropout</em> is that neural networks should not use all hidden units during the training stage. The analogy to the human brain is that a human being regularly forgets information that was previously learned. This, so to say, keeps the human brain “open minded.” Ideally, a neural network should behave similarly: the connections in the DNN should not become too strong in order to avoid overfitting to the training data.</p>

<p>Technically, a <code>Keras</code> model has additional layers between the hidden layers that manage the dropout. The major parameter is the rate with which the hidden units of a layer get dropped. These drops in general happen in randomized fashion. This can be avoided by fixing the <code>seed</code> parameter. While the in-sample performance decreases, the out-of-sample performance slightly decreases as well. However, the difference between the two performance measures is smaller, which is in general a desirable 
<span class="keep-together">situation:</span></p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">52</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">keras.layers</code><code> </code><code class="kn">import</code><code> </code><code class="n">Dropout</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">53</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">create_model</code><code class="p">(</code><code class="n">hl</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">128</code><code class="p">,</code><code> </code><code class="n">dropout</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code> </code><code class="n">rate</code><code class="o">=</code><code class="mf">0.3</code><code class="p">,</code><code>
</code><code>                          </code><code class="n">optimizer</code><code class="o">=</code><code class="n">optimizer</code><code class="p">)</code><code class="p">:</code><code>
</code><code>             </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">Sequential</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">hu</code><code class="p">,</code><code> </code><code class="n">input_dim</code><code class="o">=</code><code class="nb">len</code><code class="p">(</code><code class="n">cols</code><code class="p">)</code><code class="p">,</code><code>
</code><code>                             </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>
</code><code>             </code><code class="k">if</code><code> </code><code class="n">dropout</code><code class="p">:</code><code>
</code><code>                 </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dropout</code><code class="p">(</code><code class="n">rate</code><code class="p">,</code><code> </code><code class="n">seed</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO7-1" href="#callout_dense_neural_networks_CO7-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>             </code><code class="k">for</code><code> </code><code class="n">_</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="n">hl</code><code class="p">)</code><code class="p">:</code><code>
</code><code>                 </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">hu</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>
</code><code>                 </code><code class="k">if</code><code> </code><code class="n">dropout</code><code class="p">:</code><code>
</code><code>                     </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dropout</code><code class="p">(</code><code class="n">rate</code><code class="p">,</code><code> </code><code class="n">seed</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO7-2" href="#callout_dense_neural_networks_CO7-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">sigmoid</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code><code class="o">=</code><code class="s1">'</code><code class="s1">binary_crossentropy</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">optimizer</code><code class="o">=</code><code class="n">optimizer</code><code class="p">,</code><code>
</code><code>                          </code><code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="s1">'</code><code class="s1">accuracy</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>             </code><code class="k">return</code><code> </code><code class="n">model</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">54</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>
</code><code>         </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">create_model</code><code class="p">(</code><code class="n">hl</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">128</code><code class="p">,</code><code> </code><code class="n">rate</code><code class="o">=</code><code class="mf">0.3</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">55</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">train_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">epochs</code><code class="o">=</code><code class="mi">50</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">validation_split</code><code class="o">=</code><code class="mf">0.15</code><code class="p">,</code><code> </code><code class="n">shuffle</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">class_weight</code><code class="o">=</code><code class="n">cw</code><code class="p">(</code><code class="n">train</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">5.46</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mi">758</code><code> </code><code class="n">ms</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">6.21</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">3.53</code><code> </code><code class="n">s</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">55</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7fbfa6386550</code><code class="o">&gt;</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">56</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">train_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>         </code><code class="mi">1746</code><code class="o">/</code><code class="mi">1746</code><code> </code><code class="p">[</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="p">]</code><code> </code><code class="o">-</code><code> </code><code class="mi">0</code><code class="n">s</code><code> </code><code class="mi">20</code><code class="n">us</code><code class="o">/</code><code class="n">step</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">56</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">[</code><code class="mf">0.4423361133190911</code><code class="p">,</code><code> </code><code class="mf">0.7840778827667236</code><code class="p">]</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">57</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">test_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>         </code><code class="mi">437</code><code class="o">/</code><code class="mi">437</code><code> </code><code class="p">[</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="p">]</code><code> </code><code class="o">-</code><code> </code><code class="mi">0</code><code class="n">s</code><code> </code><code class="mi">34</code><code class="n">us</code><code class="o">/</code><code class="n">step</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">57</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">[</code><code class="mf">0.5875822428434883</code><code class="p">,</code><code> </code><code class="mf">0.6430205702781677</code><code class="p">]</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_dense_neural_networks_CO7-1" href="#co_dense_neural_networks_CO7-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Adds dropout after each layer</p></dd>
</dl>

<p>As <a data-type="xref" href="#figure_dnn_04">Figure 7-4</a> illustrates, the training accuracy and validation accuracy now do not drift apart as fast as before:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">58</code><code class="p">]:</code> <code class="n">res</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">history</code><code class="o">.</code><code class="n">history</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">59</code><code class="p">]:</code> <code class="n">res</code><code class="p">[[</code><code class="s1">'accuracy'</code><code class="p">,</code> <code class="s1">'val_accuracy'</code><code class="p">]]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code> <code class="n">style</code><code class="o">=</code><code class="s1">'--'</code><code class="p">);</code></pre>

<figure class="thumb"><div id="figure_dnn_04" class="figure">
<img src="Images/aiif_0704.png" alt="aiif 0704" width="2444" height="1421"/>
<h6><span class="label">Figure 7-4. </span>Training and validation accuracy values (with dropout)</h6>
</div></figure>
<div data-type="note" epub:type="note"><h1>Intentional Forgetting</h1>
<p><a data-type="indexterm" data-primary="intentional forgetting, training use of" id="idm45625292847368"/><a data-type="indexterm" data-primary="Keras deep learning package" data-secondary="Sequential model" id="idm45625292763944"/><a data-type="indexterm" data-primary="Sequential model, Keras package" id="idm45625292763064"/>Dropout in the <code>Sequential</code> model of <code>Keras</code> emulates what all human beings experience: forgetting previously memorized information. This is accomplished by deactivating certain hidden units of a hidden layer during training. In effect, this often avoids, to a larger extent, overfitting a neural network to the training data.<a data-type="indexterm" data-primary="" data-startref="ix_DNNs_dropout" id="idm45625292761128"/><a data-type="indexterm" data-primary="" data-startref="ix_dropout_DNNs" id="idm45625292695016"/></p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Regularization"><div class="sect1" id="dnn_regularization">
<h1>Regularization</h1>

<p><a data-type="indexterm" data-primary="regularization, DNNs" id="ix_regulariz_DNNs"/><a data-type="indexterm" data-primary="DNNs (dense neural networks)" data-secondary="regularization" id="ix_DNNs_regulariz"/>Another means to avoid overfitting is <em>regularization</em>. <a data-type="indexterm" data-primary="weights in neural network" id="idm45625292814088"/>With regularization, large weights in the neural network get penalized in the calculation of the loss (function). This avoids the situation where certain connections in the DNN become too strong and dominant. Regularization can be introduced in a <code>Keras</code> DNN through a parameter in the <code>Dense</code> layers. Depending on the regularization parameter chosen, training and test accuracy can be kept quite close together. Two regularizers are in general used, one based on the linear norm, <code>l1</code>, and one based on the Euclidean norm, <code>l2</code>. The following Python code adds regularization to the model creation function:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">60</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">keras.regularizers</code><code> </code><code class="kn">import</code><code> </code><code class="n">l1</code><code class="p">,</code><code> </code><code class="n">l2</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">61</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">create_model</code><code class="p">(</code><code class="n">hl</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">128</code><code class="p">,</code><code> </code><code class="n">dropout</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code> </code><code class="n">rate</code><code class="o">=</code><code class="mf">0.3</code><code class="p">,</code><code>
</code><code>                          </code><code class="n">regularize</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code> </code><code class="n">reg</code><code class="o">=</code><code class="n">l1</code><code class="p">(</code><code class="mf">0.0005</code><code class="p">)</code><code class="p">,</code><code>
</code><code>                          </code><code class="n">optimizer</code><code class="o">=</code><code class="n">optimizer</code><code class="p">,</code><code> </code><code class="n">input_dim</code><code class="o">=</code><code class="nb">len</code><code class="p">(</code><code class="n">cols</code><code class="p">)</code><code class="p">)</code><code class="p">:</code><code>
</code><code>             </code><code class="k">if</code><code> </code><code class="ow">not</code><code> </code><code class="n">regularize</code><code class="p">:</code><code>
</code><code>                 </code><code class="n">reg</code><code> </code><code class="o">=</code><code> </code><code class="bp">None</code><code>
</code><code>             </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">Sequential</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">hu</code><code class="p">,</code><code> </code><code class="n">input_dim</code><code class="o">=</code><code class="n">input_dim</code><code class="p">,</code><code>
</code><code>                             </code><code class="n">activity_regularizer</code><code class="o">=</code><code class="n">reg</code><code class="p">,</code><code>  </code><a class="co" id="co_dense_neural_networks_CO8-1" href="#callout_dense_neural_networks_CO8-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>                             </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>
</code><code>             </code><code class="k">if</code><code> </code><code class="n">dropout</code><code class="p">:</code><code>
</code><code>                 </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dropout</code><code class="p">(</code><code class="n">rate</code><code class="p">,</code><code> </code><code class="n">seed</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code><code class="p">)</code><code>
</code><code>             </code><code class="k">for</code><code> </code><code class="n">_</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="n">hl</code><code class="p">)</code><code class="p">:</code><code>
</code><code>                 </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">hu</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                                 </code><code class="n">activity_regularizer</code><code class="o">=</code><code class="n">reg</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO8-2" href="#callout_dense_neural_networks_CO8-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>                 </code><code class="k">if</code><code> </code><code class="n">dropout</code><code class="p">:</code><code>
</code><code>                     </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dropout</code><code class="p">(</code><code class="n">rate</code><code class="p">,</code><code> </code><code class="n">seed</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code><code class="p">)</code><code>
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">sigmoid</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code><code class="o">=</code><code class="s1">'</code><code class="s1">binary_crossentropy</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">optimizer</code><code class="o">=</code><code class="n">optimizer</code><code class="p">,</code><code>
</code><code>                          </code><code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="s1">'</code><code class="s1">accuracy</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>             </code><code class="k">return</code><code> </code><code class="n">model</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">62</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>
</code><code>         </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">create_model</code><code class="p">(</code><code class="n">hl</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">128</code><code class="p">,</code><code> </code><code class="n">regularize</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">63</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">train_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">epochs</code><code class="o">=</code><code class="mi">50</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">validation_split</code><code class="o">=</code><code class="mf">0.2</code><code class="p">,</code><code> </code><code class="n">shuffle</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">class_weight</code><code class="o">=</code><code class="n">cw</code><code class="p">(</code><code class="n">train</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">5.49</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mf">1.05</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">6.54</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">3.15</code><code> </code><code class="n">s</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">63</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7fbfa6b8e110</code><code class="o">&gt;</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">64</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">train_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>         </code><code class="mi">1746</code><code class="o">/</code><code class="mi">1746</code><code> </code><code class="p">[</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="p">]</code><code> </code><code class="o">-</code><code> </code><code class="mi">0</code><code class="n">s</code><code> </code><code class="mi">15</code><code class="n">us</code><code class="o">/</code><code class="n">step</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">64</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">[</code><code class="mf">0.5307255412568205</code><code class="p">,</code><code> </code><code class="mf">0.7691867351531982</code><code class="p">]</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">65</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">test_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>         </code><code class="mi">437</code><code class="o">/</code><code class="mi">437</code><code> </code><code class="p">[</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="p">]</code><code> </code><code class="o">-</code><code> </code><code class="mi">0</code><code class="n">s</code><code> </code><code class="mi">22</code><code class="n">us</code><code class="o">/</code><code class="n">step</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">65</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">[</code><code class="mf">0.8428352184644826</code><code class="p">,</code><code> </code><code class="mf">0.6590389013290405</code><code class="p">]</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_dense_neural_networks_CO8-1" href="#co_dense_neural_networks_CO8-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Regularization is added to each layer.</p></dd>
</dl>

<p><a data-type="xref" href="#figure_dnn_05">Figure 7-5</a> shows the training and validation accuracy under regularization. The two performance measures are much closer together than previously seen:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">66</code><code class="p">]:</code> <code class="n">res</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">history</code><code class="o">.</code><code class="n">history</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">67</code><code class="p">]:</code> <code class="n">res</code><code class="p">[[</code><code class="s1">'accuracy'</code><code class="p">,</code> <code class="s1">'val_accuracy'</code><code class="p">]]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code> <code class="n">style</code><code class="o">=</code><code class="s1">'--'</code><code class="p">);</code></pre>

<figure class="thumb"><div id="figure_dnn_05" class="figure">
<img src="Images/aiif_0705.png" alt="aiif 0705" width="2444" height="1421"/>
<h6><span class="label">Figure 7-5. </span>Training and validation accuracy values (with regularization)</h6>
</div></figure>

<p><a data-type="indexterm" data-primary="DNNs (dense neural networks)" data-secondary="dropout" id="idm45625292996344"/><a data-type="indexterm" data-primary="dropout, managing" data-secondary="DNNs" id="idm45625291232648"/>Of course, dropout and regularization can be used together. The idea is that the two measures combined even better avoid overfitting and bring the in-sample and out-of-sample accuracy values closer together. And indeed the difference between the two measures is lowest in this case:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">68</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>
</code><code>         </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">create_model</code><code class="p">(</code><code class="n">hl</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">128</code><code class="p">,</code><code>
</code><code>                              </code><code class="n">dropout</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code> </code><code class="n">rate</code><code class="o">=</code><code class="mf">0.3</code><code class="p">,</code><code>  </code><a class="co" id="co_dense_neural_networks_CO9-1" href="#callout_dense_neural_networks_CO9-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>                              </code><code class="n">regularize</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code> </code><code class="n">reg</code><code class="o">=</code><code class="n">l2</code><code class="p">(</code><code class="mf">0.001</code><code class="p">)</code><code class="p">,</code><code>  </code><a class="co" id="co_dense_neural_networks_CO9-2" href="#callout_dense_neural_networks_CO9-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>                             </code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">69</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">train_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">epochs</code><code class="o">=</code><code class="mi">50</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">validation_split</code><code class="o">=</code><code class="mf">0.2</code><code class="p">,</code><code> </code><code class="n">shuffle</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                   </code><code class="n">class_weight</code><code class="o">=</code><code class="n">cw</code><code class="p">(</code><code class="n">train</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">7.06</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mi">958</code><code> </code><code class="n">ms</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">8.01</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">4.28</code><code> </code><code class="n">s</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">69</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7fbfa701cb50</code><code class="o">&gt;</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">70</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">train_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>         </code><code class="mi">1746</code><code class="o">/</code><code class="mi">1746</code><code> </code><code class="p">[</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="p">]</code><code> </code><code class="o">-</code><code> </code><code class="mi">0</code><code class="n">s</code><code> </code><code class="mi">18</code><code class="n">us</code><code class="o">/</code><code class="n">step</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">70</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">[</code><code class="mf">0.5007762827004764</code><code class="p">,</code><code> </code><code class="mf">0.7691867351531982</code><code class="p">]</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">71</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">test_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>         </code><code class="mi">437</code><code class="o">/</code><code class="mi">437</code><code> </code><code class="p">[</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="p">]</code><code> </code><code class="o">-</code><code> </code><code class="mi">0</code><code class="n">s</code><code> </code><code class="mi">23</code><code class="n">us</code><code class="o">/</code><code class="n">step</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">71</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">[</code><code class="mf">0.6191965124699835</code><code class="p">,</code><code> </code><code class="mf">0.6864988803863525</code><code class="p">]</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_dense_neural_networks_CO9-1" href="#co_dense_neural_networks_CO9-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Dropout is added to the model creation.</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO9-2" href="#co_dense_neural_networks_CO9-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Regularization is added to the model creation.</p></dd>
</dl>

<p><a data-type="xref" href="#figure_dnn_06">Figure 7-6</a> shows the training and validation accuracy when combining dropout with regularization. The difference between training and validation data accuracy over the training epochs is some four percentage points only on average:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">72</code><code class="p">]:</code> <code class="n">res</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">history</code><code class="o">.</code><code class="n">history</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">73</code><code class="p">]:</code> <code class="n">res</code><code class="p">[[</code><code class="s1">'accuracy'</code><code class="p">,</code> <code class="s1">'val_accuracy'</code><code class="p">]]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code> <code class="n">style</code><code class="o">=</code><code class="s1">'--'</code><code class="p">);</code></pre>

<figure class="thumb"><div id="figure_dnn_06" class="figure">
<img src="Images/aiif_0706.png" alt="aiif 0706" width="2444" height="1421"/>
<h6><span class="label">Figure 7-6. </span>Training and validation accuracy values (with dropout and regularization)</h6>
</div></figure>
<div data-type="note" epub:type="note"><h1>Penalizing Large Weights</h1>
<p><a data-type="indexterm" data-primary="weights in neural network" id="idm45625292205864"/>Regularization avoids overfitting by penalizing large weights in a neural network. Single weights cannot get that large enough to dominate a neural network. The penalties keep weights on a comparable level.<a data-type="indexterm" data-primary="" data-startref="ix_DNNs_regulariz" id="idm45625292370712"/><a data-type="indexterm" data-primary="" data-startref="ix_regulariz_DNNs" id="idm45625292369800"/></p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Bagging"><div class="sect1" id="dnn_bagging">
<h1>Bagging</h1>

<p><a data-type="indexterm" data-primary="DNNs (dense neural networks)" data-secondary="bagging method to avoid overfitting" id="ix_DNNs_bag_overfit"/><a data-type="indexterm" data-primary="bagging method to avoid overfitting" id="ix_bag_overfit"/>The bagging method to avoid overfitting is already used in <a data-type="xref" href="ch06.xhtml#ai_first_finance">Chapter 6</a>, although only for the <code>scikit-learn</code> <code>MLPRegressor</code> model. <a data-type="indexterm" data-primary="KerasClassifier class" id="idm45625298882728"/>There is also a wrapper for a <code>Keras</code> DNN classification model to expose it in <code>scikit-learn</code> fashion, namely the <code>KerasClassifier</code> class. The following Python code combines the <code>Keras</code> DNN modeling based on the wrapper with the <code>BaggingClassifier</code> from <code>scikit-learn</code>. The in-sample and out-of-sample performance measures are relatively high, around 70%. However, the result is driven by the class imbalance, as addressed previously, and as reflected here in the high frequency of the <code>0</code> predictions:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">75</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">sklearn.ensemble</code><code> </code><code class="kn">import</code><code> </code><code class="n">BaggingClassifier</code><code>
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">keras.wrappers.scikit_learn</code><code> </code><code class="kn">import</code><code> </code><code class="n">KerasClassifier</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">76</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">max_features</code><code> </code><code class="o">=</code><code> </code><code class="mf">0.75</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">77</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>
</code><code>         </code><code class="n">base_estimator</code><code> </code><code class="o">=</code><code> </code><code class="n">KerasClassifier</code><code class="p">(</code><code class="n">build_fn</code><code class="o">=</code><code class="n">create_model</code><code class="p">,</code><code>
</code><code>                                 </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code> </code><code class="n">epochs</code><code class="o">=</code><code class="mi">20</code><code class="p">,</code><code> </code><code class="n">hl</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">128</code><code class="p">,</code><code>
</code><code>                                 </code><code class="n">dropout</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code> </code><code class="n">regularize</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                                 </code><code class="n">input_dim</code><code class="o">=</code><code class="nb">int</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">cols</code><code class="p">)</code><code> </code><code class="o">*</code><code> </code><code class="n">max_features</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO10-1" href="#callout_dense_neural_networks_CO10-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">78</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model_bag</code><code> </code><code class="o">=</code><code> </code><code class="n">BaggingClassifier</code><code class="p">(</code><code class="n">base_estimator</code><code class="o">=</code><code class="n">base_estimator</code><code class="p">,</code><code>
</code><code>                                   </code><code class="n">n_estimators</code><code class="o">=</code><code class="mi">15</code><code class="p">,</code><code>
</code><code>                                   </code><code class="n">max_samples</code><code class="o">=</code><code class="mf">0.75</code><code class="p">,</code><code>
</code><code>                                   </code><code class="n">max_features</code><code class="o">=</code><code class="n">max_features</code><code class="p">,</code><code>
</code><code>                                   </code><code class="n">bootstrap</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code>
</code><code>                                   </code><code class="n">bootstrap_features</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code>
</code><code>                                   </code><code class="n">n_jobs</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code>
</code><code>                                   </code><code class="n">random_state</code><code class="o">=</code><code class="mi">100</code><code class="p">,</code><code>
</code><code>                                  </code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO10-2" href="#callout_dense_neural_networks_CO10-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">79</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="n">time</code><code> </code><code class="n">model_bag</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">train_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mi">40</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mf">5.23</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">45.3</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">26.3</code><code> </code><code class="n">s</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">79</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">BaggingClassifier</code><code class="p">(</code><code class="n">base_estimator</code><code class="o">=</code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">wrappers</code><code class="o">.</code><code class="n">scikit_learn</code><code class="o">.</code><code class="n">KerasClassifier</code><code>
</code><code>          </code><code class="nb">object</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7fbfa7cc7b90</code><code class="o">&gt;</code><code class="p">,</code><code>
</code><code>         </code><code class="n">bootstrap_features</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code> </code><code class="n">max_features</code><code class="o">=</code><code class="mf">0.75</code><code class="p">,</code><code> </code><code class="n">max_samples</code><code class="o">=</code><code class="mf">0.75</code><code class="p">,</code><code>
</code><code>                           </code><code class="n">n_estimators</code><code class="o">=</code><code class="mi">15</code><code class="p">,</code><code> </code><code class="n">n_jobs</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">random_state</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">80</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model_bag</code><code class="o">.</code><code class="n">score</code><code class="p">(</code><code class="n">train_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">80</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">0.720504009163803</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">81</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model_bag</code><code class="o">.</code><code class="n">score</code><code class="p">(</code><code class="n">test_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">81</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">0.6704805491990846</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">82</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">p</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">model_bag</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">test_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">83</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">p</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">83</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mi">0</code><code>    </code><code class="mi">408</code><code>
</code><code>         </code><code class="mi">1</code><code>     </code><code class="mi">29</code><code>
</code><code>         </code><code class="n">Name</code><code class="p">:</code><code> </code><code class="n">p</code><code class="p">,</code><code> </code><code class="n">dtype</code><code class="p">:</code><code> </code><code class="n">int64</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_dense_neural_networks_CO10-1" href="#co_dense_neural_networks_CO10-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>The base estimator, here a <code>Keras</code> <code>Sequential</code> model, is instantiated.</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO10-2" href="#co_dense_neural_networks_CO10-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>The <code>BaggingClassifier</code> model is instantiated for a number of equal base 
<span class="keep-together">estimators.</span></p></dd>
</dl>
<div data-type="note" epub:type="note"><h1>Distributing Learning</h1>
<p><a data-type="indexterm" data-primary="distributed learning, bagging as" id="idm45625293401048"/>Bagging, in a sense, distributes learning among a number of neural networks (or other models) in that each neural network, for example, only sees certain parts of the training data set and only a selection of the features. This avoids the risk that a single neural network overfits the complete training data set. The prediction is based on all selectively trained neural networks together.<a data-type="indexterm" data-primary="" data-startref="ix_overfit_avoid_ch7" id="idm45625292654920"/><a data-type="indexterm" data-primary="" data-startref="ix_bag_overfit" id="idm45625292654088"/><a data-type="indexterm" data-primary="" data-startref="ix_DNNs_bag_overfit" id="idm45625292653144"/></p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Optimizers"><div class="sect1" id="dnn_optimizers">
<h1>Optimizers</h1>

<p><a data-type="indexterm" data-primary="optimizers, DNNs" id="ix_optimiz_DNNs"/><a data-type="indexterm" data-primary="DNNs (dense neural networks)" data-secondary="optimizers" id="ix_DNNs_optimiz"/><a data-type="indexterm" data-primary="Keras deep learning package" data-secondary="Sequential model" id="idm45625291592920"/><a data-type="indexterm" data-primary="Sequential model, Keras package" id="idm45625291592008"/>The <code>Keras</code> package offers a selection of optimizers that can be used in combination with the <code>Sequential</code> model (see <a href="https://oreil.ly/atpu8"><em class="hyperlink">https://oreil.ly/atpu8</em></a>). Different optimizers might show different performances, with regard to both the time the training takes and the prediction accuracy. The following Python code uses different optimizers and benchmarks their performance. In all cases, the default parametrization of <code>Keras</code> is used. The out-of-sample performance does not vary that much. However, the in-sample performance, given the different optimizers, varies by a wide margin:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">84</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">import</code><code> </code><code class="nn">time</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">85</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">optimizers</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="s1">'</code><code class="s1">sgd</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">rmsprop</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">adagrad</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">adadelta</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                       </code><code class="s1">'</code><code class="s1">adam</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">adamax</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">nadam</code><code class="s1">'</code><code class="p">]</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">86</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>         </code><code class="k">for</code><code> </code><code class="n">optimizer</code><code> </code><code class="ow">in</code><code> </code><code class="n">optimizers</code><code class="p">:</code><code>
</code><code>             </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">create_model</code><code class="p">(</code><code class="n">hl</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">128</code><code class="p">,</code><code>
</code><code>                              </code><code class="n">dropout</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code> </code><code class="n">rate</code><code class="o">=</code><code class="mf">0.3</code><code class="p">,</code><code>
</code><code>                              </code><code class="n">regularize</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code> </code><code class="n">reg</code><code class="o">=</code><code class="n">l2</code><code class="p">(</code><code class="mf">0.001</code><code class="p">)</code><code class="p">,</code><code>
</code><code>                              </code><code class="n">optimizer</code><code class="o">=</code><code class="n">optimizer</code><code>
</code><code>                             </code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO11-1" href="#callout_dense_neural_networks_CO11-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">t0</code><code> </code><code class="o">=</code><code> </code><code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">train_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                       </code><code class="n">epochs</code><code class="o">=</code><code class="mi">50</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                       </code><code class="n">validation_split</code><code class="o">=</code><code class="mf">0.2</code><code class="p">,</code><code> </code><code class="n">shuffle</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code>
</code><code>                       </code><code class="n">class_weight</code><code class="o">=</code><code class="n">cw</code><code class="p">(</code><code class="n">train</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_dense_neural_networks_CO11-2" href="#callout_dense_neural_networks_CO11-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">t1</code><code> </code><code class="o">=</code><code> </code><code class="n">time</code><code class="o">.</code><code class="n">time</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="n">t</code><code> </code><code class="o">=</code><code> </code><code class="n">t1</code><code> </code><code class="o">-</code><code> </code><code class="n">t0</code><code>
</code><code>             </code><code class="n">acc_tr</code><code> </code><code class="o">=</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">train_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code>  </code><a class="co" id="co_dense_neural_networks_CO11-3" href="#callout_dense_neural_networks_CO11-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">acc_te</code><code> </code><code class="o">=</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">evaluate</code><code class="p">(</code><code class="n">test_</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">d</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code>  </code><a class="co" id="co_dense_neural_networks_CO11-4" href="#callout_dense_neural_networks_CO11-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">out</code><code> </code><code class="o">=</code><code> </code><code class="n">f</code><code class="s1">'</code><code class="s1">{optimizer:10s} | time[s]: {t:.4f} | in-sample={acc_tr:.4f}</code><code class="s1">'</code><code>
</code><code>             </code><code class="n">out</code><code> </code><code class="o">+</code><code class="o">=</code><code> </code><code class="n">f</code><code class="s1">'</code><code class="s1"> | out-of-sample={acc_te:.4f}</code><code class="s1">'</code><code>
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="n">out</code><code class="p">)</code><code>
</code><code>         </code><code class="n">sgd</code><code>        </code><code class="o">|</code><code> </code><code class="n">time</code><code class="p">[</code><code class="n">s</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">2.8092</code><code> </code><code class="o">|</code><code> </code><code class="ow">in</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.6363</code><code> </code><code class="o">|</code><code> </code><code class="n">out</code><code class="o">-</code><code class="n">of</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.6568</code><code>
</code><code>         </code><code class="n">rmsprop</code><code>    </code><code class="o">|</code><code> </code><code class="n">time</code><code class="p">[</code><code class="n">s</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">2.9480</code><code> </code><code class="o">|</code><code> </code><code class="ow">in</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.7600</code><code> </code><code class="o">|</code><code> </code><code class="n">out</code><code class="o">-</code><code class="n">of</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.6613</code><code>
</code><code>         </code><code class="n">adagrad</code><code>    </code><code class="o">|</code><code> </code><code class="n">time</code><code class="p">[</code><code class="n">s</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">2.8472</code><code> </code><code class="o">|</code><code> </code><code class="ow">in</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.6747</code><code> </code><code class="o">|</code><code> </code><code class="n">out</code><code class="o">-</code><code class="n">of</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.6499</code><code>
</code><code>         </code><code class="n">adadelta</code><code>   </code><code class="o">|</code><code> </code><code class="n">time</code><code class="p">[</code><code class="n">s</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">3.2068</code><code> </code><code class="o">|</code><code> </code><code class="ow">in</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.7279</code><code> </code><code class="o">|</code><code> </code><code class="n">out</code><code class="o">-</code><code class="n">of</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.6522</code><code>
</code><code>         </code><code class="n">adam</code><code>       </code><code class="o">|</code><code> </code><code class="n">time</code><code class="p">[</code><code class="n">s</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">3.2364</code><code> </code><code class="o">|</code><code> </code><code class="ow">in</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.7365</code><code> </code><code class="o">|</code><code> </code><code class="n">out</code><code class="o">-</code><code class="n">of</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.6545</code><code>
</code><code>         </code><code class="n">adamax</code><code>     </code><code class="o">|</code><code> </code><code class="n">time</code><code class="p">[</code><code class="n">s</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">3.2465</code><code> </code><code class="o">|</code><code> </code><code class="ow">in</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.6982</code><code> </code><code class="o">|</code><code> </code><code class="n">out</code><code class="o">-</code><code class="n">of</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.6476</code><code>
</code><code>         </code><code class="n">nadam</code><code>      </code><code class="o">|</code><code> </code><code class="n">time</code><code class="p">[</code><code class="n">s</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">4.1275</code><code> </code><code class="o">|</code><code> </code><code class="ow">in</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.7944</code><code> </code><code class="o">|</code><code> </code><code class="n">out</code><code class="o">-</code><code class="n">of</code><code class="o">-</code><code class="n">sample</code><code class="o">=</code><code class="mf">0.6590</code><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">35.9</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mf">4.55</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">40.4</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">23.1</code><code> </code><code class="n">s</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_dense_neural_networks_CO11-1" href="#co_dense_neural_networks_CO11-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Instantiates the DNN model for the given optimizer</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO11-2" href="#co_dense_neural_networks_CO11-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Fits the model with the given optimizer</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO11-3" href="#co_dense_neural_networks_CO11-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>Evaluates the <em>in-sample</em> performance</p></dd>
<dt><a class="co" id="callout_dense_neural_networks_CO11-4" href="#co_dense_neural_networks_CO11-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a></dt>
<dd><p>Evaluates the <em>out-of-sample</em> performance<a data-type="indexterm" data-primary="" data-startref="ix_DNNs_ch7" id="idm45625292784216"/><a data-type="indexterm" data-primary="" data-startref="ix_market_predict_DNNs_ch7" id="idm45625290425416"/><a data-type="indexterm" data-primary="" data-startref="ix_stat_ineffic_DNNs_ch7" id="idm45625290424504"/><a data-type="indexterm" data-primary="" data-startref="ix_DNNs_optimiz" id="idm45625290423592"/><a data-type="indexterm" data-primary="" data-startref="ix_optimiz_DNNs" id="idm45625290422648"/></p></dd>
</dl>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Conclusions"><div class="sect1" id="idm45625292345832">
<h1>Conclusions</h1>

<p>This chapter dives deeper into the world of DNNs and uses <code>Keras</code> as the primary package. <code>Keras</code> offers a high degree of flexibility in composing DNNs. The results in this chapter are promising in that both in-sample and out-of-sample performance—with regard to the prediction accuracy—are consistently 60% and higher. However, prediction accuracy is just one side of the coin. An appropriate trading strategy must be available and implementable to economically profit from the predictions, or 
<span class="keep-together">“signals.”</span> This topic of paramount importance in the context of algorithmic trading is discussed in detail in <a data-type="xref" href="part04.xhtml#part_economic_inefficiencies">Part IV</a>. The next two chapters first illustrate the use of different neural networks (recurrent and convolutional neural networks) and learning techniques (reinforcement learning).</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="References"><div class="sect1" id="idm45625293512120">
<h1>References</h1>

<p><code>Keras</code> is a powerful and comprehensive package for deep learning with TensforFlow as its primary backend. The project is also evolving fast. Make sure to stay up to date via the <a href="http://keras.io">main project page</a>. The major resources about <code>Keras</code> in book form are the following:</p>

<ul class="author-date-bib">
<li>
<p>Chollet, Francois. 2017. <em>Deep Learning with Python</em>. Shelter Island: Manning.</p>
</li>
<li>
<p>Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. Cambridge: MIT Press. <a href="http://deeplearningbook.org"><em class="hyperlink">http://deeplearningbook.org</em></a>.</p>
</li>
</ul>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm45625297582184"><sup><a href="ch07.xhtml#idm45625297582184-marker">1</a></sup> See Chollet (2017) for more details and background information on the <code>Keras</code> package. See Goodfellow et al. (2016) for a comprehensive treatment of neural networks and related methods.</p><p data-type="footnote" id="idm45625295132152"><sup><a href="ch07.xhtml#idm45625295132152-marker">2</a></sup> See this <a href="https://oreil.ly/3X1Qk">blog post</a>, which discusses solutions to class imbalance with <code>Keras</code>.</p></div></div></section></div>



  </body></html>