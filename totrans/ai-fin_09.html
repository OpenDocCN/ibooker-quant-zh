<html><head></head><body><div id="sbo-rt-content"><div data-type="part" epub:type="part" data-pdf-bookmark="Part III. Statistical Inefficiencies" id="part_statistical_inefficiencies">
<h1><span class="label">Part III. </span>Statistical Inefficiencies</h1>

<div class="partintro"><blockquote>
<p>“There are patterns in the market,” Simons told a colleague. “I know we can find them.”<sup><a data-type="noteref" id="idm45625297609656-marker" href="part03.xhtml#idm45625297609656">1</a></sup></p>
<p data-type="attribution">Gregory Zuckerman (2019)</p>
</blockquote>

<p>The major goal of this part is to apply neural networks and reinforcement learning to discover statistical inefficiencies in financial markets (data). A <em>statistical inefficiency</em>, for the purposes of this book, is found when a <em>predictor</em> (a model or algorithm in general or a neural network in particular) predicts markets significantly better than a random predictor assigning equal probability to upwards and downwards movements. In an algorithmic trading context, to have such a predictor available is a prerequisite for the generation of <em>alpha</em> or above-market returns.</p>

<p>This part consists of three chapters that provide more background, details, and examples related to dense neural networks (DNNs), recurrent neural networks (RNNs), and reinforcement learning (RL):</p>

<ul>
<li>
<p><a data-type="xref" href="ch07.xhtml#dense_networks">Chapter 7</a> covers DNNs in some more detail and applies them to the problem of predicting the direction of financial market movements. Historical data is used to generate lagged features data and to generate binary labels data. Such data sets are then used to train DNNs via supervised learning. The focus lies on identifying statistical inefficiencies in financial markets. In some of the examples, the DNN achieves an out-of-sample prediction accuracy of more than 60%.</p>
</li>
<li>
<p><a data-type="xref" href="ch08.xhtml#recurrent_networks">Chapter 8</a> is about RNNs, which are designed to accommodate the specific nature of sequential data, such as textual data or time series data. The idea is to add some form of memory to the network that carries previous (historical) information through the network (layers). The approach taken in this chapter is close to the one in <a data-type="xref" href="ch07.xhtml#dense_networks">Chapter 7</a>, with the same goal of discovering statistical inefficiencies in the financial market data. As numerical examples illustrate, RNNs also can reach prediction accuracies out-of-sample of more than 60%.</p>
</li>
<li>
<p><a data-type="xref" href="ch09.xhtml#reinforcement_learning">Chapter 9</a> discusses RL as one of the major success stories in AI. The chapter discusses different RL agents applied to both a simulated physical environment from the OpenAI Gym and financial market environments as developed in the chapter. The algorithm of choice in RL often is Q-learning, which is discussed in detail and applied to train a trading bot. The trading bot shows respectable out-of-sample financial performance, which is generally an even more important yardstick than prediction accuracy alone. In that sense, the chapter builds a natural bridge to <a data-type="xref" href="part04.xhtml#part_economic_inefficiencies">Part IV</a>, which is concerned with exploiting statistical inefficiencies economically.</p>
</li>
</ul>

<p>Although they are quite an important type of a neural network, <em>convolutional neural networks</em> (CNNs) are not discussed in detail in this part. <a data-type="xref" href="app03.xhtml#app_convolutional_neural_networks">Appendix C</a> illustrates the application of CNNs in a concise way. In many cases, CNNs can also be applied to the problems that DNNs and RNNs are applied to in this part of the book.</p>

<p>The approach in this part is a practical one, leaving out many important details with regard to the algorithms and techniques applied. This seems justified since there are a number of good resources in book form and otherwise available that can be consulted for technical details and background information. The chapters to follow provide references to a select few, generally comprehensive, resources when appropriate.</p>
</div>
<div data-type="footnotes"><p data-type="footnote" id="idm45625297609656"><sup><a href="part03.xhtml#idm45625297609656-marker">1</a></sup> Gregory Zuckerman. 2019. <em>The Man Who Solved the Market</em>. New York: Penguin Random House.</p></div></div></div>



  </body></html>