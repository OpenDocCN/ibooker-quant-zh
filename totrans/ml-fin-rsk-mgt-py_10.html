<html><head></head><body><section data-pdf-bookmark="Chapter 8. Modeling Operational Risk" data-type="chapter" epub:type="chapter"><div class="chapter" id="chapter_8">&#13;
<h1><span class="label">Chapter 8. </span>Modeling Operational Risk</h1>&#13;
&#13;
<blockquote data-type="epigram">&#13;
<p>...It’s not necessarily the biggest missteps that deliver the biggest blows; share prices can plummet as a result of even the smallest events.</p>&#13;
<p data-type="attribution">Dunnett, Levy, and Simoes (2005)</p>&#13;
</blockquote>&#13;
&#13;
<p><a data-primary="operational risk" data-type="indexterm" id="ix_ops_risk_ch8"/>Thus far, we have talked about three main financial risks: market, credit, and liquidity risks. Now it is time to discuss operational risk, which is more ambiguous than the other types of financial risks. This ambiguity arises from the huge variety of risk sources by which financial institutions may face huge losses.</p>&#13;
&#13;
<p><a data-primary="indirect versus direct costs, operational risk" data-type="indexterm" id="idm45737213237920"/>Operational risk is the risk of direct or indirect loss resulting from inadequate or failed interval processes, people, and systems or from external events (BIS 2019). Please note that loss can be direct and/or indirect. Some direct losses would be:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Legal liability arising from judicial process</p>&#13;
</li>&#13;
<li>&#13;
<p>Write-downs due to theft or reduction in assets</p>&#13;
</li>&#13;
<li>&#13;
<p>Compliance emanating from tax, license, fines, etc.</p>&#13;
</li>&#13;
<li>&#13;
<p>Business interruption</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Indirect cost is related to the opportunity cost in the way that a decision made by an institution may trigger a host of events resulting in a loss at an uncertain time in the future.</p>&#13;
&#13;
<p><a data-primary="unexpected loss, operational risk" data-type="indexterm" id="idm45737213231792"/>Normally, financial institutions allocate a certain amount of money to cover the loss emanating from operational risk, which is known as <em>unexpected loss</em>. However, allocating an appropriate amount of funds to cover unexpected loss is not as easy as it sounds. It is necessary to determine the right amount of unexpected loss; otherwise, either more funds are devoted to it, which makes it idle and creates opportunity cost, or less than the required funds are allocated, resulting in a liquidity problem.</p>&#13;
&#13;
<p>As we briefly touched on earlier, operational risk can take on several forms. Among them, we’ll restrict our focus to the fraud risk, which is considered to be the most pervasive and disruptive type of operational risk.</p>&#13;
&#13;
<p><a data-primary="fraud" data-type="indexterm" id="idm45737213229136"/>Fraud may generally be characterized as an intentional act, misstatement, or omission designed to deceive others, resulting in the victim suffering a loss or the perpetrator achieving a gain (OCC 2019). A fraud can be an internal one if losses occurred from inside a financial institution or an external one if it is committed by a third party.</p>&#13;
&#13;
<p>What makes fraud a primary concern of financial institutions? What increases the likelihood of committing fraudulent activities? To address these questions, we can refer to three important factors:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Globalization</p>&#13;
</li>&#13;
<li>&#13;
<p>Lack of proper risk management</p>&#13;
</li>&#13;
<li>&#13;
<p>Economic pressure</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p><a data-primary="globalization, and fraud risk" data-type="indexterm" id="idm45737213223952"/>Globalization led financial institutions to expand their operations across the world, and this came with a complexity that gave rise to a higher probability of corruption, bribery, and any kind of illegal act as financial institutions started operating in environments where they have no prior knowledge.</p>&#13;
&#13;
<p><a data-primary="risk management" data-secondary="fraud as consequence of lack of proper" data-type="indexterm" id="idm45737213222576"/>Lack of proper risk management has been and is the most obvious reasons for fraud. Misleading reporting and rogue, unauthorized trading plants the seeds of fraudulent acts. A very well known example is the Barings case, in which Nick Leeson, a young trader at Barings, ran a speculative trading and subsequent cover-up operation using accounting tricks that cost Barings Bank a&#13;
fortune, totaling $1.3 billion. Thus, when there is a lack of well-defined risk management policies along with a well-established culture of risk, employees may tend to commit fraud.</p>&#13;
&#13;
<p><a data-primary="economic pressure, and fraud risk" data-type="indexterm" id="idm45737213220672"/>Another motivation for fraud would be an employee’s worsening financial situation. Particularly during an economic downturn, employees might be tempted into fraudulent activities. In addition, financial institutions themselves might embrace illegal operations (such as accounting tricks) to find a way out of the &#13;
<span class="keep-together">downturn</span>.</p>&#13;
&#13;
<p>Fraud does not only cause a considerable amount of loss, but it also poses a threat to a company’s reputation, which may in turn disrupt the long-term sustainability of the company. <a data-primary="Enron accounting fraud case" data-type="indexterm" id="idm45737213218224"/>Take the case of Enron, a good example of accounting fraud, which broke out in 2001. Enron was established in 1985 and became one of the biggest companies in the United States and the world. Let me briefly tell you the story of this big &#13;
<span class="keep-together">collapse</span>.</p>&#13;
&#13;
<p>Due to the pressure that Enron faced in the energy market, executives were motivated to rely on dubious accounting practices, resulting in inflated profits from writing huge unrealized future gains. Thanks to whistleblower Sherron Watkins, who was the former vice president of corporate development, one of the biggest fraud cases in the history of modern finance came to light. This event also stresses the importance of preventing fraudulent activities, which otherwise might lead to huge damages to an individual’s or company’s reputation or financial collapse.</p>&#13;
&#13;
<p>In this chapter, we aim to introduce an ML-based model to detect fraud or would-be fraud operations. This is and should be a constantly growing field to stay ahead of the perpetrators. <a data-primary="labeled versus unlabeled data" data-type="indexterm" id="idm45737213214848"/><a data-primary="unlabeled versus labeled data" data-type="indexterm" id="idm45737213214176"/>Datasets related to fraud may come in two forms: <em>labeled</em> or <em>unlabeled data</em>. To take both into account, we first apply a supervised learning algorithm and then use an unsupervised learning algorithm pretending like we do not have labels, even though the dataset we’ll be using does include labels.</p>&#13;
&#13;
<p><a data-primary="Credit Card Transaction Fraud Detection Dataset" data-type="indexterm" id="ix_cc_trans_fraud_dataset"/>The dataset we’ll use for our fraud analysis is known as the <em>Credit Card Transaction Fraud Detection Dataset</em> created by Brandon Harris. Credit card fraud is not a rare issue, and the goal is to detect the likelihood of fraud and inform the bank so that the bank can investigate the situation with due diligence. This is the way a bank protects itself from incurring huge losses. According to the Nilsen Report (2020), payment card fraud losses hit a record-high level of $32.04 billion, amounting to 6.8¢ for every $100 of total volume.</p>&#13;
&#13;
<p>This dataset is a good example of a mix of attributes of variable types as we have continuous, discrete, and nominal data. <a data-primary="Kaggle" data-type="indexterm" id="idm45737213209376"/>You can find the data on <a href="https://oreil.ly/fxxFg">Kaggle</a>. An explanation of the data is provided in <a data-type="xref" href="#att_exp">Table 8-1</a>.</p>&#13;
<table id="att_exp">&#13;
<caption><span class="label">Table 8-1. </span>Attributes and explanations</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Attribute</th>&#13;
<th>Explanation</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p><code>trans_date_trans_time</code></p></td>&#13;
<td><p>Date the transaction</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>cc_num</code></p></td>&#13;
<td><p>Credit card number of the customer</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>merchant</code></p></td>&#13;
<td><p>Merchant by whom the trade occurred</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>amt</code></p></td>&#13;
<td><p>Amount of transaction</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>first</code></p></td>&#13;
<td><p>First name of customer</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>last</code></p></td>&#13;
<td><p>Last name of customer</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>gender</code></p></td>&#13;
<td><p>Gender of the customer</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>street, city, state</code></p></td>&#13;
<td><p>Address of the customer</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>zip</code></p></td>&#13;
<td><p>Zip code of the transaction</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>lat</code></p></td>&#13;
<td><p>Latitude of the customer</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>long</code></p></td>&#13;
<td><p>Longitude of the customer</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>city_pop</code></p></td>&#13;
<td><p>Population of the city</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>job</code></p></td>&#13;
<td><p>Type of the customer’s profession</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>dob</code></p></td>&#13;
<td><p>Date of birth of the customer</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>trans_num</code></p></td>&#13;
<td><p>Unique transaction number for each transaction</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>unix_time</code></p></td>&#13;
<td><p>Time of the transaction in Unix</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>merch_lat</code></p></td>&#13;
<td><p>Merchant latitude</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>merch_long</code></p></td>&#13;
<td><p>Merchant longitude</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p><code>is_fraud</code></p></td>&#13;
<td><p>Whether the transaction is fraudulent or not</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Getting Familiar with Fraud Data" data-type="sect1"><div class="sect1" id="idm45737213170256">&#13;
<h1>Getting Familiar with Fraud Data</h1>&#13;
&#13;
<p><a data-primary="operational risk" data-secondary="fraud data familiarization" data-type="indexterm" id="ix_ops_risk_fraud_familiar"/>As you probably noticed, ML algorithms work better if the number of observations among different classes are more or less equal to each other—that is, it works best with balanced data. <a data-primary="class imbalance" data-secondary="fraud risk analysis" data-type="indexterm" id="idm45737213166944"/>We do not have balanced data in the fraud case, so this is called a <em>class imbalance</em>. In <a data-type="xref" href="ch06.html#chapter_6">Chapter 6</a>, we learned how to handle class imbalance problems, and we’ll use this skill again in this chapter.</p>&#13;
&#13;
<p>Let’s start off. To begin with, it makes sense to go through the data types of the variables in the Credit Card Transaction Fraud Detection Dataset:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">1</code><code class="p">]:</code> <code class="kn">import</code> <code class="nn">pandas</code> <code class="kn">as</code> <code class="nn">pd</code>&#13;
        <code class="kn">import</code> <code class="nn">numpy</code> <code class="kn">as</code> <code class="nn">np</code>&#13;
        <code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="kn">as</code> <code class="nn">plt</code>&#13;
        <code class="kn">import</code> <code class="nn">seaborn</code> <code class="kn">as</code> <code class="nn">sns</code>&#13;
        <code class="kn">from</code> <code class="nn">scipy.stats</code> <code class="kn">import</code> <code class="n">zscore</code>&#13;
        <code class="kn">import</code> <code class="nn">warnings</code>&#13;
        <code class="n">warnings</code><code class="o">.</code><code class="n">filterwarnings</code><code class="p">(</code><code class="s1">'ignore'</code><code class="p">)</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">2</code><code class="p">]:</code> <code class="n">fraud_data</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'fraudTrain.csv'</code><code class="p">)</code>&#13;
        <code class="k">del</code> <code class="n">fraud_data</code><code class="p">[</code><code class="s1">'Unnamed: 0'</code><code class="p">]</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">3</code><code class="p">]:</code> <code class="n">fraud_data</code><code class="o">.</code><code class="n">info</code><code class="p">()</code>&#13;
        <code class="o">&lt;</code><code class="k">class</code> <code class="err">'</code><code class="nc">pandas</code><code class="o">.</code><code class="n">core</code><code class="o">.</code><code class="n">frame</code><code class="o">.</code><code class="n">DataFrame</code><code class="s1">'&gt;</code>&#13;
        <code class="n">RangeIndex</code><code class="p">:</code> <code class="mi">1296675</code> <code class="n">entries</code><code class="p">,</code> <code class="mi">0</code> <code class="n">to</code> <code class="mi">1296674</code>&#13;
        <code class="n">Data</code> <code class="n">columns</code> <code class="p">(</code><code class="n">total</code> <code class="mi">22</code> <code class="n">columns</code><code class="p">):</code>&#13;
         <code class="c1">#   Column                 Non-Null Count    Dtype</code>&#13;
        <code class="o">---</code>  <code class="o">------</code>                 <code class="o">--------------</code>    <code class="o">-----</code>&#13;
         <code class="mi">0</code>   <code class="n">trans_date_trans_time</code>  <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="nb">object</code>&#13;
         <code class="mi">1</code>   <code class="n">cc_num</code>                 <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="n">int64</code>&#13;
         <code class="mi">2</code>   <code class="n">merchant</code>               <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="nb">object</code>&#13;
         <code class="mi">3</code>   <code class="n">category</code>               <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="nb">object</code>&#13;
         <code class="mi">4</code>   <code class="n">amt</code>                    <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="n">float64</code>&#13;
         <code class="mi">5</code>   <code class="n">first</code>                  <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="nb">object</code>&#13;
         <code class="mi">6</code>   <code class="n">last</code>                   <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="nb">object</code>&#13;
         <code class="mi">7</code>   <code class="n">gender</code>                 <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="nb">object</code>&#13;
         <code class="mi">8</code>   <code class="n">street</code>                 <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="nb">object</code>&#13;
         <code class="mi">9</code>   <code class="n">city</code>                   <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="nb">object</code>&#13;
         <code class="mi">10</code>  <code class="n">state</code>                  <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="nb">object</code>&#13;
         <code class="mi">11</code>  <code class="nb">zip</code>                    <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="n">int64</code>&#13;
         <code class="mi">12</code>  <code class="n">lat</code>                    <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="n">float64</code>&#13;
         <code class="mi">13</code>  <code class="nb">long</code>                   <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="n">float64</code>&#13;
         <code class="mi">14</code>  <code class="n">city_pop</code>               <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="n">int64</code>&#13;
         <code class="mi">15</code>  <code class="n">job</code>                    <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="nb">object</code>&#13;
         <code class="mi">16</code>  <code class="n">dob</code>                    <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="nb">object</code>&#13;
         <code class="mi">17</code>  <code class="n">trans_num</code>              <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="nb">object</code>&#13;
         <code class="mi">18</code>  <code class="n">unix_time</code>              <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="n">int64</code>&#13;
         <code class="mi">19</code>  <code class="n">merch_lat</code>              <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="n">float64</code>&#13;
         <code class="mi">20</code>  <code class="n">merch_long</code>             <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="n">float64</code>&#13;
         <code class="mi">21</code>  <code class="n">is_fraud</code>               <code class="mi">1296675</code> <code class="n">non</code><code class="o">-</code><code class="n">null</code>  <code class="n">int64</code>&#13;
        <code class="n">dtypes</code><code class="p">:</code> <code class="n">float64</code><code class="p">(</code><code class="mi">5</code><code class="p">),</code> <code class="n">int64</code><code class="p">(</code><code class="mi">5</code><code class="p">),</code> <code class="nb">object</code><code class="p">(</code><code class="mi">12</code><code class="p">)</code>&#13;
        <code class="n">memory</code> <code class="n">usage</code><code class="p">:</code> <code class="mf">217.6</code><code class="o">+</code> <code class="n">MB</code></pre>&#13;
&#13;
<p>It turns out we have all types of data: object, integer, and float. However, the majority of the variables are of the object type, so additional analysis is required to turn these categorical variables into numerical ones.<a data-primary="" data-startref="ix_cc_trans_fraud_dataset" data-type="indexterm" id="idm45737213137968"/></p>&#13;
&#13;
<p>The dependent variable is of considerable importance in such an analysis, as it often has imbalance characteristics that require due attention. This is shown in the following snippet (and resultant <a data-type="xref" href="#pie_chart_fraud">Figure 8-1</a>), which indicates a highly disproportionate number of observations:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">4</code><code class="p">]:</code> <code class="n">plt</code><code class="o">.</code><code class="n">pie</code><code class="p">(</code><code class="n">fraud_data</code><code class="p">[</code><code class="s1">'is_fraud'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(),</code> <code class="n">labels</code><code class="o">=</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">])</code>&#13;
        <code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'Pie Chart for Dependent Variable'</code><code class="p">);</code>&#13;
        <code class="k">print</code><code class="p">(</code><code class="n">fraud_data</code><code class="p">[</code><code class="s1">'is_fraud'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">())</code>&#13;
        <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code>&#13;
        <code class="mi">0</code>    <code class="mi">1289169</code>&#13;
        <code class="mi">1</code>       <code class="mi">7506</code>&#13;
        <code class="n">Name</code><code class="p">:</code> <code class="n">is_fraud</code><code class="p">,</code> <code class="n">dtype</code><code class="p">:</code> <code class="n">int64</code></pre>&#13;
&#13;
<figure><div class="figure" id="pie_chart_fraud">&#13;
<img alt="pie_chart_fraud" src="assets/mlfr_0801.png"/>&#13;
<h6><span class="label">Figure 8-1. </span>Pie chart for dependent variable</h6>&#13;
</div></figure>&#13;
&#13;
<p>As we can see, the number of observations for the nonfraud case is 1,289,169, while there are only 7,506 for the fraud case, so we know that the data is highly imbalanced, as expected.</p>&#13;
&#13;
<p class="pagebreak-before less_space"><a data-primary="missingno tool, fraud analysis" data-type="indexterm" id="idm45737212700096"/>At this point, we can use a rather different tool to detect the number of missing observations. This tool is known as <code>missingno</code>, and it also provides us with a visualization module for missing values (as can be seen in <a data-type="xref" href="#missingno_fraud">Figure 8-2</a>):</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">5</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">import</code><code> </code><code class="nn">missingno</code><code> </code><code class="kn">as</code><code> </code><code class="nn">msno</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO1-1" id="co_modeling_operational_risk_CO1-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="n">msno</code><code class="o">.</code><code class="n">bar</code><code class="p">(</code><code class="n">fraud_data</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO1-2" id="co_modeling_operational_risk_CO1-2"><img alt="2" src="assets/2.png"/></a></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO1-1" id="callout_modeling_operational_risk_CO1-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Importing <code>missingno</code></p></dd>&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO1-2" id="callout_modeling_operational_risk_CO1-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Creating a bar plot for missing values</p></dd>&#13;
</dl>&#13;
&#13;
<figure><div class="figure" id="missingno_fraud">&#13;
<img alt="missingno_fraud" src="assets/mlfr_0802.png"/>&#13;
<h6><span class="label">Figure 8-2. </span>Missing observations</h6>&#13;
</div></figure>&#13;
&#13;
<p><a data-type="xref" href="#missingno_fraud">Figure 8-2</a> indicates the number of nonmissing observations per variable at the top, and on the left-hand side we can see the percentage of nonmissing values. This analysis shows that the data has no missing values.</p>&#13;
&#13;
<p>In the next step, first we convert the date variable, <code>trans_date_trans_time</code>, into a proper format, and then we break time down into days and hours, assuming that fraudulent activities surge during particular time periods. It makes sense to analyze the effect of fraud on the different categories of a variable. To do that, we’ll employ a bar plot. It becomes clearer that the number of fraud cases may change given the category of some variables. But it stays the same in gender variables, meaning that gender has no impact on fraudulent activities. Another striking and evident observation is that the fraud cases change wildly per day and hour. This can be visually confirmed in the resulting <a data-type="xref" href="#bar_fraud">Figure 8-3</a>:</p>&#13;
&#13;
<pre class="pagebreak-before less_space" data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">6</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">fraud_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">time</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">to_datetime</code><code class="p">(</code><code class="n">fraud_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">trans_date_trans_time</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>&#13;
</code><code>        </code><code class="k">del</code><code> </code><code class="n">fraud_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">trans_date_trans_time</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">7</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">fraud_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">days</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">fraud_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">time</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">dt</code><code class="o">.</code><code class="n">day_name</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>        </code><code class="n">fraud_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">hour</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">fraud_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">time</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">dt</code><code class="o">.</code><code class="n">hour</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">8</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">fraud_cat</code><code class="p">(</code><code class="n">cols</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>            </code><code class="n">k</code><code> </code><code class="o">=</code><code> </code><code class="mi">1</code><code>&#13;
</code><code>            </code><code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">20</code><code class="p">,</code><code> </code><code class="mi">40</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>            </code><code class="k">for</code><code> </code><code class="n">i</code><code> </code><code class="ow">in</code><code> </code><code class="n">cols</code><code class="p">:</code><code>&#13;
</code><code>                </code><code class="n">categ</code><code> </code><code class="o">=</code><code> </code><code class="n">fraud_data</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="n">fraud_data</code><code class="p">[</code><code class="s1">'</code><code class="s1">is_fraud</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">==</code><code> </code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">i</code><code class="p">]</code><code class="o">.</code><code>\&#13;
</code><code>                        </code><code class="n">value_counts</code><code class="p">(</code><code class="p">)</code><code class="o">.</code><code class="n">sort_values</code><code class="p">(</code><code class="n">ascending</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code class="o">.</code><code>\&#13;
</code><code>                        </code><code class="n">reset_index</code><code class="p">(</code><code class="p">)</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="mi">10</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO2-1" id="co_modeling_operational_risk_CO2-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>                </code><code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">cols</code><code class="p">)</code><code> </code><code class="o">/</code><code> </code><code class="mi">2</code><code class="p">,</code><code> </code><code class="nb">len</code><code class="p">(</code><code class="n">cols</code><code class="p">)</code><code> </code><code class="o">/</code><code> </code><code class="mi">2</code><code class="p">,</code><code> </code><code class="n">k</code><code class="p">)</code><code>&#13;
</code><code>                </code><code class="n">bar_plot</code><code> </code><code class="o">=</code><code> </code><code class="n">plt</code><code class="o">.</code><code class="n">bar</code><code class="p">(</code><code class="n">categ</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="p">:</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">categ</code><code class="p">[</code><code class="n">i</code><code class="p">]</code><code class="p">)</code><code>&#13;
</code><code>                </code><code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="n">f</code><code class="s1">'</code><code class="s1">Cases per {i} Categories</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>                </code><code class="n">plt</code><code class="o">.</code><code class="n">xticks</code><code class="p">(</code><code class="n">rotation</code><code class="o">=</code><code class="s1">'</code><code class="s1">45</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>                </code><code class="n">k</code><code class="o">+</code><code class="o">=</code><code> </code><code class="mi">1</code><code>&#13;
</code><code>            </code><code class="k">return</code><code> </code><code class="n">categ</code><code class="p">,</code><code> </code><code class="n">bar_plot</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">9</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">cols</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="s1">'</code><code class="s1">job</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">state</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">gender</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">category</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">days</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">hour</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>        </code><code class="n">_</code><code class="p">,</code><code> </code><code class="n">bar_plot</code><code> </code><code class="o">=</code><code> </code><code class="n">fraud_cat</code><code class="p">(</code><code class="n">cols</code><code class="p">)</code><code>&#13;
</code><code>        </code><code class="n">bar_plot</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO2-1" id="callout_modeling_operational_risk_CO2-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Sorting <code>fraud_data</code> based on fraudulent activities in an ascending order</p></dd>&#13;
</dl>&#13;
&#13;
<p>Based on the analysis and our previous knowledge about the fraud analysis, we can decide on the number of variables to be used in our modeling. The categorical variables sort out so that we can create dummy variables using <code>pd.get_dummies</code>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">10</code><code class="p">]:</code> <code class="n">cols</code><code class="o">=</code><code class="p">[</code><code class="s1">'amt'</code><code class="p">,</code><code class="s1">'gender'</code><code class="p">,</code><code class="s1">'state'</code><code class="p">,</code><code class="s1">'category'</code><code class="p">,</code>&#13;
               <code class="s1">'city_pop'</code><code class="p">,</code><code class="s1">'job'</code><code class="p">,</code><code class="s1">'is_fraud'</code><code class="p">,</code><code class="s1">'days'</code><code class="p">,</code><code class="s1">'hour'</code><code class="p">]</code>&#13;
         <code class="n">fraud_data_df</code><code class="o">=</code><code class="n">fraud_data</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">11</code><code class="p">]:</code> <code class="n">cat_cols</code><code class="o">=</code><code class="n">fraud_data</code><code class="p">[</code><code class="n">cols</code><code class="p">]</code><code class="o">.</code><code class="n">select_dtypes</code><code class="p">(</code><code class="n">include</code><code class="o">=</code><code class="s1">'object'</code><code class="p">)</code><code class="o">.</code><code class="n">columns</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">12</code><code class="p">]:</code> <code class="k">def</code> <code class="nf">one_hot_encoded_cat</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">cat_cols</code><code class="p">):</code>&#13;
             <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="n">cat_cols</code><code class="p">:</code>&#13;
                 <code class="n">df1</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">get_dummies</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="nb">str</code><code class="p">(</code><code class="n">i</code><code class="p">)],</code>&#13;
                                      <code class="n">prefix</code><code class="o">=</code><code class="n">i</code><code class="p">,</code> <code class="n">drop_first</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>&#13;
                 <code class="n">data</code><code class="o">.</code><code class="n">drop</code><code class="p">(</code><code class="nb">str</code><code class="p">(</code><code class="n">i</code><code class="p">),</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>&#13;
                 <code class="n">data</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">data</code><code class="p">,</code> <code class="n">df1</code><code class="p">],</code> <code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>&#13;
             <code class="k">return</code> <code class="n">data</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">13</code><code class="p">]:</code> <code class="n">fraud_df</code> <code class="o">=</code> <code class="n">one_hot_encoded_cat</code><code class="p">(</code><code class="n">fraud_data_df</code><code class="p">,</code> <code class="n">cat_cols</code><code class="p">)</code></pre>&#13;
&#13;
<figure><div class="figure" id="bar_fraud">&#13;
<img alt="bar_fraud" src="assets/mlfr_0803.png"/>&#13;
<h6><span class="label">Figure 8-3. </span>Bar plots per variable</h6>&#13;
</div></figure>&#13;
&#13;
<p>Subsequent to categorical variable analysis, it’s worth discussing the interactions between the numerical variables, namely, <code>amount</code>, <code>population</code>, and <code>hour</code>. A correlation analysis provides us with a strong tool for figuring out the interaction(s) among these variables, and the resulting heatmap (<a data-type="xref" href="#heatmap_fraud">Figure 8-4</a>) suggests that the correlations are very low:<a data-primary="" data-startref="ix_ops_risk_fraud_familiar" data-type="indexterm" id="idm45737212437360"/></p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">14</code><code class="p">]:</code> <code class="n">num_col</code> <code class="o">=</code> <code class="n">fraud_data_df</code><code class="o">.</code><code class="n">select_dtypes</code><code class="p">(</code><code class="n">exclude</code><code class="o">=</code><code class="s1">'object'</code><code class="p">)</code><code class="o">.</code><code class="n">columns</code>&#13;
         <code class="n">fraud_data_df</code> <code class="o">=</code> <code class="n">fraud_data_df</code><code class="p">[</code><code class="n">num_col</code><code class="p">]</code>&#13;
         <code class="k">del</code> <code class="n">fraud_data_df</code><code class="p">[</code><code class="s1">'is_fraud'</code><code class="p">]</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">15</code><code class="p">]:</code> <code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code class="mi">6</code><code class="p">))</code>&#13;
         <code class="n">corrmat</code> <code class="o">=</code> <code class="n">fraud_data_df</code><code class="o">.</code><code class="n">corr</code><code class="p">()</code>&#13;
         <code class="n">top_corr_features</code> <code class="o">=</code> <code class="n">corrmat</code><code class="o">.</code><code class="n">index</code>&#13;
         <code class="n">heat_map</code> <code class="o">=</code> <code class="n">sns</code><code class="o">.</code><code class="n">heatmap</code><code class="p">(</code><code class="n">corrmat</code><code class="p">,</code> <code class="n">annot</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code> <code class="n">cmap</code><code class="o">=</code><code class="s2">"viridis"</code><code class="p">)</code></pre>&#13;
&#13;
<figure><div class="figure" id="heatmap_fraud">&#13;
<img alt="heatmap_fraud" src="assets/mlfr_0804.png"/>&#13;
<h6><span class="label">Figure 8-4. </span>Heatmap</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Supervised Learning Modeling for Fraud Examination" data-type="sect1"><div class="sect1" id="idm45737213169344">&#13;
<h1>Supervised Learning Modeling for Fraud Examination</h1>&#13;
&#13;
<p><a data-primary="supervised learning modeling" data-type="indexterm" id="ix_sup_learning_ops_risk"/><a data-primary="operational risk" data-secondary="supervised learning modeling" data-type="indexterm" id="ix_ops_risk_sup_learning"/>We have determined the peculiar characteristics of the variables using interactions, missing values, and creating dummy variables. Now we are ready to move on and run ML models for fraud analysis. The models we are about to run are:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Logistic regression</p>&#13;
</li>&#13;
<li>&#13;
<p>Decision tree</p>&#13;
</li>&#13;
<li>&#13;
<p>Random forest</p>&#13;
</li>&#13;
<li>&#13;
<p>XGBoost</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p><a data-primary="undersampling technique to balance data" data-type="indexterm" id="ix_undersample_bal_data"/><a data-primary="balanced data, creating for fraud analysis" data-type="indexterm" id="ix_bal_data_fraud"/><a data-primary="logistic regression" data-type="indexterm" id="idm45737211996384"/>As you can imagine, it’s key to have balanced data before doing our modeling. Even though there are numerous ways to get balanced data, we’ll choose the undersampling method because of its performance. Undersampling is a technique that matches the majority classes to minority classes, as shown in <a data-type="xref" href="#imbalance">Figure 8-5</a>.</p>&#13;
&#13;
<figure><div class="figure" id="imbalance">&#13;
<img alt="imbalance" src="assets/mlfr_0805.png"/>&#13;
<h6><span class="label">Figure 8-5. </span>Undersampling</h6>&#13;
</div></figure>&#13;
&#13;
<p>Alternatively, the number of observations from the majority class is removed until we get the same number of observations as the minority class.&#13;
We’ll apply undersampling in the following code block, where the independent and dependent variables are named <code>X_under</code> and <code>y_under</code>, respectively. In what follows, train-test split is used to obtain the train and test splits in a random fashion:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">16</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">sklearn.model_selection</code><code> </code><code class="kn">import</code><code> </code><code class="n">train_test_split</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">sklearn.linear_model</code><code> </code><code class="kn">import</code><code> </code><code class="n">LogisticRegression</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">sklearn.model_selection</code><code> </code><code class="kn">import</code><code> </code><code class="n">train_test_split</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">sklearn.model_selection</code><code> </code><code class="kn">import</code><code> </code><code class="n">GridSearchCV</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">sklearn.model_selection</code><code> </code><code class="kn">import</code><code> </code><code class="n">RandomizedSearchCV</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">sklearn.metrics</code><code> </code><code class="kn">import</code><code> </code><code class="p">(</code><code class="n">classification_report</code><code class="p">,</code><code>&#13;
</code><code>                                     </code><code class="n">confusion_matrix</code><code class="p">,</code><code> </code><code class="n">f1_score</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">17</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">non_fraud_class</code><code> </code><code class="o">=</code><code> </code><code class="n">fraud_df</code><code class="p">[</code><code class="n">fraud_df</code><code class="p">[</code><code class="s1">'</code><code class="s1">is_fraud</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">==</code><code> </code><code class="mi">0</code><code class="p">]</code><code>&#13;
</code><code>         </code><code class="n">fraud_class</code><code> </code><code class="o">=</code><code> </code><code class="n">fraud_df</code><code class="p">[</code><code class="n">fraud_df</code><code class="p">[</code><code class="s1">'</code><code class="s1">is_fraud</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">==</code><code> </code><code class="mi">1</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">18</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">non_fraud_count</code><code class="p">,</code><code class="n">fraud_count</code><code class="o">=</code><code class="n">fraud_df</code><code class="p">[</code><code class="s1">'</code><code class="s1">is_fraud</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">The number of observations in non_fraud_class:</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">non_fraud_count</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">The number of observations in fraud_class:</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">fraud_count</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">number</code><code> </code><code class="n">of</code><code> </code><code class="n">observations</code><code> </code><code class="ow">in</code><code> </code><code class="n">non_fraud_class</code><code class="p">:</code><code> </code><code class="mi">1289169</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">number</code><code> </code><code class="n">of</code><code> </code><code class="n">observations</code><code> </code><code class="ow">in</code><code> </code><code class="n">fraud_class</code><code class="p">:</code><code> </code><code class="mi">7506</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">19</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">non_fraud_under</code><code> </code><code class="o">=</code><code> </code><code class="n">non_fraud_class</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="n">fraud_count</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO3-1" id="co_modeling_operational_risk_CO3-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="n">under_sampled</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">(</code><code class="p">[</code><code class="n">non_fraud_under</code><code class="p">,</code><code> </code><code class="n">fraud_class</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">axis</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO3-2" id="co_modeling_operational_risk_CO3-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>         </code><code class="n">X_under</code><code> </code><code class="o">=</code><code> </code><code class="n">under_sampled</code><code class="o">.</code><code class="n">drop</code><code class="p">(</code><code class="s1">'</code><code class="s1">is_fraud</code><code class="s1">'</code><code class="p">,</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO3-3" id="co_modeling_operational_risk_CO3-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>         </code><code class="n">y_under</code><code> </code><code class="o">=</code><code> </code><code class="n">under_sampled</code><code class="p">[</code><code class="s1">'</code><code class="s1">is_fraud</code><code class="s1">'</code><code class="p">]</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO3-4" id="co_modeling_operational_risk_CO3-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">20</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">X_train_under</code><code class="p">,</code><code> </code><code class="n">X_test_under</code><code class="p">,</code><code> </code><code class="n">y_train_under</code><code class="p">,</code><code> </code><code class="n">y_test_under</code><code> </code><code class="o">=</code><code>\&#13;
</code><code>                 </code><code class="n">train_test_split</code><code class="p">(</code><code class="n">X_under</code><code class="p">,</code><code> </code><code class="n">y_under</code><code class="p">,</code><code> </code><code class="n">random_state</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist pagebreak-before less_space">&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO3-1" id="callout_modeling_operational_risk_CO3-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Sampling <code>fraud_count</code></p></dd>&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO3-2" id="callout_modeling_operational_risk_CO3-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Concatenating the data including fraudulent cases with data including no fraudulent cases</p></dd>&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO3-3" id="callout_modeling_operational_risk_CO3-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Creating independent variables by dropping <code>is_fraud</code></p></dd>&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO3-4" id="callout_modeling_operational_risk_CO3-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Creating dependent variables by <code>is_fraud</code></p></dd>&#13;
</dl>&#13;
&#13;
<p>After using the undersampling method, let’s now run some of the classification models we described earlier and observe the performance of these models in detecting the fraud:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">21</code><code class="p">]:</code> <code class="n">param_log</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'C'</code><code class="p">:</code> <code class="n">np</code><code class="o">.</code><code class="n">logspace</code><code class="p">(</code><code class="o">-</code><code class="mi">4</code><code class="p">,</code> <code class="mi">4</code><code class="p">,</code> <code class="mi">4</code><code class="p">),</code> <code class="s1">'penalty'</code><code class="p">:</code> <code class="p">[</code><code class="s1">'l1'</code><code class="p">,</code> <code class="s1">'l2'</code><code class="p">]}</code>&#13;
         <code class="n">log_grid</code> <code class="o">=</code> <code class="n">GridSearchCV</code><code class="p">(</code><code class="n">LogisticRegression</code><code class="p">(),</code>&#13;
                                 <code class="n">param_grid</code><code class="o">=</code><code class="n">param_log</code><code class="p">,</code> <code class="n">n_jobs</code><code class="o">=-</code><code class="mi">1</code><code class="p">)</code>&#13;
         <code class="n">log_grid</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train_under</code><code class="p">,</code> <code class="n">y_train_under</code><code class="p">)</code>&#13;
         <code class="n">prediction_log</code> <code class="o">=</code> <code class="n">log_grid</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test_under</code><code class="p">)</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">22</code><code class="p">]:</code> <code class="n">conf_mat_log</code> <code class="o">=</code> <code class="n">confusion_matrix</code><code class="p">(</code><code class="n">y_true</code><code class="o">=</code><code class="n">y_test_under</code><code class="p">,</code>&#13;
                                         <code class="n">y_pred</code><code class="o">=</code><code class="n">prediction_log</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Confusion matrix:</code><code class="se">\n</code><code class="s1">'</code><code class="p">,</code> <code class="n">conf_mat_log</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'--'</code> <code class="o">*</code> <code class="mi">25</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Classification report:</code><code class="se">\n</code><code class="s1">'</code><code class="p">,</code>&#13;
               <code class="n">classification_report</code><code class="p">(</code><code class="n">y_test_under</code><code class="p">,</code> <code class="n">prediction_log</code><code class="p">))</code>&#13;
         <code class="n">Confusion</code> <code class="n">matrix</code><code class="p">:</code>&#13;
          <code class="p">[[</code><code class="mi">1534</code>  <code class="mi">310</code><code class="p">]</code>&#13;
          <code class="p">[</code> <code class="mi">486</code> <code class="mi">1423</code><code class="p">]]</code>&#13;
         <code class="o">--------------------------------------------------</code>&#13;
         <code class="n">Classification</code> <code class="n">report</code><code class="p">:</code>&#13;
                        <code class="n">precision</code>    <code class="n">recall</code>  <code class="n">f1</code><code class="o">-</code><code class="n">score</code>   <code class="n">support</code>&#13;
&#13;
                    <code class="mi">0</code>       <code class="mf">0.76</code>      <code class="mf">0.83</code>      <code class="mf">0.79</code>      <code class="mi">1844</code>&#13;
                    <code class="mi">1</code>       <code class="mf">0.82</code>      <code class="mf">0.75</code>      <code class="mf">0.78</code>      <code class="mi">1909</code>&#13;
&#13;
             <code class="n">accuracy</code>                           <code class="mf">0.79</code>      <code class="mi">3753</code>&#13;
            <code class="n">macro</code> <code class="n">avg</code>       <code class="mf">0.79</code>      <code class="mf">0.79</code>      <code class="mf">0.79</code>      <code class="mi">3753</code>&#13;
         <code class="n">weighted</code> <code class="n">avg</code>       <code class="mf">0.79</code>      <code class="mf">0.79</code>      <code class="mf">0.79</code>      <code class="mi">3753</code></pre>&#13;
&#13;
<p><a data-primary="confusion matrix, fraud analysis" data-type="indexterm" id="idm45737211690496"/>First, let’s look at the confusion matrix. The confusion matrix suggests that the number of observations in false positives and false negatives are 310 and 486, respectively. We’ll be using the confusion matrix in the cost-based method.</p>&#13;
&#13;
<p><a data-primary="F1Score, fraud analysis" data-type="indexterm" id="idm45737211689152"/>The <em>F1 score</em> is the metric that is used to measure the performance of these models. It presents a weighted average of recall and precision, making it an ideal measure for a case such as this one.</p>&#13;
&#13;
<p><a data-primary="decision tree model, fraud analysis" data-type="indexterm" id="idm45737211802352"/>The second model is decision tree, which works well in modeling fraud. After tuning hyperparameters, it turns out that F1 score is much higher, indicating that decision tree does a relatively good job. As expected, the number of false positive and false negative observations are much fewer compared to logistic regression:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">23</code><code class="p">]:</code> <code class="kn">from</code> <code class="nn">sklearn.tree</code> <code class="kn">import</code> <code class="n">DecisionTreeClassifier</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">24</code><code class="p">]:</code> <code class="n">param_dt</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'max_depth'</code><code class="p">:</code> <code class="p">[</code><code class="mi">3</code><code class="p">,</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">10</code><code class="p">],</code>&#13;
                     <code class="s1">'min_samples_split'</code><code class="p">:</code> <code class="p">[</code><code class="mi">2</code><code class="p">,</code> <code class="mi">4</code><code class="p">,</code> <code class="mi">6</code><code class="p">],</code>&#13;
                     <code class="s1">'criterion'</code><code class="p">:</code> <code class="p">[</code><code class="s1">'gini'</code><code class="p">,</code> <code class="s1">'entropy'</code><code class="p">]}</code>&#13;
         <code class="n">dt_grid</code> <code class="o">=</code> <code class="n">GridSearchCV</code><code class="p">(</code><code class="n">DecisionTreeClassifier</code><code class="p">(),</code>&#13;
                                <code class="n">param_grid</code><code class="o">=</code><code class="n">param_dt</code><code class="p">,</code> <code class="n">n_jobs</code><code class="o">=-</code><code class="mi">1</code><code class="p">)</code>&#13;
         <code class="n">dt_grid</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train_under</code><code class="p">,</code> <code class="n">y_train_under</code><code class="p">)</code>&#13;
         <code class="n">prediction_dt</code> <code class="o">=</code> <code class="n">dt_grid</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test_under</code><code class="p">)</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">25</code><code class="p">]:</code> <code class="n">conf_mat_dt</code> <code class="o">=</code> <code class="n">confusion_matrix</code><code class="p">(</code><code class="n">y_true</code><code class="o">=</code><code class="n">y_test_under</code><code class="p">,</code>&#13;
                                        <code class="n">y_pred</code><code class="o">=</code><code class="n">prediction_dt</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Confusion matrix:</code><code class="se">\n</code><code class="s1">'</code><code class="p">,</code> <code class="n">conf_mat_dt</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'--'</code> <code class="o">*</code> <code class="mi">25</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Classification report:</code><code class="se">\n</code><code class="s1">'</code><code class="p">,</code>&#13;
               <code class="n">classification_report</code><code class="p">(</code><code class="n">y_test_under</code><code class="p">,</code> <code class="n">prediction_dt</code><code class="p">))</code>&#13;
         <code class="n">Confusion</code> <code class="n">matrix</code><code class="p">:</code>&#13;
          <code class="p">[[</code><code class="mi">1795</code>   <code class="mi">49</code><code class="p">]</code>&#13;
          <code class="p">[</code>  <code class="mi">84</code> <code class="mi">1825</code><code class="p">]]</code>&#13;
         <code class="o">--------------------------------------------------</code>&#13;
         <code class="n">Classification</code> <code class="n">report</code><code class="p">:</code>&#13;
                        <code class="n">precision</code>    <code class="n">recall</code>  <code class="n">f1</code><code class="o">-</code><code class="n">score</code>   <code class="n">support</code>&#13;
&#13;
                    <code class="mi">0</code>       <code class="mf">0.96</code>      <code class="mf">0.97</code>      <code class="mf">0.96</code>      <code class="mi">1844</code>&#13;
                    <code class="mi">1</code>       <code class="mf">0.97</code>      <code class="mf">0.96</code>      <code class="mf">0.96</code>      <code class="mi">1909</code>&#13;
&#13;
             <code class="n">accuracy</code>                           <code class="mf">0.96</code>      <code class="mi">3753</code>&#13;
            <code class="n">macro</code> <code class="n">avg</code>       <code class="mf">0.96</code>      <code class="mf">0.96</code>      <code class="mf">0.96</code>      <code class="mi">3753</code>&#13;
         <code class="n">weighted</code> <code class="n">avg</code>       <code class="mf">0.96</code>      <code class="mf">0.96</code>      <code class="mf">0.96</code>      <code class="mi">3753</code></pre>&#13;
&#13;
<p><a data-primary="random forest model" data-type="indexterm" id="idm45737211800784"/>According to common belief, the random forest model, as an ensemble model, outperforms decision tree. However, this is true only if decision tree suffers from predictive instability in such a way that predictions of different samples vary wildly, and this is not the case here. As you can observe from the following result, random forest does not perform better than decision tree, even if it has an F1 score of 87:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">26</code><code class="p">]:</code> <code class="kn">from</code> <code class="nn">sklearn.ensemble</code> <code class="kn">import</code> <code class="n">RandomForestClassifier</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">27</code><code class="p">]:</code> <code class="n">param_rf</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'n_estimators'</code><code class="p">:[</code><code class="mi">20</code><code class="p">,</code><code class="mi">50</code><code class="p">,</code><code class="mi">100</code><code class="p">]</code> <code class="p">,</code>&#13;
                  <code class="s1">'max_depth'</code><code class="p">:[</code><code class="mi">3</code><code class="p">,</code><code class="mi">5</code><code class="p">,</code><code class="mi">10</code><code class="p">],</code>&#13;
                  <code class="s1">'min_samples_split'</code><code class="p">:[</code><code class="mi">2</code><code class="p">,</code><code class="mi">4</code><code class="p">,</code><code class="mi">6</code><code class="p">],</code>&#13;
                  <code class="s1">'max_features'</code><code class="p">:[</code><code class="s1">'auto'</code><code class="p">,</code> <code class="s1">'sqrt'</code><code class="p">,</code> <code class="s1">'log2'</code><code class="p">]}</code>&#13;
         <code class="n">rf_grid</code> <code class="o">=</code> <code class="n">GridSearchCV</code><code class="p">(</code><code class="n">RandomForestClassifier</code><code class="p">(),</code>&#13;
                               <code class="n">param_grid</code><code class="o">=</code><code class="n">param_rf</code><code class="p">,</code> <code class="n">n_jobs</code><code class="o">=-</code><code class="mi">1</code><code class="p">)</code>&#13;
         <code class="n">rf_grid</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train_under</code><code class="p">,</code> <code class="n">y_train_under</code><code class="p">)</code>&#13;
         <code class="n">prediction_rf</code> <code class="o">=</code> <code class="n">rf_grid</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test_under</code><code class="p">)</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">28</code><code class="p">]:</code> <code class="n">conf_mat_rf</code> <code class="o">=</code> <code class="n">confusion_matrix</code><code class="p">(</code><code class="n">y_true</code><code class="o">=</code><code class="n">y_test_under</code><code class="p">,</code>&#13;
                                        <code class="n">y_pred</code><code class="o">=</code><code class="n">prediction_rf</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Confusion matrix:</code><code class="se">\n</code><code class="s1">'</code><code class="p">,</code> <code class="n">conf_mat_rf</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'--'</code> <code class="o">*</code> <code class="mi">25</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Classification report:</code><code class="se">\n</code><code class="s1">'</code><code class="p">,</code>&#13;
               <code class="n">classification_report</code><code class="p">(</code><code class="n">y_test_under</code><code class="p">,</code> <code class="n">prediction_rf</code><code class="p">))</code>&#13;
         <code class="n">Confusion</code> <code class="n">matrix</code><code class="p">:</code>&#13;
          <code class="p">[[</code><code class="mi">1763</code>   <code class="mi">81</code><code class="p">]</code>&#13;
          <code class="p">[</code> <code class="mi">416</code> <code class="mi">1493</code><code class="p">]]</code>&#13;
         <code class="o">--------------------------------------------------</code>&#13;
         <code class="n">Classification</code> <code class="n">report</code><code class="p">:</code>&#13;
                        <code class="n">precision</code>    <code class="n">recall</code>  <code class="n">f1</code><code class="o">-</code><code class="n">score</code>   <code class="n">support</code>&#13;
&#13;
                    <code class="mi">0</code>       <code class="mf">0.81</code>      <code class="mf">0.96</code>      <code class="mf">0.88</code>      <code class="mi">1844</code>&#13;
                    <code class="mi">1</code>       <code class="mf">0.95</code>      <code class="mf">0.78</code>      <code class="mf">0.86</code>      <code class="mi">1909</code>&#13;
&#13;
             <code class="n">accuracy</code>                           <code class="mf">0.87</code>      <code class="mi">3753</code>&#13;
            <code class="n">macro</code> <code class="n">avg</code>       <code class="mf">0.88</code>      <code class="mf">0.87</code>      <code class="mf">0.87</code>      <code class="mi">3753</code>&#13;
         <code class="n">weighted</code> <code class="n">avg</code>       <code class="mf">0.88</code>      <code class="mf">0.87</code>      <code class="mf">0.87</code>      <code class="mi">3753</code></pre>&#13;
&#13;
<p><a data-primary="XGBoost model, fraud analysis" data-type="indexterm" id="idm45737211237328"/>The final model we’ll look at is XGBoost, which generates similar results to the decision tree, as it outputs an F1 score of 97:<a data-primary="" data-startref="ix_bal_data_fraud" data-type="indexterm" id="idm45737211236464"/><a data-primary="" data-startref="ix_undersample_bal_data" data-type="indexterm" id="idm45737211235616"/></p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">29</code><code class="p">]:</code> <code class="kn">from</code> <code class="nn">xgboost</code> <code class="kn">import</code> <code class="n">XGBClassifier</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">30</code><code class="p">]:</code> <code class="n">param_boost</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'learning_rate'</code><code class="p">:</code> <code class="p">[</code><code class="mf">0.01</code><code class="p">,</code> <code class="mf">0.1</code><code class="p">],</code>&#13;
                        <code class="s1">'max_depth'</code><code class="p">:</code> <code class="p">[</code><code class="mi">3</code><code class="p">,</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">7</code><code class="p">],</code>&#13;
                        <code class="s1">'subsample'</code><code class="p">:</code> <code class="p">[</code><code class="mf">0.5</code><code class="p">,</code> <code class="mf">0.7</code><code class="p">],</code>&#13;
                        <code class="s1">'colsample_bytree'</code><code class="p">:</code> <code class="p">[</code><code class="mf">0.5</code><code class="p">,</code> <code class="mf">0.7</code><code class="p">],</code>&#13;
                        <code class="s1">'n_estimators'</code><code class="p">:</code> <code class="p">[</code><code class="mi">10</code><code class="p">,</code> <code class="mi">20</code><code class="p">,</code> <code class="mi">30</code><code class="p">]}</code>&#13;
         <code class="n">boost_grid</code> <code class="o">=</code> <code class="n">RandomizedSearchCV</code><code class="p">(</code><code class="n">XGBClassifier</code><code class="p">(),</code>&#13;
                                         <code class="n">param_boost</code><code class="p">,</code> <code class="n">n_jobs</code><code class="o">=-</code><code class="mi">1</code><code class="p">)</code>&#13;
         <code class="n">boost_grid</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train_under</code><code class="p">,</code> <code class="n">y_train_under</code><code class="p">)</code>&#13;
         <code class="n">prediction_boost</code> <code class="o">=</code> <code class="n">boost_grid</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test_under</code><code class="p">)</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">31</code><code class="p">]:</code> <code class="n">conf_mat_boost</code> <code class="o">=</code> <code class="n">confusion_matrix</code><code class="p">(</code><code class="n">y_true</code><code class="o">=</code><code class="n">y_test_under</code><code class="p">,</code>&#13;
                                           <code class="n">y_pred</code><code class="o">=</code><code class="n">prediction_boost</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Confusion matrix:</code><code class="se">\n</code><code class="s1">'</code><code class="p">,</code> <code class="n">conf_mat_boost</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'--'</code> <code class="o">*</code> <code class="mi">25</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Classification report:</code><code class="se">\n</code><code class="s1">'</code><code class="p">,</code>&#13;
               <code class="n">classification_report</code><code class="p">(</code><code class="n">y_test_under</code><code class="p">,</code> <code class="n">prediction_boost</code><code class="p">))</code>&#13;
         <code class="n">Confusion</code> <code class="n">matrix</code><code class="p">:</code>&#13;
          <code class="p">[[</code><code class="mi">1791</code>   <code class="mi">53</code><code class="p">]</code>&#13;
          <code class="p">[</code>  <code class="mi">75</code> <code class="mi">1834</code><code class="p">]]</code>&#13;
         <code class="o">--------------------------------------------------</code>&#13;
         <code class="n">Classification</code> <code class="n">report</code><code class="p">:</code>&#13;
                        <code class="n">precision</code>    <code class="n">recall</code>  <code class="n">f1</code><code class="o">-</code><code class="n">score</code>   <code class="n">support</code>&#13;
&#13;
                    <code class="mi">0</code>       <code class="mf">0.96</code>      <code class="mf">0.97</code>      <code class="mf">0.97</code>      <code class="mi">1844</code>&#13;
                    <code class="mi">1</code>       <code class="mf">0.97</code>      <code class="mf">0.96</code>      <code class="mf">0.97</code>      <code class="mi">1909</code>&#13;
&#13;
             <code class="n">accuracy</code>                           <code class="mf">0.97</code>      <code class="mi">3753</code>&#13;
            <code class="n">macro</code> <code class="n">avg</code>       <code class="mf">0.97</code>      <code class="mf">0.97</code>      <code class="mf">0.97</code>      <code class="mi">3753</code>&#13;
         <code class="n">weighted</code> <code class="n">avg</code>       <code class="mf">0.97</code>      <code class="mf">0.97</code>      <code class="mf">0.97</code>      <code class="mi">3753</code></pre>&#13;
&#13;
<p>Given all the applications, here is the summary result:</p>&#13;
<table>&#13;
<caption><span class="label">Table 8-2. </span>The result of modeling fraud with undersampling</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Model</th>&#13;
<th>F1 score</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Logistic regression</p></td>&#13;
<td><p>0.79</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Decision tree</p></td>&#13;
<td><p>0.96</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Random forest</p></td>&#13;
<td><p>0.87</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>XGBoost</p></td>&#13;
<td><p>0.97</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Cost-Based Fraud Examination" data-type="sect2"><div class="sect2" id="idm45737210749840">&#13;
<h2>Cost-Based Fraud Examination</h2>&#13;
&#13;
<p><a data-primary="supervised learning modeling" data-secondary="cost-based fraud examination" data-type="indexterm" id="ix_sup_learn_cost-based"/><a data-primary="operational risk" data-secondary="supervised learning modeling" data-tertiary="cost-based fraud examination" data-type="indexterm" id="ix_ops_risk_sup_learn_cost"/>Undersampling gives us a convenient tool for dealing with imbalanced data. It comes with costs, however, and the biggest cost is its discarding of important observations. Even though different sampling procedures can be applied to sensitive analyses such as health care, fraud, and so on, it should be noted that performance metrics fail to consider the extent to which different misclassifications have varying economic impact. <a data-primary="cost-sensitive classifier" data-type="indexterm" id="idm45737210744896"/>Hence, if a method proposes different misclassification costs, it is referred to as a <em>cost-sensitive classifier</em>. <a data-primary="cost-sensitive modeling" data-type="indexterm" id="ix_cost-sens_model"/>Let’s consider the fraud case, which is a classic example of cost-sensitive analysis. In this type of analysis, it is evident that a false positive is less costly than a false negative. To be more precise, a false positive means blocking an already legitimate transaction. The cost of this type of classification tends to be administrative and opportunity cost–related, such as the time and energy spent on detection and the lost potential gain a financial institution can make from&#13;
the transaction.</p>&#13;
&#13;
<p>However, failing to detect a fraud (i.e., having a false negative) means a lot for a company, as it might imply various internal weaknesses as well as poorly designed operational procedures.&#13;
Having failed to detect a real fraud, a company can incur large financial costs—including the transaction amount—not to mention costs stemming from any damage to its reputation. The former type of cost puts the burden on the company’s shoulder, but the latter can be neither quantified nor ignored.</p>&#13;
&#13;
<p>As you can see, the need to assign varying costs for different misclassifications leads us to a more pronounced, realistic solution. For the sake of simplicity, let’s assume the cost of false negative and true positive to be the transaction amount and 2, respectively.&#13;
<a data-type="xref" href="#cost_sen_mat">Table 8-3</a> summarizes the results. Another approach for evaluating cost sensitivity would be to assume a constant false negative, as in other cases. However, this approach is considered unrealistic.</p>&#13;
<table class="pagebreak-before less_space" id="cost_sen_mat">&#13;
<caption><span class="label">Table 8-3. </span>Cost-sensitive matrix</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Model</th>&#13;
<th>F1 score</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>True Positive = 2</p></td>&#13;
<td><p>False Negative = Transaction Amount</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>False Positive = 2</p></td>&#13;
<td><p>True Negative = 0</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p>Consequently, the&#13;
total cost that an institution might face with varying false negative costs takes the following form:</p>&#13;
<div data-type="equation">&#13;
<math alttext="Cost equals sigma-summation Underscript i equals 1 Overscript upper N Endscripts y Subscript i Baseline left-parenthesis c Subscript i Baseline upper C Subscript upper T upper P Sub Subscript i Subscript Baseline plus left-parenthesis 1 minus c Subscript i Baseline right-parenthesis upper C Subscript upper F upper N Sub Subscript i Subscript Baseline right-parenthesis plus left-parenthesis 1 minus y Subscript i Baseline right-parenthesis c Subscript i Baseline upper C Subscript upper F upper P Sub Subscript i Subscript Baseline" display="block">&#13;
  <mrow>&#13;
    <mtext>Cost</mtext>&#13;
    <mo>=</mo>&#13;
    <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>N</mi> </munderover>&#13;
    <msub><mi>y</mi> <mi>i</mi> </msub>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>i</mi> </msub>&#13;
      <msub><mi>C</mi> <mrow><mi>T</mi><msub><mi>P</mi> <mi>i</mi> </msub></mrow> </msub>&#13;
      <mo>+</mo>&#13;
      <mrow>&#13;
        <mo>(</mo>&#13;
        <mn>1</mn>&#13;
        <mo>-</mo>&#13;
        <msub><mi>c</mi> <mi>i</mi> </msub>&#13;
        <mo>)</mo>&#13;
      </mrow>&#13;
      <msub><mi>C</mi> <mrow><mi>F</mi><msub><mi>N</mi> <mi>i</mi> </msub></mrow> </msub>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>+</mo>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mn>1</mn>&#13;
      <mo>-</mo>&#13;
      <msub><mi>y</mi> <mi>i</mi> </msub>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <msub><mi>c</mi> <mi>i</mi> </msub>&#13;
    <msub><mi>C</mi> <mrow><mi>F</mi><msub><mi>P</mi> <mi>i</mi> </msub></mrow> </msub>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <math alttext="c Subscript i">&#13;
  <msub><mi>c</mi> <mi>i</mi> </msub>&#13;
</math> is the predicted label, <math alttext="y Subscript i">&#13;
  <msub><mi>y</mi> <mi>i</mi> </msub>&#13;
</math> is the actual label, <em>N</em> is the number of observations, and <math alttext="upper C Subscript upper T upper P Sub Subscript i">&#13;
  <msub><mi>C</mi> <mrow><mi>T</mi><msub><mi>P</mi> <mi>i</mi> </msub></mrow> </msub>&#13;
</math> and <math alttext="upper C Subscript upper F upper P Sub Subscript i">&#13;
  <msub><mi>C</mi> <mrow><mi>F</mi><msub><mi>P</mi> <mi>i</mi> </msub></mrow> </msub>&#13;
</math> correspond to administrative cost, which is 2 in our case. <math alttext="upper C Subscript upper F upper N Sub Subscript i">&#13;
  <msub><mi>C</mi> <mrow><mi>F</mi><msub><mi>N</mi> <mi>i</mi> </msub></mrow> </msub>&#13;
</math> represents transaction amount.</p>&#13;
&#13;
<p>Now, with this information in hand, let’s revisit the ML models considering the cost-sensitive approach and calculate the changing cost of these models. However, before we start, it is worth noting that cost-sensitive models are not fast-processing ones, so as we have a large number of observations, it would be wise to sample from them &#13;
<span class="keep-together">to model</span> the data in a timely manner. A class-dependent cost measure is given as &#13;
<span class="keep-together">follows</span>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">32</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">fraud_df_sampled</code><code> </code><code class="o">=</code><code> </code><code class="n">fraud_df</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="nb">int</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">fraud_df</code><code class="p">)</code><code> </code><code class="o">*</code><code> </code><code class="mf">0.2</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO4-1" id="co_modeling_operational_risk_CO4-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">33</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">cost_fp</code><code> </code><code class="o">=</code><code> </code><code class="mi">2</code><code>&#13;
</code><code>         </code><code class="n">cost_fn</code><code> </code><code class="o">=</code><code> </code><code class="n">fraud_df_sampled</code><code class="p">[</code><code class="s1">'</code><code class="s1">amt</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>         </code><code class="n">cost_tp</code><code> </code><code class="o">=</code><code> </code><code class="mi">2</code><code>&#13;
</code><code>         </code><code class="n">cost_tn</code><code> </code><code class="o">=</code><code> </code><code class="mi">0</code><code>&#13;
</code><code>         </code><code class="n">cost_mat</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code class="n">cost_fp</code><code> </code><code class="o">*</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">ones</code><code class="p">(</code><code class="n">fraud_df_sampled</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>                              </code><code class="n">cost_fn</code><code class="p">,</code><code>&#13;
</code><code>                              </code><code class="n">cost_tp</code><code> </code><code class="o">*</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">ones</code><code class="p">(</code><code class="n">fraud_df_sampled</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>                              </code><code class="n">cost_tn</code><code> </code><code class="o">*</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">ones</code><code class="p">(</code><code class="n">fraud_df_sampled</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">T</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO4-2" id="co_modeling_operational_risk_CO4-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">34</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">cost_log</code><code> </code><code class="o">=</code><code> </code><code class="n">conf_mat_log</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code class="n">cost_fp</code><code> </code><code class="o">+</code><code> </code><code class="n">conf_mat_boost</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code>\&#13;
</code><code>                     </code><code class="n">cost_fn</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">+</code><code> </code><code class="n">conf_mat_log</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code class="n">cost_tp</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO4-3" id="co_modeling_operational_risk_CO4-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>         </code><code class="n">cost_dt</code><code> </code><code class="o">=</code><code> </code><code class="n">conf_mat_dt</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code class="n">cost_fp</code><code> </code><code class="o">+</code><code> </code><code class="n">conf_mat_boost</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code>\&#13;
</code><code>                   </code><code class="n">cost_fn</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">+</code><code> </code><code class="n">conf_mat_dt</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code class="n">cost_tp</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO4-3" id="co_modeling_operational_risk_CO4-4"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>         </code><code class="n">cost_rf</code><code> </code><code class="o">=</code><code> </code><code class="n">conf_mat_rf</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code class="n">cost_fp</code><code> </code><code class="o">+</code><code> </code><code class="n">conf_mat_boost</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code>\&#13;
</code><code>                   </code><code class="n">cost_fn</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">+</code><code> </code><code class="n">conf_mat_rf</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code class="n">cost_tp</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO4-3" id="co_modeling_operational_risk_CO4-5"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>         </code><code class="n">cost_boost</code><code> </code><code class="o">=</code><code> </code><code class="n">conf_mat_boost</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code class="n">cost_fp</code><code> </code><code class="o">+</code><code> </code><code class="n">conf_mat_boost</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code>\&#13;
</code><code>                      </code><code class="n">cost_fn</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="p">)</code><code> </code><code class="o">+</code><code> </code><code class="n">conf_mat_boost</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code> </code><code class="o">*</code><code> </code><code class="n">cost_tp</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO4-3" id="co_modeling_operational_risk_CO4-6"><img alt="3" src="assets/3.png"/></a></pre>&#13;
<dl class="calloutlist pagebreak-before less_space">&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO4-1" id="callout_modeling_operational_risk_CO4-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Sampling from <code>fraud_df</code> data</p></dd>&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO4-2" id="callout_modeling_operational_risk_CO4-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Computing the cost matrix</p></dd>&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO4-3" id="callout_modeling_operational_risk_CO4-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Computing the total cost per models employed</p></dd>&#13;
</dl>&#13;
&#13;
<p>Calculating the total cost enables us to have different approaches in assessing model performance. <a data-primary="logistic regression" data-secondary="cost-sensitive fraud analysis" data-type="indexterm" id="idm45737210569296"/><a data-primary="random forest model" data-secondary="cost-sensitive fraud analysis" data-type="indexterm" id="idm45737210568304"/><a data-primary="XGBoost model, fraud analysis" data-type="indexterm" id="idm45737210324848"/>The model with a high F1 score is expected to have low total cost, and this is what we have in <a data-type="xref" href="#total_cost">Table 8-4</a>. Logistic regression has the highest total cost, and XGBoost has the lowest.<a data-primary="" data-startref="ix_ops_risk_sup_learn_cost" data-type="indexterm" id="idm45737210323120"/><a data-primary="" data-startref="ix_sup_learn_cost-based" data-type="indexterm" id="idm45737210322160"/></p>&#13;
<table id="total_cost">&#13;
<caption><span class="label">Table 8-4. </span>Total cost</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Model</th>&#13;
<th>Total cost</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Logistic Regression</p></td>&#13;
<td><p>5995</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Decision Tree</p></td>&#13;
<td><p>5351</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Random Forest</p></td>&#13;
<td><p>5413</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>XGBoost</p></td>&#13;
<td><p>5371</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Saving Score" data-type="sect2"><div class="sect2" id="idm45737210749216">&#13;
<h2>Saving Score</h2>&#13;
&#13;
<p><a data-primary="supervised learning modeling" data-secondary="saving score" data-type="indexterm" id="ix_sup_learn_sav_score"/><a data-primary="operational risk" data-secondary="supervised learning modeling" data-tertiary="saving score" data-type="indexterm" id="ix_ops_risk_sav_score"/><a data-primary="saving score, cost-based fraud examination" data-type="indexterm" id="ix_sav_score_fraud"/><a data-primary="decision tree model, fraud analysis" data-type="indexterm" id="ix_decision_tree"/>There are different metrics that can be used in cost improvement, and saving score is absolutely one of them.&#13;
To be able to define saving, let us give the formula of cost.</p>&#13;
&#13;
<p>Bahnsen, Aouada, and Ottersten (2014) clearly explain the saving score formula in the following manner:</p>&#13;
<div data-type="equation">&#13;
<math alttext="Cost left-parenthesis f left-parenthesis upper S right-parenthesis right-parenthesis equals sigma-summation Underscript i equals 1 Overscript upper N Endscripts left-parenthesis y Subscript i Baseline left-parenthesis c Subscript i Baseline upper C Subscript upper T upper P Sub Subscript i Subscript Baseline plus left-parenthesis 1 minus c Subscript i Baseline right-parenthesis upper C Subscript upper F upper N Sub Subscript i Subscript Baseline right-parenthesis plus left-parenthesis 1 minus y Subscript i Baseline right-parenthesis left-parenthesis c Subscript i Baseline upper C Subscript upper F upper P Sub Subscript i Subscript Baseline plus left-parenthesis 1 minus c Subscript i Baseline right-parenthesis upper C Subscript upper T upper N Sub Subscript i Subscript Baseline right-parenthesis right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mtext>Cost(f(S))</mtext>&#13;
    <mo>=</mo>&#13;
    <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>N</mi> </munderover>&#13;
    <mfenced close=")" open="(" separators=""><msub><mi>y</mi> <mi>i</mi> </msub> <mrow><mo>(</mo><msub><mi>c</mi> <mi>i</mi> </msub><msub><mi>C</mi> <mrow><mi>T</mi><msub><mi>P</mi> <mi>i</mi> </msub></mrow> </msub><mo>+</mo><mrow><mo>(</mo><mn>1</mn><mo>-</mo><msub><mi>c</mi> <mi>i</mi> </msub><mo>)</mo></mrow><msub><mi>C</mi> <mrow><mi>F</mi><msub><mi>N</mi> <mi>i</mi> </msub></mrow> </msub><mo>)</mo></mrow> <mo>+</mo> <mrow><mo>(</mo><mn>1</mn><mo>-</mo><msub><mi>y</mi> <mi>i</mi> </msub><mo>)</mo></mrow> <mrow><mo>(</mo><msub><mi>c</mi> <mi>i</mi> </msub><msub><mi>C</mi> <mrow><mi>F</mi><msub><mi>P</mi> <mi>i</mi> </msub></mrow> </msub><mo>+</mo><mrow><mo>(</mo><mn>1</mn><mo>-</mo><msub><mi>c</mi> <mi>i</mi> </msub><mo>)</mo></mrow><msub><mi>C</mi> <mrow><mi>T</mi><msub><mi>N</mi> <mi>i</mi> </msub></mrow> </msub><mo>)</mo></mrow></mfenced>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <em>TP</em>, <em>FN</em>, <em>FP</em>, and <em>TN</em> are true positive, false negative, false positive, and true negative, respectively. <math alttext="c Subscript i">&#13;
  <msub><mi>c</mi> <mi>i</mi> </msub>&#13;
</math> is the predicted label for each observation <em>i</em> on training set <em>S</em>. <math alttext="y Subscript i">&#13;
  <msub><mi>y</mi> <mi>i</mi> </msub>&#13;
</math> is the class label and takes the value of either 1 or 0—that is, <math alttext="y element-of 0 comma 1">&#13;
  <mrow>&#13;
    <mi>y</mi>&#13;
    <mo>∈</mo>&#13;
    <mrow>&#13;
      <mn>0</mn>&#13;
      <mo>,</mo>&#13;
      <mn>1</mn>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>. Our saving formula is then:</p>&#13;
<div data-type="equation" id="saving_formula">&#13;
<math alttext="Saving left-parenthesis f left-parenthesis upper S right-parenthesis right-parenthesis equals StartFraction Cost left-parenthesis f left-parenthesis upper S right-parenthesis right-parenthesis minus upper C o s t Subscript l Baseline left-parenthesis upper S right-parenthesis Over upper C o s t Subscript l Baseline left-parenthesis upper S right-parenthesis EndFraction" display="block">&#13;
  <mrow>&#13;
    <mtext>Saving(f(S))</mtext>&#13;
    <mo>=</mo>&#13;
    <mfrac><mrow><mtext>Cost(f(S))</mtext><mo>-</mo><mi>C</mi><mi>o</mi><mi>s</mi><msub><mi>t</mi> <mi>l</mi> </msub><mrow><mo>(</mo><mi>S</mi><mo>)</mo></mrow></mrow> <mrow><mi>C</mi><mi>o</mi><mi>s</mi><msub><mi>t</mi> <mi>l</mi> </msub><mrow><mo>(</mo><mi>S</mi><mo>)</mo></mrow></mrow></mfrac>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <math alttext="upper C o s t Subscript l Baseline equals m i n upper C o s t left-parenthesis f 0 left-parenthesis upper S right-parenthesis right-parenthesis comma upper C o s t left-parenthesis f 1 left-parenthesis upper S right-parenthesis right-parenthesis">&#13;
  <mrow>&#13;
    <mi>C</mi>&#13;
    <mi>o</mi>&#13;
    <mi>s</mi>&#13;
    <msub><mi>t</mi> <mi>l</mi> </msub>&#13;
    <mo>=</mo>&#13;
    <mi>m</mi>&#13;
    <mi>i</mi>&#13;
    <mi>n</mi>&#13;
    <mrow>&#13;
      <mi>C</mi>&#13;
      <mi>o</mi>&#13;
      <mi>s</mi>&#13;
      <mi>t</mi>&#13;
      <mrow>&#13;
        <mo>(</mo>&#13;
        <msub><mi>f</mi> <mn>0</mn> </msub>&#13;
        <mrow>&#13;
          <mo>(</mo>&#13;
          <mi>S</mi>&#13;
          <mo>)</mo>&#13;
        </mrow>&#13;
        <mo>)</mo>&#13;
      </mrow>&#13;
      <mo>,</mo>&#13;
      <mi>C</mi>&#13;
      <mi>o</mi>&#13;
      <mi>s</mi>&#13;
      <mi>t</mi>&#13;
      <mrow>&#13;
        <mo>(</mo>&#13;
        <msub><mi>f</mi> <mn>1</mn> </msub>&#13;
        <mrow>&#13;
          <mo>(</mo>&#13;
          <mi>S</mi>&#13;
          <mo>)</mo>&#13;
        </mrow>&#13;
        <mo>)</mo>&#13;
      </mrow>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math> where <math alttext="f 0">&#13;
  <msub><mi>f</mi> <mn>0</mn> </msub>&#13;
</math> predicts class 0, <math alttext="c 0">&#13;
  <msub><mi>c</mi> <mn>0</mn> </msub>&#13;
</math>, and <math alttext="f 1">&#13;
  <msub><mi>f</mi> <mn>1</mn> </msub>&#13;
</math> predicts observations in class 1, <math alttext="c 1">&#13;
  <msub><mi>c</mi> <mn>1</mn> </msub>&#13;
</math>.</p>&#13;
&#13;
<p class="pagebreak-before less_space">In code, we have the following:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">35</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">import</code><code> </code><code class="nn">joblib</code><code>&#13;
</code><code>         </code><code class="kn">import</code><code> </code><code class="nn">sys</code><code>&#13;
</code><code>         </code><code class="n">sys</code><code class="o">.</code><code class="n">modules</code><code class="p">[</code><code class="s1">'</code><code class="s1">sklearn.externals.joblib</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">joblib</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">costcla.metrics</code><code> </code><code class="kn">import</code><code> </code><code class="n">cost_loss</code><code class="p">,</code><code> </code><code class="n">savings_score</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">costcla.models</code><code> </code><code class="kn">import</code><code> </code><code class="n">BayesMinimumRiskClassifier</code><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">36</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">X_train</code><code class="p">,</code><code> </code><code class="n">X_test</code><code class="p">,</code><code> </code><code class="n">y_train</code><code class="p">,</code><code> </code><code class="n">y_test</code><code class="p">,</code><code> </code><code class="n">cost_mat_train</code><code class="p">,</code><code> </code><code class="n">cost_mat_test</code><code> </code><code class="o">=</code><code> </code><code>\&#13;
</code><code>         </code><code class="n">train_test_split</code><code class="p">(</code><code class="n">fraud_df_sampled</code><code class="o">.</code><code class="n">drop</code><code class="p">(</code><code class="s1">'</code><code class="s1">is_fraud</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>                                    </code><code class="n">fraud_df_sampled</code><code class="o">.</code><code class="n">is_fraud</code><code class="p">,</code><code> </code><code class="n">cost_mat</code><code class="p">,</code><code>&#13;
</code><code>                                    </code><code class="n">test_size</code><code class="o">=</code><code class="mf">0.2</code><code class="p">,</code><code> </code><code class="n">random_state</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">37</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">saving_models</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>&#13;
</code><code>         </code><code class="n">saving_models</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="s1">'</code><code class="s1">Log. Reg.</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                               </code><code class="n">LogisticRegression</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">saving_models</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="s1">'</code><code class="s1">Dec. Tree</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                               </code><code class="n">DecisionTreeClassifier</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">saving_models</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="s1">'</code><code class="s1">Random Forest</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                               </code><code class="n">RandomForestClassifier</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">38</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">saving_score_base_all</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code>         </code><code class="k">for</code><code> </code><code class="n">name</code><code class="p">,</code><code> </code><code class="n">save_model</code><code> </code><code class="ow">in</code><code> </code><code class="n">saving_models</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">sv_model</code><code> </code><code class="o">=</code><code> </code><code class="n">save_model</code><code>&#13;
</code><code>             </code><code class="n">sv_model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code><code> </code><code class="n">y_train</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">y_pred</code><code> </code><code class="o">=</code><code> </code><code class="n">sv_model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">saving_score_base</code><code> </code><code class="o">=</code><code> </code><code class="n">savings_score</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code><code> </code><code class="n">y_pred</code><code class="p">,</code><code> </code><code class="n">cost_mat_test</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO5-1" id="co_modeling_operational_risk_CO5-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>             </code><code class="n">saving_score_base_all</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">saving_score_base</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">The saving score for {} is {:.4f}</code><code class="s1">'</code><code class="o">.</code><code>&#13;
</code><code>                   </code><code class="n">format</code><code class="p">(</code><code class="n">name</code><code class="p">,</code><code> </code><code class="n">saving_score_base</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">--</code><code class="s1">'</code><code> </code><code class="o">*</code><code> </code><code class="mi">20</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">saving</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Log</code><code class="o">.</code><code> </code><code class="n">Reg</code><code class="o">.</code><code> </code><code class="ow">is</code><code> </code><code class="o">-</code><code class="mf">0.5602</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">saving</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Dec</code><code class="o">.</code><code> </code><code class="n">Tree</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.6557</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">saving</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Random</code><code> </code><code class="n">Forest</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.4789</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">39</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">f1_score_base_all</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code>         </code><code class="k">for</code><code> </code><code class="n">name</code><code class="p">,</code><code> </code><code class="n">save_model</code><code> </code><code class="ow">in</code><code> </code><code class="n">saving_models</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">sv_model</code><code> </code><code class="o">=</code><code> </code><code class="n">save_model</code><code>&#13;
</code><code>             </code><code class="n">sv_model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code><code> </code><code class="n">y_train</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">y_pred</code><code> </code><code class="o">=</code><code> </code><code class="n">sv_model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">f1_score_base</code><code> </code><code class="o">=</code><code> </code><code class="n">f1_score</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code><code> </code><code class="n">y_pred</code><code class="p">,</code><code> </code><code class="n">cost_mat_test</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO5-2" id="co_modeling_operational_risk_CO5-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>             </code><code class="n">f1_score_base_all</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">f1_score_base</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">The F1 score for {} is {:.4f}</code><code class="s1">'</code><code class="o">.</code><code>&#13;
</code><code>                   </code><code class="n">format</code><code class="p">(</code><code class="n">name</code><code class="p">,</code><code> </code><code class="n">f1_score_base</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">--</code><code class="s1">'</code><code> </code><code class="o">*</code><code> </code><code class="mi">20</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">F1</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Log</code><code class="o">.</code><code> </code><code class="n">Reg</code><code class="o">.</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.0000</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">F1</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Dec</code><code class="o">.</code><code> </code><code class="n">Tree</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.7383</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">F1</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Random</code><code> </code><code class="n">Forest</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.7068</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO5-1" id="callout_modeling_operational_risk_CO5-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Calculating the saving score</p></dd>&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO5-2" id="callout_modeling_operational_risk_CO5-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Calculating the F1 score</p></dd>&#13;
</dl>&#13;
<div data-type="warning" epub:type="warning"><h6>Warning</h6>&#13;
<p><a data-primary="costcla library" data-type="indexterm" id="idm45737208792032"/>Please note that, if you are using <code>sklearn</code> version 0.23 or higher, you need to downgrade it to 0.22 to use <code>costcla</code> library. <a data-primary="sklearn.external.six package" data-type="indexterm" id="idm45737208790240"/>This adjustment is required due to the <code>sklearn.external.six</code> package inside the <code>costcla</code> library.</p>&#13;
</div>&#13;
&#13;
<p><a data-type="xref" href="#saving_score">Table 8-5</a> shows that decision tree has the highest saving score among the three models, and interestingly,<a data-primary="random forest model" data-secondary="saving score" data-type="indexterm" id="idm45737208850624"/> <a data-primary="logistic regression" data-secondary="saving score" data-type="indexterm" id="idm45737208849552"/>logistic regression produces a negative saving score, implying that the number of false negative and false positive predictions is quite large, which inflates the denominator of the saving score formula.<a data-primary="" data-startref="ix_decision_tree" data-type="indexterm" id="idm45737208848224"/><a data-primary="" data-startref="ix_ops_risk_sav_score" data-type="indexterm" id="idm45737208847280"/><a data-primary="" data-startref="ix_sav_score_fraud" data-type="indexterm" id="idm45737208878672"/><a data-primary="" data-startref="ix_sup_learn_sav_score" data-type="indexterm" id="idm45737208877728"/></p>&#13;
<table id="saving_score">&#13;
<caption><span class="label">Table 8-5. </span>Saving scores</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Model</th>&#13;
<th>Saving score</th>&#13;
<th>F1 score</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Logistic regression</p></td>&#13;
<td><p>-0.5602</p></td>&#13;
<td><p>0.0000</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Decision tree</p></td>&#13;
<td><p>0.6557</p></td>&#13;
<td><p>0.7383</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Random forest</p></td>&#13;
<td><p>0.4789</p></td>&#13;
<td><p>0.7068</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Cost-Sensitive Modeling" data-type="sect2"><div class="sect2" id="idm45737210310848">&#13;
<h2>Cost-Sensitive Modeling</h2>&#13;
&#13;
<p><a data-primary="supervised learning modeling" data-secondary="cost-sensitive modeling" data-type="indexterm" id="ix_sup_learn_cost_sens"/><a data-primary="operational risk" data-secondary="supervised learning modeling" data-tertiary="cost-sensitive modeling" data-type="indexterm" id="ix_ops_risk_sup_learn_cost_sens"/>Thus far, we have discussed the concepts of saving score and cost sensitivity, and now we are ready to run cost-sensitive logistic regression, decision tree, and random forest. The question that we are trying to address here is what happens if fraud is modeled by considering varying costs of misclassification? How does it affect the saving score?</p>&#13;
&#13;
<p>To undertake this investigation, we’ll use the <code>costcla</code> library. This library was specifically created to employ the cost-sensitive classifiers in which varying costs of misclassification are considered. Because, as discussed earlier, traditional fraud models assume that all correctly classified and misclassified examples carry the same cost, which is not correct due to the varying costs of misclassification in fraud (Bahnsen 2021).</p>&#13;
&#13;
<p>Having applied the cost-sensitive models, the saving score is used to compare the models in the following code:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">40</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">costcla.models</code><code> </code><code class="kn">import</code><code> </code><code class="n">CostSensitiveLogisticRegression</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">costcla.models</code><code> </code><code class="kn">import</code><code> </code><code class="n">CostSensitiveDecisionTreeClassifier</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">costcla.models</code><code> </code><code class="kn">import</code><code> </code><code class="n">CostSensitiveRandomForestClassifier</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">41</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">cost_sen_models</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>&#13;
</code><code>         </code><code class="n">cost_sen_models</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="s1">'</code><code class="s1">Log. Reg. CS</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                                 </code><code class="n">CostSensitiveLogisticRegression</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">cost_sen_models</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="s1">'</code><code class="s1">Dec. Tree CS</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                                 </code><code class="n">CostSensitiveDecisionTreeClassifier</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">cost_sen_models</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="p">(</code><code class="s1">'</code><code class="s1">Random Forest CS</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                                 </code><code class="n">CostSensitiveRandomForestClassifier</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">42</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">saving_cost_all</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code>         </code><code class="k">for</code><code> </code><code class="n">name</code><code class="p">,</code><code> </code><code class="n">cost_model</code><code> </code><code class="ow">in</code><code> </code><code class="n">cost_sen_models</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">cs_model</code><code> </code><code class="o">=</code><code> </code><code class="n">cost_model</code><code>&#13;
</code><code>             </code><code class="n">cs_model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">y_train</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>                          </code><code class="n">cost_mat_train</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO6-1" id="co_modeling_operational_risk_CO6-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>             </code><code class="n">y_pred</code><code> </code><code class="o">=</code><code> </code><code class="n">cs_model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">X_test</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">saving_score_cost</code><code> </code><code class="o">=</code><code> </code><code class="n">savings_score</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">y_test</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>                                               </code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">y_pred</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">cost_mat_test</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">saving_cost_all</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">saving_score_cost</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">The saving score for {} is {:.4f}</code><code class="s1">'</code><code class="o">.</code><code>&#13;
</code><code>                   </code><code class="n">format</code><code class="p">(</code><code class="n">name</code><code class="p">,</code><code> </code><code class="n">saving_score_cost</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">--</code><code class="s1">'</code><code class="o">*</code><code class="mi">20</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">saving</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Log</code><code class="o">.</code><code> </code><code class="n">Reg</code><code class="o">.</code><code> </code><code class="n">CS</code><code> </code><code class="ow">is</code><code> </code><code class="o">-</code><code class="mf">0.5906</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">saving</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Dec</code><code class="o">.</code><code> </code><code class="n">Tree</code><code> </code><code class="n">CS</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.8419</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">saving</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Random</code><code> </code><code class="n">Forest</code><code> </code><code class="n">CS</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.8903</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">43</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">f1_score_cost_all</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code>         </code><code class="k">for</code><code> </code><code class="n">name</code><code class="p">,</code><code> </code><code class="n">cost_model</code><code> </code><code class="ow">in</code><code> </code><code class="n">cost_sen_models</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">cs_model</code><code> </code><code class="o">=</code><code> </code><code class="n">cost_model</code><code>&#13;
</code><code>             </code><code class="n">cs_model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">y_train</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>                          </code><code class="n">cost_mat_train</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">y_pred</code><code> </code><code class="o">=</code><code> </code><code class="n">cs_model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">X_test</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">f1_score_cost</code><code> </code><code class="o">=</code><code> </code><code class="n">f1_score</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">y_test</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>                                      </code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">y_pred</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">cost_mat_test</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">f1_score_cost_all</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">f1_score_cost</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">The F1 score for {} is {:.4f}</code><code class="s1">'</code><code class="o">.</code><code> </code><code class="n">format</code><code class="p">(</code><code class="n">name</code><code class="p">,</code><code>&#13;
</code><code>                                                           </code><code class="n">f1_score_cost</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">--</code><code class="s1">'</code><code class="o">*</code><code class="mi">20</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">F1</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Log</code><code class="o">.</code><code> </code><code class="n">Reg</code><code class="o">.</code><code> </code><code class="n">CS</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.0000</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">F1</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Dec</code><code class="o">.</code><code> </code><code class="n">Tree</code><code> </code><code class="n">CS</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.3281</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">F1</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Random</code><code> </code><code class="n">Forest</code><code> </code><code class="n">CS</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.4012</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO6-1" id="callout_modeling_operational_risk_CO6-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Training the cost-sensitive models by iteration</p></dd>&#13;
</dl>&#13;
&#13;
<p>According to <a data-type="xref" href="#saving_score_model">Table 8-6</a>, the best and the worst saving scores are obtained in random forest and logistic regression, respectively. This confirms two important facts: first, it implies that random forest has a low number of&#13;
inaccurate observations, and second, that those inaccurate observations are less costly.&#13;
<a data-primary="logistic regression" data-secondary="saving score" data-type="indexterm" id="idm45737210160912"/><a data-primary="random forest model" data-secondary="saving score" data-type="indexterm" id="idm45737210159968"/>To be precise, modeling fraud with random forest generates a very low number of false negatives, which is the denominator of the saving score formula.<a data-primary="" data-startref="ix_cost-sens_model" data-type="indexterm" id="idm45737210158736"/><a data-primary="" data-startref="ix_ops_risk_sup_learn_cost_sens" data-type="indexterm" id="idm45737210144688"/><a data-primary="" data-startref="ix_sup_learn_cost_sens" data-type="indexterm" id="idm45737210143776"/></p>&#13;
<table id="saving_score_model">&#13;
<caption><span class="label">Table 8-6. </span>Saving scores of cost-sensitive models</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Model</th>&#13;
<th>Saving score</th>&#13;
<th>F1 score</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Logistic regression</p></td>&#13;
<td><p>-0.5906</p></td>&#13;
<td><p>0.0000</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Decision tree</p></td>&#13;
<td><p>0.8414</p></td>&#13;
<td><p>0.3281</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Random forest</p></td>&#13;
<td><p>0.8913</p></td>&#13;
<td><p>0.4012</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Bayesian Minimum Risk" data-type="sect2"><div class="sect2" id="idm45737210069984">&#13;
<h2>Bayesian Minimum Risk</h2>&#13;
&#13;
<p><a data-primary="operational risk" data-secondary="supervised learning modeling" data-tertiary="Bayesian minimum risk" data-type="indexterm" id="ix_ops_risk_sup_learn_bayes"/><a data-primary="supervised learning modeling" data-secondary="Bayesian minimum risk" data-type="indexterm" id="ix_sup_learn_bayes"/><a data-primary="Bayesian approach" data-secondary="minimum risk method for fraud analysis" data-type="indexterm" id="ix_bayes_min_risk"/>Bayesian decision can also be used to model fraud taking into account the cost sensitivity. The Bayesian minimum risk method rests on a decision process using different costs (or loss) and probabilities. Mathematically, if the transaction is predicted to be fraud, the overall risk is defined as follows:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper R left-parenthesis c Subscript f Baseline vertical-bar upper S right-parenthesis equals upper L left-parenthesis c Subscript f Baseline vertical-bar y Subscript f Baseline right-parenthesis upper P left-parenthesis c Subscript f Baseline vertical-bar upper S right-parenthesis plus upper L left-parenthesis c Subscript f Baseline vertical-bar y Subscript l Baseline right-parenthesis upper P left-parenthesis c Subscript l Baseline vertical-bar upper S right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>R</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>f</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <mi>L</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>f</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <msub><mi>y</mi> <mi>f</mi> </msub>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mi>P</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>f</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>+</mo>&#13;
    <mi>L</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>f</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <msub><mi>y</mi> <mi>l</mi> </msub>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mi>P</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>On the other hand, if a transaction is predicted to be legitimate, then the overall risk turns out to be:</p>&#13;
<div data-type="equation" id="bmr_eq">&#13;
<math alttext="upper R left-parenthesis c Subscript l Baseline vertical-bar upper S right-parenthesis equals upper L left-parenthesis c Subscript l Baseline vertical-bar y Subscript l Baseline right-parenthesis upper P left-parenthesis c Subscript l Baseline vertical-bar upper S right-parenthesis plus upper L left-parenthesis c Subscript l Baseline vertical-bar y Subscript f Baseline right-parenthesis upper P left-parenthesis c Subscript f Baseline vertical-bar upper S right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>R</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <mi>L</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <msub><mi>y</mi> <mi>l</mi> </msub>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mi>P</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>+</mo>&#13;
    <mi>L</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <msub><mi>y</mi> <mi>f</mi> </msub>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mi>P</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>f</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <math alttext="y Subscript f">&#13;
  <msub><mi>y</mi> <mi>f</mi> </msub>&#13;
</math> and <math alttext="y Subscript l">&#13;
  <msub><mi>y</mi> <mi>l</mi> </msub>&#13;
</math> are the actual classes for fraudulent and legitimate cases, respectively. <math alttext="upper L left-parenthesis c Subscript f Baseline vertical-bar y Subscript f Baseline right-parenthesis">&#13;
  <mrow>&#13;
    <mi>L</mi>&#13;
    <mo>(</mo>&#13;
    <msub><mi>c</mi> <mi>f</mi> </msub>&#13;
    <mo>|</mo>&#13;
    <msub><mi>y</mi> <mi>f</mi> </msub>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> represents the cost when fraud is detected and the real class is fraud. Similarly, <math alttext="upper L left-parenthesis c Subscript l Baseline vertical-bar y Subscript l Baseline right-parenthesis">&#13;
  <mrow>&#13;
    <mi>L</mi>&#13;
    <mo>(</mo>&#13;
    <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
    <mo>|</mo>&#13;
    <msub><mi>y</mi> <mi>l</mi> </msub>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> denotes the cost when the transaction is predicted to be legitimate and the real class is legitimate. Conversely, <math alttext="upper L left-parenthesis c Subscript f Baseline vertical-bar y Subscript l Baseline right-parenthesis">&#13;
  <mrow>&#13;
    <mi>L</mi>&#13;
    <mo>(</mo>&#13;
    <msub><mi>c</mi> <mi>f</mi> </msub>&#13;
    <mo>|</mo>&#13;
    <msub><mi>y</mi> <mi>l</mi> </msub>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> and <math alttext="upper L left-parenthesis c Subscript l Baseline vertical-bar y Subscript f Baseline right-parenthesis">&#13;
  <mrow>&#13;
    <mi>L</mi>&#13;
    <mo>(</mo>&#13;
    <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
    <mo>|</mo>&#13;
    <msub><mi>y</mi> <mi>f</mi> </msub>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> calculate the cost of the off-diagonal elements in <a data-type="xref" href="#cost_sen_mat">Table 8-3</a>. The former calculates the cost when the transaction is predicted to be a fraud but the actual class is not, and the latter shows the cost when the transaction is legitimate but the actual class is fraud. <math alttext="upper P left-parenthesis c Subscript l Baseline vertical-bar upper S right-parenthesis">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
    <mo>|</mo>&#13;
    <mi>S</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> indicates the predicted probability of having a legitimate transaction given <em>S</em> and <math alttext="upper P left-parenthesis c Subscript f Baseline vertical-bar upper S right-parenthesis">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mo>(</mo>&#13;
    <msub><mi>c</mi> <mi>f</mi> </msub>&#13;
    <mo>|</mo>&#13;
    <mi>S</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> and the predicted probability of having a fraudulent transaction given <em>S</em>.</p>&#13;
&#13;
<p class="pagebreak-before less_space">Alternatively, the Bayesian minimum risk formula can be interpreted as:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper R left-parenthesis c Subscript f Baseline vertical-bar upper S right-parenthesis equals upper C Subscript a d m i n Baseline upper P left-parenthesis c Subscript f Baseline vertical-bar upper S right-parenthesis plus upper C Subscript a d m i n Baseline upper P left-parenthesis c Subscript l Baseline vertical-bar upper S right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>R</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>f</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <msub><mi>C</mi> <mrow><mi>a</mi><mi>d</mi><mi>m</mi><mi>i</mi><mi>n</mi></mrow> </msub>&#13;
    <mi>P</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>f</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>+</mo>&#13;
    <msub><mi>C</mi> <mrow><mi>a</mi><mi>d</mi><mi>m</mi><mi>i</mi><mi>n</mi></mrow> </msub>&#13;
    <mi>P</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
<div data-type="equation">&#13;
<math alttext="upper R left-parenthesis c Subscript l Baseline vertical-bar upper S right-parenthesis equals 0 plus upper C Subscript a m t Baseline upper P left-parenthesis c Subscript l Baseline vertical-bar upper S right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>R</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <mn>0</mn>&#13;
    <mo>+</mo>&#13;
    <msub><mi>C</mi> <mrow><mi>a</mi><mi>m</mi><mi>t</mi></mrow> </msub>&#13;
    <mi>P</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>with <em>admin</em> is administrative cost and <em>amt</em> is the transaction amount. With that being said, the transaction is labeled as fraud if:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper R left-parenthesis c Subscript f Baseline vertical-bar upper S right-parenthesis greater-than-or-equal-to upper R left-parenthesis c Subscript l Baseline vertical-bar upper S right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>R</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>f</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>≥</mo>&#13;
    <mi>R</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>Alternatively:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper C Subscript a d m i n Baseline upper P left-parenthesis c Subscript f Baseline vertical-bar upper S right-parenthesis plus upper C Subscript a d m i n Baseline upper P left-parenthesis c Subscript l Baseline vertical-bar upper S right-parenthesis greater-than-or-equal-to upper C Subscript a m t Baseline upper P left-parenthesis c Subscript l Baseline vertical-bar upper S right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <msub><mi>C</mi> <mrow><mi>a</mi><mi>d</mi><mi>m</mi><mi>i</mi><mi>n</mi></mrow> </msub>&#13;
    <mi>P</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>f</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>+</mo>&#13;
    <msub><mi>C</mi> <mrow><mi>a</mi><mi>d</mi><mi>m</mi><mi>i</mi><mi>n</mi></mrow> </msub>&#13;
    <mi>P</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>≥</mo>&#13;
    <msub><mi>C</mi> <mrow><mi>a</mi><mi>m</mi><mi>t</mi></mrow> </msub>&#13;
    <mi>P</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <msub><mi>c</mi> <mi>l</mi> </msub>&#13;
      <mo>|</mo>&#13;
      <mi>S</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p><a data-primary="decision tree model, fraud analysis" data-type="indexterm" id="idm45737209630288"/>Well, it is time to apply the Bayesian Minimum Risk model in Python. Again, three models are employed and compared using F1 score: F1 score results can be found in <a data-type="xref" href="#f1_score_bmr">Table 8-7</a>, and it turns out decision tree has the highest F1 score and logistic regression has the lowest one. <a data-primary="logistic regression" data-secondary="saving score" data-type="indexterm" id="idm45737209628400"/><a data-primary="random forest model" data-secondary="saving score" data-type="indexterm" id="idm45737209627456"/>So, the order of saving scores is other way around, indicating the effectiveness of the cost-sensitive approach:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">44</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">saving_score_bmr_all</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code>         </code><code class="k">for</code><code> </code><code class="n">name</code><code class="p">,</code><code> </code><code class="n">bmr_model</code><code> </code><code class="ow">in</code><code> </code><code class="n">saving_models</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">f</code><code> </code><code class="o">=</code><code> </code><code class="n">bmr_model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code><code> </code><code class="n">y_train</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">y_prob_test</code><code> </code><code class="o">=</code><code> </code><code class="n">f</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">X_test</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">f_bmr</code><code> </code><code class="o">=</code><code> </code><code class="n">BayesMinimumRiskClassifier</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO7-1" id="co_modeling_operational_risk_CO7-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>             </code><code class="n">f_bmr</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">y_test</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">y_prob_test</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">y_pred_test</code><code> </code><code class="o">=</code><code> </code><code class="n">f_bmr</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">y_prob_test</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>                                         </code><code class="n">cost_mat_test</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">saving_score_bmr</code><code> </code><code class="o">=</code><code> </code><code class="n">savings_score</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code><code> </code><code class="n">y_pred_test</code><code class="p">,</code><code>&#13;
</code><code>                                              </code><code class="n">cost_mat_test</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">saving_score_bmr_all</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">saving_score_bmr</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">The saving score for {} is {:.4f}</code><code class="s1">'</code><code class="o">.</code><code>\&#13;
</code><code>                   </code><code class="n">format</code><code class="p">(</code><code class="n">name</code><code class="p">,</code><code> </code><code class="n">saving_score_bmr</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">--</code><code class="s1">'</code><code> </code><code class="o">*</code><code> </code><code class="mi">20</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">saving</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Log</code><code class="o">.</code><code> </code><code class="n">Reg</code><code class="o">.</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.8064</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">saving</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Dec</code><code class="o">.</code><code> </code><code class="n">Tree</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.7343</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">saving</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Random</code><code> </code><code class="n">Forest</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.9624</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">45</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">f1_score_bmr_all</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code>         </code><code class="k">for</code><code> </code><code class="n">name</code><code class="p">,</code><code> </code><code class="n">bmr_model</code><code> </code><code class="ow">in</code><code> </code><code class="n">saving_models</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">f</code><code> </code><code class="o">=</code><code> </code><code class="n">bmr_model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code><code> </code><code class="n">y_train</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">y_prob_test</code><code> </code><code class="o">=</code><code> </code><code class="n">f</code><code class="o">.</code><code class="n">predict_proba</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">X_test</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">f_bmr</code><code> </code><code class="o">=</code><code> </code><code class="n">BayesMinimumRiskClassifier</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">f_bmr</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">y_test</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">y_prob_test</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">y_pred_test</code><code> </code><code class="o">=</code><code> </code><code class="n">f_bmr</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">y_prob_test</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>                                         </code><code class="n">cost_mat_test</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">f1_score_bmr</code><code> </code><code class="o">=</code><code> </code><code class="n">f1_score</code><code class="p">(</code><code class="n">y_test</code><code class="p">,</code><code> </code><code class="n">y_pred_test</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">f1_score_bmr_all</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">f1_score_bmr</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">The F1 score for {} is {:.4f}</code><code class="s1">'</code><code class="o">.</code><code>\&#13;
</code><code>                   </code><code class="n">format</code><code class="p">(</code><code class="n">name</code><code class="p">,</code><code> </code><code class="n">f1_score_bmr</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">--</code><code class="s1">'</code><code class="o">*</code><code class="mi">20</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">F1</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Log</code><code class="o">.</code><code> </code><code class="n">Reg</code><code class="o">.</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.1709</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">F1</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Dec</code><code class="o">.</code><code> </code><code class="n">Tree</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.6381</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">F1</code><code> </code><code class="n">score</code><code> </code><code class="k">for</code><code> </code><code class="n">Random</code><code> </code><code class="n">Forest</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.4367</code><code>&#13;
</code><code>         </code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO7-1" id="callout_modeling_operational_risk_CO7-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Calling the Bayesian Minimum Risk Classifier library</p></dd>&#13;
</dl>&#13;
<table id="f1_score_bmr">&#13;
<caption><span class="label">Table 8-7. </span>F1 score based on BMR</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Model</th>&#13;
<th>Saving score</th>&#13;
<th>F1 score</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Logistic regression</p></td>&#13;
<td><p>0.8064</p></td>&#13;
<td><p>0.1709</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Decision tree</p></td>&#13;
<td><p>0.7343</p></td>&#13;
<td><p>0.6381</p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Random forest</p></td>&#13;
<td><p>0.9624</p></td>&#13;
<td><p>0.4367</p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p><a data-primary="F1Score, fraud analysis" data-type="indexterm" id="ix_f1score_fraud"/>To create a plot of this data, we do the following (resulting in <a data-type="xref" href="#score_barplot_fraud">Figure 8-6</a>):</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">46</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">savings</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="n">saving_score_base_all</code><code class="p">,</code><code> </code><code class="n">saving_cost_all</code><code class="p">,</code><code> </code><code class="n">saving_score_bmr_all</code><code class="p">]</code><code>&#13;
</code><code>         </code><code class="n">f1</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="n">f1_score_base_all</code><code class="p">,</code><code> </code><code class="n">f1_score_cost_all</code><code class="p">,</code><code> </code><code class="n">f1_score_bmr_all</code><code class="p">]</code><code>&#13;
</code><code>         </code><code class="n">saving_scores</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">(</code><code class="p">[</code><code class="n">pd</code><code class="o">.</code><code class="n">Series</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code> </code><code class="k">for</code><code> </code><code class="n">x</code><code> </code><code class="ow">in</code><code> </code><code class="n">savings</code><code class="p">]</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">f1_scores</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">(</code><code class="p">[</code><code class="n">pd</code><code class="o">.</code><code class="n">Series</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code> </code><code class="k">for</code><code> </code><code class="n">x</code><code> </code><code class="ow">in</code><code> </code><code class="n">f1</code><code class="p">]</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">scores</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">(</code><code class="p">[</code><code class="n">saving_scores</code><code class="p">,</code><code> </code><code class="n">f1_scores</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">scores</code><code class="o">.</code><code class="n">columns</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="s1">'</code><code class="s1">saving_scores</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">F1_scores</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">47</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model_names</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="s1">'</code><code class="s1">Log. Reg_base</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">Dec. Tree_base</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">Random Forest_base</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                        </code><code class="s1">'</code><code class="s1">Log. Reg_cs</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">Dec. Tree_cs</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">Random Forest_cs</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                       </code><code class="s1">'</code><code class="s1">Log. Reg_bayes</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">Dec. Tree_bayes</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                        </code><code class="s1">'</code><code class="s1">Random Forest_bayes</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">48</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code> </code><code class="mi">6</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="nb">range</code><code class="p">(</code><code class="n">scores</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">scores</code><code class="p">[</code><code class="s2">"</code><code class="s2">F1_scores</code><code class="s2">"</code><code class="p">]</code><code class="p">,</code><code>&#13;
</code><code>                  </code><code class="s2">"</code><code class="s2">--</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="n">label</code><code class="o">=</code><code class="s1">'</code><code class="s1">F1Score</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO8-1" id="co_modeling_operational_risk_CO8-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">bar</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="n">scores</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">scores</code><code class="p">[</code><code class="s1">'</code><code class="s1">saving_scores</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>&#13;
</code><code>                 </code><code class="mf">0.6</code><code class="p">,</code><code> </code><code class="n">label</code><code class="o">=</code><code class="s1">'</code><code class="s1">Savings</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO8-2" id="co_modeling_operational_risk_CO8-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>         </code><code class="n">_</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">model_names</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">xticks</code><code class="p">(</code><code class="n">_</code><code class="p">,</code><code> </code><code class="n">model_names</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s1">'</code><code class="s1">best</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">xticks</code><code class="p">(</code><code class="n">rotation</code><code class="o">=</code><code class="s1">'</code><code class="s1">vertical</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO8-1" id="callout_modeling_operational_risk_CO8-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Drawing the F1 score with a line plot</p></dd>&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO8-2" id="callout_modeling_operational_risk_CO8-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Drawing the bar plot based on the models used</p></dd>&#13;
</dl>&#13;
&#13;
<figure><div class="figure" id="score_barplot_fraud">&#13;
<img alt="f1_saving" src="assets/mlfr_0806.png"/>&#13;
<h6><span class="label">Figure 8-6. </span>F1 and saving scores</h6>&#13;
</div></figure>&#13;
&#13;
<p><a data-type="xref" href="#score_barplot_fraud">Figure 8-6</a> shows the F1 and saving scores across the models we have employed so far. Accordingly, the cost-sensitive and Bayesian minimum risk model outperform the base models, as expected.<a data-primary="" data-startref="ix_ops_risk_sup_learning" data-type="indexterm" id="idm45737209938992"/><a data-primary="" data-startref="ix_sup_learning_ops_risk" data-type="indexterm" id="idm45737209938032"/><a data-primary="" data-startref="ix_bayes_min_risk" data-type="indexterm" id="idm45737209937072"/><a data-primary="" data-startref="ix_ops_risk_sup_learn_bayes" data-type="indexterm" id="idm45737209936128"/><a data-primary="" data-startref="ix_sup_learn_bayes" data-type="indexterm" id="idm45737209935168"/><a data-primary="" data-startref="ix_f1score_fraud" data-type="indexterm" id="idm45737209934224"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Unsupervised Learning Modeling for Fraud Examination" data-type="sect1"><div class="sect1" id="idm45737210068912">&#13;
<h1>Unsupervised Learning Modeling for Fraud Examination</h1>&#13;
&#13;
<p><a data-primary="unsupervised learning modeling" data-type="indexterm" id="ix_unsup_learn_model"/><a data-primary="operational risk" data-secondary="unsupervised learning modeling" data-type="indexterm" id="ix_ops_risk_unsup_learn"/>Unsupervised learning models are also used to detect fraudulent activities in a way that extracts the hidden characteristics of the data. The most prominent advantage of this method over the supervised model is that there is no need to apply a sampling procedure to fix the imbalanced-data problem. Unsupervised models, by their nature, do not require any prior knowledge about the data. <a data-primary="operational risk" data-secondary="unsupervised learning modeling" data-tertiary="self-organizing map" data-type="indexterm" id="ix_ops_risk_unsup_learn_som"/><a data-primary="SOM (self-organizing map)" data-type="indexterm" id="ix_som_ch8"/>To see how unsupervised learning models perform on this type of data, we will explore the self-organizing map (SOM) and autoencoder models.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Self-Organizing Map" data-type="sect2"><div class="sect2" id="idm45737209901312">&#13;
<h2>Self-Organizing Map</h2>&#13;
&#13;
<p><a data-primary="unsupervised learning modeling" data-secondary="self-organizing map" data-type="indexterm" id="ix_unsup_learn_som"/>SOM is an unsupervised method to obtain a low-dimensional space from a high-dimensional space. This is a method that was introduced by Finnish scholar Teuvo Kohonen in 1980s&#13;
and it became widespread.&#13;
SOM is a type of artificial <a data-primary="NNs (neural networks)" data-secondary="SOM as artificial neural network" data-type="indexterm" id="ix_nns_som"/>NN, and therefore it rests on competitive learning in the sense that output neurons compete to be activated. <a data-primary="winning neuron, SOM" data-type="indexterm" id="idm45737208814112"/>The activated neuron is referred to as the <em>winning neuron</em>, and each &#13;
<span class="keep-together">neuron</span> has neighboring weights, so it is the spatial locations of the nodes in the output space that are indicative of the inherent statistical features in the input space &#13;
<span class="keep-together">(Haykin 1999).</span></p>&#13;
&#13;
<p>The most distinctive features of SOM methods are as follows (Asan and Ercan 2012):</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>No assumptions regarding the distribution of variables</p>&#13;
</li>&#13;
<li>&#13;
<p>Dependent structure among variables</p>&#13;
</li>&#13;
<li>&#13;
<p>Dealing with nonlinear structure</p>&#13;
</li>&#13;
<li>&#13;
<p>Coping with noisy and missing data</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Let’s walk through the important steps of the SOM technique. As you might have guessed, the first step is to identify the winning node, or the activated neuron. The winning node is identified by distance metrics—that is, Manhattan, Chebyshev, and Euclidean distances. <a data-primary="Euclidean distance metric" data-secondary="SOM" data-type="indexterm" id="idm45737208806528"/>Of these distance metrics, Euclidean distance is the most commonly used because it works well under the gradient descent process. Thus, given the following Euclidean formula, we can find the distance between sample and weight:</p>&#13;
<div data-type="equation">&#13;
<math alttext="parallel-to left-parenthesis x Subscript t Baseline minus w Subscript i Baseline left-parenthesis t right-parenthesis right-parenthesis parallel-to equals StartRoot sigma-summation Underscript i Endscripts equals 1 Superscript n Baseline left-parenthesis x Subscript t j Baseline minus w Subscript t j i Baseline right-parenthesis squared EndRoot comma i equals 1 comma 2 comma period period period comma n" display="block">&#13;
  <mrow>&#13;
    <mfenced close="∥" open="∥" separators="">&#13;
      <mo>(</mo>&#13;
      <msub><mi>x</mi> <mi>t</mi> </msub>&#13;
      <mo>-</mo>&#13;
      <msub><mi>w</mi> <mi>i</mi> </msub>&#13;
      <mrow>&#13;
        <mo>(</mo>&#13;
        <mi>t</mi>&#13;
        <mo>)</mo>&#13;
      </mrow>&#13;
      <mo>)</mo>&#13;
    </mfenced>&#13;
    <mo>=</mo>&#13;
    <msqrt>&#13;
      <mrow>&#13;
        <msub><mo>∑</mo> <mi>i</mi> </msub>&#13;
        <mo>=</mo>&#13;
        <msup><mn>1</mn> <mi>n</mi> </msup>&#13;
        <msup><mrow><mo>(</mo><msub><mi>x</mi> <mrow><mi>t</mi><mi>j</mi></mrow> </msub><mo>-</mo><msub><mi>w</mi> <mrow><mi>t</mi><mi>j</mi><mi>i</mi></mrow> </msub><mo>)</mo></mrow> <mn>2</mn> </msup>&#13;
      </mrow>&#13;
    </msqrt>&#13;
    <mo>,</mo>&#13;
    <mi>i</mi>&#13;
    <mo>=</mo>&#13;
    <mn>1</mn>&#13;
    <mo>,</mo>&#13;
    <mn>2</mn>&#13;
    <mo>,</mo>&#13;
    <mo>.</mo>&#13;
    <mo>.</mo>&#13;
    <mo>.</mo>&#13;
    <mo>,</mo>&#13;
    <mi>n</mi>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <em>x</em> is sample, <em>w</em> is weight, and the winning node, <em>k(t)</em>, is shown in <a data-type="xref" href="#winning_node">Equation 8-1</a>.</p>&#13;
<div data-type="equation" id="winning_node">&#13;
<h5><span class="label">Equation 8-1. </span>Identifying the winning node</h5>&#13;
<math alttext="k left-parenthesis t right-parenthesis equals arg min parallel-to x left-parenthesis t right-parenthesis minus w right-parenthesis i left-parenthesis t right-parenthesis parallel-to" display="block">&#13;
  <mrow>&#13;
    <mi>k</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>t</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <mtext>arg</mtext>&#13;
    <mspace width="4.pt"/>&#13;
    <mtext>min</mtext>&#13;
    <mfenced close="∥" open="∥" separators="">&#13;
      <mi>x</mi>&#13;
      <mo>(</mo>&#13;
      <mi>t</mi>&#13;
      <mo>)</mo>&#13;
      <mo>-</mo>&#13;
      <mi>w</mi>&#13;
      <mo>)</mo>&#13;
      <mi>i</mi>&#13;
      <mo>(</mo>&#13;
      <mi>t</mi>&#13;
      <mo>)</mo>&#13;
    </mfenced>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>The other important step is to update the weight. Given the learning rate and neighborhood size, the following update is applied:</p>&#13;
<div data-type="equation">&#13;
<math alttext="w Subscript i Baseline left-parenthesis t plus 1 right-parenthesis equals w Subscript i Baseline left-parenthesis t right-parenthesis plus lamda left-bracket x left-parenthesis t right-parenthesis minus w Subscript i Baseline left-parenthesis t right-parenthesis right-bracket" display="block">&#13;
  <mrow>&#13;
    <msub><mi>w</mi> <mi>i</mi> </msub>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>t</mi>&#13;
      <mo>+</mo>&#13;
      <mn>1</mn>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <msub><mi>w</mi> <mi>i</mi> </msub>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>t</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>+</mo>&#13;
    <mi>λ</mi>&#13;
    <mrow>&#13;
      <mo>[</mo>&#13;
      <mi>x</mi>&#13;
      <mrow>&#13;
        <mo>(</mo>&#13;
        <mi>t</mi>&#13;
        <mo>)</mo>&#13;
      </mrow>&#13;
      <mo>-</mo>&#13;
      <msub><mi>w</mi> <mi>i</mi> </msub>&#13;
      <mrow>&#13;
        <mo>(</mo>&#13;
        <mi>t</mi>&#13;
        <mo>)</mo>&#13;
      </mrow>&#13;
      <mo>]</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <math alttext="w Subscript i Baseline left-parenthesis t right-parenthesis">&#13;
  <mrow>&#13;
    <msub><mi>w</mi> <mi>i</mi> </msub>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>t</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math> is the weight of the winning neuron <em>i</em> at <math alttext="t Superscript t h">&#13;
  <msup><mi>t</mi> <mrow><mi>t</mi><mi>h</mi></mrow> </msup>&#13;
</math> iteration, and <math alttext="lamda">&#13;
  <mi>λ</mi>&#13;
</math> is the learning rate.</p>&#13;
&#13;
<p><a data-primary="neighborhood functions, SOM" data-type="indexterm" id="idm45737209418496"/>Richardson, Risien, and Shillington (2003) state that the rate of adaptation of the weights decays as it moves away from the winning node. This is defined by neighborhood function, <math alttext="h Subscript k i Baseline left-parenthesis t right-parenthesis">&#13;
  <mrow>&#13;
    <msub><mi>h</mi> <mrow><mi>k</mi><mi>i</mi></mrow> </msub>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>t</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>, where <em>i</em> is index of the neighbor. Of the neighborhood functions, the most famous one is the Gaussian function with the following form:</p>&#13;
<div data-type="equation" id="gaussian_shape">&#13;
<math alttext="h Subscript k i Baseline left-parenthesis t right-parenthesis equals e x p left-parenthesis minus StartFraction d Subscript k i Superscript 2 Baseline Over 2 sigma squared left-parenthesis t right-parenthesis EndFraction right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <msub><mi>h</mi> <mrow><mi>k</mi><mi>i</mi></mrow> </msub>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>t</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <mi>e</mi>&#13;
    <mi>x</mi>&#13;
    <mi>p</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mo>-</mo>&#13;
      <mfrac><msubsup><mi>d</mi> <mrow><mi>k</mi><mi>i</mi></mrow> <mn>2</mn> </msubsup> <mrow><mn>2</mn><msup><mi>σ</mi> <mn>2</mn> </msup><mrow><mo>(</mo><mi>t</mi><mo>)</mo></mrow></mrow></mfrac>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <math alttext="d Subscript k i Superscript 2">&#13;
  <msubsup><mi>d</mi> <mrow><mi>k</mi><mi>i</mi></mrow> <mn>2</mn> </msubsup>&#13;
</math> denotes the distance between the winning neuron and the related neuron, and <math alttext="sigma squared left-parenthesis t right-parenthesis">&#13;
  <mrow>&#13;
    <msup><mi>σ</mi> <mn>2</mn> </msup>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>t</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math> denotes the radius at iteration <em>t</em>.</p>&#13;
&#13;
<p>Considering all this, the updating process becomes what’s shown in <a data-type="xref" href="#weightupdate2">Equation 8-2</a>.</p>&#13;
<div data-type="equation" id="weightupdate2">&#13;
<h5><span class="label">Equation 8-2. </span>Updating the weight</h5>&#13;
<math alttext="w Subscript i Baseline left-parenthesis t plus 1 right-parenthesis equals w Subscript i Baseline left-parenthesis t right-parenthesis plus lamda h Subscript k i Baseline left-parenthesis t right-parenthesis left-bracket x left-parenthesis t right-parenthesis minus w Subscript i Baseline left-parenthesis t right-parenthesis right-bracket" display="block">&#13;
  <mrow>&#13;
    <msub><mi>w</mi> <mi>i</mi> </msub>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>t</mi>&#13;
      <mo>+</mo>&#13;
      <mn>1</mn>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <msub><mi>w</mi> <mi>i</mi> </msub>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>t</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>+</mo>&#13;
    <mi>λ</mi>&#13;
    <msub><mi>h</mi> <mrow><mi>k</mi><mi>i</mi></mrow> </msub>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>t</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mrow>&#13;
      <mo>[</mo>&#13;
      <mi>x</mi>&#13;
      <mrow>&#13;
        <mo>(</mo>&#13;
        <mi>t</mi>&#13;
        <mo>)</mo>&#13;
      </mrow>&#13;
      <mo>-</mo>&#13;
      <msub><mi>w</mi> <mi>i</mi> </msub>&#13;
      <mrow>&#13;
        <mo>(</mo>&#13;
        <mi>t</mi>&#13;
        <mo>)</mo>&#13;
      </mrow>&#13;
      <mo>]</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>That’s all there is to it, but I’m aware that the process is a bit tedious. So let us summarize the steps:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Initialize the weights: assigning random values to weights is the most common approach.</p>&#13;
</li>&#13;
<li>&#13;
<p>Find the winning neuron using <a data-type="xref" href="#winning_node">Equation 8-1</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Update the weights as given in <a data-type="xref" href="#weightupdate2">Equation 8-2</a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Adjust the parameters based on the results of <a data-type="xref" href="#weightupdate2">Equation 8-2</a> by setting <em>t</em> to <em>t</em> + 1.<a data-primary="" data-startref="ix_nns_som" data-type="indexterm" id="idm45737209377040"/><a data-primary="" data-startref="ix_ops_risk_unsup_learn_som" data-type="indexterm" id="idm45737209376032"/><a data-primary="" data-startref="ix_som_ch8" data-type="indexterm" id="idm45737209375072"/><a data-primary="" data-startref="ix_unsup_learn_som" data-type="indexterm" id="idm45737209374128"/></p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p>We already know that there are two classes in the fraud data that we use, so the dimensions for our self organizing map should have a two-by-one structure. You can find the application in the following code:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">49</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">sklearn.preprocessing</code><code> </code><code class="kn">import</code><code> </code><code class="n">StandardScaler</code><code>&#13;
</code><code>         </code><code class="n">standard</code><code> </code><code class="o">=</code><code> </code><code class="n">StandardScaler</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">scaled_fraud</code><code> </code><code class="o">=</code><code> </code><code class="n">standard</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X_under</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">50</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">sklearn_som.som</code><code> </code><code class="kn">import</code><code> </code><code class="n">SOM</code><code>&#13;
</code><code>         </code><code class="n">som</code><code> </code><code class="o">=</code><code> </code><code class="n">SOM</code><code class="p">(</code><code class="n">m</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code><code> </code><code class="n">n</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">dim</code><code class="o">=</code><code class="n">scaled_fraud</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO9-1" id="co_modeling_operational_risk_CO9-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="n">som</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">scaled_fraud</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">predictions_som</code><code> </code><code class="o">=</code><code> </code><code class="n">som</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">scaled_fraud</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">51</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">predictions_som</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">predictions_som</code><code> </code><code class="o">==</code><code> </code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">52</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">Classification report:</code><code class="se">\n</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>               </code><code class="n">classification_report</code><code class="p">(</code><code class="n">y_under</code><code class="p">,</code><code> </code><code class="n">predictions_som</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">Classification</code><code> </code><code class="n">report</code><code class="p">:</code><code>&#13;
</code><code>                        </code><code class="n">precision</code><code>    </code><code class="n">recall</code><code>  </code><code class="n">f1</code><code class="o">-</code><code class="n">score</code><code>   </code><code class="n">support</code><code>&#13;
</code><code>&#13;
</code><code>                    </code><code class="mi">0</code><code>       </code><code class="mf">0.56</code><code>      </code><code class="mf">0.40</code><code>      </code><code class="mf">0.47</code><code>      </code><code class="mi">7506</code><code>&#13;
</code><code>                    </code><code class="mi">1</code><code>       </code><code class="mf">0.53</code><code>      </code><code class="mf">0.68</code><code>      </code><code class="mf">0.60</code><code>      </code><code class="mi">7506</code><code>&#13;
</code><code>&#13;
</code><code>             </code><code class="n">accuracy</code><code>                           </code><code class="mf">0.54</code><code>     </code><code class="mi">15012</code><code>&#13;
</code><code>            </code><code class="n">macro</code><code> </code><code class="n">avg</code><code>       </code><code class="mf">0.54</code><code>      </code><code class="mf">0.54</code><code>      </code><code class="mf">0.53</code><code>     </code><code class="mi">15012</code><code>&#13;
</code><code>         </code><code class="n">weighted</code><code> </code><code class="n">avg</code><code>       </code><code class="mf">0.54</code><code>      </code><code class="mf">0.54</code><code>      </code><code class="mf">0.53</code><code>     </code><code class="mi">15012</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO9-1" id="callout_modeling_operational_risk_CO9-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Configuring the SOP</p></dd>&#13;
</dl>&#13;
&#13;
<p><a data-primary="F1Score, fraud analysis" data-type="indexterm" id="idm45737208508928"/>Having checked the classification report, it becomes obvious that the F1 score is somewhat similar to what we found with the other methods. This confirms that the SOM is a useful model in detecting fraud when we don’t have labeled data. In the following code, we generate <a data-type="xref" href="#som_pred">Figure 8-7</a>, which shows the actual and predicted classes:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">53</code><code class="p">]:</code> <code class="n">fig</code><code class="p">,</code> <code class="n">ax</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">(</code><code class="n">nrows</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">ncols</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">8</code><code class="p">,</code> <code class="mi">6</code><code class="p">))</code>&#13;
         <code class="n">x</code> <code class="o">=</code> <code class="n">X_under</code><code class="o">.</code><code class="n">iloc</code><code class="p">[:,</code><code class="mi">0</code><code class="p">]</code>&#13;
         <code class="n">y</code> <code class="o">=</code> <code class="n">X_under</code><code class="o">.</code><code class="n">iloc</code><code class="p">[:,</code><code class="mi">1</code><code class="p">]</code>&#13;
&#13;
         <code class="n">ax</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">scatter</code><code class="p">(</code><code class="n">x</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="n">alpha</code><code class="o">=</code><code class="mf">0.1</code><code class="p">,</code> <code class="n">cmap</code><code class="o">=</code><code class="s1">'Greys'</code><code class="p">,</code> <code class="n">c</code><code class="o">=</code><code class="n">y_under</code><code class="p">)</code>&#13;
         <code class="n">ax</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">title</code><code class="o">.</code><code class="n">set_text</code><code class="p">(</code><code class="s1">'Actual Classes'</code><code class="p">)</code>&#13;
         <code class="n">ax</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">scatter</code><code class="p">(</code><code class="n">x</code><code class="p">,</code> <code class="n">y</code><code class="p">,</code> <code class="n">alpha</code><code class="o">=</code><code class="mf">0.1</code><code class="p">,</code> <code class="n">cmap</code><code class="o">=</code><code class="s1">'Greys'</code><code class="p">,</code> <code class="n">c</code><code class="o">=</code><code class="n">predictions_som</code><code class="p">)</code>&#13;
         <code class="n">ax</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">title</code><code class="o">.</code><code class="n">set_text</code><code class="p">(</code><code class="s1">'SOM Predictions'</code><code class="p">)</code></pre>&#13;
&#13;
<figure class="width-90"><div class="figure" id="som_pred">&#13;
<img alt="som_prediction" src="assets/mlfr_0807.png"/>&#13;
<h6><span class="label">Figure 8-7. </span>SOM prediction</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Autoencoders" data-type="sect2"><div class="sect2" id="idm45737209900400">&#13;
<h2>Autoencoders</h2>&#13;
&#13;
<p><a data-primary="unsupervised learning modeling" data-secondary="autoencoders" data-type="indexterm" id="ix_unsup_autoencoder"/><a data-primary="deep learning" data-secondary="autoencoders" data-type="indexterm" id="ix_deep_learn_autoencoder"/><a data-primary="operational risk" data-secondary="unsupervised learning modeling" data-tertiary="autoencoders" data-type="indexterm" id="ix_ops_risk_unsup_autoencoder"/><a data-primary="autoencoders" data-type="indexterm" id="ix_autoencoder_ch8"/>An <em>autoencoder</em> is an unsupervised deep learning model trained to transform inputs into outputs via a hidden layer. <a data-primary="decoder, in autoencoder" data-type="indexterm" id="idm45737208307248"/><a data-primary="encoder, in autoencoder" data-type="indexterm" id="idm45737208306544"/>However, the network structure of autoencoder is different from other structures in the sense that autoencoder consists of two parts: an <em>encoder</em> and a <em>decoder</em>.</p>&#13;
&#13;
<p>The encoder serves as a feature extraction function, and the decoder works as a reconstruction function. To illustrate, let <em>x</em> be an input and <em>h</em> be a hidden layer. Then, the encoder function is <em>h</em> = <math alttext="f left-parenthesis x right-parenthesis">&#13;
  <mrow>&#13;
    <mi>f</mi>&#13;
    <mo>(</mo>&#13;
    <mi>x</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>, and the decoder function reconstructs by <em>r</em> = <math alttext="g left-parenthesis h right-parenthesis">&#13;
  <mrow>&#13;
    <mi>g</mi>&#13;
    <mo>(</mo>&#13;
    <mi>h</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>. If an autoencoder learns by simple copying, i.e., <math alttext="g left-parenthesis f left-parenthesis x right-parenthesis right-parenthesis">&#13;
  <mrow>&#13;
    <mi>g</mi>&#13;
    <mo>(</mo>&#13;
    <mi>f</mi>&#13;
    <mo>(</mo>&#13;
    <mi>x</mi>&#13;
    <mo>)</mo>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> = <em>x</em>, it is not an ideal situation in that the autoencoder seeks feature extraction. This amounts to copying only the relevant aspects of the input (Goodfellow et al. 2016).</p>&#13;
&#13;
<p>Consequently, autoencoder has a network structure such that it compresses knowledge in a way to have a lower-dimensional representation of the original input. Given the encoder and decoder functions, there are different types of autoencoders. Of them, we’ll discuss the three most commonly used autoencoders to keep ourselves on track:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Undercomplete autoencoders</p>&#13;
</li>&#13;
<li>&#13;
<p>Sparse autoencoders</p>&#13;
</li>&#13;
<li>&#13;
<p>Denoising autoencoders</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Undercomplete autoencoders" data-type="sect3"><div class="sect3" id="idm45737208287216">&#13;
<h3>Undercomplete autoencoders</h3>&#13;
&#13;
<p><a data-primary="undercomplete autoencoder" data-type="indexterm" id="idm45737208285968"/>This is the most basic type of autoencoder, as the hidden layer, <em>h</em>, has a smaller dimension than training data, <em>x</em>. So the number of neurons is less than that of the training data. The aim of this autoencoder is to capture the latent attribute of the data by minimizing the loss function—that is, <math alttext="double-struck upper L left-parenthesis x comma g left-parenthesis f left-parenthesis x right-parenthesis right-parenthesis right-parenthesis">&#13;
  <mrow>&#13;
    <mi>𝕃</mi>&#13;
    <mo>(</mo>&#13;
    <mi>x</mi>&#13;
    <mo>,</mo>&#13;
    <mi>g</mi>&#13;
    <mo>(</mo>&#13;
    <mi>f</mi>&#13;
    <mo>(</mo>&#13;
    <mi>x</mi>&#13;
    <mo>)</mo>&#13;
    <mo>)</mo>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>, where&#13;
<math alttext="double-struck upper L">&#13;
  <mi>𝕃</mi>&#13;
</math> is the loss function.</p>&#13;
&#13;
<p><a data-primary="bias-variance tradeoff, autoencoders" data-type="indexterm" id="idm45737208275616"/>Autoencoders famously face a trade-off in ML known as the bias-variance trade-off,&#13;
in which autoencoders aim to reconstruct the input well while having low-dimensional representations. To remedy this issue, we’ll introduce sparse and denoising autoencoders.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Sparse autoencoder" data-type="sect3"><div class="sect3" id="idm45737208274192">&#13;
<h3>Sparse autoencoder</h3>&#13;
&#13;
<p><a data-primary="sparse autoencoder" data-type="indexterm" id="idm45737208272784"/>Sparse autoencoders suggest a solution to this trade-off by imposing sparsity on the reconstruction error. There are two ways to enforce regularization in sparce autoencoders. The first way is to apply <math alttext="upper L 1">&#13;
  <msub><mi>L</mi> <mn>1</mn> </msub>&#13;
</math> regularization. In this case, the autoencoders optimization becomes (Banks, Koenigstein, and Giryes 2020):</p>&#13;
<div data-type="equation" id="weightupdate2_1">&#13;
<math alttext="dollar-sign arg min Subscript g comma f Baseline double-struck upper L left-parenthesis x comma g left-parenthesis f left-parenthesis x right-parenthesis right-parenthesis right-parenthesis plus lamda left-parenthesis h right-parenthesis dollar-sign">&#13;
  <mrow>&#13;
    <mtext>arg</mtext>&#13;
    <msub><mtext>min</mtext> <mrow><mi>g</mi><mo>,</mo><mi>f</mi></mrow> </msub>&#13;
    <mi>𝕃</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>x</mi>&#13;
      <mo>,</mo>&#13;
      <mi>g</mi>&#13;
      <mrow>&#13;
        <mo>(</mo>&#13;
        <mi>f</mi>&#13;
        <mrow>&#13;
          <mo>(</mo>&#13;
          <mi>x</mi>&#13;
          <mo>)</mo>&#13;
        </mrow>&#13;
        <mo>)</mo>&#13;
      </mrow>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>+</mo>&#13;
    <mi>λ</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>h</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <math alttext="g left-parenthesis f left-parenthesis x right-parenthesis right-parenthesis">&#13;
  <mrow>&#13;
    <mi>g</mi>&#13;
    <mo>(</mo>&#13;
    <mi>f</mi>&#13;
    <mo>(</mo>&#13;
    <mi>x</mi>&#13;
    <mo>)</mo>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math> is the decoder, and <em>h</em> is the encoder outputs. <a data-type="xref" href="#sparse_auto">Figure 8-8</a> illustrates the sparse autoencoder.</p>&#13;
&#13;
<figure><div class="figure" id="sparse_auto">&#13;
<img alt="sparse_auto" src="assets/mlfr_0808.png"/>&#13;
<h6><span class="label">Figure 8-8. </span>Sparse autoencoder model stucture</h6>&#13;
</div></figure>&#13;
&#13;
<p><a data-primary="KL (Kullback-Leibler) divergence" data-type="indexterm" id="idm45737208246912"/>The second way to regularize the sparse autoencoders is with Kullback-Leibler (KL) divergence, which tells us the similarity of the two probability distributions simply by measuring the distance between them. KL divergence can be put mathematically as:</p>&#13;
<div data-type="equation" id="weightupdate2_2">&#13;
<math alttext="dollar-sign double-struck upper L left-parenthesis x comma ModifyingAbove x With caret right-parenthesis plus sigma-summation Underscript j Endscripts upper K upper L left-parenthesis rho parallel-to ModifyingAbove rho With caret parallel-to right-parenthesis dollar-sign">&#13;
  <mrow>&#13;
    <mi>𝕃</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>x</mi>&#13;
      <mo>,</mo>&#13;
      <mover accent="true"><mi>x</mi> <mo>^</mo></mover>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>+</mo>&#13;
    <msub><mo>∑</mo> <mi>j</mi> </msub>&#13;
    <mi>K</mi>&#13;
    <mi>L</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>ρ</mi>&#13;
      <mfenced close="∥" open="∥" separators="">&#13;
        <mover accent="true"><mi>ρ</mi> <mo>^</mo></mover>&#13;
      </mfenced>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <math alttext="rho">&#13;
  <mi>ρ</mi>&#13;
</math> and <math alttext="ModifyingAbove rho With caret">&#13;
  <mover accent="true"><mi>ρ</mi> <mo>^</mo></mover>&#13;
</math> are ideal and observed distributions, respectively.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Denoising autoencoders" data-type="sect3"><div class="sect3" id="idm45737207743568">&#13;
<h3>Denoising autoencoders</h3>&#13;
&#13;
<p><a data-primary="denoising" data-secondary="autoencoders" data-type="indexterm" id="ix_denois_autoencoder"/>The idea behind denoising autoencoders is that instead of using a penalty term, <math alttext="lamda">&#13;
  <mi>λ</mi>&#13;
</math>, add noise to the input data and learn from this changed construction—that is, reconstruction. Thus, instead of minimizing  <math alttext="double-struck upper L left-parenthesis x comma g left-parenthesis f left-parenthesis x right-parenthesis right-parenthesis right-parenthesis">&#13;
  <mrow>&#13;
    <mi>𝕃</mi>&#13;
    <mo>(</mo>&#13;
    <mi>x</mi>&#13;
    <mo>,</mo>&#13;
    <mi>g</mi>&#13;
    <mo>(</mo>&#13;
    <mi>f</mi>&#13;
    <mo>(</mo>&#13;
    <mi>x</mi>&#13;
    <mo>)</mo>&#13;
    <mo>)</mo>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>, denoising autoencoders offer to minimize the following loss function:</p>&#13;
<div data-type="equation">&#13;
<math alttext="double-struck upper L left-parenthesis x comma g left-parenthesis f left-parenthesis ModifyingAbove x With caret right-parenthesis right-parenthesis right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>𝕃</mi>&#13;
    <mo>(</mo>&#13;
    <mi>x</mi>&#13;
    <mo>,</mo>&#13;
    <mi>g</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>f</mi>&#13;
      <mrow>&#13;
        <mo>(</mo>&#13;
        <mover accent="true"><mi>x</mi> <mo>^</mo></mover>&#13;
        <mo>)</mo>&#13;
      </mrow>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <math alttext="ModifyingAbove x With caret">&#13;
  <mover accent="true"><mi>x</mi> <mo>^</mo></mover>&#13;
</math> is the corrupted input obtained by adding noise by, for instance, Gaussian noise. <a data-type="xref" href="#corrupt_noise">Figure 8-9</a> illustrates this process.</p>&#13;
&#13;
<figure><div class="figure" id="corrupt_noise">&#13;
<img alt="corrupt" src="assets/mlfr_0809.png"/>&#13;
<h6><span class="label">Figure 8-9. </span>Denoising autoencoder model structure</h6>&#13;
</div></figure>&#13;
&#13;
<p>In the following code, we’ll use an autoencoder model with Keras. Before moving forward, it is scaled using Standard Scaler, and then, using a batch size of 200 and an epoch number of 100, we are able to get a satisfactory prediction result.&#13;
We’ll then create a reconstruction error table from the autoencoder model to compare with the true class, and it turns out that the means and standard deviations of these models are close to each other:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">54</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">sklearn.preprocessing</code><code> </code><code class="kn">import</code><code> </code><code class="n">StandardScaler</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">tensorflow</code><code> </code><code class="kn">import</code><code> </code><code class="n">keras</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">tensorflow.keras.layers</code><code> </code><code class="kn">import</code><code> </code><code class="n">Dense</code><code class="p">,</code><code> </code><code class="n">Dropout</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">keras</code><code> </code><code class="kn">import</code><code> </code><code class="n">regularizers</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">55</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">fraud_df</code><code class="p">[</code><code class="p">[</code><code class="s1">'</code><code class="s1">amt</code><code class="s1">'</code><code class="p">,</code><code class="s1">'</code><code class="s1">city_pop</code><code class="s1">'</code><code class="p">,</code><code class="s1">'</code><code class="s1">hour</code><code class="s1">'</code><code class="p">]</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">StandardScaler</code><code class="p">(</code><code class="p">)</code><code class="o">.</code><code>\&#13;
</code><code>         </code><code class="n">fit_transform</code><code class="p">(</code><code class="n">fraud_df</code><code class="p">[</code><code class="p">[</code><code class="s1">'</code><code class="s1">amt</code><code class="s1">'</code><code class="p">,</code><code class="s1">'</code><code class="s1">city_pop</code><code class="s1">'</code><code class="p">,</code><code class="s1">'</code><code class="s1">hour</code><code class="s1">'</code><code class="p">]</code><code class="p">]</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">56</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">X_train</code><code class="p">,</code><code> </code><code class="n">X_test</code><code> </code><code class="o">=</code><code> </code><code class="n">train_test_split</code><code class="p">(</code><code class="n">fraud_df</code><code class="p">,</code><code>&#13;
</code><code>                                            </code><code class="n">test_size</code><code class="o">=</code><code class="mf">0.2</code><code class="p">,</code><code> </code><code class="n">random_state</code><code class="o">=</code><code class="mi">123</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">X_train</code><code class="p">[</code><code class="n">X_train</code><code class="p">[</code><code class="s1">'</code><code class="s1">is_fraud</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">==</code><code> </code><code class="mi">0</code><code class="p">]</code><code>&#13;
</code><code>         </code><code class="n">X_train</code><code> </code><code class="o">=</code><code> </code><code class="n">X_train</code><code class="o">.</code><code class="n">drop</code><code class="p">(</code><code class="p">[</code><code class="s1">'</code><code class="s1">is_fraud</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code class="o">.</code><code class="n">values</code><code>&#13;
</code><code>         </code><code class="n">y_test</code><code> </code><code class="o">=</code><code> </code><code class="n">X_test</code><code class="p">[</code><code class="s1">'</code><code class="s1">is_fraud</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>         </code><code class="n">X_test</code><code> </code><code class="o">=</code><code> </code><code class="n">X_test</code><code class="o">.</code><code class="n">drop</code><code class="p">(</code><code class="p">[</code><code class="s1">'</code><code class="s1">is_fraud</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code class="o">.</code><code class="n">values</code><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">57</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">autoencoder</code><code> </code><code class="o">=</code><code> </code><code class="n">keras</code><code class="o">.</code><code class="n">Sequential</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">autoencoder</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">X_train_under</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">tanh</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                               </code><code class="n">activity_regularizer</code><code class="o">=</code><code class="n">regularizers</code><code class="o">.</code><code class="n">l1</code><code class="p">(</code><code class="mf">10e-5</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>                               </code><code class="n">input_dim</code><code class="o">=</code><code> </code><code class="n">X_train_under</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="c1">#encoder</code><code>&#13;
</code><code>         </code><code class="n">autoencoder</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">64</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">tanh</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO10-1" id="co_modeling_operational_risk_CO10-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="n">autoencoder</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">32</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO10-2" id="co_modeling_operational_risk_CO10-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>         </code><code class="c1">#decoder</code><code>&#13;
</code><code>         </code><code class="n">autoencoder</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">32</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">elu</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO10-1" id="co_modeling_operational_risk_CO10-3"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="n">autoencoder</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">64</code><code class="p">,</code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">tanh</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO10-2" id="co_modeling_operational_risk_CO10-4"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>         </code><code class="n">autoencoder</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">X_train_under</code><code class="o">.</code><code class="n">shape</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">elu</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">autoencoder</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code><code class="o">=</code><code class="s1">'</code><code class="s1">mse</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                             </code><code class="n">optimizer</code><code class="o">=</code><code class="s1">'</code><code class="s1">adam</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">autoencoder</code><code class="o">.</code><code class="n">summary</code><code class="p">(</code><code class="p">)</code><code class="p">;</code><code>&#13;
</code><code>         </code><code class="n">Model</code><code class="p">:</code><code> </code><code class="s2">"</code><code class="s2">sequential</code><code class="s2">"</code><code>&#13;
</code><code>         </code><code class="n">_________________________________________________________________</code><code>&#13;
</code><code>         </code><code class="n">Layer</code><code> </code><code class="p">(</code><code class="nb">type</code><code class="p">)</code><code>                 </code><code class="n">Output</code><code> </code><code class="n">Shape</code><code>              </code><code class="n">Param</code><code> </code><code class="c1">#</code><code>&#13;
</code><code>         </code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">=</code><code>&#13;
</code><code>         </code><code class="n">dense</code><code> </code><code class="p">(</code><code class="n">Dense</code><code class="p">)</code><code>                </code><code class="p">(</code><code class="bp">None</code><code class="p">,</code><code> </code><code class="mi">566</code><code class="p">)</code><code>               </code><code class="mi">320922</code><code>&#13;
</code><code>         </code><code class="n">_________________________________________________________________</code><code>&#13;
</code><code>         </code><code class="n">dense_1</code><code> </code><code class="p">(</code><code class="n">Dense</code><code class="p">)</code><code>              </code><code class="p">(</code><code class="bp">None</code><code class="p">,</code><code> </code><code class="mi">64</code><code class="p">)</code><code>                </code><code class="mi">36288</code><code>&#13;
</code><code>         </code><code class="n">_________________________________________________________________</code><code>&#13;
</code><code>         </code><code class="n">dense_2</code><code> </code><code class="p">(</code><code class="n">Dense</code><code class="p">)</code><code>              </code><code class="p">(</code><code class="bp">None</code><code class="p">,</code><code> </code><code class="mi">32</code><code class="p">)</code><code>                </code><code class="mi">2080</code><code>&#13;
</code><code>         </code><code class="n">_________________________________________________________________</code><code>&#13;
</code><code>         </code><code class="n">dense_3</code><code> </code><code class="p">(</code><code class="n">Dense</code><code class="p">)</code><code>              </code><code class="p">(</code><code class="bp">None</code><code class="p">,</code><code> </code><code class="mi">32</code><code class="p">)</code><code>                </code><code class="mi">1056</code><code>&#13;
</code><code>         </code><code class="n">_________________________________________________________________</code><code>&#13;
</code><code>         </code><code class="n">dense_4</code><code> </code><code class="p">(</code><code class="n">Dense</code><code class="p">)</code><code>              </code><code class="p">(</code><code class="bp">None</code><code class="p">,</code><code> </code><code class="mi">64</code><code class="p">)</code><code>                </code><code class="mi">2112</code><code>&#13;
</code><code>         </code><code class="n">_________________________________________________________________</code><code>&#13;
</code><code>         </code><code class="n">dense_5</code><code> </code><code class="p">(</code><code class="n">Dense</code><code class="p">)</code><code>              </code><code class="p">(</code><code class="bp">None</code><code class="p">,</code><code> </code><code class="mi">566</code><code class="p">)</code><code>               </code><code class="mi">36790</code><code>&#13;
</code><code>         </code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">=</code><code>&#13;
</code><code>         </code><code class="n">Total</code><code> </code><code class="n">params</code><code class="p">:</code><code> </code><code class="mi">399</code><code class="p">,</code><code class="mi">248</code><code>&#13;
</code><code>         </code><code class="n">Trainable</code><code> </code><code class="n">params</code><code class="p">:</code><code> </code><code class="mi">399</code><code class="p">,</code><code class="mi">248</code><code>&#13;
</code><code>         </code><code class="n">Non</code><code class="o">-</code><code class="n">trainable</code><code> </code><code class="n">params</code><code class="p">:</code><code> </code><code class="mi">0</code><code>&#13;
</code><code>         </code><code class="n">_________________________________________________________________</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO10-1" id="callout_modeling_operational_risk_CO10-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Identifying 64 and 32 hidden layers in the encoder and decoder parts, &#13;
<span class="keep-together">respectively</span></p></dd>&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO10-2" id="callout_modeling_operational_risk_CO10-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Identifying 32 and 64 hidden layers in the encoder and decoder parts, &#13;
<span class="keep-together">respectively</span></p></dd>&#13;
</dl>&#13;
&#13;
<p>After configuring the autoencoder model, the next step is to fit and predict. After doing the prediction, we check the quality of the model using summary statistics, as they are a reliable way to see whether reconstruction works well:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">58</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">batch_size</code><code> </code><code class="o">=</code><code> </code><code class="mi">200</code><code>&#13;
</code><code>         </code><code class="n">epochs</code><code> </code><code class="o">=</code><code> </code><code class="mi">100</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">59</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">history</code><code> </code><code class="o">=</code><code> </code><code class="n">autoencoder</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code><code> </code><code class="n">X_train</code><code class="p">,</code><code>&#13;
</code><code>                                   </code><code class="n">shuffle</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code>&#13;
</code><code>                                   </code><code class="n">epochs</code><code class="o">=</code><code class="n">epochs</code><code class="p">,</code><code>&#13;
</code><code>                                   </code><code class="n">batch_size</code><code class="o">=</code><code class="n">batch_size</code><code class="p">,</code><code>&#13;
</code><code>                                   </code><code class="n">validation_data</code><code class="o">=</code><code class="p">(</code><code class="n">X_test</code><code class="p">,</code><code> </code><code class="n">X_test</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>                                   </code><code class="n">verbose</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code><code class="o">.</code><code class="n">history</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">60</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">autoencoder_pred</code><code> </code><code class="o">=</code><code> </code><code class="n">autoencoder</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">mse</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">power</code><code class="p">(</code><code class="n">X_test</code><code> </code><code class="o">-</code><code> </code><code class="n">autoencoder_pred</code><code class="p">,</code><code> </code><code class="mi">2</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">error_df</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="p">{</code><code class="s1">'</code><code class="s1">reconstruction_error</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="n">mse</code><code class="p">,</code><code>&#13;
</code><code>                                 </code><code class="s1">'</code><code class="s1">true_class</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="n">y_test</code><code class="p">}</code><code class="p">)</code><code> </code><a class="co" href="#callout_modeling_operational_risk_CO11-1" id="co_modeling_operational_risk_CO11-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="n">error_df</code><code class="o">.</code><code class="n">describe</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code class="n">Out</code><code class="p">[</code><code class="mi">60</code><code class="p">]</code><code class="p">:</code><code>        </code><code class="n">reconstruction_error</code><code>     </code><code class="n">true_class</code><code>&#13;
</code><code>         </code><code class="n">count</code><code>         </code><code class="mf">259335.000000</code><code>  </code><code class="mf">259335.000000</code><code>&#13;
</code><code>         </code><code class="n">mean</code><code>               </code><code class="mf">0.002491</code><code>       </code><code class="mf">0.005668</code><code>&#13;
</code><code>         </code><code class="n">std</code><code>                </code><code class="mf">0.007758</code><code>       </code><code class="mf">0.075075</code><code>&#13;
</code><code>         </code><code class="nb">min</code><code>                </code><code class="mf">0.000174</code><code>       </code><code class="mf">0.000000</code><code>&#13;
</code><code>         </code><code class="mi">25</code><code class="o">%</code><code>                </code><code class="mf">0.001790</code><code>       </code><code class="mf">0.000000</code><code>&#13;
</code><code>         </code><code class="mi">50</code><code class="o">%</code><code>                </code><code class="mf">0.001993</code><code>       </code><code class="mf">0.000000</code><code>&#13;
</code><code>         </code><code class="mi">75</code><code class="o">%</code><code>                </code><code class="mf">0.003368</code><code>       </code><code class="mf">0.000000</code><code>&#13;
</code><code>         </code><code class="nb">max</code><code>                </code><code class="mf">2.582811</code><code>       </code><code class="mf">1.000000</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_modeling_operational_risk_CO11-1" id="callout_modeling_operational_risk_CO11-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Creating a table named <code>error_df</code> to compare the results obtained from the model with the real data</p></dd>&#13;
</dl>&#13;
&#13;
<p>Finally, we create our plot (<a data-type="xref" href="#autoencoder_fraud">Figure 8-10</a>):</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">61</code><code class="p">]:</code> <code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">6</code><code class="p">))</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">history</code><code class="p">[</code><code class="s1">'loss'</code><code class="p">],</code> <code class="n">linewidth</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s1">'Train'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">history</code><code class="p">[</code><code class="s1">'val_loss'</code><code class="p">],</code> <code class="n">linewidth</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s1">'Test'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s1">'upper right'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'Model loss'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">ylabel</code><code class="p">(</code><code class="s1">'Loss'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">xlabel</code><code class="p">(</code><code class="s1">'Epoch'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>&#13;
&#13;
<figure><div class="figure" id="autoencoder_fraud">&#13;
<img alt="autoencoder_fraud" src="assets/mlfr_0810.png"/>&#13;
<h6><span class="label">Figure 8-10. </span>Autoencoder performance</h6>&#13;
</div></figure>&#13;
&#13;
<p><a data-type="xref" href="#autoencoder_fraud">Figure 8-10</a> shows the results of our autoencoder modeling using a line plot, and we can see that the test loss result is more volatile than that of&#13;
train but, on average, the mean loss is similar.<a data-primary="" data-startref="ix_ops_risk_unsup_learn" data-type="indexterm" id="idm45737205858464"/><a data-primary="" data-startref="ix_unsup_learn_model" data-type="indexterm" id="idm45737205857520"/><a data-primary="" data-startref="ix_autoencoder_ch8" data-type="indexterm" id="idm45737205856576"/><a data-primary="" data-startref="ix_deep_learn_autoencoder" data-type="indexterm" id="idm45737205855632"/><a data-primary="" data-startref="ix_ops_risk_unsup_autoencoder" data-type="indexterm" id="idm45737205692640"/><a data-primary="" data-startref="ix_unsup_autoencoder" data-type="indexterm" id="idm45737205691680"/><a data-primary="" data-startref="ix_denois_autoencoder" data-type="indexterm" id="idm45737205690736"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="idm45737207742976">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>Fraud is a hot topic in finance for several reasons. Strict regulation, reputation loss, and costs arising from fraud are the primary reasons to fight it. Until recently, fraud has been a big problem for financial institutions, as modeling fraud had not produced satisfactory results and, because of this, financial institutions had to employ more resources to handle this phenomenon. Thanks to recent advancements in ML, we now have various tools at our disposal for combatting fraud, and this chapter was dedicated to introducing these models and comparing their results. These models ranged from parametric approaches such as logistic regression to deep learning models such as autoencoders.</p>&#13;
&#13;
<p>In the next chapter, we’ll look at a rather different financial risk model known as stock price crash risk, which will enable us to gain insight about the well-being of corporate governance. This is an important tool for financial risk management because&#13;
risk management is ultimately rooted in corporate management. It would be naive to expect low risk in a company with bad corporate governance.<a data-primary="" data-startref="ix_ops_risk_ch8" data-type="indexterm" id="idm45737205669664"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="References" data-type="sect1"><div class="sect1" id="idm45737205818752">&#13;
<h1>References</h1>&#13;
&#13;
<p>Articles cited in this chapter:</p>&#13;
&#13;
<ul class="author-date-bib">&#13;
<li>&#13;
<p>Asan, Umut, and Secil Ercan. 2012. “An Introduction to Self-Organizing Maps.” In <em>Computational Intelligence Systems in Industrial Engineering</em>, edited by Cengiz Kahraman. 295-315. Paris: Atlantis Press</p>&#13;
</li>&#13;
<li>&#13;
<p>Bahnsen, Alejandro Correa, Djamia Aouada, and Björn Ottersten. 2014. “Example-Dependent Cost-Sensitive Logistic Regression for Credit Scoring.” In <em>The 13th International Conference on Machine Learning and Applications</em>, pp. 263-269. IEEE.</p>&#13;
</li>&#13;
<li>&#13;
<p>Bank, Dor, Noam Koenigstein, and Raja Giryes. 2020. “Autoencoders.” arXiv preprint arXiv:2003.05991.</p>&#13;
</li>&#13;
<li>&#13;
<p>Dunnett, Robert S., Cindy B. Levy, and Antonio P. Simoes. 2005. “The Hidden Costs of Operational Risk.” McKinsey St Company.</p>&#13;
</li>&#13;
<li>&#13;
<p>Richardson, Anthony J., C. Risien, and Frank Alan Shillington.  2003. “Using Self-Organizing Maps to Identify Patterns in Satellite Imagery.” Progress in Oceanography 59 (2-3): 223-239.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Books and online resources cited in this chapter:</p>&#13;
&#13;
<ul class="author-date-bib">&#13;
<li>&#13;
<p>Bahnsen, Alejandro Correa. 2021. “Introduction to Example-Dependent Cost-Sensitive Classification.” <a href="https://oreil.ly/5eCsJ"><em class="hyperlink">https://oreil.ly/5eCsJ</em></a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. Cambridge: MIT press.</p>&#13;
</li>&#13;
<li>&#13;
<p>Nilsen. 2020. “Card Fraud Losses Reach $28.65 Billion.” Nilsen Report. <a href="https://oreil.ly/kSls7"><em class="hyperlink">https://oreil.ly/kSls7</em></a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Office of the Comptroller of the Currency. 2019. “Operational Risk: Fraud Risk Management Principles.” CC Bulletin. <a href="https://oreil.ly/GaQez"><em class="hyperlink">https://oreil.ly/GaQez</em></a>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Simon, Haykin. 1999. <em>Neural Networks: A Comprehensive Foundation</em>, second edition. Englewood Cliffs, New Jersey: Prentice-Hall.</p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section></body></html>