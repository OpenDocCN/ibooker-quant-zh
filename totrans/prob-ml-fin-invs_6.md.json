["```py\n# Import the relevant Python libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# Create 9 grid points for the model parameter, from 0.1 to 0.9 spaced 0.1 apart\np = np.arange(0.1, 1, 0.1)\n\n# Since all parameters are uniformly distributed and equally likely, the \n# probability for each parameter = 1/n = 1/9\nprior = 1/len(p)\n\n# Create a pandas DataFrame with the relevant columns to store \n# individual calculations\nearnings_beat = pd.DataFrame(columns = ['parameter', 'prior', 'likelihood', \n'posterior*', 'posterior'])\n\n# Store each parameter value\nearnings_beat['parameter'] = p\n\n# Loop computes the unnormalized posterior probability distribution\n# for each value of the parameter\nfor i in range(0,len(p)):\n earnings_beat.iloc[i,1] = prior\n # Since our training data has three earnings beats in a row, \n # each having a probability of p\n earnings_beat.iloc[i,2] = p[i]**3\n # Use the unnormalized inverse probability rule\n earnings_beat.iloc[i,3] = prior * (p[i]**3)\n\n# Normalize the probability distribution so that all values add up to 1\nearnings_beat['posterior'] = earnings_beat['posterior*']\n                                /sum(earnings_beat['posterior*'])\n\n# Display the data frame to show each calculation\nearnings_beat\n```", "```py\n# Plot the prior and posterior probability distribution for the model parameter\nplt.figure(figsize=(16,6)), plt.subplot(1,2,1), plt.ylim([0,0.5])\nplt.stem(earnings_beat['parameter'],earnings_beat['prior'], \nuse_line_collection=True)\nplt.xlabel('Model parameter p'), plt.ylabel('Probability of parameter P(p)'), \nplt.title('Prior distribution of our model parameter')\n\nplt.subplot(1,2,2), plt.ylim([0,0.5])\nplt.stem(earnings_beat['parameter'],earnings_beat['posterior'], \nuse_line_collection=True)\nplt.xlabel('Model parameter p'), plt.ylabel('Probability of parameter P(p)'), \nplt.title('Posterior distribution of our model parameter')\nplt.show()\n```", "```py\n# Since P(yi=1|pi) = pi, we compute the probability weighted average of \n# observing y=1 using our prior probabilities as the weights\n# This probability weighted average gives us the prior predictive probability of \n# observing y=1 before observing any data\nprior_predictive_1=sum(earnings_beat['parameter']*earnings_beat['prior'])\n\n# The prior predictive probability of observing outcome y=0 is the complement of\n# P(y=1) calculated above\nprior_predictive_0 = 1 - prior_predictive_1\n\n# Since we have picked a uniform distribution for our parameter, our model \n# predicts that both outcomes are equally likely prior to observing any data\nprint(prior_predictive_0, prior_predictive_1) \n(0.5, 0.5)\n\n# Since P(yi=1|pi) = pi, we compute the probability weighted average of \n# observing y=1 but now we use the posterior probabilities as the weights\n# This probability weighted average gives us the posterior predictive \n# probability of observing y=1 after observing in-sample data \nD={y1=1, y2=1, y3=1}\nposterior_predictive_1 = \nsum(earnings_beat['parameter'] * earnings_beat['posterior'])\n\n# The posterior predictive probability of observing outcome y=0 is the \n# complement of P(y=1|D) calculated above\nposterior_predictive_0 = 1- posterior_predictive_1\n\n# After observing data D, our model predicts that observing y=1 is \n# about 3 times more likely than observing y=0\nround(posterior_predictive_0,2), round(posterior_predictive_1,2) \n(0.24, 0.76)\n\n# Plot the prior and posterior predictive probability distribution \n# for the event outcomes\nplt.figure(figsize=(16,6)), plt.subplot(1,2,1), plt.ylim([0,1])\nplt.stem([0,1],[prior_predictive_0, prior_predictive_1], \n\nuse_line_collection=True)\nplt.xlabel('Binary outcome for variable y'), plt.ylabel('Probability P(y)'), \nplt.title('Prior predictive distribution of an earnings beat')\n\nplt.subplot(1,2,2), plt.ylim([0,1])\nplt.stem([0,1],[posterior_predictive_0, posterior_predictive_1], \n\nuse_line_collection=True)\nplt.xlabel('Binary outcome for variable y'), plt.ylabel('Probability P(y)'), \nplt.title('Posterior predictive distribution of an earnings beat')\nplt.show()\n```", "```py\n#Import Python libraries\nimport numpy as np\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\n\n# Define the target distribution - Student's t-distribution \n# with 6 degrees of freedom.\n# Use location=0 and scale=1 parameters which are the default \n# values of the Student's t-distribution\n# x is any continuous variable\ndef target(x):\n   return stats.t.pdf(x, df=6)\n\n# Define the proposal distribution (uniform distribution)\ndef proposal(x):\n   # Returns random sample between x-0.5 and x+0.5 of the current value\n   return stats.uniform.rvs(loc=x-0.5, scale=1)\n\n# Set the initial state arbitrarily at 0 and set the number of \n# iterations to 10,000\nx0 = 0\nn_iter = 10000\n\n# Initialize the Markov chain and the samples list\nx = x0\nsamples = [x]\n\n# Run the Metropolis algorithm to generate new samples and store them in \n# the 'samples' list\nfor i in range(n_iter):\n   # Generate a proposed state from the proposal distribution\n   x_proposed = proposal(x)\n\n   # Calculate the acceptance ratio\n   acceptance_ratio = target(x_proposed) / target(x)\n\n   # Accept or reject the proposed state\n   if acceptance_ratio >= 1:\n       # Accept new sample\n       x = x_proposed\n   else:\n       u = np.random.rand()\n       # Reject new sample\n       if u < acceptance_ratio:\n           x = x_proposed\n\n   # Add the current state to the list of samples\n   samples.append(x)\n\n# Plot the sample path of the Markov chain\nplt.plot(samples)\nplt.xlabel('Sample Number')\nplt.ylabel('Sample Value')\nplt.title('Sample Path of the Markov Chain')\nplt.show()\n\n# Plot the histogram of the samples and compare it with the target distribution\nplt.hist(samples, bins=50, density=True, alpha=0.5, label='MCMC Samples')\nx_range = np.linspace(-5, 5, 1000)\nplt.plot(x_range, target(x_range), 'r-', label='Target Distribution')\nplt.xlabel('Sample Value')\nplt.ylabel('Probability Density')\nplt.title('MCMC Simulation of Students-T Distribution')\nplt.legend()\nplt.show()\n```"]