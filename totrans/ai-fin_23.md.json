["```py\nIn [1]: import os\n        import math\n        import numpy as np\n        import pandas as pd\n        from pylab import plt, mpl\n        plt.style.use('seaborn')\n        mpl.rcParams['savefig.dpi'] = 300\n        mpl.rcParams['font.family'] = 'serif'\n        os.environ['PYTHONHASHSEED'] = '0'\n\nIn [2]: url = 'http://hilpisch.com/aiif_eikon_eod_data.csv'  ![1](Images/1.png)\n\nIn [3]: symbol = 'EUR='  ![1](Images/1.png)\n\nIn [4]: data = pd.DataFrame(pd.read_csv(url, index_col=0,\n                                        parse_dates=True).dropna()[symbol])  ![1](Images/1.png)\n\nIn [5]: data.info()  ![1](Images/1.png)\n        <class 'pandas.core.frame.DataFrame'>\n        DatetimeIndex: 2516 entries, 2010-01-04 to 2019-12-31\n        Data columns (total 1 columns):\n         #   Column  Non-Null Count  Dtype\n        ---  ------  --------------  -----\n         0   EUR=    2516 non-null   float64\n        dtypes: float64(1)\n        memory usage: 39.3 KB\n```", "```py\nIn [6]: lags = 5\n\nIn [7]: features = [symbol, 'r', 'd', 'sma', 'min', 'max', 'mom', 'vol']\n\nIn [8]: def add_lags(data, symbol, lags, window=20, features=features):\n            cols = []\n            df = data.copy()\n            df.dropna(inplace=True)\n            df['r'] = np.log(df / df.shift(1))\n            df['sma'] = df[symbol].rolling(window).mean()  ![1](Images/1.png)\n            df['min'] = df[symbol].rolling(window).min()  ![2](Images/2.png)\n            df['max'] = df[symbol].rolling(window).max()  ![3](Images/3.png)\n            df['mom'] = df['r'].rolling(window).mean()  ![4](Images/4.png)\n            df['vol'] = df['r'].rolling(window).std()  ![5](Images/5.png)\n            df.dropna(inplace=True)\n            df['d'] = np.where(df['r'] > 0, 1, 0)\n            for f in features:\n                for lag in range(1, lags + 1):\n                    col = f'{f}_lag_{lag}'\n                    df[col] = df[f].shift(lag)\n                    cols.append(col)\n            df.dropna(inplace=True)\n            return df, cols\n\nIn [9]: data, cols = add_lags(data, symbol, lags, window=20, features=features)\n\nIn [10]: split = int(len(data) * 0.8)\n\nIn [11]: train = data.iloc[:split].copy()  ![6](Images/6.png)\n\nIn [12]: mu, std = train[cols].mean(), train[cols].std()  ![6](Images/6.png)\n\nIn [13]: train[cols] = (train[cols] - mu) / std  ![6](Images/6.png)\n\nIn [14]: test = data.iloc[split:].copy()  ![7](Images/7.png)\n\nIn [15]: test[cols] = (test[cols] - mu) / std  ![7](Images/7.png)\n```", "```py\nIn [16]: import random\n         import tensorflow as tf\n         from keras.models import Sequential\n         from keras.layers import Dense, Conv1D, Flatten\n         Using TensorFlow backend.\n\nIn [17]: def set_seeds(seed=100):\n             random.seed(seed)\n             np.random.seed(seed)\n             tf.random.set_seed(seed)\n```", "```py\nIn [18]: set_seeds()\n         model = Sequential()\n         model.add(Conv1D(filters=96, kernel_size=5, activation='relu',\n                          input_shape=(len(cols), 1)))\n         model.add(Flatten())\n         model.add(Dense(10, activation='relu'))\n         model.add(Dense(1, activation='sigmoid'))\n\n         model.compile(optimizer='adam',\n                       loss='binary_crossentropy',\n                       metrics=['accuracy'])\n\nIn [19]: model.summary()\n         Model: \"sequential_1\"\n         _________________________________________________________________\n         Layer (type)                 Output Shape              Param #\n         =================================================================\n         conv1d_1 (Conv1D)            (None, 36, 96)            576\n         _________________________________________________________________\n         flatten_1 (Flatten)          (None, 3456)              0\n         _________________________________________________________________\n         dense_1 (Dense)              (None, 10)                34570\n         _________________________________________________________________\n         dense_2 (Dense)              (None, 1)                 11\n         =================================================================\n         Total params: 35,157\n         Trainable params: 35,157\n         Non-trainable params: 0\n         _________________________________________________________________\n\nIn [20]: %%time\n         model.fit(np.atleast_3d(train[cols]), train['d'],\n                   epochs=60, batch_size=48, verbose=False,\n                   validation_split=0.15, shuffle=False)\n         CPU times: user 10.1 s, sys: 1.87 s, total: 12 s\n         Wall time: 4.78 s\n\nOut[20]: <keras.callbacks.callbacks.History at 0x7ffe3f32b110>\n```", "```py\nIn [21]: res = pd.DataFrame(model.history.history)\n\nIn [22]: res.tail(3)\nOut[22]:     val_loss  val_accuracy      loss  accuracy\n         57  0.699932      0.508361  0.635633  0.597165\n         58  0.719671      0.501672  0.634539  0.598937\n         59  0.729954      0.505017  0.634403  0.601890\n\nIn [23]: res.plot(figsize=(10, 6));\n```", "```py\nIn [24]: model.evaluate(np.atleast_3d(test[cols]), test['d'])  ![1](Images/1.png)\n         499/499 [==============================] - 0s 25us/step\n\nOut[24]: [0.7364848222665653, 0.5210421085357666]\n\nIn [25]: test['p'] = np.where(model.predict(np.atleast_3d(test[cols])) > 0.5, 1, 0)\n\nIn [26]: test['p'] = np.where(test['p'] > 0, 1, -1)  ![2](Images/2.png)\n\nIn [27]: test['p'].value_counts()  ![2](Images/2.png)\nOut[27]: -1    478\n          1     21\n         Name: p, dtype: int64\n\nIn [28]: (test['p'].diff() != 0).sum()  ![3](Images/3.png)\nOut[28]: 41\n\nIn [29]: test['s'] = test['p'] * test['r']  ![4](Images/4.png)\n\nIn [30]: ptc = 0.00012 / test[symbol]  ![5](Images/5.png)\n\nIn [31]: test['s_'] = np.where(test['p'] != 0, test['s'] - ptc, test['s'])  ![6](Images/6.png)\n\nIn [32]: test[['r', 's', 's_']].sum().apply(np.exp)\nOut[32]: r     0.931992\n         s     1.086525\n         s_    1.031307\n         dtype: float64\n\nIn [33]: test[['r', 's', 's_']].cumsum().apply(np.exp).plot(figsize=(10, 6));\n```"]