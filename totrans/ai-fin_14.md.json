["```py\nIn [1]: import os\n        import math\n        import numpy as np\n        import pandas as pd\n        from pylab import plt, mpl\n        plt.style.use('seaborn')\n        mpl.rcParams['savefig.dpi'] = 300\n        mpl.rcParams['font.family'] = 'serif'\n        pd.set_option('mode.chained_assignment', None)\n        pd.set_option('display.float_format', '{:.4f}'.format)\n        np.set_printoptions(suppress=True, precision=4)\n        os.environ['PYTHONHASHSEED'] = '0'\n\nIn [2]: url = 'http://hilpisch.com/aiif_eikon_eod_data.csv'  ![1](Images/1.png)\n\nIn [3]: symbol = 'EUR='  ![1](Images/1.png)\n\nIn [4]: data = pd.DataFrame(pd.read_csv(url, index_col=0,\n                                        parse_dates=True).dropna()[symbol])  ![1](Images/1.png)\n\nIn [5]: data.info()  ![1](Images/1.png)\n        <class 'pandas.core.frame.DataFrame'>\n        DatetimeIndex: 2516 entries, 2010-01-04 to 2019-12-31\n        Data columns (total 1 columns):\n         #   Column  Non-Null Count  Dtype\n        ---  ------  --------------  -----\n         0   EUR=    2516 non-null   float64\n        dtypes: float64(1)\n        memory usage: 39.3 KB\n```", "```py\nIn [6]: data['SMA1'] = data[symbol].rolling(42).mean()  ![1](Images/1.png)\n\nIn [7]: data['SMA2'] = data[symbol].rolling(258).mean()  ![2](Images/2.png)\n\nIn [8]: data.plot(figsize=(10, 6));  ![3](Images/3.png)\n```", "```py\nIn [9]: data.dropna(inplace=True)  ![1](Images/1.png)\n\nIn [10]: data['p'] = np.where(data['SMA1'] > data['SMA2'], 1, -1)  ![2](Images/2.png)\n\nIn [11]: data['p'] = data['p'].shift(1)  ![3](Images/3.png)\n\nIn [12]: data.dropna(inplace=True)  ![1](Images/1.png)\n\nIn [13]: data.plot(figsize=(10, 6), secondary_y='p');  ![4](Images/4.png)\n```", "```py\nIn [14]: data['r'] = np.log(data[symbol] / data[symbol].shift(1))  ![1](Images/1.png)\n\nIn [15]: data.dropna(inplace=True)\n\nIn [16]: data['s'] = data['p'] * data['r']  ![2](Images/2.png)\n\nIn [17]: data[['r', 's']].sum().apply(np.exp)  ![3](Images/3.png)\nOut[17]: r   0.8640\n         s   1.3773\n         dtype: float64\n\nIn [18]: data[['r', 's']].sum().apply(np.exp) - 1  ![4](Images/4.png)\nOut[18]: r   -0.1360\n         s    0.3773\n         dtype: float64\n\nIn [19]: data[['r', 's']].cumsum().apply(np.exp).plot(figsize=(10, 6));  ![5](Images/5.png)\n```", "```py\nIn [20]: sum(data['p'].diff() != 0) + 2  ![1](Images/1.png)\nOut[20]: 10\n\nIn [21]: pc = 0.005  ![2](Images/2.png)\n\nIn [22]: data['s_'] = np.where(data['p'].diff() != 0,\n                               data['s'] - pc, data['s'])  ![3](Images/3.png)\n\nIn [23]: data['s_'].iloc[0] -= pc  ![4](Images/4.png)\n\nIn [24]: data['s_'].iloc[-1] -= pc  ![5](Images/5.png)\n\nIn [25]: data[['r', 's', 's_']][data['p'].diff() != 0]  ![6](Images/6.png)\nOut[25]:                  r       s      s_\n         Date\n         2011-01-12  0.0123  0.0123  0.0023\n         2011-10-10  0.0198 -0.0198 -0.0248\n         2012-11-07 -0.0034 -0.0034 -0.0084\n         2014-07-24 -0.0001  0.0001 -0.0049\n         2016-03-16  0.0102  0.0102  0.0052\n         2016-11-10 -0.0018  0.0018 -0.0032\n         2017-06-05 -0.0025 -0.0025 -0.0075\n         2018-06-15  0.0035 -0.0035 -0.0085\n\nIn [26]: data[['r', 's', 's_']].sum().apply(np.exp)\nOut[26]: r    0.8640\n         s    1.3773\n         s_   1.3102\n         dtype: float64\n\nIn [27]: data[['r', 's', 's_']].sum().apply(np.exp) - 1\nOut[27]: r    -0.1360\n         s     0.3773\n         s_    0.3102\n         dtype: float64\n\nIn [28]: data[['r', 's', 's_']].cumsum().apply(np.exp).plot(figsize=(10, 6));\n```", "```py\nIn [29]: data[['r', 's', 's_']].std()  ![1](Images/1.png)\nOut[29]: r    0.0054\n         s    0.0054\n         s_   0.0054\n         dtype: float64\n\nIn [30]: data[['r', 's', 's_']].std() * math.sqrt(252)  ![2](Images/2.png)\nOut[30]: r    0.0853\n         s    0.0853\n         s_   0.0855\n         dtype: float64\n```", "```py\nIn [31]: data = pd.DataFrame(pd.read_csv(url, index_col=0,\n                                         parse_dates=True).dropna()[symbol])\n\nIn [32]: data.info()\n         <class 'pandas.core.frame.DataFrame'>\n         DatetimeIndex: 2516 entries, 2010-01-04 to 2019-12-31\n         Data columns (total 1 columns):\n          #   Column  Non-Null Count  Dtype\n         ---  ------  --------------  -----\n          0   EUR=    2516 non-null   float64\n         dtypes: float64(1)\n         memory usage: 39.3 KB\n\nIn [33]: lags = 5\n\nIn [34]: def add_lags(data, symbol, lags, window=20):\n             cols = []\n             df = data.copy()\n             df.dropna(inplace=True)\n             df['r'] = np.log(df / df.shift(1))\n             df['sma'] = df[symbol].rolling(window).mean()\n             df['min'] = df[symbol].rolling(window).min()\n             df['max'] = df[symbol].rolling(window).max()\n             df['mom'] = df['r'].rolling(window).mean()\n             df['vol'] = df['r'].rolling(window).std()\n             df.dropna(inplace=True)\n             df['d'] = np.where(df['r'] > 0, 1, 0)\n             features = [symbol, 'r', 'd', 'sma', 'min', 'max', 'mom', 'vol']\n             for f in features:\n                 for lag in range(1, lags + 1):\n                     col = f'{f}_lag_{lag}'\n                     df[col] = df[f].shift(lag)\n                     cols.append(col)\n             df.dropna(inplace=True)\n             return df, cols\n\nIn [35]: data, cols = add_lags(data, symbol, lags, window=20)\n```", "```py\nIn [36]: import random\n         import tensorflow as tf\n         from keras.layers import Dense, Dropout\n         from keras.models import Sequential\n         from keras.regularizers import l1\n         from keras.optimizers import Adam\n         from sklearn.metrics import accuracy_score\n         Using TensorFlow backend.\n\nIn [37]: def set_seeds(seed=100):\n             random.seed(seed)\n             np.random.seed(seed)\n             tf.random.set_seed(seed)\n         set_seeds()\n\nIn [38]: optimizer = Adam(learning_rate=0.0001)\n\nIn [39]: def create_model(hl=2, hu=128, dropout=False, rate=0.3,\n                         regularize=False, reg=l1(0.0005),\n                         optimizer=optimizer, input_dim=len(cols)):\n             if not regularize:\n                 reg = None\n             model = Sequential()\n             model.add(Dense(hu, input_dim=input_dim,\n                          activity_regularizer=reg,\n                          activation='relu'))\n             if dropout:\n                 model.add(Dropout(rate, seed=100))\n             for _ in range(hl):\n                 model.add(Dense(hu, activation='relu',\n                              activity_regularizer=reg))\n                 if dropout:\n                     model.add(Dropout(rate, seed=100))\n             model.add(Dense(1, activation='sigmoid'))\n             model.compile(loss='binary_crossentropy',\n                           optimizer=optimizer,\n                           metrics=['accuracy'])\n             return model\n```", "```py\nIn [40]: split = '2018-01-01'  ![1](Images/1.png)\n\nIn [41]: train = data.loc[:split].copy()  ![1](Images/1.png)\n\nIn [42]: np.bincount(train['d'])  ![2](Images/2.png)\nOut[42]: array([ 982, 1006])\n\nIn [43]: mu, std = train.mean(), train.std()  ![3](Images/3.png)\n\nIn [44]: train_ = (train - mu) / std  ![3](Images/3.png)\n\nIn [45]: set_seeds()\n         model = create_model(hl=2, hu=64)  ![4](Images/4.png)\n\nIn [46]: %%time\n         model.fit(train_[cols], train['d'],\n                 epochs=20, verbose=False,\n                 validation_split=0.2, shuffle=False)  ![5](Images/5.png)\n         CPU times: user 2.93 s, sys: 574 ms, total: 3.5 s\n         Wall time: 1.93 s\n\nOut[46]: <keras.callbacks.callbacks.History at 0x7fc9392f38d0>\n\nIn [47]: model.evaluate(train_[cols], train['d'])  ![6](Images/6.png)\n         1988/1988 [==============================] - 0s 17us/step\n\nOut[47]: [0.6745863538872549, 0.5925553441047668]\n```", "```py\nIn [48]: train['p'] = np.where(model.predict(train_[cols]) > 0.5, 1, 0)  ![1](Images/1.png)\n\nIn [49]: train['p'] = np.where(train['p'] == 1, 1, -1)  ![2](Images/2.png)\n\nIn [50]: train['p'].value_counts()  ![3](Images/3.png)\nOut[50]: -1    1098\n          1     890\n         Name: p, dtype: int64\n\nIn [51]: train['s'] = train['p'] * train['r']  ![4](Images/4.png)\n\nIn [52]: train[['r', 's']].sum().apply(np.exp)  ![5](Images/5.png)\nOut[52]: r   0.8787\n         s   5.0766\n         dtype: float64\n\nIn [53]: train[['r', 's']].sum().apply(np.exp)  - 1  ![5](Images/5.png)\nOut[53]: r   -0.1213\n         s    4.0766\n         dtype: float64\n\nIn [54]: train[['r', 's']].cumsum().apply(np.exp).plot(figsize=(10, 6));  ![6](Images/6.png)\n```", "```py\nIn [55]: test = data.loc[split:].copy()  ![1](Images/1.png)\n\nIn [56]: test_ = (test - mu) / std  ![2](Images/2.png)\n\nIn [57]: model.evaluate(test_[cols], test['d'])  ![3](Images/3.png)\n         503/503 [==============================] - 0s 17us/step\n\nOut[57]: [0.6933823573897421, 0.5407554507255554]\n\nIn [58]: test['p'] = np.where(model.predict(test_[cols]) > 0.5, 1, -1)\n\nIn [59]: test['p'].value_counts()\nOut[59]: -1    406\n          1     97\n         Name: p, dtype: int64\n\nIn [60]: test['s'] = test['p'] * test['r']\n\nIn [61]: test[['r', 's']].sum().apply(np.exp)\nOut[61]: r   0.9345\n         s   1.2431\n         dtype: float64\n\nIn [62]: test[['r', 's']].sum().apply(np.exp) - 1\nOut[62]: r   -0.0655\n         s    0.2431\n         dtype: float64\n\nIn [63]: test[['r', 's']].cumsum().apply(np.exp).plot(figsize=(10, 6));\n```", "```py\nIn [64]: sum(test['p'].diff() != 0)\nOut[64]: 147\n\nIn [65]: spread = 0.00012  ![1](Images/1.png)\n         pc = spread / data[symbol].mean()  ![2](Images/2.png)\n         print(f'{pc:.6f}')\n         0.000098\n\nIn [66]: test['s_'] = np.where(test['p'].diff() != 0,\n                               test['s'] - pc, test['s'])\n\nIn [67]: test['s_'].iloc[0] -= pc\n\nIn [68]: test['s_'].iloc[-1] -= pc\n\nIn [69]: test[['r', 's', 's_']].sum().apply(np.exp)\nOut[69]: r    0.9345\n         s    1.2431\n         s_   1.2252\n         dtype: float64\n\nIn [70]: test[['r', 's', 's_']].sum().apply(np.exp) - 1\nOut[70]: r    -0.0655\n         s     0.2431\n         s_    0.2252\n         dtype: float64\n\nIn [71]: test[['r', 's', 's_']].cumsum().apply(np.exp).plot(figsize=(10, 6));\n```", "```py\nIn [72]: url = 'http://hilpisch.com/aiif_eikon_id_eur_usd.csv'  ![1](Images/1.png)\n\nIn [73]: symbol = 'EUR='  ![1](Images/1.png)\n\nIn [74]: data = pd.DataFrame(pd.read_csv(url, index_col=0,\n                             parse_dates=True).dropna()['CLOSE'])  ![1](Images/1.png)\n         data.columns = [symbol]\n\nIn [75]: data = data.resample('5min', label='right').last().ffill()  ![2](Images/2.png)\n\nIn [76]: data.info()  ![2](Images/2.png)\n         <class 'pandas.core.frame.DataFrame'>\n         DatetimeIndex: 26486 entries, 2019-10-01 00:05:00 to 2019-12-31 23:10:00\n         Freq: 5T\n         Data columns (total 1 columns):\n          #   Column  Non-Null Count  Dtype\n         ---  ------  --------------  -----\n          0   EUR=    26486 non-null  float64\n         dtypes: float64(1)\n         memory usage: 413.8 KB\n\nIn [77]: lags = 5\n\nIn [78]: data, cols = add_lags(data, symbol, lags, window=20)\n```", "```py\nIn [79]: split = int(len(data) * 0.85)\n\nIn [80]: train = data.iloc[:split].copy()\n\nIn [81]: np.bincount(train['d'])\nOut[81]: array([16284,  6207])\n\nIn [82]: def cw(df):\n             c0, c1 = np.bincount(df['d'])\n             w0 = (1 / c0) * (len(df)) / 2\n             w1 = (1 / c1) * (len(df)) / 2\n             return {0: w0, 1: w1}\n\nIn [83]: mu, std = train.mean(), train.std()\n\nIn [84]: train_ = (train - mu) / std\n\nIn [85]: set_seeds()\n         model = create_model(hl=1, hu=128,\n                              reg=True, dropout=False)\n\nIn [86]: %%time\n         model.fit(train_[cols], train['d'],\n                   epochs=40, verbose=False,\n                   validation_split=0.2, shuffle=False,\n                   class_weight=cw(train))\n         CPU times: user 40.6 s, sys: 5.49 s, total: 46 s\n         Wall time: 25.2 s\n\nOut[86]: <keras.callbacks.callbacks.History at 0x7fc91a6b2a90>\n\nIn [87]: model.evaluate(train_[cols], train['d'])\n         22491/22491 [==============================] - 0s 13us/step\n\nOut[87]: [0.5218664327576152, 0.6729803085327148]\n```", "```py\nIn [88]: train['p'] = np.where(model.predict(train_[cols]) > 0.5, 1, -1)\n\nIn [89]: train['p'].value_counts()\nOut[89]: -1    11519\n          1    10972\n         Name: p, dtype: int64\n\nIn [90]: train['s'] = train['p'] * train['r']\n\nIn [91]: train[['r', 's']].sum().apply(np.exp)\nOut[91]: r   1.0223\n         s   1.6665\n         dtype: float64\n\nIn [92]: train[['r', 's']].sum().apply(np.exp) - 1\nOut[92]: r   0.0223\n         s   0.6665\n         dtype: float64\n\nIn [93]: train[['r', 's']].cumsum().apply(np.exp).plot(figsize=(10, 6));\n```", "```py\nIn [94]: test = data.iloc[split:].copy()\n\nIn [95]: test_ = (test - mu) / std\n\nIn [96]: model.evaluate(test_[cols], test['d'])\n         3970/3970 [==============================] - 0s 19us/step\n\nOut[96]: [0.5226116042706168, 0.668513834476471]\n\nIn [97]: test['p'] = np.where(model.predict(test_[cols]) > 0.5, 1, -1)\n\nIn [98]: test['p'].value_counts()\nOut[98]: -1    2273\n          1    1697\n         Name: p, dtype: int64\n\nIn [99]: test['s'] = test['p'] * test['r']\n\nIn [100]: test[['r', 's']].sum().apply(np.exp)\nOut[100]: r   1.0071\n          s   1.0658\n          dtype: float64\n\nIn [101]: test[['r', 's']].sum().apply(np.exp) - 1\nOut[101]: r   0.0071\n          s   0.0658\n          dtype: float64\n\nIn [102]: test[['r', 's']].cumsum().apply(np.exp).plot(figsize=(10, 6));\n```", "```py\nIn [103]: sum(test['p'].diff() != 0)\nOut[103]: 1303\n\nIn [104]: spread = 0.00012  ![1](Images/1.png)\n          pc_1 = spread / test[symbol]  ![1](Images/1.png)\n\nIn [105]: spread = 0.00006  ![2](Images/2.png)\n          pc_2 = spread / test[symbol]  ![2](Images/2.png)\n\nIn [106]: test['s_1'] = np.where(test['p'].diff() != 0,\n                                 test['s'] - pc_1, test['s'])  ![1](Images/1.png)\n\nIn [107]: test['s_1'].iloc[0] -= pc_1.iloc[0]  ![1](Images/1.png)\n          test['s_1'].iloc[-1] -= pc_1.iloc[0]  ![1](Images/1.png)\n\nIn [108]: test['s_2'] = np.where(test['p'].diff() != 0,\n                                 test['s'] - pc_2, test['s'])  ![2](Images/2.png)\n\nIn [109]: test['s_2'].iloc[0] -= pc_2.iloc[0]  ![2](Images/2.png)\n          test['s_2'].iloc[-1] -= pc_2.iloc[0]  ![2](Images/2.png)\n\nIn [110]: test[['r', 's', 's_1', 's_2']].sum().apply(np.exp)\nOut[110]: r     1.0071\n          s     1.0658\n          s_1   0.9259\n          s_2   0.9934\n          dtype: float64\n\nIn [111]: test[['r', 's', 's_1', 's_2']].sum().apply(np.exp) - 1\nOut[111]: r      0.0071\n          s      0.0658\n          s_1   -0.0741\n          s_2   -0.0066\n          dtype: float64\n\nIn [112]: test[['r', 's', 's_1', 's_2']].cumsum().apply(\n              np.exp).plot(figsize=(10, 6), style=['-', '-', '--', '--']);\n```"]