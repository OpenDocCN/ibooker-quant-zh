["```py\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas_datareader as pdr\nfrom master_function import data_preprocessing, plot_train_test_values\nfrom master_function import calculate_accuracy, model_bias\nfrom sklearn.metrics import mean_squared_error\n\n```", "```py\n# Set the start and end dates for the data\nstart_date = '1990-01-01'\nend_date   = '2023-06-01'\n# Fetch S&P 500 price data\ndata = np.array((pdr.get_data_fred('SP500', start = start_date, \n                                   end = end_date)).dropna())\n# Difference the data and make it stationary\ndata = np.diff(data[:, 0])\n\n```", "```py\nnum_lags = 100\ntrain_test_split = 0.80\nnum_neurons_in_hidden_layers = 20\nnum_epochs = 500\nbatch_size = 16\n```", "```py\n# Creating the training and test sets\nx_train, y_train, x_test, y_test = data_preprocessing(data, num_lags, \n                                                      train_test_split)\n\n```", "```py\n# Designing the architecture of the model\nmodel = Sequential()\n# First hidden layer with ReLU as activation function\nmodel.add(Dense(num_neurons_in_hidden_layers, input_dim = num_lags, \n                activation = 'relu'))  \n# Second hidden layer with ReLU as activation function\nmodel.add(Dense(num_neurons_in_hidden_layers, activation = 'relu'))  \n# Output layer\nmodel.add(Dense(1))\n# Compiling\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n# Fitting the model\nmodel.fit(x_train, np.reshape(y_train, (–1, 1)), epochs = num_epochs, \n          batch_size = batch_size)\n# Predicting in-sample\ny_predicted_train = np.reshape(model.predict(x_train), (–1, 1))\n# Predicting out-of-sample\ny_predicted = np.reshape(model.predict(x_test), (–1, 1))\n\n```", "```py\nAccuracy Train =  92.4 %\nAccuracy Test =  54.85 %\nRMSE Train =  4.3602984254\nRMSE Test =  75.7542774467\nCorrelation In-Sample Predicted/Train =  0.989\nCorrelation Out-of-Sample Predicted/Test =  0.044\nModel Bias =  1.03\n\n```", "```py\nimport tensorflow as tf\nlosses = []\nepochs = []\nclass LossCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs = None):\n        losses.append(logs['loss'])\n        epochs.append(epoch + 1)\n        plt.clf()\n        plt.plot(epochs, losses, marker = 'o')\n        plt.title('Loss Curve')\n        plt.xlabel('Epoch')\n        plt.ylabel('Loss Value')\n        plt.grid(True)\n        plt.pause(0.01)\nmodel.fit(x_train, np.reshape(y_train, (–1, 1)), epochs = 100, \n          verbose = 0, callbacks = [LossCallback()])\nplt.show()\n\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers import Dense, SimpleRNN\nimport keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas_datareader as pdr\nfrom master_function import data_preprocessing, plot_train_test_values\nfrom master_function import calculate_accuracy, model_bias\nfrom sklearn.metrics import mean_squared_error\n\n```", "```py\nnum_lags = 100\ntrain_test_split = 0.80\nnum_neurons_in_hidden_layers = 20\nnum_epochs = 500\nbatch_size = 16\n\n```", "```py\n# Designing the architecture of the model\nmodel = Sequential()\n# First hidden layer\nmodel.add(Dense(num_neurons_in_hidden_layers, input_dim = num_lags, \n                activation = 'relu'))  \n# Second hidden layer\nmodel.add(Dense(num_neurons_in_hidden_layers, activation = 'relu'))  \n# Output layer\nmodel.add(Dense(1))\n# Compiling\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n# Fitting the model\nmodel.fit(x_train, np.reshape(y_train, (–1, 1)), epochs = num_epochs, \n          batch_size = batch_size)\n# Predicting in-sample\ny_predicted_train = np.reshape(model.predict(x_train), (–1, 1))\n# Predicting out-of-sample\ny_predicted = np.reshape(model.predict(x_test), (–1, 1))\n\n```", "```py\nAccuracy Train =  67.16 %\nAccuracy Test =  52.11 %\nRMSE Train =  22.7704952044\nRMSE Test =  60.3443059267\nCorrelation In-Sample Predicted/Train =  0.642\nCorrelation Out-of-Sample Predicted/Test =  –0.022\nModel Bias =  2.18\n\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nimport keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas_datareader as pdr\nfrom master_function import data_preprocessing, plot_train_test_values\nfrom master_function import calculate_accuracy, model_bias\nfrom sklearn.metrics import mean_squared_error\n\n```", "```py\nnum_lags = 100\ntrain_test_split = 0.80\nnum_neurons_in_hidden_layers = 20\nnum_epochs = 100\nbatch_size = 32\n\n```", "```py\nx_train = x_train.reshape((–1, num_lags, 1))\nx_test = x_test.reshape((–1, num_lags, 1))\n```", "```py\n# Create the LSTM model\nmodel = Sequential()\n# First LSTM layer\nmodel.add(LSTM(units = num_neurons_in_hidden_layers, \n               input_shape = (num_lags, 1)))\n# Second hidden layer\nmodel.add(Dense(num_neurons_in_hidden_layers, activation = 'relu'))  \n# Output layer\nmodel.add(Dense(units = 1))\n# Compile the model\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n# Train the model\nmodel.fit(x_train, y_train, epochs = num_epochs, batch_size = batch_size)\n# Predicting in-sample\ny_predicted_train = np.reshape(model.predict(x_train), (–1, 1))\n# Predicting out-of-sample\ny_predicted = np.reshape(model.predict(x_test), (–1, 1))\n\n```", "```py\nAccuracy Train =  65.63 %\nAccuracy Test =  50.42 %\nRMSE Train =  25.5619843783\nRMSE Test =  55.1133475721\nCorrelation In-Sample Predicted/Train =  0.515\nCorrelation Out-of-Sample Predicted/Test =  0.057\nModel Bias =  2.56\n\n```", "```py\nfrom keras.models import Sequential\nfrom keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\nimport keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas_datareader as pdr\nfrom master_function import data_preprocessing, plot_train_test_values\nfrom master_function import calculate_accuracy, model_bias\nfrom sklearn.metrics import mean_squared_error\n\n```", "```py\nnum_lags = 100 \ntrain_test_split = 0.80 \nfilters = 64 \nkernel_size = 4\npool_size = 2\nnum_epochs = 100 \nbatch_size = 8\n\n```", "```py\nx_train = x_train.reshape((–1, num_lags, 1))\nx_test = x_test.reshape((–1, num_lags, 1))\n```", "```py\n# Create the temporal convolutional network model\nmodel = Sequential()\nmodel.add(Conv1D(filters = filters, kernel_size = kernel_size, \n                 activation = 'relu', input_shape = (num_lags, 1)))\nmodel.add(MaxPooling1D(pool_size = pool_size))\nmodel.add(Flatten())\nmodel.add(Dense(units = 1))\n# Compile the model\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n# Train the model\nmodel.fit(x_train, y_train, epochs = num_epochs , batch_size = batch_size)\n# Predicting in-sample\ny_predicted_train = np.reshape(model.predict(x_train), (–1, 1))\n# Predicting out-of-sample\ny_predicted = np.reshape(model.predict(x_test), (–1, 1))\n\n```", "```py\nAccuracy Train =  68.9 %\nAccuracy Test =  49.16 %\nRMSE Train =  18.3047790152\nRMSE Test =  63.4069105299\nCorrelation In-Sample Predicted/Train =  0.786\nCorrelation Out-of-Sample Predicted/Test =  0.041\nModel Bias =  0.98\n\n```"]