- en: Chapter 2\. Superintelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The fact that there are many paths that lead to superintelligence should increase
    our confidence that we will eventually get there. If one path turns out to be
    blocked, we can still progress.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Nick Bostrom (2014)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'There are multiple definitions for the term *technological singularity*. Its
    use dates back at least to the article by Vinge (1993), which the author provocatively
    begins like this:'
  prefs: []
  type: TYPE_NORMAL
- en: Within thirty years, we will have the technological means to create superhuman
    intelligence. Shortly after, the human era will be ended.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: For the purposes of this chapter and book, *technological singularity* refers
    to a point in time at which certain machines achieve superhuman intelligence,
    or *superintelligence*—this is mostly in line with the original idea of Vinge
    (1993). The idea and concept was further popularized by the widely read and cited
    book by Kurzweil (2005). Barrat (2013) has a wealth of historical and anecdotal
    information around the topic. Shanahan (2015) provides an informal introduction
    and overview of its central aspects. The expression *technological singularity*
    itself has its origin in the concept of a *singularity* in physics. It refers
    to the center of a black hole, where mass is highly concentrated, gravitation
    becomes infinite, and traditional laws of physics break down. The beginning of
    the universe, the so-called Big Bang, is also referred to as a singularity.
  prefs: []
  type: TYPE_NORMAL
- en: Although the general ideas and concepts of the technological singularity and
    of superintelligence might not have an obvious and direct relationship to AI applied
    to finance, a better understanding of their background, related problems, and
    potential consequences is beneficial. The insights gained in the general framework
    are important in a narrower context as well, such as for AI in finance. Those
    insights also help guide the discussion about how AI might reshape the financial
    industry in the near and long term.
  prefs: []
  type: TYPE_NORMAL
- en: '[“Success Stories”](#si_success_stories) takes a look at a selection of recent
    success stories in the field of AI. Among others, it covers how the company DeepMind
    solved the problem of playing Atari 2600 games with neural networks. It also tells
    the story of how the same company solved the problem of playing the game of Go
    at above-human-expert level. The story of chess and computer programs is also
    recounted in that section. [“Importance of Hardware”](#si_importance_of_hardware)
    discusses the importance of hardware in the context of these recent success stories.
    [“Forms of Intelligence”](#si_forms_intelligence) introduces different forms of
    intelligence, such as artificial narrow intelligence (ANI), artificial general
    intelligence (AGI), and superintelligence (SI). [“Paths to Superintelligence”](#si_paths_to_superintelligence)
    is about potential paths to superintelligence, such as whole brain emulation (WBE),
    while [“Intelligence Explosion”](#si_intelligence_explosion) is about what researchers
    call intelligence explosion. [“Goals and Control”](#si_control_problem) provides
    a discussion of aspects related to the so-called control problem in the context
    of superintelligence. Finally, [“Potential Outcomes”](#si_potential_outcomes)
    briefly looks at potential future outcomes and scenarios once superintelligence
    has been achieved.'
  prefs: []
  type: TYPE_NORMAL
- en: Success Stories
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Many ideas and algorithms in AI date back a few decades already. Over these
    decades there have been longer periods of hope on the one hand and despair on
    the other hand. Bostrom (2014, ch. 1) provides a review of these periods.
  prefs: []
  type: TYPE_NORMAL
- en: In 2020, one can say for sure that AI is in the middle of a period of hope,
    if not excitement. One reason for this is recent successes in applying AI to domains
    and problems that even a few years ago seemed immune to AI dominance for decades
    to come. The list of such success stories is long and growing rapidly. Therefore,
    this section focuses on three such stories only. Gerrish (2018) provides a broader
    selection and more detailed accounts of the single cases.
  prefs: []
  type: TYPE_NORMAL
- en: Atari
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This sub-section first tells the success story of how DeepMind mastered playing
    Atari 2600 games with reinforcement learning and neural networks, and then illustrates
    the basic approach that led to its success based on a concrete code example.
  prefs: []
  type: TYPE_NORMAL
- en: The story
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The first success story is about playing Atari 2600 games on a superhuman level.^([1](ch02.xhtml#idm45625339005208))
    The Atari 2600 Video Computer System (VCS) was released in 1977 and was one of
    the first widespread game-playing consoles in the 1980s. Selected popular games
    from that period, such as *Space Invaders*, *Asteroids*, or *Missile Command*,
    count as classics and are still played decades later by retro games enthusiasts.
  prefs: []
  type: TYPE_NORMAL
- en: '[DeepMind](https://deepmind.com) published a paper (Mnih et al. 2013) in which
    its team detailed results from applying reinforcement learning to the problem
    of playing Atari 2600 games by an AI algorithm, or a so-called AI agent. The algorithm
    is a variant of Q-learning applied to a convolutional neural network.^([2](ch02.xhtml#idm45625339299256))
    The algorithm is trained on high-dimensional visual input (raw pixels) only, without
    any guidance by or input from a human. The original project focused on seven Atari
    2600 games, and for three of them—*Pong*, *Enduro*, and *Breakout*—the DeepMind
    team reported above-human expert performance of the AI agent.'
  prefs: []
  type: TYPE_NORMAL
- en: From an AI point of view, it is remarkable not only that the DeepMind team achieved
    such a result, but also how it achieved it. First, the team only used a single
    neural network to learn and play all seven games. Second, no human guidance or
    humanly labeled data was provided, just the interactive learning experience based
    on visual input properly transformed into features data.^([3](ch02.xhtml#idm45625339295608))
    Third, the approach used is reinforcement learning, which relies on observation
    of the relationships between actions and outcomes (rewards) only—basically the
    same way a human player learns to play such a game.
  prefs: []
  type: TYPE_NORMAL
- en: One of the Atari 2600 games, for which the DeepMind AI agent achieved above-human
    expert performance, is [*Breakout*](http://bit.ly/aiif_breakout). In this game,
    the goal is to destroy lines of bricks at the top of the screen by using a paddle
    at the bottom of the screen from which a ball bounces back and moves straight
    across the screen. Whenever the ball hits a brick, the brick is destroyed and
    the ball bounces back. The ball also bounces back from the left, right, and top
    walls. The player loses a life in this game whenever the ball reaches the bottom
    of the screen without being hit by the paddle.
  prefs: []
  type: TYPE_NORMAL
- en: 'The action space has three elements, all related to the paddle: staying at
    current position, moving left, and moving right. The state space is represented
    by frames of the game screen of size 210 x 160 pixels with a 128-color palette.
    The reward is represented by the game score, which the DeepMind algorithm is programmed
    to maximize. With regard to the action policy, the algorithm learns which action
    is best to take, given a certain game state, to maximize the game score (total
    reward).'
  prefs: []
  type: TYPE_NORMAL
- en: An example
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: There is not enough room in this chapter to explore in detail the approach taken
    by DeepMind for *Breakout* and the other Atari 2600 games. However, the OpenAI
    Gym environment (see [*https://gym.openai.com*](https://gym.openai.com)) allows
    for the illustration of a similar, but simpler, neural network approach for a
    similar, but again simpler, game.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Python code in this section works with the `CartPole` environment of the
    OpenAI Gym (see [*http://bit.ly/aiif_cartpole*](http://bit.ly/aiif_cartpole)).^([4](ch02.xhtml#idm45625339281976))
    In this environment, a cart needs to be moved to the right or left to balance
    an upright pole on top of the paddle. Therefore, the action space is similar to
    the *Breakout* action space. The state space consists of four physical data points:
    cart position, cart velocity, pole angle, and pole angular velocity (see [Figure 2-1](#figure_cart_pole)).
    If, after having taken an action, the pole is still in balance, the agent gets
    a reward of 1\. If the pole is out of balance, the game ends. The agent is considered
    successful if it reaches a total reward of 200.^([5](ch02.xhtml#idm45625339278824))'
  prefs: []
  type: TYPE_NORMAL
- en: '![aiif 0201](Images/aiif_0201.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 2-1\. Graphical representation of the `CartPole` environment
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: 'The following code first instantiates a `CartPole` environment object, and
    then inspects the action and state spaces, takes a random action, and captures
    the results. The AI agent moves on toward the next round when the `done` variable
    is `False`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_superintelligence_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Instantiates the environment object
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_superintelligence_CO1-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Fixes the random number seed for the environment
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_superintelligence_CO1-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Shows the size of the action space
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_superintelligence_CO1-5)'
  prefs: []
  type: TYPE_NORMAL
- en: Takes some random actions and collects them
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](Images/5.png)](#co_superintelligence_CO1-6)'
  prefs: []
  type: TYPE_NORMAL
- en: Shows the size of the state space
  prefs: []
  type: TYPE_NORMAL
- en: '[![6](Images/6.png)](#co_superintelligence_CO1-8)'
  prefs: []
  type: TYPE_NORMAL
- en: Resets (initializes) the environment and captures the state
  prefs: []
  type: TYPE_NORMAL
- en: '[![7](Images/7.png)](#co_superintelligence_CO1-9)'
  prefs: []
  type: TYPE_NORMAL
- en: Takes a random action and steps the environment forward to the next state
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to play the game based on random actions to generate a large
    enough data set. However, to increase the quality of the data set, only data that
    results from games with a total reward of 110 or more is collected. To this end,
    a few thousand games are played to collect enough data for the training of a neural
    network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_superintelligence_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Only if the total reward of the random agent is at least 100…
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_superintelligence_CO2-2)'
  prefs: []
  type: TYPE_NORMAL
- en: …is the data is collected…
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_superintelligence_CO2-3)'
  prefs: []
  type: TYPE_NORMAL
- en: …and the total reward recorded.
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_superintelligence_CO2-4)'
  prefs: []
  type: TYPE_NORMAL
- en: The average total reward of all random games included in the data set.
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](Images/5.png)](#co_superintelligence_CO2-5)'
  prefs: []
  type: TYPE_NORMAL
- en: A look at the collected data in the `DataFrame` object.
  prefs: []
  type: TYPE_NORMAL
- en: 'Equipped with the data, a neural network can be trained as follows. Set up
    a neural network for classification. Train it with the columns representing the
    state data as features and the column with the taken actions as labels data. Given
    that the data set only includes actions that have been successful for the given
    state, the neural network learns about what action to take (label) given the state
    (features):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_superintelligence_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: A neural network with one hidden layer only is used.
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_superintelligence_CO3-5)'
  prefs: []
  type: TYPE_NORMAL
- en: The model is trained on the previously collected data.
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_superintelligence_CO3-6)'
  prefs: []
  type: TYPE_NORMAL
- en: The metrics per training step are shown for the final few steps.
  prefs: []
  type: TYPE_NORMAL
- en: 'The trained neural network, or AI agent, can then play the `CartPole` game
    given its learned best actions for any state it is presented with. The AI agent
    achieves the maximum total reward of 200 for each of the 100 games played. This
    is based on a relatively small data set in combination with a relatively simple
    neural network:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](Images/1.png)](#co_superintelligence_CO4-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Chooses an action given the state and the trained model
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](Images/2.png)](#co_superintelligence_CO4-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Moves the environment one step forward based on the learned action
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](Images/3.png)](#co_superintelligence_CO4-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Plays a number of games and records the total reward for each game
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](Images/4.png)](#co_superintelligence_CO4-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Calculates the average total reward for all games
  prefs: []
  type: TYPE_NORMAL
- en: The Arcade Learning Environment (ALE) works similarly to OpenAI Gym. It allows
    one to programmatically interact with emulated Atari 2600 games, take actions,
    collect the results from a taken action, and so on. The task of learning to play
    *Breakout*, for example, is of course more involved, if only because the state
    space is much larger. The basic approach, however, is similar to the one taken
    here, with several algorithmic refinements.
  prefs: []
  type: TYPE_NORMAL
- en: Go
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The board game [Go](http://bit.ly/aiif_go) is more than 2,000 years old. It
    has long been considered a creation of beauty and art—because it is simple in
    principle but nevertheless highly complex—and was expected to withstand the advance
    of game-playing AI agents for decades to come. The strength of a Go player is
    measured in *dans*, in line with graduation systems for many martial arts systems.
    For example, Lee Sedol, who was the Go world champion for years, holds the 9th
    dan. In 2014, Bostrom postulated:'
  prefs: []
  type: TYPE_NORMAL
- en: Go-playing programs have been improving at a rate of about 1 dan/year in recent
    years. If this rate of improvement continues, they might beat the human world
    champion in about a decade.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Again, it was a team at DeepMind that was able to achieve breakthroughs for
    AI agents playing Go with its AlphaGo algorithm (see the AlphaGo page on [DeepMind’s
    website](https://oreil.ly/y6n5N)). In Silver et al. (2016), the researchers describe
    the situation as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: The game of Go has long been viewed as the most challenging of classic games
    for artificial intelligence owing to its enormous search space and the difficulty
    of evaluating board positions and moves.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'The members of the team used a combination of a neural network with a Monte
    Carlo tree search algorithm, which they briefly sketch in their paper. Recounting
    their early successes from 2015, the team points out in the introduction:'
  prefs: []
  type: TYPE_NORMAL
- en: '[O]ur program AlphaGo achieved a 99.8% winning rate against other Go programs,
    and defeated the human European Go champion [Fan Hui] by 5 games to 0\. This is
    the first time that a computer program has defeated a human professional player
    in the full-sized game of Go, a feat previously thought to be at least a decade
    away.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is remarkable that this milestone was achieved just one year after a leading
    AI researcher, Nick Bostrom, predicted that it might take another decade to reach
    that level. Many observers remarked, however, that the beating European Go champion
    of that time, Fan Hui, cannot really be considered a benchmark since the world
    Go elite play on a much higher level. The DeepMind team took on the challenge
    and organized in March 2016 a best-of-five-games competition against the then
    18-time world Go champion Lee Sedol—for sure a proper benchmark for elite-level
    human Go playing. (A wealth of background information is provided on the [AlphaGo
    Korea web page](https://oreil.ly/EL51T), and there is even a [movie](https://oreil.ly/1vYQ5)
    available about the event.) To this end, the DeepMind team further improved the
    AlphaGo Fan version to the AlphaGo Lee iteration.
  prefs: []
  type: TYPE_NORMAL
- en: 'The story of the competition and AlphaGo Lee is well documented and has drawn
    attention all over the world. DeepMind writes on its [web page](https://oreil.ly/h0WEs):'
  prefs: []
  type: TYPE_NORMAL
- en: AlphaGo’s 4-1 victory in Seoul, South Korea, on March 2016 was watched by over
    200 million people worldwide. This landmark achievement was a decade ahead of
    its time. The game earned AlphaGo a 9 dan professional ranking, the highest certification.
    This was the first time a computer Go player had ever received the accolade.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Up until that point, AlphaGo used, among other resources, training data sets
    based on millions of human expert games for its supervised learning. The team’s
    next iteration, AlphaGo Zero, skipped that approach completely and relied instead
    on reinforcement learning and self-play only, putting together different generations
    of trained, neural network–based AI agents to compete against each other. Silver
    et al.’s article (2017b) provides details of AlphaGo Zero. In the abstract, the
    researchers summarize:'
  prefs: []
  type: TYPE_NORMAL
- en: 'AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo’s
    own move selections and also the winner of AlphaGo’s games. This neural network
    improves the strength of the tree search, resulting in higher quality move selection
    and stronger self-play in the next iteration. Starting tabula rasa, our new program
    AlphaGo Zero achieved superhuman performance, winning 100–0 against the previously
    published, champion-defeating AlphaGo.'
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: It is remarkable that a neural network trained not too dissimilarly to the `CartPole`
    example from the previous section (that is, based on self-play) can crack a game
    as complex as Go, whose possible board positions outnumber the atoms of the universe.
    It is also remarkable that the Go wisdom collected over centuries by human players
    is simply not necessary to achieve this milestone.
  prefs: []
  type: TYPE_NORMAL
- en: 'The DeepMind team did not stop there. AlphaZero was intended to be a general
    game-playing AI agent that was supposed to be able to learn different complex
    board games, such as Go, chess, and shogi. With regard to AlphaZero, the team
    summarizes in Silver (2017a):'
  prefs: []
  type: TYPE_NORMAL
- en: In this paper, we generalise this approach into a single AlphaZero algorithm
    that can achieve, tabula rasa, superhuman performance in many challenging domains.
    Starting from random play, and given no domain knowledge except the game rules,
    AlphaZero achieved within 24 hours a superhuman level of play in the games of
    chess and shogi (Japanese chess) as well as Go, and convincingly defeated a world-champion
    program in each case.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'Again, a remarkable milestone was reached by DeepMind in 2017: a game-playing
    AI agent that, after less than 24 hours of self-playing and training, achieved
    above-human-expert levels in three intensely studied board games with centuries-long
    histories in each case.'
  prefs: []
  type: TYPE_NORMAL
- en: Chess
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Chess is, of course, one of the most popular board games in the world. Chess-playing
    computer programs have been around since the very early days of computing, and
    in particular, home computing. For example, an almost complete chess engine called
    *ZX Chess*, which only consisted of about 672 bytes of machine code, was introduced
    in 1983 for the ZX-81 Spectrum home computer.^([6](ch02.xhtml#idm45625341766120))
    Although an incomplete implementation that lacked certain rules like castling,
    it was a great achievement at the time and is still fascinating for computer chess
    fans today. The record of *ZX Chess* as the smallest chess program stood for 32
    years and was broken only by *BootChess* in 2015, at 487 bytes.^([7](ch02.xhtml#idm45625341829208))
  prefs: []
  type: TYPE_NORMAL
- en: It can almost be considered software engineering genius to write a computer
    program with such a small code base that can play a board game that has more possible
    permutations of a game than the universe has atoms. While not being as complex
    with regard to the pure numbers as Go, chess can be considered one of the most
    challenging board games, as players take decades to reach grandmaster level.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the mid-1980s, expert-level computer chess programs were still far away,
    even on better hardware with many fewer constraints than the basic home computer
    ZX-81 Spectrum. No wonder then that leading chess players at that time felt confident
    when playing against computers. For example, Garry Kasparov (2017) recalls an
    event in 1985 during which he played 32 simultaneous games as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: It was a pleasant day in Hamburg in June 6, 1985….Each of my opponents, all
    thirty-two of them, was a computer…it didn’t come as much of a surprise…when I
    achieved a perfect 32-0 score.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: 'It took computer chess developers and the hardware experts from International
    Business Machines Corporation (IBM) 12 years until a computer called Deep Blue
    was able to beat Kasparov, then the human world chess champion. In his book, published
    20 years after his historic loss against Deep Blue, he writes:'
  prefs: []
  type: TYPE_NORMAL
- en: Twelve years later I was in New York City fighting for my chess life. Against
    just one machine, a $10 million IBM supercomputer nicknamed “Deep Blue.”
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Kasparov played a total of six games against Deep Blue. The computer won with
    3.5 points to Kasparov’s 2.5; whereby a full point is awarded for a win and half
    a point to each player for a draw. While Deep Blue lost the first game, it would
    win two of the remaining five, with three games ending in a draw by mutual agreement.
    It has been pointed out that Deep Blue should not be considered a form of AI since
    it mainly relied on a huge hardware cluster. This hardware cluster with 30 nodes
    and 480 special-purpose chess chips—designed by IBM specifically for this event—could
    analyze some 200 million positions per second. In that sense, Deep Blue mainly
    relied on brute force techniques rather than modern AI algorithms such as neural
    networks.
  prefs: []
  type: TYPE_NORMAL
- en: 'Since 1997, both hardware and software have seen tremendous advancements. Kasparov
    sums it up as follows when he refers in his book to chess applications on modern
    smartphones:'
  prefs: []
  type: TYPE_NORMAL
- en: Jump forward another 20 years to today, to 2017, and you can download any number
    of free chess apps for your phone that rival any human grandmaster.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The hardware requirements to beat a human grandmaster have fallen from $10 million
    to about $100 (that is, by a factor of 100,000). However, chess applications for
    regular computers and smartphones still rely on the collected wisdom of decades
    of computer chess. They embody a large number of human-designed rules and strategies
    for the game, rely on a large database for openings, and then benefit from the
    increased compute power and memory of modern devices for their mostly brute force–based
    evaluation of millions of chess positions.
  prefs: []
  type: TYPE_NORMAL
- en: 'This is where AlphaZero comes in. The approach of AlphaZero to mastering the
    game of chess is exclusively based on reinforcement learning with self-play of
    different versions of the AI agent competing against each other. The DeepMind
    team contrasts the traditional approach to computer chess with AlphaZero as follows
    (see [AlphaZero research paper](https://oreil.ly/Ur-fI)):'
  prefs: []
  type: TYPE_NORMAL
- en: Traditional chess engines, including the world computer chess champion Stockfish and IBM’s
    ground-breaking Deep Blue, rely on thousands of rules and heuristics handcrafted
    by strong human players that try to account for every eventuality in a game….AlphaZero
    takes a totally different approach, replacing these hand-crafted rules with a
    deep neural network and general purpose algorithms that know nothing about the
    game beyond the basic rules.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Given this tabula rasa approach of AlphaZero, its performance after a few hours
    of self-play-based training is exceptional when compared to the leading traditional
    chess-playing computer programs. AlphaZero only needs nine hours or less of training
    to master chess on a level that surpasses every human player and every other computer
    chess program, including the Stockfish engine, which at one time dominated computer
    chess. In a 2016 test series comprising 1,000 games, AlphaZero beat Stockfish
    by winning 155 games (mostly while playing white), losing just six games, and
    drawing the rest.
  prefs: []
  type: TYPE_NORMAL
- en: While IBM’s Deep Blue was able to analyze 200 million positions per second,
    modern chess engines, such as Stockfish, on many-core commodity hardware, can
    analyze some 60 million positions per second. At the same time, AlphaZero only
    analyzes about 60,000 positions per second. Despite analyzing 1,000 times fewer
    positions per second, it nevertheless is able to beat Stockfish. One might be
    inclined to think that AlphaZero indeed shows some form of intelligence that sheer
    brute force cannot compensate for. Given that human grandmasters can maybe analyze
    a few hundred positions per second based on experience, patterns, and intuition,
    AlphaZero might inhabit a sweet spot between expert human chess player and traditional
    chess engine based on a brute-force approach, aided by handcrafted rules and stored
    chess knowledge. One could speculate that AlphaZero acquires something similar
    to human pattern recognition, foresight, and intuition combined with higher computational
    speeds due to its comparatively better hardware for that purpose.
  prefs: []
  type: TYPE_NORMAL
- en: Importance of Hardware
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: AI researchers and practitioners have made tremendous progress over the past
    decade with regard to AI algorithms. Reinforcement learning, generally combined
    with neural networks for action policy representation, has proven useful and superior
    in many different areas, as the previous section illustrates.
  prefs: []
  type: TYPE_NORMAL
- en: However, without advances on the hardware side, the recent AI achievements would
    not have been possible. Again, the story of DeepMind and its effort to master
    the game of Go with reinforcement learning (RL) provides some valuable insights.
    [Table 2-1](#si_hardware_table) provides an overview of the hardware usage and
    power consumption for the major AlphaGo versions from 2015 onwards.^([8](ch02.xhtml#idm45625341895352))
    Not only has the strength of AlphaGo increased steadily, but both the hardware
    requirements and the associated power consumption have also come down dramatically.^([9](ch02.xhtml#idm45625341893368))
  prefs: []
  type: TYPE_NORMAL
- en: Table 2-1\. DeepMind hardware for AlphaGo
  prefs: []
  type: TYPE_NORMAL
- en: '| Version | Year | Elo rating^([a](ch02.xhtml#idm45625341729752)) | Hardware
    | Power consumption [TDP] |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| AlphaGo Fan | 2015 | >3,000 | 176 GPUs | >40,000 |'
  prefs: []
  type: TYPE_TB
- en: '| AlphaGo Lee | 2016 | >3,500 | 48 TPUs | 10,000+ |'
  prefs: []
  type: TYPE_TB
- en: '| AlphaGo Master | 2016 | >4,500 | 4 TPUs | <2,000 |'
  prefs: []
  type: TYPE_TB
- en: '| AlphaGo Zero | 2017 | >5,000 | 4 TPUs | <2,000 |'
  prefs: []
  type: TYPE_TB
- en: '| ^([a](ch02.xhtml#idm45625341729752-marker)) For the Elo ratings of the world’s
    best human Go players, see [*https://www.goratings.org/en*](https://www.goratings.org/en).
    |'
  prefs: []
  type: TYPE_TB
- en: The first major hardware push in AI came from GPUs. Although developed originally
    to generate fast high-resolution graphics for computer games, modern GPUs can
    be used for many other purposes as well. One of these other purposes involves
    linear algebra (for example, in the form of matrix multiplication), a mathematical
    discipline of paramount importance for AI in general and neural networks in particular.
  prefs: []
  type: TYPE_NORMAL
- en: As of mid-2020, one of the fastest consumer CPUs on the market is the Intel
    i9 processor in its latest iteration (with 8 cores and a maximum of 16 parallel
    threads).^([10](ch02.xhtml#idm45625341802072)) It reaches, depending on the benchmark
    task at hand, speeds of about 1 TFLOPS or slightly above (that is, one trillion
    floating point operations per second).
  prefs: []
  type: TYPE_NORMAL
- en: At the same time, one of the fastest consumer GPUs on the market has been the
    Nvidia GTX 2080 Ti. It has 4,352 CUDA cores, Nvidia’s version of GPU cores. This
    allows for a high degree of parallelism (for example, in the context of linear
    algebra operations). This GPU reaches a speed of up to 15 TFLOPS, which is about
    15 times faster than the fastest consumer CPU from Intel. GPUs have been faster
    than CPUs for quite a while. However, one major limiting factor usually has been
    the relatively small and specialized memory of GPUs. This has been notably mitigated
    with newer GPU models, such as the GTX 2080 Ti, which has up to 11 GB of fast
    GDDR6 memory and high bus speeds to transfer data to and from the GPU.^([11](ch02.xhtml#idm45625341512360))
  prefs: []
  type: TYPE_NORMAL
- en: In mid-2020, the retail price for such a GPU was about $1,400, which is orders
    of magnitude cheaper than comparably powerful hardware a decade ago. This development
    has made AI research, for example, more affordable for individual academic researchers
    with relatively small budgets compared to those of companies such as DeepMind.
  prefs: []
  type: TYPE_NORMAL
- en: 'Another hardware trend is spurring further developments and adoption of AI
    approaches and algorithms: GPUs and TPUs in the cloud. Cloud providers such as
    Scaleway offer cloud instances that can be rented by the hour and that have powerful
    GPUs available (see [Scaleway GPU instances](https://oreil.ly/bkaH3)). Others
    such as Google have developed TPUs, chips dedicated explicitly to AI, that, similar
    to GPUs, make linear algebra operations more efficient (see [Google TPUs](https://oreil.ly/xnmdw)).'
  prefs: []
  type: TYPE_NORMAL
- en: 'All in all, from the point of view of AI, hardware has improved tremendously
    over the last few years. In summary, three aspects are worth highlighting:'
  prefs: []
  type: TYPE_NORMAL
- en: Performance
  prefs: []
  type: TYPE_NORMAL
- en: GPUs and TPUs provide hardware with heavily parallel architectures that are
    well suited to AI algorithms and neural networks.
  prefs: []
  type: TYPE_NORMAL
- en: Costs
  prefs: []
  type: TYPE_NORMAL
- en: The costs per TFLOPS compute power have come down significantly, allowing for
    smaller AI-related budgets or rather more compute power for the same budget.
  prefs: []
  type: TYPE_NORMAL
- en: Power
  prefs: []
  type: TYPE_NORMAL
- en: Power consumption has come down as well. The same AI-related tasks require less
    power while usually also executing much faster.
  prefs: []
  type: TYPE_NORMAL
- en: Forms of Intelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Is AlphaGo Zero intelligent? It’s hard to tell without a specific definition
    of *intelligence*. AI researcher Max Tegmark (2017) defines intelligence concisely
    as the “ability to accomplish complex goals.”
  prefs: []
  type: TYPE_NORMAL
- en: This definition is general enough to encompass more specific definitions. AlphaZero
    is intelligent given that definition since it is able to accomplish a complex
    goal, namely to win games of Go or chess against human players or other AI agents.
    Of course, human beings, and animals in general, are consequently considered intelligent
    as well.
  prefs: []
  type: TYPE_NORMAL
- en: For the purposes of this book, the following more specific definitions seem
    appropriate and precise enough.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial narrow intelligence (ANI)
  prefs: []
  type: TYPE_NORMAL
- en: This specifies an AI agent that exceeds human-expert-level capabilities and
    skills in a narrow field. AlphaZero can be considered an ANI in the fields of
    Go, chess, and shogi. An algorithmic stock-trading AI agent that realizes a net
    return of consistently 100% per year (per anno) on the invested capital could
    be considered an ANI.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial general intelligence (AGI)
  prefs: []
  type: TYPE_NORMAL
- en: This specifies an AI agent that reaches human-level intelligence in any field,
    such as chess, mathematics, text composition, or finance, and might exceed human-level
    intelligence in some other domains.
  prefs: []
  type: TYPE_NORMAL
- en: Superintelligence (SI)
  prefs: []
  type: TYPE_NORMAL
- en: This specifies an intellect or AI agent that exceeds human-level intelligence
    in any respect.
  prefs: []
  type: TYPE_NORMAL
- en: An ANI has the ability to reach a complex goal in a narrow field on a level
    higher than any human. An AGI is equally as good as any human being in achieving
    complex goals in a wide variety of fields. Finally, a superintelligence is significantly
    better than any human being, or even a collective of human beings, at achieving
    complex goals in almost any conceivable field.
  prefs: []
  type: TYPE_NORMAL
- en: 'The preceding definition of superintelligence is in line with the one provided
    by Bostrom in his book titled *Superintelligence* (2014):'
  prefs: []
  type: TYPE_NORMAL
- en: We can tentatively define a superintelligence as *any intellect that greatly
    exceeds the cognitive performance of humans in virtually all domains of interest.*
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: As defined earlier, the technological singularity is the point in time from
    which a superintelligence exists. However, which paths might lead to superintelligence?
    This is the topic of the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Paths to Superintelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Researchers and practitioners alike have debated for years whether it is possible
    to create a superintelligence. Estimates for the materialization of the technological
    singularity range from a few years to decades, to centuries, to never. No matter
    whether one believes in the feasibility of a superintelligence or not, the discussion
    of potential paths to achieve it is a fruitful one.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the following is a somewhat longer quote from Bostrom (2014, ch. 2),
    which sets out some general considerations that probably are valid for any potential
    path to superintelligence:'
  prefs: []
  type: TYPE_NORMAL
- en: We can, however, discern some general features of the kind of system that would
    be required. It now seems clear that a capacity to learn would be an integral
    feature of the core design of a system intended to attain general intelligence,
    not something to be tacked on later as an extension or an afterthought. The same
    holds for the ability to deal effectively with uncertainty and probabilistic information.
    Some faculty for extracting useful concepts from sensory data and internal states,
    and for leveraging acquired concepts into flexible combinatorial representations
    for use in logical and intuitive reasoning, also likely belong among the core
    design features in a modern AI intended to attain general intelligence.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: These general features are reminiscent of the approach and capabilities of AlphaZero,
    although terms like *intuitive* might need to be defined to apply to an AI agent.
    But how to practically implement these general features? Bostrom (2014, ch. 2)
    discusses five possible paths, explored in the following sub-sections.
  prefs: []
  type: TYPE_NORMAL
- en: Networks and Organizations
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The first path to a superintelligent intellect is via networks and organizations
    involving a possibly large number of human beings, coordinated in such a way that
    their individual intelligences are amplified and working synchronously. Teams,
    comprising people with different skills, are a simple example of such a network
    or organization. One example mentioned often in this context is the team of leading
    experts that the United States government assembled for the Manhattan Project
    to build nuclear weapons as a means to decisively end World War II.
  prefs: []
  type: TYPE_NORMAL
- en: This path seems to have natural limits since the individual capabilities and
    capacities of a single human being are relatively fixed. Evolution also has shown
    that human beings have difficulty coordinating within networks and organizations
    of more than 150 individuals. Large corporations often form much smaller teams,
    departments, or groups than that.
  prefs: []
  type: TYPE_NORMAL
- en: On the other hand, networks of computers and machines, such as the internet,
    tend to work mostly seamlessly, even with millions of compute nodes. Such networks
    are today at least capable of organizing humankind’s knowledge and other data
    (sounds, pictures, videos, and so on). And, of course, AI algorithms already help
    humans navigate all this knowledge and data. However, it is doubtful whether a
    superintelligence might arise “spontaneously,” say, from the internet. A dedicated
    effort seems required from today’s perspective.
  prefs: []
  type: TYPE_NORMAL
- en: Biological Enhancements
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: A lot of effort is spent these days on improving the cognitive and physical
    performance of individual human beings. From more natural approaches, such as
    better training and learning methods, to those involving substances, such as supplements
    or smart and even psychedelic drugs, to those involving special tools, humankind
    today tries more than ever to systematically and scientifically improve the cognitive
    and physical performance of individuals. Harari (2015) describes this effort as
    the quest of *homo sapiens* to create a new and better version of itself, *homo
    deus*.
  prefs: []
  type: TYPE_NORMAL
- en: However, this approach again faces the obstacle that human hardware is basically
    fixed. It has evolved over hundreds of thousands of years and will probably continue
    to do so for the foreseeable future. But this will happen at a rather slow pace
    and over many generations only. It will also happen only to a very small extent,
    since natural selection for human beings plays a reduced role nowadays, and natural
    selection is what gives evolution its power for improvement. Domingos (2015, ch.
    5) discusses central aspects of progress through evolution.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this context, it is helpful to think in terms of the *versions of life*
    as outlined in Tegmark (2017, ch. 1):'
  prefs: []
  type: TYPE_NORMAL
- en: '**Life 1.0** (biological): Life-forms with basically fixed hardware (biological
    bodies) and software (genes). Both are slowly evolved simultaneously through evolution.
    Examples are bacteria or insects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Life 2.0** (cultural): Life-forms with basically fixed and slowly evolving
    hardware but mostly designed and learned software (genes plus language, knowledge,
    skills, etc.). An example is human beings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Life 3.0** (technological): Life-forms with designed and adjustable hardware
    and fully learned and evolved software. An example would be a superintelligence
    created with computer hardware, software, and AI algorithms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: With technological life embodied in a machine superintelligence, the limitations
    of the available hardware would more or less completely vanish. Therefore, paths
    to superintelligence other than networks or biological enhancements might prove
    more promising for the time being.
  prefs: []
  type: TYPE_NORMAL
- en: Brain-Machine Hybrids
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The hybrid approach to improving human performance in any field is omnipresent
    in our lives and symbolized by the use of diverse hardware and software tools
    by humans. Humankind has used tools since its beginning. Today, billions of people
    carry a smartphone with Google Maps on it, allowing for easy navigation even through
    areas and cities they have never been to before. This is a luxury our ancestors
    did not have, so they needed to acquire navigation skills based on objects seen
    in the sky or use much less sophisticated tools, such as a compass.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of chess, for example, it is not the case that humans stopped
    playing once computers, such as Deep Blue, were proven to be superior. To the
    contrary, improvements in the performance of computer chess programs have made
    them indispensable tools for every grandmaster to systematically improve their
    game. The human grandmaster and the fast-calculating chess engine form a human-machine
    team that, everything else equal, performs better than a human alone. There are
    even chess tournaments during which humans play against each other while making
    use of a computer to come up with the next move.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, one can imagine directly connecting the human brain to a machine
    via appropriate interfaces such that the brain could communicate properly with
    the machine, exchanging data and initiating certain computational, analysis, or
    learning tasks. What sounds like science fiction is an active field of research.
    Musk, ElonFor example, Elon Musk is the founder behind a startup called Neuralink,
    which focuses on *neurotech*, as the field often is called.
  prefs: []
  type: TYPE_NORMAL
- en: All in all, the brain-machine hybrid seems practically feasible and likely to
    surpass human intelligence significantly. However, whether it will lead to superintelligence
    is not obvious.
  prefs: []
  type: TYPE_NORMAL
- en: Whole Brain Emulation
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Another suggested path to superintelligence is to first emulate the human brain
    completely and then improve it. The idea here is to map a whole human brain by
    modern brain scanning along with biological and medical analysis methods to exactly
    replicate its structure in the form of neurons, synapses, and so on through software.
    The software is to be run on appropriate hardware. Domingos (2015, ch. 4) gives
    background information about the human brain and what characterizes it with regard
    to learning. Kurzweil (2012) offers a book-length treatment of this topic, providing
    detailed background information and sketching out ways to achieve whole brain
    emulation (WBE, sometimes also called *uploading*).^([12](ch02.xhtml#idm45625341733496))
  prefs: []
  type: TYPE_NORMAL
- en: On a less ambitious level, neural networks do exactly what WBE tries to achieve.
    Neural networks, as the name suggests, are inspired by the brain, and because
    they have already proven so useful and successful in many different areas, one
    might be inclined to conclude that WBE could indeed be considered a viable path
    to superintelligence. However, the necessary technology to map out the complete
    human brain is so far only partially available. Even if the mapping out is successful,
    it is not clear whether the software version would be able to do the same things
    that a human brain is capable of.
  prefs: []
  type: TYPE_NORMAL
- en: However, if WBE is successful, then the human brain software could, for example,
    be run on more powerful and faster hardware than the human body, potentially leading
    to superintelligence. The software could also be easily replicated then, and a
    large number of emulated brains could be put together in a coordinated way, also
    potentially leading to superintelligence. The human brain software could also
    be enhanced in ways that humans are incapable of due to biological limitations.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial Intelligence
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Last, but not least, AI itself as understood in the context of this book might
    lead to superintelligence: algorithms, such as neural networks, run on standard
    or specialized hardware and are trained on available or self-created data. There
    are a number of good reasons why most researchers and practitioners consider this
    path to be the most likely one, if superintelligence is achievable at all.'
  prefs: []
  type: TYPE_NORMAL
- en: The first major reason is that historically humans have been successful in engineering
    often by ignoring what nature and evolution have come up with to solve a certain
    problem. Consider airplanes. Their design makes use of the modern understanding
    of physics, aerodynamics, thermodynamics, and so on instead of trying to mimic
    how birds or insects fly. Or consider a calculator. When engineers built the first
    calculators, they did not analyze how the human brain performs calculations, nor
    did they even try to replicate the biological approach. They rather relied on
    mathematical algorithms that they implemented on technical hardware. In both cases,
    the more important aspect is the functionality or capability itself (flying, calculating).
    The more efficiently it can be provided, the better. There is no need to mimic
    nature.
  prefs: []
  type: TYPE_NORMAL
- en: The second major reason is that the number of AI’s success stories seems ever
    increasing. For example, the application of neural networks to domains that only
    a few years ago seemed immune to AI superiority has proven to be a fruitful path
    to ANIs in many fields. The example of AlphaGo morphing into AlphaZero, mastering
    multiple board games in a short amount of time, is one that gives hope that the
    generalization can be pushed much further.
  prefs: []
  type: TYPE_NORMAL
- en: The third major reason is that a superintelligence probably only appears (“singularity”)
    after many ANIs and maybe even some AGIs have been observed. Since there is no
    doubt about the power of AI in specific fields and domains, researchers and businesses
    alike will continue to focus on improving AI algorithms and hardware. For example,
    large hedge funds will push their efforts to generate alpha—a measure for the
    outperformance of a fund compared to a market benchmark—with AI methods and agents.
    Many of them have large dedicated teams working on such efforts. These global
    efforts across different industries might then together yield the required advancements
    for a superintelligence.
  prefs: []
  type: TYPE_NORMAL
- en: Artificial Intelligence
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Of all the possible paths to superintelligence, AI seems to be the most promising
    one. Recent successes in the field based on reinforcement learning and neural
    networks have led to another AI spring, after a number of AI winters. Many even
    now believe that a superintelligence might not be as far away as we thought even
    a few years ago. The field currently is characterized by much faster advancements
    than originally predicted by experts only a short while ago.
  prefs: []
  type: TYPE_NORMAL
- en: Intelligence Explosion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The quote from Vinge (1993) mentioned earlier not only depicts a dangerous scenario
    for humankind after the technological singularity, but also predicts that the
    dangerous scenario will materialize *shortly afterwards*. Why so quickly?
  prefs: []
  type: TYPE_NORMAL
- en: If there is one superintelligence, then engineers or the superintelligence itself
    can create another superintelligence, maybe even a better one, since a superintelligence
    would have superior engineering know-how and skills compared to the creators of
    the initial one. The replication of the superintelligence would not be constrained
    by the duration of biological processes that have evolved over millions of years.
    It would only be constrained by the technical assembling processes for new hardware,
    which a superintelligence could improve upon itself and in a significant manner.
    Software is quickly and easily copied to new hardware. Resources might constrain
    the replication as well. The superintelligence might come up with better or even
    new ways to mine and produce the required resources.
  prefs: []
  type: TYPE_NORMAL
- en: These and similar arguments support the idea that once the technological singularity
    is reached, there will be an explosion in intelligence. This might happen similarly
    to the Big Bang, which started as a (physical) singularity and from which the
    known universe emerged as from an explosion.
  prefs: []
  type: TYPE_NORMAL
- en: With regard to specific fields and ANIs, similar arguments might apply. Suppose
    an algorithmic trading AI agent is much more successful and consistent performance-wise
    than other traders and hedge funds in the markets. Such an AI agent would accumulate
    ever more funds, both from gains of trade and by attracting outside money. This
    in turn would increase the available budget to improve upon the hardware, the
    algorithms, the learning methods, and so forth by, for example, paying above-market
    salaries and incentives to the brightest minds in AI applied to finance.
  prefs: []
  type: TYPE_NORMAL
- en: Goals and Control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In a normal AI context, say, when an AI agent is supposed to master the simple
    `CartPole` game depicted in [Figure 2-1](#figure_cart_pole) or a more complex
    game such as chess or Go, the goal is in general well defined: “reach at least
    a reward of 200,” “win the chess game through checkmate,” and so on. But what
    about the goal(s) of a superintelligence?'
  prefs: []
  type: TYPE_NORMAL
- en: Superintelligence and Goals
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: For a superintelligence that has superhuman capabilities, the goal might not
    be as simple and stable as in the preceding examples. For one, a superintelligence
    might come up with a new goal for itself that it considers more appropriate than
    its originally formulated and programmed goal. After all, it has the capabilities
    to do so in the same way its engineering team could. In general, it would be able
    to reprogram itself in any respect. Many science fiction novels and movies let
    us believe that such a change in the main goal is in general to the worse for
    humankind, which is what Vinge (1993) assumes as well.
  prefs: []
  type: TYPE_NORMAL
- en: 'Even if one assumes that the main goal of a superintelligence can be programmed
    and embedded in a nonchangeable way or that a superintelligence might simply stick
    to its original goal, problems might arise. Independent of the main goal, Bostrom
    (2014, ch. 7) argues, every superintelligence has five instrumental sub-goals:'
  prefs: []
  type: TYPE_NORMAL
- en: Self-preservation
  prefs: []
  type: TYPE_NORMAL
- en: A long enough survival of the superintelligence is necessary to achieve its
    main goal. To this end, the superintelligence might implement different measures,
    some of them maybe harmful to humans, to ensure its survival.
  prefs: []
  type: TYPE_NORMAL
- en: Goal-content integrity
  prefs: []
  type: TYPE_NORMAL
- en: This refers to the idea that a superintelligence will try to preserve its current
    main goal because this increases the probability that its future self will achieve
    this very goal. Therefore, present and future main goals are likely to be the
    same. Consider a chess-playing AI agent that starts with the goal of winning a
    chess game. It might change its goal to avoiding the capturing of its queen at
    any cost. This might prevent it from winning the game in the end, and such a change
    in goals would therefore be inconsistent.
  prefs: []
  type: TYPE_NORMAL
- en: Cognitive enhancement
  prefs: []
  type: TYPE_NORMAL
- en: No matter the main goal of the superintelligence, cognitive enhancements will
    in general prove beneficial. It might therefore strive to increase its capabilities
    as fast and as far as possible if this seems to serve its main goal. Cognitive
    enhancement is therefore a major instrumental goal.
  prefs: []
  type: TYPE_NORMAL
- en: Technological perfection
  prefs: []
  type: TYPE_NORMAL
- en: Another instrumental goal is technological perfection. In the sense of Life
    3.0, a superintelligence would not be confined to its current hardware nor to
    the state of its software. It could rather strive to exist on better hardware
    that it might design and produce, and to make use of improved software that it
    has coded. This would in general serve its main goal and probably allow for its
    faster achievement. In the financial industry, for example, high frequency trading
    (HFT) is a field that is characterized by a race to technological superiority.
  prefs: []
  type: TYPE_NORMAL
- en: Resource acquisition
  prefs: []
  type: TYPE_NORMAL
- en: For almost any main goal, more resources in general increase both the probability
    of achieving the goal and the speed at which it can be achieved. This holds particularly
    true when there is a competitive situation implicit in the goal. Consider an AI
    agent with the goal of mining as many Bitcoins as possible as fast as possible.
    The more resources in the form of hardware, energy, and so on the AI agent has
    available, the better it will be for achieving its goal. In such a situation,
    it might even come up with illegal practices to acquire (steal) resources from
    others in the cryptocurrency markets.
  prefs: []
  type: TYPE_NORMAL
- en: On the surface, instrumental goals might not seem to pose a threat. After all,
    they ensure that the main goal of an AI agent is achieved. However, as the widely
    cited example of Bostrom (2014) shows, issues might easily arise. Bostrom argues
    that, for example, a superintelligence with the goal of maximizing the production
    of paper clips might pose a serious threat to humankind. To see this, consider
    the preceding instrumental goals in the context of such an AI agent.
  prefs: []
  type: TYPE_NORMAL
- en: First, it would try to protect itself by all means, even with weaponry used
    against its own creators. Second, even though its own cognitive reasoning capabilities
    might suggest that its main goal is not really sensible, it might stick to it
    over time to maximize its chances of achieving it. Third, cognitive enhancements
    for sure are valuable in achieving its goal. Therefore, it would try every measure,
    probably many of them at the expense and to the harm of human beings, to improve
    its capabilities. Fourth, the better its technology, both for itself as well as
    for producing paper clips, the better it is for its main goal. It would therefore
    acquire all existing technology through buying or stealing, for instance, and
    build new ones that help with its goal. Finally, the more resources it has available,
    the more paper clips it can produce—up to the point where it builds space exploration
    and mining technology when resources on earth are exhausted. In the extreme, such
    a superintelligence might then exhaust the resources in the solar system, the
    galaxy, and even the whole universe.
  prefs: []
  type: TYPE_NORMAL
- en: Instrumental Goals
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is to be assumed that any form of superintelligence will have instrumental
    goals that are independent of its main goal. This might lead to a number of unintended
    consequences, such as the insatiable quest to acquire ever more resources with
    any means that seem promising.
  prefs: []
  type: TYPE_NORMAL
- en: The example illustrates two important points with regard to goals for AI agents.
    First, it might not be possible to formulate complex goals for an AI agent in
    a way that fully and clearly reflects the intentions of those formulating the
    goal. For example, a noble goal such as “Preserve and protect the human species”
    might lead to the killing of three-quarters of it to ensure a higher likelihood
    of survival of the remaining quarter. The superintelligence decides, after billions
    of simulations for the future on planet earth and for the human species, that
    this measure leads to the highest probability of achieving its main goal. Second,
    a seemingly well-intended and harmlessly formulated goal might lead to unintended
    consequences due to the instrumental goals. In the paper clip example, one problem
    with the goal is the phrase “as many as possible.” An easy fix here would be to
    specify the number to, say, one million. But even this might only be a partial
    fix because instrumental goals, such as self-preservation, might become primary
    ones.
  prefs: []
  type: TYPE_NORMAL
- en: Superintelligence and Control
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: If bad or even catastrophic consequences are *possible* after the technological
    singularity, it is of paramount importance to devise measures that can at least
    potentially control a superintelligence.
  prefs: []
  type: TYPE_NORMAL
- en: The first set of measures is related to the proper formulation and design of
    the main goal. The previous section discusses this aspect to some extent. Bostrom
    (2014, ch. 9) provides more details under the topic *motivation selection methods*.
  prefs: []
  type: TYPE_NORMAL
- en: The second set of measures is related to controlling the capabilities of a superintelligence.
    Bostrom (2014, ch. 9) sketches four basic approaches.
  prefs: []
  type: TYPE_NORMAL
- en: Boxing
  prefs: []
  type: TYPE_NORMAL
- en: This is an approach that separates a superintelligence in emergence from the
    outside world. For example, the AI agent might not be connected to the internet.
    It might also lack any sensory capabilities. Human interaction can also be excluded.
    Given this approach to control the capabilities, a large set of interesting goals
    might not be achievable at all. Consider an algorithmically trading AI agent that
    is supposed to achieve the ANI level. Without being connected to the outside world,
    such as to stock trading platforms, the AI agent has no chance of achieving its
    goal.
  prefs: []
  type: TYPE_NORMAL
- en: Incentives
  prefs: []
  type: TYPE_NORMAL
- en: An AI agent might be programmed to maximize its reward function for purposefully
    designed (electronic) rewards that reward desired behavior and punish undesired
    behavior. Although this indirect approach gives more freedom in the goal design,
    it suffers to a large extent from problems similar to those of formulating the
    goal directly.
  prefs: []
  type: TYPE_NORMAL
- en: Stunting
  prefs: []
  type: TYPE_NORMAL
- en: This approach refers to deliberately limiting the capabilities of an AI agent,
    say, with respect to hardware, computing speed, or memory. However, this is a
    delicate task. Too much stunting and a superintelligence will never emerge. Too
    little stunting and the ensuing intelligence explosion will render the measure
    obsolete.
  prefs: []
  type: TYPE_NORMAL
- en: Tripwires
  prefs: []
  type: TYPE_NORMAL
- en: This refers to measures that should help in identifying any suspicious or unwanted
    behavior early on such that targeted countermeasures can be initiated. This approach,
    however, suffers the problem of an alarm system alerting the police of a burglary.
    The police might take 10 minutes to appear on the scene although the burglars
    left the scene 5 minutes before. Even surveillance camera footage might not help
    in figuring out who the burglars are.
  prefs: []
  type: TYPE_NORMAL
- en: Capability Control
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: All in all, it seems questionable whether a superintelligence can be properly
    and systematically controlled when it has reached that level. After all, its superpowers
    can at least in principle be used to overcome any human-designed control mechanism.
  prefs: []
  type: TYPE_NORMAL
- en: Potential Outcomes
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Besides the early prophecy of Vinge (1993) that the emergence of a superintelligence
    will imply doomsday for humankind, what potential outcomes and scenarios are conceivable?
  prefs: []
  type: TYPE_NORMAL
- en: More and more AI researchers and practitioners warn about potential threats
    that uncontrolled AI might bring. Before the emergence of superintelligence, AI
    can lead to discrimination, social imbalances, financial risks, and so on. (A
    prominent AI critic in this context is Elon Musk, founder of Tesla, SpaceX, and
    the aforementioned Neuralink, among others.) Therefore, AI ethics and governance
    are intensively debated topics among researchers and practitioners. To simplify
    things, one can say that this group fears an AI-induced *dystopia*. Others, like
    Ray Kurzweil (2005, 2012), emphasize that AI might be the only way to utopia.
  prefs: []
  type: TYPE_NORMAL
- en: The problem in this context is that even a relatively low probability for a
    dystopian outcome is enough to be worried. As the previous section illustrates,
    appropriate control mechanisms might not be available given the state of the art.
    Against this background, it is no wonder that at the time of this writing, the
    first international accord on AI development has been signed by 42 countries.
  prefs: []
  type: TYPE_NORMAL
- en: 'As Murgia and Shrikanth (2019) report in the *Financial Times*:'
  prefs: []
  type: TYPE_NORMAL
- en: In a historic step last week, 42 countries came together to support a global
    governance framework for one of the most powerful emerging technologies of our
    times—artificial intelligence.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The accord, signed by OECD countries such as the US, UK and Japan, as well as
    non-members, comes at a moment of reckoning for governments, which have only recently
    begun to grapple with the ethical and practical consequences of applying AI in
    industry….[T]he rapid development of AI in recent years by companies such as Google,
    Amazon, Baidu, Tencent and ByteDance has far outrun regulation in the area, exposing
    major challenges including biased AI decisions, outright fakery and misinformation,
    and the dangers of automated military weapons.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Utopia Versus Dystopia
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Even strong proponents of a utopian future based on advancements in AI must
    agree that a dystopian future after a technological singularity cannot be fully
    excluded. Since the consequences might be catastrophic, dystopian outcomes must
    play a role in broader discussions about AI and superintelligence.
  prefs: []
  type: TYPE_NORMAL
- en: What about the number of superintelligences and the situation after the technological
    singularity? Three basic scenarios seem possible.
  prefs: []
  type: TYPE_NORMAL
- en: Singleton
  prefs: []
  type: TYPE_NORMAL
- en: A single superintelligence emerges and gains such power that no other can survive
    or even emerge. For example, Google dominates the search market and has reached
    almost a monopoly position in the field. A superintelligence might quickly reach
    comparable positions in many relevant fields and industries soon after its emergence.
  prefs: []
  type: TYPE_NORMAL
- en: Multipolar
  prefs: []
  type: TYPE_NORMAL
- en: Multiple superintelligences emerge about the same time and co-exist for a longer
    period. The hedge fund industry, for instance, has a few large players that can
    be considered an oligopoly given their combined market share. Multiple superintelligences
    could similarly co-exist, at least for a certain time, according to a divide-and-conquer
    agreement between them.
  prefs: []
  type: TYPE_NORMAL
- en: Atomic
  prefs: []
  type: TYPE_NORMAL
- en: A very large number of superintelligences emerge shortly after the technological
    singularity. Economically, this scenario resembles a market with perfect competition.
    Technologically, the evolution of chess provides an analogy for this scenario.
    While IBM in 1997 built a single machine to dominate both the computer and human
    chess worlds, chess applications on every smartphone today outperform every human
    chess player. In 2018, there were already more than three billion smartphones
    in use. In this context, it is noteworthy that a recent hardware trend for smartphones
    is to add dedicated AI chips in addition to the regular CPUs, steadily increasing
    the capabilities of these small devices.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section does not argue for one or another potential outcome after the
    technological singularity: dystopia, utopia, singleton, multipolar, or atomic.
    It rather provides a basic framework to think about the potential impact of superintelligences
    or powerful ANIs in their respective fields.'
  prefs: []
  type: TYPE_NORMAL
- en: Conclusions
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Recent success stories such as those of DeepMind and AlphaZero have led to a
    new AI spring, with new and stronger-than-ever hopes that a superintelligence
    might be achievable. Currently, AI has come up with ANIs that far surpass human
    expert levels in different domains. Whether AGIs and superintelligences are even
    possible is still debated. However, it at least can not be excluded that by one
    path or another—recent experience points toward AI—it can indeed be achieved.
    Once the technological singularity has happened, it can also not be excluded that
    a superintelligence might have unintended, negative, or even catastrophic consequences
    for humankind. Therefore, appropriate goal and incentive design as well as appropriate
    control mechanisms might be of paramount importance to keep the emerging, ever
    more powerful AI agents under control, even long before the technological singularity
    is in sight. Once the singularity is reached, an intelligence explosion might
    take the control over a superintelligence quickly out of the hands of its own
    creators and sponsors.
  prefs: []
  type: TYPE_NORMAL
- en: AI, machine learning, neural networks, superintelligence, and technological
    singularity are topics that are or will be important for any area of human life.
    Already today, many fields of research, many industries, and many areas of human
    existence are undergoing fundamental changes due to AI, machine learning, and
    deep learning. The same holds true for finance and the financial industry, for
    which the influence of AI might not be as high yet due to a somewhat slower adoption.
    But as with other fields, AI will change finance and the way players in financial
    markets operate fundamentally and for good, as later chapters argue.
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Books and papers cited in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Barrat, James. 2013\. *Our Final Invention: Artificial Intelligence and The
    End of the Human Era*. New York: St. Martin’s Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bostrom, Nick. 2014\. *Superintelligence: Paths, Dangers, Strategies*. Oxford:
    Oxford University Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Chollet, François. 2017\. *Deep Learning with Python*. Shelter Island: Manning.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Domingos, Pedro. 2015\. *The Master Algorithm: How the Quest for the Ultimate
    Learning Machine will Remake our World*. United Kingdom: Penguin Random House.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Doudna, Jennifer and Samuel H. Sternberg. 2017\. *A Crack in Creation: The
    New Power to Control Evolution*. London: The Bodley Head.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gerrish, Sean. 2018\. *How Smart Machines Think*. Cambridge: MIT Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Harari, Yuval Noah. 2015\. *Homo Deus: A Brief History of Tomorrow*. London:
    Harvill Secker.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kasparov, Garry. 2017\. *Deep Thinking: Where Machine Intelligence Ends*. London:
    John Murray.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kurzweil, Ray. 2005\. *The Singularity Is Near: When Humans Transcend Biology*.
    New York: Penguin Group.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '⸻. 2012\. *How to Create a Mind: The Secret of Human Thought Revealed*. New
    York: Penguin Group.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Mnih, Volodymyr et al. 2013\. “Playing Atari with Deep Reinforcement Learning.”
    arXiv. December 19, 2013\. [*https://oreil.ly/HD20U*](https://oreil.ly/HD20U).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Murgia, Madhumita and Siddarth Shrikanth. 2019\. “How Governments Are Beginning
    to Regulate AI.” *Financial Times*, May 30, 2019.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Silver, David et al. 2016\. “Mastering the Game of Go with Deep Neural Networks
    and Tree Search.” *Nature* 529 (January): 484-489.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ⸻. 2017a. “Mastering Chess and Shogi by Self-Play with a General Reinforcement
    Learning Algorithm.” arXiv. December 5, 2017\. [*https://oreil.ly/SBrWQ*](https://oreil.ly/SBrWQ).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '⸻. 2017b. “Mastering the Game of Go without Human Knowledge.” *Nature*, 550
    (October): 354–359\. [*https://oreil.ly/lB8DH*](https://oreil.ly/lB8DH).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Shanahan, Murray. 2015\. *The Technological Singularity*. Cambridge: MIT Press.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Tegmark, Max. 2017\. *Life 3.0: Being Human in the Age of Artificial Intelligence*.
    United Kingdom: Penguin Random House.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Vinge, Vernor. 1993\. “Vernor Vinge on the Singularity.” [*https://oreil.ly/NaorT*](https://oreil.ly/NaorT).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ^([1](ch02.xhtml#idm45625339005208-marker)) For background and historical information,
    see [*http://bit.ly/aiif_atari*](http://bit.ly/aiif_atari).
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch02.xhtml#idm45625339299256-marker)) For details, refer to Mnih et al.
    (2013).
  prefs: []
  type: TYPE_NORMAL
- en: ^([3](ch02.xhtml#idm45625339295608-marker)) Among other factors, this is made
    possible by the availability of the [Arcade Learning Environment (ALE)](https://oreil.ly/OqnWk)
    that allows researchers to train AI agents for Atari 2600 games via a standardized
    API.
  prefs: []
  type: TYPE_NORMAL
- en: ^([4](ch02.xhtml#idm45625339281976-marker)) [Chapter 9](ch09.xhtml#reinforcement_learning)
    revisits this example in more detail.
  prefs: []
  type: TYPE_NORMAL
- en: ^([5](ch02.xhtml#idm45625339278824-marker)) More specifically, an AI agent is
    considered successful if it reaches an average total reward of 195 or more over
    100 consecutive games.
  prefs: []
  type: TYPE_NORMAL
- en: ^([6](ch02.xhtml#idm45625341766120-marker)) See [*http://bit.ly/aiif_1k_chess*](http://bit.ly/aiif_1k_chess)
    for an electronic reprint of the original article published in the February 1983
    issue of *Your Computer* and scans of the original code.
  prefs: []
  type: TYPE_NORMAL
- en: ^([7](ch02.xhtml#idm45625341829208-marker)) See [*http://bit.ly/aiif_bootchess*](http://bit.ly/aiif_bootchess)
    for more background.
  prefs: []
  type: TYPE_NORMAL
- en: '^([8](ch02.xhtml#idm45625341895352-marker)) For more on this, see: [*https://oreil.ly/im174*](https://oreil.ly/im174).'
  prefs: []
  type: TYPE_NORMAL
- en: ^([9](ch02.xhtml#idm45625341893368-marker)) In the table, *GPU* stands for graphical
    processing unit. *TPU* stands for tensor processing unit, which is a computer
    chip specifically designed to process so-called tensors and operations on tensors
    more efficiently. More on tensors, which are the basic building blocks of neural
    networks and deep learning, appears later in the book and in Chollet (2017, ch.
    2). *TDP* stands for thermal design power (see [*http://bit.ly/aiif_tdp*](http://bit.ly/aiif_tdp)).
  prefs: []
  type: TYPE_NORMAL
- en: ^([10](ch02.xhtml#idm45625341802072-marker)) *CPU* stands for central processing
    unit, the general purpose processors found in any standard desktop or notebook
    computer.
  prefs: []
  type: TYPE_NORMAL
- en: ^([11](ch02.xhtml#idm45625341512360-marker)) For a description of the GDDR6
    GPU memory standard from 2018, refer to [*http://bit.ly/aiif_gddr6*](http://bit.ly/aiif_gddr6).
  prefs: []
  type: TYPE_NORMAL
- en: ^([12](ch02.xhtml#idm45625341733496-marker)) In January 2019, an American science
    fiction thriller called *Replicas*, starring Keanu Reeves, was released in the
    US. The main theme of the movie, which proved to be a commercial failure, is the
    mapping of the human brain and the transfer of the mapping to machines or even
    other human bodies grown through cloning and replication. The movie touches on
    a centuries-old human desire to transcend the human body and to become immortal,
    at least with regard to mind and soul. Even if WBE might not lead to superintelligence,
    it might theoretically be a basis for achieving this kind of immortality.
  prefs: []
  type: TYPE_NORMAL
