<html><head></head><body><section data-pdf-bookmark="Chapter 9. Deep Learning for Time Series Prediction II" data-type="chapter" epub:type="chapter"><div class="chapter" id="ch09">&#13;
<h1><span class="label">Chapter 9. </span>Deep Learning for Time Series Prediction II</h1>&#13;
&#13;
<p><a contenteditable="false" data-primary="time series prediction (deep learning techniques and methods for)" data-type="indexterm" id="Chapter_9.html0"/>This chapter presents a few techniques and methods to complement the forecasting task of machine and deep learning algorithms. It is composed of different topics that each discuss a way to improve and optimize the process. At this point, you should have a sound understanding of the basics of machine and deep learning models, and you know how to code a basic algorithm that predicts the returns of a financial time series (or any stationary time series). This chapter bridges the gap between the basic knowledge and the advanced knowledge required to elevate the algorithms to a <span class="keep-together">functional</span> level.</p>&#13;
&#13;
<section data-pdf-bookmark="Fractional Differentiation" data-type="sect1"><div class="sect1" id="id71">&#13;
<h1>Fractional Differentiation</h1>&#13;
&#13;
<p><a contenteditable="false" data-primary="fractional differentiation" data-type="indexterm" id="Chapter_9.html1"/><a contenteditable="false" data-primary="time series prediction (deep learning techniques and methods for)" data-secondary="fractional differentiation" data-type="indexterm" id="Chapter_9.html2"/>In his book <em>Advances in Financial Machine Learning</em>, Marcos López de Prado describes a technique to transform nonstationary data into stationary data. This is referred to as fractional differentiation.</p>&#13;
&#13;
<p><em>Fractional differentiation</em> is a mathematical technique used to transform a time series into a stationary series while preserving some of its memory. It extends the concept of <em>differencing </em>(or taking the returns), which is commonly used to remove trends and make time series stationary.</p>&#13;
&#13;
<p>In traditional differencing, the data sequence is differenced by a whole number, typically 1, which involves subtracting the previous value from the current value. This helps eliminate trends and makes the series stationary. However, in some cases, the series may exhibit long-term dependencies or memory effects that are not effectively captured by traditional differencing. These dependencies may help in forecasting the time series, and if they are completely eliminated, that may hinder the ability of the algorithm to perform well. These dependencies are referred to as <em>memory</em>.</p>&#13;
&#13;
<p>Fractional differentiation addresses this limitation by allowing the differencing parameter to be a fractional value. The fractional differencing operator effectively applies a weighted sum of lagged values to each observation in the series, with the weights determined by the fractional differencing parameter. This allows for capturing long-term dependencies or memory effects in the series. Fractional differentiation is particularly useful in financial time series analysis, where data often exhibits long memory or persistent behavior. This can be implemented in Python. First, <code>pip install</code> the required library from the prompt:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">pip</code> <code class="n">install</code> <code class="n">fracdiff</code></pre>&#13;
&#13;
<p>Next, import the required libraries:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">fracdiff.sklearn</code> <code class="kn">import</code> <code class="n">Fracdiff</code>&#13;
<code class="kn">import</code> <code class="nn">pandas_datareader</code> <code class="k">as</code> <code class="nn">pdr</code>&#13;
<code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="k">as</code> <code class="nn">plt</code>&#13;
</pre>&#13;
&#13;
<p>Let’s use the classic example that de Prado uses in his book, the S&amp;P 500, to prove that fractional differentiation transforms a nonstationary time series into a stationary one with visible preserved memory.</p>&#13;
&#13;
<p>The following code applies fractional differentiation and compares it to traditional differencing:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Set the start and end dates for the data</code>&#13;
<code class="n">start_date</code> <code class="o">=</code> <code class="s1">'1990-01-01'</code>&#13;
<code class="n">end_date</code>   <code class="o">=</code> <code class="s1">'2023-06-01'</code>&#13;
<code class="c1"># Fetch S&amp;P 500 price data</code>&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">((</code><code class="n">pdr</code><code class="o">.</code><code class="n">get_data_fred</code><code class="p">(</code><code class="s1">'SP500'</code><code class="p">,</code> <code class="n">start</code> <code class="o">=</code> <code class="n">start_date</code><code class="p">,</code> &#13;
                                   <code class="n">end</code> <code class="o">=</code> <code class="n">end_date</code><code class="p">))</code><code class="o">.</code><code class="n">dropna</code><code class="p">())</code>&#13;
<code class="c1"># Calculate the fractional differentiation</code>&#13;
<code class="n">window</code> <code class="o">=</code> <code class="mi">100</code>&#13;
<code class="n">f</code> <code class="o">=</code> <code class="n">Fracdiff</code><code class="p">(</code><code class="mf">0.48</code><code class="p">,</code> <code class="n">mode</code> <code class="o">=</code> <code class="s1">'valid'</code><code class="p">,</code> <code class="n">window</code> <code class="o">=</code> <code class="n">window</code><code class="p">)</code>&#13;
<code class="n">frac_data</code> <code class="o">=</code> <code class="n">f</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">data</code><code class="p">)</code>&#13;
<code class="c1"># Calculate a simple differencing function for comparison</code>&#13;
<code class="n">diff_data</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">diff</code><code class="p">(</code><code class="n">data</code><code class="p">[:,</code> <code class="mi">0</code><code class="p">]),</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code>&#13;
<code class="c1"># Harmonizing time indices</code>&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">data</code><code class="p">[</code><code class="n">window</code> <code class="err">–</code> <code class="mi">1</code><code class="p">:,</code> <code class="p">]</code>&#13;
<code class="n">diff_data</code> <code class="o">=</code> <code class="n">diff_data</code><code class="p">[</code><code class="n">window</code> <code class="err">–</code> <code class="mi">2</code><code class="p">:,</code> <code class="p">]</code>&#13;
</pre>&#13;
&#13;
<p><a data-type="xref" href="#figure-9-1">Figure 9-1</a> shows the three types of transformations. You can notice the trending nature in the top panel with the nontransformed S&amp;P 500 data. You can also notice that in the middle panel, this trend is less visible but still there. This is what fractional differentiation aims to do. By keeping a hint of the market’s memory while rendering it stationary, this technique can help improve some forecasting algorithms. The bottom panel shows normal differencing of the price data.</p>&#13;
&#13;
<figure><div class="figure" id="figure-9-1"><img alt="" class="iimagesbeta_fractpng" src="assets/dlff_0901.png"/>&#13;
<h6><span class="label">Figure 9-1. </span>Fractional differentiation on S&amp;P 500 (order = 0.48)</h6>&#13;
</div></figure>&#13;
&#13;
<p><a data-type="xref" href="#figure-9-1">Figure 9-1</a> was generated using this code:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">fig</code><code class="p">,</code> <code class="n">axes</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">(</code><code class="n">nrows</code> <code class="o">=</code> <code class="mi">3</code><code class="p">,</code> <code class="n">ncols</code> <code class="o">=</code> <code class="mi">1</code><code class="p">)</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="mi">5</code><code class="p">:,],</code> <code class="n">label</code> <code class="o">=</code> <code class="s1">'S&amp;P 500'</code><code class="p">,</code> <code class="n">color</code> <code class="o">=</code> <code class="s1">'blue'</code><code class="p">,</code> <code class="n">linewidth</code> <code class="o">=</code> <code class="mi">1</code><code class="p">)</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">frac_data</code><code class="p">[</code><code class="mi">5</code><code class="p">:,],</code> <code class="n">label</code> <code class="o">=</code> &#13;
             <code class="s1">'Fractionally Differentiated S&amp;P 500 (0.48)'</code><code class="p">,</code> &#13;
             <code class="n">color</code> <code class="o">=</code> <code class="s1">'orange'</code><code class="p">,</code> <code class="n">linewidth</code> <code class="o">=</code> <code class="mi">1</code><code class="p">)</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">2</code><code class="p">]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">diff_data</code><code class="p">[</code><code class="mi">5</code><code class="p">:,],</code> <code class="n">label</code> <code class="o">=</code> &#13;
             <code class="s1">'Differenced S&amp;P 500'</code><code class="p">,</code> <code class="n">color</code> <code class="o">=</code> <code class="s1">'green'</code><code class="p">,</code> <code class="n">linewidth</code> <code class="o">=</code> <code class="mi">1</code><code class="p">)</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">legend</code><code class="p">()</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">legend</code><code class="p">()</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">2</code><code class="p">]</code><code class="o">.</code><code class="n">legend</code><code class="p">()</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">grid</code><code class="p">()</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">grid</code><code class="p">()</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">2</code><code class="p">]</code><code class="o">.</code><code class="n">grid</code><code class="p">()</code>   &#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">axhline</code><code class="p">(</code><code class="n">y</code> <code class="o">=</code> <code class="mi">0</code><code class="p">,</code> <code class="n">color</code> <code class="o">=</code> <code class="s1">'black'</code><code class="p">,</code> <code class="n">linestyle</code> <code class="o">=</code> <code class="s1">'dashed'</code><code class="p">)</code> &#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">2</code><code class="p">]</code><code class="o">.</code><code class="n">axhline</code><code class="p">(</code><code class="n">y</code> <code class="o">=</code> <code class="mi">0</code><code class="p">,</code> <code class="n">color</code> <code class="o">=</code> <code class="s1">'black'</code><code class="p">,</code> <code class="n">linestyle</code> <code class="o">=</code> <code class="s1">'dashed'</code><code class="p">)</code>  &#13;
</pre>&#13;
&#13;
<p>Let’s make sure that the fractionally differentiated data is indeed stationary by applying the augmented Dickey—Fuller (ADF) test (you used this test in <a data-type="xref" href="ch03.html#ch03">Chapter 3</a>):</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">statsmodels.tsa.stattools</code> <code class="kn">import</code> <code class="n">adfuller</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="s1">'p-value: </code><code class="si">%f</code><code class="s1">'</code> <code class="o">%</code> <code class="n">adfuller</code><code class="p">(</code><code class="n">data</code><code class="p">)[</code><code class="mi">1</code><code class="p">])</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="s1">'p-value: </code><code class="si">%f</code><code class="s1">'</code> <code class="o">%</code> <code class="n">adfuller</code><code class="p">(</code><code class="n">frac_data</code><code class="p">)[</code><code class="mi">1</code><code class="p">])</code>&#13;
<code class="nb">print</code><code class="p">(</code><code class="s1">'p-value: </code><code class="si">%f</code><code class="s1">'</code> <code class="o">%</code> <code class="n">adfuller</code><code class="p">(</code><code class="n">diff_data</code><code class="p">)[</code><code class="mi">1</code><code class="p">])</code>&#13;
</pre>&#13;
&#13;
<p class="pagebreak-before">The output of the previous code block is as follows (assuming a 5% significance level):</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># The original S&amp;P 500 dataset is nonstationary</code>&#13;
<code class="n">p</code><code class="o">-</code><code class="n">value</code><code class="p">:</code> <code class="mf">0.842099</code> &#13;
<code class="c1"># The fractionally differentiated S&amp;P 500 dataset is stationary</code>&#13;
<code class="n">p</code><code class="o">-</code><code class="n">value</code><code class="p">:</code> <code class="mf">0.038829</code>&#13;
<code class="c1"># The normally differenced S&amp;P 500 dataset is stationary</code>&#13;
<code class="n">p</code><code class="o">-</code><code class="n">value</code><code class="p">:</code> <code class="mf">0.000000</code>&#13;
</pre>&#13;
&#13;
<p>As the results show, the data is indeed stationary. Let’s look at another example. The following code imports the daily values of the EURUSD:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">((</code><code class="n">pdr</code><code class="o">.</code><code class="n">get_data_fred</code><code class="p">(</code><code class="s1">'DEXUSEU'</code><code class="p">,</code> <code class="n">start</code> <code class="o">=</code> <code class="n">start_date</code><code class="p">,</code> &#13;
                                   <code class="n">end</code> <code class="o">=</code> <code class="n">end_date</code><code class="p">))</code><code class="o">.</code><code class="n">dropna</code><code class="p">())</code></pre>&#13;
&#13;
<p><a data-type="xref" href="#figure-9-2">Figure 9-2</a> compares the EURUSD with fractional differentiation (0.20) applied onto it, with the regular differencing shown in the bottom panel.</p>&#13;
&#13;
<figure><div class="figure" id="figure-9-2"><img alt="" class="iimagesbeta_fract_22png" src="assets/dlff_0902.png"/>&#13;
<h6><span class="label">Figure 9-2. </span>Fractional differentiation on the EURUSD (order = 0.20)</h6>&#13;
</div></figure>&#13;
&#13;
<p>The results of the ADF test are as follows:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># The original EURUSD dataset is nonstationary</code>&#13;
<code class="n">p</code><code class="o">-</code><code class="n">value</code><code class="p">:</code> <code class="mf">0.397494</code>&#13;
<code class="c1"># The fractionally differentiated EURUSD  dataset is stationary</code>&#13;
<code class="n">p</code><code class="o">-</code><code class="n">value</code><code class="p">:</code> <code class="mf">0.043214</code>&#13;
<code class="c1"># The normally differenced EURUSD  dataset is stationary</code>&#13;
<code class="n">p</code><code class="o">-</code><code class="n">value</code><code class="p">:</code> <code class="mf">0.000000</code> </pre>&#13;
&#13;
<p class="pagebreak-before">As a comparison, <a data-type="xref" href="#figure-9-3">Figure 9-3</a> compares the same dataset with fractional differentiation (0.30) applied onto it, with the regular differencing shown in the bottom panel.</p>&#13;
&#13;
<figure><div class="figure" id="figure-9-3"><img alt="" class="iimagesbeta_fract_3png" src="assets/dlff_0903.png"/>&#13;
<h6><span class="label">Figure 9-3. </span>Fractional differentiation on EURUSD (order = 0.30)</h6>&#13;
</div></figure>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Approaching an order of 1.00 intuitively makes the fractional differentiation approach a normal integer differencing. Similarly, approaching an order of 0.00 makes the fractional differentiation approach the untransformed data series.</p>&#13;
</div>&#13;
&#13;
<p><a data-type="xref" href="#figure-9-3">Figure 9-3</a> shows a more stationary EURUSD series in the middle panel than <a data-type="xref" href="#figure-9-2">Figure 9-2</a> does, and this is because the order of fractional differentiation is increased. This is why the ADF test result for the fractional differentiation of order = 0.30 is 0.002, which is much lower than the ADF test result when order = 0.20 (which is at 0.043).</p>&#13;
&#13;
<p>In summary, fractional differentiation is a valuable tool for time series prediction as it captures long-term dependencies, handles nonstationarity, adapts to various dynamics, and preserves integral properties. Its ability to capture complex patterns and improve forecasting accuracy makes it a good fit for modeling and predicting a wide range of real-world time series data.<a contenteditable="false" data-primary="" data-startref="Chapter_9.html2" data-type="indexterm" id="id738"/><a contenteditable="false" data-primary="" data-startref="Chapter_9.html1" data-type="indexterm" id="id739"/></p>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Forecasting Threshold" data-type="sect1"><div class="sect1" id="id72">&#13;
<h1 class="less_space">Forecasting Threshold</h1>&#13;
&#13;
<p><a contenteditable="false" data-primary="forecasting threshold" data-type="indexterm" id="Chapter_9.html3"/><a contenteditable="false" data-primary="time series prediction (deep learning techniques and methods for)" data-secondary="forecasting threshold" data-type="indexterm" id="Chapter_9.html4"/>The <em>forecasting threshold </em>is the minimum required percentage prediction to validate a signal. This means that the forecasting threshold technique is a filter that removes low conviction predictions.</p>&#13;
&#13;
<p>Objectively, low conviction predictions are below a certain percentage. A hypothetical example is shown in <a data-type="xref" href="#table-9-1">Table 9-1</a>. The threshold is ±1%.</p>&#13;
&#13;
<table id="table-9-1">&#13;
	<caption><span class="label">Table 9-1. </span>Table of forecasts</caption>&#13;
	&#13;
<thead>&#13;
		<tr>&#13;
			<th>Time</th>&#13;
			<th>Forecast</th>&#13;
			<th>Status</th>&#13;
		</tr></thead>&#13;
			<tbody>&#13;
		<tr>&#13;
			<td class="right">1</td>&#13;
			<td class="right">0.09%</td>&#13;
			<td class="right">Dismissed</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td class="right">2</td>&#13;
			<td class="right">–0.60%</td>&#13;
			<td class="right">Dismissed</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td class="right">3</td>&#13;
			<td class="right">–1.50%</td>&#13;
			<td class="right">Taken</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td class="right">4</td>&#13;
			<td class="right">1.00%</td>&#13;
			<td class="right">Taken</td>&#13;
		</tr>&#13;
		<tr>&#13;
			<td class="right">5</td>&#13;
			<td class="right">2.33%</td>&#13;
			<td class="right">Taken</td>&#13;
		</tr>&#13;
	</tbody>&#13;
</table>&#13;
&#13;
<p>At time 1, the trading signal is bullish, with an expectation of a 0.09% rise in the hypothetical financial instrument. As this prediction is below the threshold of 1.00%, the trade is not taken. At time 2, the same intuition is applied, as the bearish signal is below the threshold.</p>&#13;
&#13;
<p>The rest of the signals are taken since they are equal to or greater than the threshold (in terms of magnitude). The aim of this section is to develop a multilayer perceptron (MLP) model and keep only the predictions that respect a certain threshold.</p>&#13;
&#13;
<p>As usual, start by importing the required libraries:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="k">as</code> <code class="nn">plt</code>&#13;
<code class="kn">from</code> <code class="nn">keras.models</code> <code class="kn">import</code> <code class="n">Sequential</code>&#13;
<code class="kn">from</code> <code class="nn">keras.layers</code> <code class="kn">import</code> <code class="n">Dense</code>&#13;
<code class="kn">from</code> <code class="nn">master_function</code> <code class="kn">import</code> <code class="n">data_preprocessing</code><code class="p">,</code> <code class="n">mass_import</code>&#13;
<code class="kn">from</code> <code class="nn">master_function</code> <code class="kn">import</code> <code class="n">plot_train_test_values</code><code class="p">,</code> <code class="n">forecasting_threshold</code>&#13;
</pre>&#13;
&#13;
<p>Next, set the hyperparameters and import the data using <code>mass_import()</code>:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">num_lags</code> <code class="o">=</code> <code class="mi">500</code>&#13;
<code class="n">train_test_split</code> <code class="o">=</code> <code class="mf">0.80</code> &#13;
<code class="n">num_neurons_in_hidden_layers</code> <code class="o">=</code> <code class="mi">256</code> &#13;
<code class="n">num_epochs</code> <code class="o">=</code> <code class="mi">100</code> &#13;
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">10</code>&#13;
<code class="n">threshold</code> <code class="o">=</code> <code class="mf">0.0015</code>&#13;
</pre>&#13;
&#13;
<p>Import and preprocess the data, then design the MLP architecture:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Fetching the historical price data</code>&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">diff</code><code class="p">(</code><code class="n">mass_import</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="s1">'D1'</code><code class="p">)[:,</code> <code class="mi">3</code><code class="p">])</code>&#13;
<code class="c1"># Creating the training and test sets</code>&#13;
<code class="n">x_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">x_test</code><code class="p">,</code> <code class="n">y_test</code> <code class="o">=</code> <code class="n">data_preprocessing</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">num_lags</code><code class="p">,</code> &#13;
                                                      <code class="n">train_test_split</code><code class="p">)</code>&#13;
<code class="c1"># Designing the architecture of the model</code>&#13;
<code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
<code class="c1"># First hidden layer</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">num_neurons_in_hidden_layers</code><code class="p">,</code> <code class="n">input_dim</code> <code class="o">=</code> <code class="n">num_lags</code><code class="p">,</code> &#13;
                <code class="n">activation</code> <code class="o">=</code> <code class="s1">'relu'</code><code class="p">))</code>  &#13;
<code class="c1"># Second hidden layer</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">num_neurons_in_hidden_layers</code><code class="p">,</code> <code class="n">activation</code> <code class="o">=</code> <code class="s1">'relu'</code><code class="p">))</code>&#13;
<code class="c1"># Output layer</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">))</code>&#13;
<code class="c1"># Compiling</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code> <code class="o">=</code> <code class="s1">'mean_squared_error'</code><code class="p">,</code> <code class="n">optimizer</code> <code class="o">=</code> <code class="s1">'adam'</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>The next step is to fit and predict the data and retain the predictions that satisfy the threshold you have defined in the hyperparameters. This is done using the function <code>forecasting_threshold()</code>:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Fitting</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">epochs</code> <code class="o">=</code> <code class="n">num_epochs</code><code class="p">,</code> <code class="n">batch_size</code> <code class="o">=</code> <code class="n">batch_size</code><code class="p">)</code>&#13;
<code class="c1"># Predicting</code>&#13;
<code class="n">y_predicted</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x_test</code><code class="p">)</code>&#13;
<code class="c1"># Threshold function</code>&#13;
<code class="n">y_predicted</code> <code class="o">=</code> <code class="n">forecasting_threshold</code><code class="p">(</code><code class="n">y_predicted</code><code class="p">,</code> <code class="n">threshold</code><code class="p">)</code>&#13;
<code class="c1"># Plotting</code>&#13;
<code class="n">plot_train_test_values</code><code class="p">(</code><code class="mi">100</code><code class="p">,</code> <code class="mi">50</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">y_test</code><code class="p">,</code> <code class="n">y_predicted</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p><a data-type="xref" href="#figure-9-4">Figure 9-4</a> shows the comparison chart between the real values and the predicted values. Flat observations on the predictions indicate the absence of signals that are lower than the required threshold—in this case, 0.0015.</p>&#13;
&#13;
<figure><div class="figure" id="figure-9-4"><img alt="" class="iimagesthesholdpng" src="assets/dlff_0904.png"/>&#13;
<h6><span class="label">Figure 9-4. </span>Predicting with the forecasting threshold</h6>&#13;
</div></figure>&#13;
&#13;
<p class="pagebreak-before">The threshold can be found in many ways, notably:</p>&#13;
&#13;
<dl>&#13;
	<dt>The fixed numerical technique</dt><dd><p>As you saw in the previous example, this technique assumes a fixed arbitrary number to be used as a threshold.</p></dd>&#13;
	<dt>The volatility-based technique</dt><dd><p>With this technique, you use a volatility indicator such as a rolling standard deviation of prices to set a variable threshold at each time step. This technique has the benefit of using up-to-date volatility information.</p></dd>&#13;
	<dt>The statistical technique</dt><dd><p>With this technique, you look at the real values from the training set (not the test set) and select a certain quantile (e.g., the 75% quantile) as a minimum threshold to validate the signals.</p></dd>&#13;
</dl>&#13;
&#13;
<p>To summarize, using the forecasting threshold may help select the trades with the highest conviction and can also help minimize transaction costs since the algorithms assume trading all the time, which is not recommended. This assumes adding a new state to the algorithm, which gives a total of three:</p>&#13;
&#13;
<dl>&#13;
 <dt>Bullish signal</dt>&#13;
 <dd><p>The algorithm predicts a higher value.</p></dd>&#13;
 &#13;
<dt>Bearish signal</dt>&#13;
<dd><p>The algorithm predicts a lower value.</p></dd>&#13;
&#13;
<dt>Neutral signal</dt>&#13;
<dd><p>The algorithm does not have any directional conviction.<a contenteditable="false" data-primary="" data-startref="Chapter_9.html4" data-type="indexterm" id="id740"/><a contenteditable="false" data-primary="" data-startref="Chapter_9.html3" data-type="indexterm" id="id741"/></p></dd>&#13;
</dl>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Continuous Retraining" data-type="sect1"><div class="sect1" id="id73">&#13;
<h1>Continuous Retraining</h1>&#13;
&#13;
<p><a contenteditable="false" data-primary="continuous retraining" data-type="indexterm" id="Chapter_9.html5"/><a contenteditable="false" data-primary="retraining, continuous" data-type="indexterm" id="Chapter_9.html6"/><a contenteditable="false" data-primary="time series prediction (deep learning techniques and methods for)" data-secondary="continuous retraining" data-type="indexterm" id="Chapter_9.html7"/><em>Retraining </em>refers to the act of training the algorithm every time new data comes in. This means that when dealing with a daily time series, the retraining is done every day while incorporating the latest daily inputs.</p>&#13;
&#13;
<p>The continuous retraining technique deserves to be tested, and that is the aim of this section. The architecture of the algorithm will follow this framework:</p>&#13;
&#13;
<ol>&#13;
	<li>Train the data on the training test.</li>&#13;
	<li>For each prediction made, rerun the algorithm and include the new real inputs in the training set.</li>&#13;
</ol>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>One big limitation of the continuous retraining technique is the speed of the algorithm, as it has to retrain at every time step. If you have 1,000 instances of test data where every training requires a few minutes, then the backtesting process becomes drastically slow. This is especially an issue with deep learning algorithms such as LSTM, which may take a long time to train.</p>&#13;
</div>&#13;
&#13;
<p>The main reason for applying continuous retraining is because of <em>concept drift</em>, which is the change in the data’s inner dynamics and structures that may invalidate the function found in the training phase. Basically, financial time series do not exhibit static relationships; rather, they change over time. Therefore, continuous retraining aims to update the models by always using the latest data to train.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Continuous retraining does not need to be done at every time step. You can set <em>n</em> periods for the retraining. For example, if you select 10, then the model retrains after each group of 10 new values.</p>&#13;
</div>&#13;
&#13;
<p>To simplify things, this section shows the code for the continuous retraining (every day) using a linear regression model on the weekly EURUSD values at every time step. You can do the same thing with other models; you just have to change the lines of code where the model is imported and designed. First, import the required <span class="keep-together">libraries:</span></p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="k">as</code> <code class="nn">plt</code>&#13;
<code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="kn">import</code> <code class="n">LinearRegression</code>&#13;
<code class="kn">from</code> <code class="nn">master_function</code> <code class="kn">import</code> <code class="n">data_preprocessing</code><code class="p">,</code> <code class="n">mass_import</code>&#13;
<code class="kn">from</code> <code class="nn">master_function</code> <code class="kn">import</code> <code class="n">plot_train_test_values</code><code class="p">,</code> &#13;
<code class="kn">from</code> <code class="nn">master_function</code> <code class="kn">import</code> <code class="n">calculate_accuracy</code><code class="p">,</code> <code class="n">model_bias</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">mean_squared_error</code>&#13;
</pre>&#13;
&#13;
<p>Import the data and set the hyperparameters of the algorithm:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Importing the time series</code>&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">diff</code><code class="p">(</code><code class="n">mass_import</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="s1">'D1'</code><code class="p">)[:,</code> <code class="mi">3</code><code class="p">])</code>&#13;
<code class="c1"># Setting the hyperparameters</code>&#13;
<code class="n">num_lags</code> <code class="o">=</code> <code class="mi">15</code>&#13;
<code class="n">train_test_split</code> <code class="o">=</code> <code class="mf">0.80</code> &#13;
<code class="c1"># Creating the training and test sets</code>&#13;
<code class="n">x_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">x_test</code><code class="p">,</code> <code class="n">y_test</code> <code class="o">=</code> <code class="n">data_preprocessing</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">num_lags</code><code class="p">,</code> &#13;
                                                      <code class="n">train_test_split</code><code class="p">)</code>&#13;
<code class="c1"># Fitting the model</code>&#13;
<code class="n">model</code> <code class="o">=</code> <code class="n">LinearRegression</code><code class="p">()</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code>&#13;
<code class="c1"># Predicting in-sample</code>&#13;
<code class="n">y_predicted_train</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x_train</code><code class="p">),</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code>&#13;
</pre>&#13;
&#13;
<p>Create the continuous retraining loop as follows:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Store the new forecasts</code>&#13;
<code class="n">y_predicted</code> <code class="o">=</code> <code class="p">[]</code>&#13;
<code class="c1"># Reshape x_test to forecast one period</code>&#13;
<code class="n">latest_values</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">transpose</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">x_test</code><code class="p">[</code><code class="mi">0</code><code class="p">],</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)))</code>&#13;
<code class="c1"># Isolate the real values for comparison</code>&#13;
<code class="n">y_test_store</code> <code class="o">=</code> <code class="n">y_test</code>&#13;
<code class="n">y_train_store</code> <code class="o">=</code> <code class="n">y_train</code>&#13;
<code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="nb">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">y_test</code><code class="p">)):</code>&#13;
    <code class="k">try</code><code class="p">:</code> &#13;
        <code class="c1"># Predict over the first x_test data</code>&#13;
        <code class="n">predicted_value</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">latest_values</code><code class="p">)</code>&#13;
        <code class="c1"># Store the prediction in an array</code>&#13;
        <code class="n">y_predicted</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">y_predicted</code><code class="p">,</code> <code class="n">predicted_value</code><code class="p">)</code>&#13;
        <code class="c1"># Add the first test values to the last training values</code>&#13;
        <code class="n">x_train</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">concatenate</code><code class="p">((</code><code class="n">x_train</code><code class="p">,</code> <code class="n">latest_values</code><code class="p">),</code> <code class="n">axis</code> <code class="o">=</code> <code class="mi">0</code><code class="p">)</code>&#13;
        <code class="n">y_train</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">y_train</code><code class="p">,</code> <code class="n">y_test</code><code class="p">[</code><code class="mi">0</code><code class="p">])</code>&#13;
        <code class="c1"># Remove the first test values from the test arrays</code>&#13;
        <code class="n">y_test</code> <code class="o">=</code> <code class="n">y_test</code><code class="p">[</code><code class="mi">1</code><code class="p">:]</code>&#13;
        <code class="n">x_test</code> <code class="o">=</code> <code class="n">x_test</code><code class="p">[</code><code class="mi">1</code><code class="p">:,</code> <code class="p">]</code>&#13;
        <code class="c1"># Retrain</code>&#13;
        <code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">)</code>&#13;
        <code class="c1"># Select the first values of the test set</code>&#13;
        <code class="n">latest_values</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">transpose</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">x_test</code><code class="p">[</code><code class="mi">0</code><code class="p">],</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)))</code>&#13;
    <code class="k">except</code> <code class="ne">IndexError</code><code class="p">:</code>&#13;
        <code class="k">pass</code>&#13;
</pre>&#13;
&#13;
<p>Plot the predicted values:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">plot_train_test_values</code><code class="p">(</code><code class="mi">100</code><code class="p">,</code> <code class="mi">50</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">y_test_store</code><code class="p">,</code> <code class="n">y_predicted</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p><a data-type="xref" href="#figure-9-5">Figure 9-5</a> shows the result.</p>&#13;
&#13;
<p>As a simple comparison, the same backtest was done on the model with no retraining. The latter got a 48.55% test set accuracy compared to the 48.92% test set accuracy for the same model with retraining.</p>&#13;
&#13;
<p>Continuous retraining is not a guarantee for better results, but it makes sense to update the model every once in a while due to changing market dynamics. The frequency at which you should update the model may be subjective.<a contenteditable="false" data-primary="" data-startref="Chapter_9.html7" data-type="indexterm" id="id742"/><a contenteditable="false" data-primary="" data-startref="Chapter_9.html6" data-type="indexterm" id="id743"/><a contenteditable="false" data-primary="" data-startref="Chapter_9.html5" data-type="indexterm" id="id744"/></p>&#13;
&#13;
<figure><div class="figure" id="figure-9-5"><img alt="" class="iimagesdlf_0905png" src="assets/dlff_0905.png"/>&#13;
<h6><span class="label">Figure 9-5. </span>Predicting using the continuous retraining technique</h6>&#13;
</div></figure>&#13;
&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Time Series Cross Validation" data-type="sect1"><div class="sect1" id="id74">&#13;
<h1>Time Series Cross Validation</h1>&#13;
&#13;
<p><a contenteditable="false" data-primary="cross validation" data-type="indexterm" id="Chapter_9.html8"/><a contenteditable="false" data-primary="cross validation" data-secondary="time series cross validation" data-type="indexterm" id="Chapter_9.html9"/><a contenteditable="false" data-primary="time series cross validation" data-type="indexterm" id="Chapter_9.html10"/><a contenteditable="false" data-primary="time series prediction (deep learning techniques and methods for)" data-secondary="time series cross validation" data-type="indexterm" id="Chapter_9.html11"/><em>Cross validation</em> is a technique used in machine learning to assess the performance of a model. It involves splitting the available data into subsets for training and evaluation. In the case of time series data, where the order of observations is important (due to the sequential nature of the data), a traditional <em>k</em>-fold cross validation approach may not be suitable. Instead, time series cross validation techniques are used, such as the <em>rolling window</em> and <em>expanding window</em> methods.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p><a contenteditable="false" data-primary="k-fold cross validation" data-type="indexterm" id="id745"/>In traditional <em>k-fold cross validation</em>, the data is randomly split into <em>k </em>equally sized folds. Each fold is used as a validation set, while the remaining <em>k – 1</em> folds are combined for training the model. The process is repeated <em>k </em>times, with each fold serving as the validation set once. Finally, the performance metrics are averaged across the <em>k </em>iterations to assess the model’s performance.</p>&#13;
</div>&#13;
&#13;
<p>Unlike traditional <em>k</em>-fold cross validation, time series cross validation methods respect the temporal order of data points. Two commonly used techniques for time series cross validation are the rolling window and expanding window methods.</p>&#13;
&#13;
<p><a contenteditable="false" data-primary="rolling window cross validation" data-type="indexterm" id="id746"/>In <em>rolling window cross validation</em>, a fixed-size training window is moved iteratively over the time series data. At each step, the model is trained on the observations within the window and evaluated on the subsequent window. This process is repeated until the end of the data is reached. The window size can be defined based on a <span class="keep-together">specific</span> time duration or a fixed number of observations. <a data-type="xref" href="#figure-9-6">Figure 9-6</a> shows an illustration of rolling window cross validation.</p>&#13;
&#13;
&#13;
<figure><div class="figure" id="figure-9-6"><img alt="" class="icv_rollingpng" src="assets/dlff_0906.png"/>&#13;
<h6><span class="label">Figure 9-6. </span>Rolling window cross validation</h6>&#13;
</div></figure>&#13;
&#13;
<p><a contenteditable="false" data-primary="expanding window cross validation" data-type="indexterm" id="id747"/>In <em>expanding window cross validation</em>, the training set starts with a small initial window and expands over time, incorporating additional data points at each step. The model is trained on the available data up to a specific point and evaluated on the subsequent time period. Similar to the rolling window approach, this process is repeated until the end of the data is reached. <a data-type="xref" href="#figure-9-7">Figure 9-7</a> shows an illustration of expanding window cross validation.</p>&#13;
&#13;
<figure><div class="figure" id="figure-9-7"><img alt="" class="icv_expandingpng" src="assets/dlff_0907.png"/>&#13;
<h6><span class="label">Figure 9-7. </span>Expanding window cross validation</h6>&#13;
</div></figure>&#13;
&#13;
<p>During each iteration of time series cross validation, the model’s performance is measured using appropriate evaluation metrics. The performance results obtained from each iteration can be aggregated and summarized to assess the model’s overall performance on the time series data.<a contenteditable="false" data-primary="" data-startref="Chapter_9.html11" data-type="indexterm" id="id748"/><a contenteditable="false" data-primary="" data-startref="Chapter_9.html10" data-type="indexterm" id="id749"/><a contenteditable="false" data-primary="" data-startref="Chapter_9.html9" data-type="indexterm" id="id750"/><a contenteditable="false" data-primary="" data-startref="Chapter_9.html8" data-type="indexterm" id="id751"/></p>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Multiperiod Forecasting" data-type="sect1"><div class="sect1" id="id75">&#13;
<h1>Multiperiod Forecasting</h1>&#13;
&#13;
<p><a contenteditable="false" data-primary="multiperiod forecasting (MPF)" data-type="indexterm" id="Chapter_9.html12"/><a contenteditable="false" data-primary="MPF (multiperiod forecasting)" data-type="indexterm" id="Chapter_9.html12a"/><a contenteditable="false" data-primary="time series prediction (deep learning algorithms for)" data-secondary="multiperiod forecasting" data-type="indexterm" id="Chapter_9.html13"/><em>Multiperiod forecasting </em>(MPF) is a technique that aims to forecast more than just the next period. It aims to generate a path with <em>n</em> periods as defined by the user. There are two ways to approach MPF:</p>&#13;
&#13;
<dl>&#13;
 <dt>Recursive model</dt>&#13;
 <dd><p>The <em>recursive model</em> uses the prediction as an input for the next prediction. As you may have already guessed, the recursive model may quickly get off track due to the exponentially rising error term from predicting while using predictions as inputs.</p></dd>&#13;
 &#13;
 <dt>Direct model</dt>&#13;
 <dd><p>The <em>direct model</em> trains the model from the beginning into outputting multiple forecasts in their respective time periods. This model is likely to be more robust than the recursive model.</p></dd>&#13;
</dl>&#13;
&#13;
<p><a contenteditable="false" data-primary="recursive model" data-secondary="multiperiod forecasting" data-type="indexterm" id="Chapter_9.html14"/>Let’s start with the recursive model. Mathematically speaking, its most basic form can be represented as follows:</p>&#13;
&#13;
<div data-type="equation"><p><math alttext="upper P r e d i c t i o n Subscript i Baseline equals f x left-parenthesis upper P r e d i c t i o n Subscript i minus 1 Baseline comma period period period comma upper P r e d i c t i o n Subscript i minus n Baseline right-parenthesis">&#13;
  <mrow>&#13;
    <mi>P</mi>&#13;
    <mi>r</mi>&#13;
    <mi>e</mi>&#13;
    <mi>d</mi>&#13;
    <mi>i</mi>&#13;
    <mi>c</mi>&#13;
    <mi>t</mi>&#13;
    <mi>i</mi>&#13;
    <mi>o</mi>&#13;
    <msub><mi>n</mi> <mi>i</mi> </msub>&#13;
    <mo>=</mo>&#13;
    <mi>f</mi>&#13;
    <mi>x</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>P</mi>&#13;
      <mi>r</mi>&#13;
      <mi>e</mi>&#13;
      <mi>d</mi>&#13;
      <mi>i</mi>&#13;
      <mi>c</mi>&#13;
      <mi>t</mi>&#13;
      <mi>i</mi>&#13;
      <mi>o</mi>&#13;
      <msub><mi>n</mi> <mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow> </msub>&#13;
      <mo>,</mo>&#13;
      <mo lspace="0%" rspace="0%">.</mo>&#13;
      <mo lspace="0%" rspace="0%">.</mo>&#13;
      <mo lspace="0%" rspace="0%">.</mo>&#13;
      <mo>,</mo>&#13;
      <mi>P</mi>&#13;
      <mi>r</mi>&#13;
      <mi>e</mi>&#13;
      <mi>d</mi>&#13;
      <mi>i</mi>&#13;
      <mi>c</mi>&#13;
      <mi>t</mi>&#13;
      <mi>i</mi>&#13;
      <mi>o</mi>&#13;
      <msub><mi>n</mi> <mrow><mi>i</mi><mo>-</mo><mi>n</mi></mrow> </msub>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
  </mrow>&#13;
</math></p></div>&#13;
&#13;
<p>This section will use weather data and an economic indicator to apply the deep learning algorithm.</p>&#13;
&#13;
<p>The first step in predictive analysis is to get to know the data, so let’s see what the algorithm will aim to forecast. The first time series is the average daily temperature in Basel, Switzerland, since 2005. <a data-type="xref" href="#figure-9-8">Figure 9-8</a> shows the time series.</p>&#13;
&#13;
<p>The second time series is the Institute for Supply Management’s Purchasing Managers’ Index (ISM PMI), a widely recognized economic indicator in the United States that provides insight into the health of the manufacturing sector and the overall economy. The index is based on a monthly survey of purchasing managers from various industries, including manufacturing, and assesses key factors such as new orders, production, employment, supplier deliveries, and inventories.</p>&#13;
&#13;
<figure><div class="figure" id="figure-9-8"><img alt="" class="iimagestemperature_baselpng" src="assets/dlff_0908.png"/>&#13;
<h6><span class="label">Figure 9-8. </span>A sample from the dataset showing the seasonal nature of temperature</h6>&#13;
</div></figure>&#13;
&#13;
<p>The index is reported as a percentage, with a value above 50 indicating expansion in the manufacturing sector and a value below 50 suggesting contraction. A higher PMI typically indicates positive economic growth, while a lower PMI may signal economic slowdown or recessionary conditions. The ISM PMI is closely monitored by policymakers, investors, and businesses as it can offer valuable insights into economic trends and potential shifts in the business cycle. <a data-type="xref" href="#figure-9-9">Figure 9-9</a> shows the ISM PMI <span class="keep-together">historical observations.</span></p>&#13;
&#13;
<p>The aim of the forecast is to test the algorithm’s ability to push through the noise and model the original mean-reverting nature of the ISM PMI. Let’s start with the recursive model.</p>&#13;
&#13;
<p>The framework for the recursive model is as follows:</p>&#13;
&#13;
<ol>&#13;
	<li>Train the data on the training set using the usual 80/20 split.</li>&#13;
	<li>Forecast the first observation using the inputs needed from the test set.</li>&#13;
	<li>Forecast the second observation using the last prediction in step 2 and the required data from the test set while dropping the first observation.</li>&#13;
	<li>Repeat step 3 until reaching the desired number of predictions. At some point, a prediction is made by solely looking at previous predictions.</li>&#13;
</ol>&#13;
&#13;
<figure><div class="figure" id="figure-9-9"><img alt="" class="iimagesism_pmipng" src="assets/dlff_0909.png"/>&#13;
<h6><span class="label">Figure 9-9. </span>A sample from the imported dataset showing the mean-reverting nature of the ISM PMI</h6>&#13;
</div></figure>&#13;
&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Up until now, you have been evaluating accuracy using <code>ca⁠lc⁠ul⁠ate_​ac⁠cur⁠acy()</code>, which works when you are predicting positive or negative values (such as EURUSD price changes). When dealing with multiperiod forecasting of values that do not hover around zero, it is better to calculate the directional accuracy, which is basically the same calculation but does not hover around zero. For this, the function <code>calculate_directional_accuracy()</code> is used. Remember that the functions can be found in <em>master_function.py</em> in the book’s <a href="https://oreil.ly/5YGHI">GitHub repository</a>.</p>&#13;
</div>&#13;
&#13;
<p>Let’s start with the average temperature in Basel. Import the dataset using the following code (make sure you download the historical observations data from the <a href="https://oreil.ly/5YGHI">GitHub repository</a>):</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">keras.models</code> <code class="kn">import</code> <code class="n">Sequential</code>&#13;
<code class="kn">from</code> <code class="nn">keras.layers</code> <code class="kn">import</code> <code class="n">Dense</code>&#13;
<code class="kn">import</code> <code class="nn">keras</code>&#13;
<code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>&#13;
<code class="kn">import</code> <code class="nn">pandas</code> <code class="k">as</code> <code class="nn">pd</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="k">as</code> <code class="nn">plt</code>&#13;
<code class="kn">from</code> <code class="nn">master_function</code> <code class="kn">import</code> <code class="n">data_preprocessing</code><code class="p">,</code> <code class="n">plot_train_test_values</code><code class="p">,</code> &#13;
<code class="kn">from</code> <code class="nn">master_function</code> <code class="kn">import</code> <code class="n">recursive_mpf</code>&#13;
<code class="kn">from</code> <code class="nn">master_function</code> <code class="kn">import</code> <code class="n">calculate_directional_accuracy</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">mean_squared_error</code>&#13;
</pre>&#13;
&#13;
<p class="pagebreak-before">Next, preprocess the data:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Importing the data</code>&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">pd</code><code class="o">.</code><code class="n">read_excel</code><code class="p">(</code><code class="s1">'Temperature_Basel.xlsx'</code><code class="p">)</code><code class="o">.</code><code class="n">dropna</code><code class="p">()</code>&#13;
                  <code class="p">),</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">))</code>&#13;
<code class="c1"># Setting the hyperparameters</code>&#13;
<code class="n">num_lags</code> <code class="o">=</code> <code class="mi">500</code>&#13;
<code class="n">train_test_split</code> <code class="o">=</code> <code class="mf">0.8</code>&#13;
<code class="n">num_neurons_in_hidden_layers</code> <code class="o">=</code> <code class="mi">100</code>&#13;
<code class="n">num_epochs</code> <code class="o">=</code> <code class="mi">200</code>&#13;
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">12</code>&#13;
<code class="c1"># Creating the training and test sets</code>&#13;
<code class="n">x_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">x_test</code><code class="p">,</code> <code class="n">y_test</code> <code class="o">=</code> <code class="n">data_preprocessing</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">num_lags</code><code class="p">,</code> &#13;
                                                      <code class="n">train_test_split</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>Design the architecture of the MLP with multiple hidden layers. Then, fit and predict on a recursive basis:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Designing the architecture of the model</code>&#13;
<code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
<code class="c1"># First hidden layer</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">num_neurons_in_hidden_layers</code><code class="p">,</code> <code class="n">input_dim</code> <code class="o">=</code> <code class="n">num_lags</code><code class="p">,</code> &#13;
          <code class="n">activation</code> <code class="o">=</code> <code class="s1">'relu'</code><code class="p">))</code>  &#13;
<code class="c1"># Second hidden layer</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">num_neurons_in_hidden_layers</code><code class="p">,</code> <code class="n">activation</code> <code class="o">=</code> <code class="s1">'relu'</code><code class="p">))</code>  &#13;
<code class="c1"># Third hidden layer</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">num_neurons_in_hidden_layers</code><code class="p">,</code> <code class="n">activation</code> <code class="o">=</code> <code class="s1">'relu'</code><code class="p">))</code>  &#13;
<code class="c1"># Fourth hidden layer</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">num_neurons_in_hidden_layers</code><code class="p">,</code> <code class="n">activation</code> <code class="o">=</code> <code class="s1">'relu'</code><code class="p">))</code> &#13;
<code class="c1"># Output layer</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">))</code>&#13;
<code class="c1"># Compiling</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code> <code class="o">=</code> <code class="s1">'mean_squared_error'</code><code class="p">,</code> <code class="n">optimizer</code> <code class="o">=</code> <code class="s1">'adam'</code><code class="p">)</code>&#13;
<code class="c1"># Fitting the model</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x_train</code><code class="p">,</code> <code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">y_train</code><code class="p">,</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">)),</code> <code class="n">epochs</code> <code class="o">=</code> <code class="n">num_epochs</code><code class="p">,</code> &#13;
          <code class="n">batch_size</code> <code class="o">=</code> <code class="n">batch_size</code><code class="p">)</code>&#13;
<code class="c1"># Predicting in-sample</code>&#13;
<code class="n">y_predicted_train</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x_train</code><code class="p">),</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code>&#13;
<code class="c1"># Predicting in the test set on a recursive basis</code>&#13;
<code class="n">x_test</code><code class="p">,</code> <code class="n">y_predicted</code> <code class="o">=</code> <code class="n">recursive_mpf</code><code class="p">(</code><code class="n">x_test</code><code class="p">,</code> <code class="n">y_test</code><code class="p">,</code> <code class="n">num_lags</code><code class="p">,</code> &#13;
                                    <code class="n">model</code><code class="p">,</code> <code class="n">architecture</code> <code class="o">=</code> <code class="s1">'MLP'</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>The <code>recursive_mpf()</code> function takes the following arguments:</p>&#13;
&#13;
<ul>&#13;
	<li>The test set features that will continuously be updated. They are represented by the variable <code>x_test</code>.</li>&#13;
	<li>The test set dependent variables. They are represented by the variable <code>y_test</code>.</li>&#13;
	<li>The number of lags. This variable is represented by <code>num_lags</code>.</li>&#13;
	<li>The fitted model as defined by the variable <code>model</code>.</li>&#13;
	<li>The type of architecture as represented by the argument <code>architecture</code>. It can either be <code>MLP</code> for two-dimensional arrays or <code>LSTM</code> for three-dimensional arrays.</li>&#13;
</ul>&#13;
&#13;
<p><a data-type="xref" href="#figure-9-10">Figure 9-10</a> shows the predictions versus the real values (the dashed time series after the cutoff line). Notice how the deep neural network re-creates the seasonal characteristics of the time series (albeit with some imperfections) and projects it well into the future with no required knowledge along the way.</p>&#13;
&#13;
<figure><div class="figure" id="figure-9-10"><img alt="" class="iimagespred_mlp_weather_recursivepng" src="assets/dlff_0910.png"/>&#13;
<h6><span class="label">Figure 9-10. </span>Multiperiod forecasts versus real values</h6>&#13;
</div></figure>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>Many machine and deep learning algorithms are able to model this relationship well. This example used MLPs, but this does not undermine other models, even simple ones such as linear regression. A good task for you would be to try applying the same example using a model of your choice (such as LSTM) and comparing the results. If you are using an LSTM model, make sure you set <code>architecture = 'LSTM'</code>.</p>&#13;
</div>&#13;
&#13;
<p>Now apply the same process on the second time series. You only need to change the name of the imported file and the hyperparameters (as you see fit):</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">pd</code><code class="o">.</code><code class="n">read_excel</code><code class="p">(</code><code class="s1">'ISM_PMI.xlsx'</code><code class="p">)</code><code class="o">.</code><code class="n">dropna</code><code class="p">()),</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">))</code>&#13;
</pre>&#13;
&#13;
<p><a data-type="xref" href="#figure-9-11">Figure 9-11</a> shows the predictions (dashed line) versus the real values.</p>&#13;
&#13;
<figure><div class="figure" id="figure-9-11"><img alt="" class="iimagespred_mlp_pmi_recursivepng" src="assets/dlff_0911.png"/>&#13;
<h6><span class="label">Figure 9-11. </span>Forecasting multiple periods ahead; predicted data in thin solid line and test data in dashed line</h6>&#13;
</div></figure>&#13;
&#13;
<p>The trained model is not too complex so as to avoid overfitting. However, it does manage to time turning points quite well during the first projections. Naturally, over time, this ability slowly fades away. Tweaking the hyperparameters is the key to achieving good directional accuracy. Start with the following hyperparameters:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">num_lags</code> <code class="o">=</code> <code class="mi">200</code>&#13;
<code class="n">train_test_split</code> <code class="o">=</code> <code class="mf">0.8</code>&#13;
<code class="n">num_neurons_in_hidden_layers</code> <code class="o">=</code> <code class="mi">500</code>&#13;
<code class="n">num_epochs</code> <code class="o">=</code> <code class="mi">400</code>&#13;
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">100</code></pre>&#13;
&#13;
<p>The second MPF technique trains the model from the beginning into outputting multiple forecasts in their respective time periods. Mathematically, it can be <span class="keep-together">represented</span> as follows:</p>&#13;
&#13;
<div data-type="equation"><p><math alttext="StartLayout 1st Row  upper P r e d i c t i o n Subscript i Baseline equals f x left-parenthesis r e a l i n p u t Subscript i minus 1 Baseline comma period period period comma i n p u t Subscript i minus n Baseline right-parenthesis 2nd Row  upper P r e d i c t i o n Subscript i plus 1 Baseline equals f x left-parenthesis r e a l i n p u t Subscript i minus 1 Baseline comma period period period comma i n p u t Subscript i minus n Baseline right-parenthesis 3rd Row  upper P r e d i c t i o n Subscript i plus 2 Baseline equals f x left-parenthesis r e a l i n p u t Subscript i minus 1 Baseline comma period period period comma i n p u t Subscript i minus n Baseline right-parenthesis EndLayout">&#13;
  <mtable>&#13;
    <mtr>&#13;
      <mtd columnalign="left">&#13;
        <mrow>&#13;
          <mi>P</mi>&#13;
          <mi>r</mi>&#13;
          <mi>e</mi>&#13;
          <mi>d</mi>&#13;
          <mi>i</mi>&#13;
          <mi>c</mi>&#13;
          <mi>t</mi>&#13;
          <mi>i</mi>&#13;
          <mi>o</mi>&#13;
          <msub><mi>n</mi> <mi>i</mi> </msub>&#13;
          <mo>=</mo>&#13;
          <mi>f</mi>&#13;
          <mi>x</mi>&#13;
          <mrow>&#13;
            <mo>(</mo>&#13;
            <mi>r</mi>&#13;
            <mi>e</mi>&#13;
            <mi>a</mi>&#13;
            <mi>l</mi>&#13;
            <mspace width="0.222222em"/>&#13;
            <mi>i</mi>&#13;
            <mi>n</mi>&#13;
            <mi>p</mi>&#13;
            <mi>u</mi>&#13;
            <msub><mi>t</mi> <mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow> </msub>&#13;
            <mo>,</mo>&#13;
            <mo lspace="0%" rspace="0%">.</mo>&#13;
            <mo lspace="0%" rspace="0%">.</mo>&#13;
            <mo lspace="0%" rspace="0%">.</mo>&#13;
            <mo>,</mo>&#13;
            <mspace width="0.222222em"/>&#13;
            <mi>i</mi>&#13;
            <mi>n</mi>&#13;
            <mi>p</mi>&#13;
            <mi>u</mi>&#13;
            <msub><mi>t</mi> <mrow><mi>i</mi><mo>-</mo><mi>n</mi></mrow> </msub>&#13;
            <mo>)</mo>&#13;
          </mrow>&#13;
        </mrow>&#13;
      </mtd>&#13;
    </mtr>&#13;
    <mtr>&#13;
      <mtd columnalign="left">&#13;
        <mrow>&#13;
          <mi>P</mi>&#13;
          <mi>r</mi>&#13;
          <mi>e</mi>&#13;
          <mi>d</mi>&#13;
          <mi>i</mi>&#13;
          <mi>c</mi>&#13;
          <mi>t</mi>&#13;
          <mi>i</mi>&#13;
          <mi>o</mi>&#13;
          <msub><mi>n</mi> <mrow><mi>i</mi><mo>+</mo><mn>1</mn></mrow> </msub>&#13;
          <mo>=</mo>&#13;
          <mi>f</mi>&#13;
          <mi>x</mi>&#13;
          <mrow>&#13;
            <mo>(</mo>&#13;
            <mi>r</mi>&#13;
            <mi>e</mi>&#13;
            <mi>a</mi>&#13;
            <mi>l</mi>&#13;
            <mspace width="0.222222em"/>&#13;
            <mi>i</mi>&#13;
            <mi>n</mi>&#13;
            <mi>p</mi>&#13;
            <mi>u</mi>&#13;
            <msub><mi>t</mi> <mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow> </msub>&#13;
            <mo>,</mo>&#13;
            <mo lspace="0%" rspace="0%">.</mo>&#13;
            <mo lspace="0%" rspace="0%">.</mo>&#13;
            <mo lspace="0%" rspace="0%">.</mo>&#13;
            <mo>,</mo>&#13;
            <mspace width="0.222222em"/>&#13;
            <mi>i</mi>&#13;
            <mi>n</mi>&#13;
            <mi>p</mi>&#13;
            <mi>u</mi>&#13;
            <msub><mi>t</mi> <mrow><mi>i</mi><mo>-</mo><mi>n</mi></mrow> </msub>&#13;
            <mo>)</mo>&#13;
          </mrow>&#13;
        </mrow>&#13;
      </mtd>&#13;
    </mtr>&#13;
    <mtr>&#13;
      <mtd columnalign="left">&#13;
        <mrow>&#13;
          <mi>P</mi>&#13;
          <mi>r</mi>&#13;
          <mi>e</mi>&#13;
          <mi>d</mi>&#13;
          <mi>i</mi>&#13;
          <mi>c</mi>&#13;
          <mi>t</mi>&#13;
          <mi>i</mi>&#13;
          <mi>o</mi>&#13;
          <msub><mi>n</mi> <mrow><mi>i</mi><mo>+</mo><mn>2</mn></mrow> </msub>&#13;
          <mo>=</mo>&#13;
          <mi>f</mi>&#13;
          <mi>x</mi>&#13;
          <mrow>&#13;
            <mo>(</mo>&#13;
            <mi>r</mi>&#13;
            <mi>e</mi>&#13;
            <mi>a</mi>&#13;
            <mi>l</mi>&#13;
            <mspace width="0.222222em"/>&#13;
            <mi>i</mi>&#13;
            <mi>n</mi>&#13;
            <mi>p</mi>&#13;
            <mi>u</mi>&#13;
            <msub><mi>t</mi> <mrow><mi>i</mi><mo>-</mo><mn>1</mn></mrow> </msub>&#13;
            <mo>,</mo>&#13;
            <mo lspace="0%" rspace="0%">.</mo>&#13;
            <mo lspace="0%" rspace="0%">.</mo>&#13;
            <mo lspace="0%" rspace="0%">.</mo>&#13;
            <mo>,</mo>&#13;
            <mspace width="0.222222em"/>&#13;
            <mi>i</mi>&#13;
            <mi>n</mi>&#13;
            <mi>p</mi>&#13;
            <mi>u</mi>&#13;
            <msub><mi>t</mi> <mrow><mi>i</mi><mo>-</mo><mi>n</mi></mrow> </msub>&#13;
            <mo>)</mo>&#13;
          </mrow>&#13;
        </mrow>&#13;
      </mtd>&#13;
    </mtr>&#13;
  </mtable>&#13;
</math></p></div>&#13;
&#13;
<p>The framework for the recursive model is as follows:</p>&#13;
&#13;
<ol>&#13;
	<li>Create a function that relates the desired number of inputs to the desired number of outputs. This means that the last layer of the neural network will contain a number of outputs equal to the number of forecasting periods you want to project into the future.</li>&#13;
	<li>Train the model to predict multiple outputs at every time step based on the inputs from the same time step.<a contenteditable="false" data-primary="" data-startref="Chapter_9.html14" data-type="indexterm" id="id752"/></li>&#13;
</ol>&#13;
&#13;
<p>Let’s continue with the ISM PMI. As usual, import the required libraries:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">from</code> <code class="nn">keras.models</code> <code class="kn">import</code> <code class="n">Sequential</code>&#13;
<code class="kn">from</code> <code class="nn">keras.layers</code> <code class="kn">import</code> <code class="n">Dense</code>&#13;
<code class="kn">import</code> <code class="nn">keras</code>&#13;
<code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>&#13;
<code class="kn">import</code> <code class="nn">pandas</code> <code class="k">as</code> <code class="nn">pd</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="k">as</code> <code class="nn">plt</code>&#13;
<code class="kn">from</code> <code class="nn">master_function</code> <code class="kn">import</code> <code class="n">direct_mpf</code>&#13;
<code class="kn">from</code> <code class="nn">master_function</code> <code class="kn">import</code> <code class="n">calculate_directional_accuracy</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">mean_squared_error</code>&#13;
</pre>&#13;
&#13;
<p>Import and preprocess the data while setting the hyperparameters:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Importing the data</code>&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">pd</code><code class="o">.</code><code class="n">read_excel</code><code class="p">(</code><code class="s1">'ISM_PMI.xlsx'</code><code class="p">)</code><code class="o">.</code><code class="n">dropna</code><code class="p">()),</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">))</code>&#13;
<code class="c1"># Setting the hyperparameters</code>&#13;
<code class="n">num_lags</code> <code class="o">=</code> <code class="mi">10</code>&#13;
<code class="n">train_test_split</code> <code class="o">=</code> <code class="mf">0.80</code>&#13;
<code class="n">num_neurons_in_hidden_layers</code> <code class="o">=</code> <code class="mi">200</code>&#13;
<code class="n">num_epochs</code> <code class="o">=</code> <code class="mi">200</code>&#13;
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">10</code>&#13;
<code class="n">forecast_horizon</code> <code class="o">=</code> <code class="mi">18</code> <code class="c1"># This means eighteen months</code>&#13;
<code class="n">x_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">x_test</code><code class="p">,</code> <code class="n">y_test</code> <code class="o">=</code> <code class="n">direct_mpf</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="n">num_lags</code><code class="p">,</code> &#13;
                                              <code class="n">train_test_split</code><code class="p">,</code> &#13;
                                              <code class="n">forecast_horizon</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p>The <code>direct_mpf()</code> function takes the following arguments:</p>&#13;
&#13;
<ul>&#13;
	<li>The dataset represented by the variable <code>data</code></li>&#13;
	<li>The number of lags represented by the variable <code>num_lags</code></li>&#13;
	<li>The split represented by the variable <code>train_test_split</code></li>&#13;
	<li>The number of observations to project represented by the variable <code>forecast_horizon</code></li>&#13;
</ul>&#13;
&#13;
<p>Prepare the arrays, design the architecture, and predict the data for a horizon of 18 months (since the ISM PMI is a monthly indicator):</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Designing the architecture of the model</code>&#13;
<code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
<code class="c1"># First hidden layer</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">num_neurons_in_hidden_layers</code><code class="p">,</code> <code class="n">input_dim</code> <code class="o">=</code> <code class="n">num_lags</code><code class="p">,</code> &#13;
                <code class="n">activation</code> <code class="o">=</code> <code class="s1">'relu'</code><code class="p">))</code>  &#13;
<code class="c1"># Second hidden layer</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">num_neurons_in_hidden_layers</code><code class="p">,</code> <code class="n">activation</code> <code class="o">=</code> <code class="s1">'relu'</code><code class="p">))</code>  &#13;
<code class="c1"># Output layer</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">forecast_horizon</code><code class="p">))</code>&#13;
<code class="c1"># Compiling</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code> <code class="o">=</code> <code class="s1">'mean_squared_error'</code><code class="p">,</code> <code class="n">optimizer</code> <code class="o">=</code> <code class="s1">'adam'</code><code class="p">)</code>&#13;
<code class="c1"># Fitting (training) the model</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">epochs</code> <code class="o">=</code> <code class="n">num_epochs</code><code class="p">,</code> <code class="n">batch_size</code> <code class="o">=</code> <code class="n">batch_size</code><code class="p">)</code>&#13;
<code class="c1"># Make predictions</code>&#13;
<code class="n">y_predicted</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x_test</code><code class="p">)</code>&#13;
<code class="c1"># Plotting</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">y_predicted</code><code class="p">[</code><code class="err">–</code><code class="mi">1</code><code class="p">],</code> <code class="n">label</code> <code class="o">=</code> <code class="s1">'Predicted data'</code><code class="p">,</code> <code class="n">color</code> <code class="o">=</code> <code class="s1">'red'</code><code class="p">,</code> &#13;
         <code class="n">linewidth</code> <code class="o">=</code> <code class="mi">1</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">y_test</code><code class="p">[</code><code class="err">–</code><code class="mi">1</code><code class="p">],</code> <code class="n">label</code> <code class="o">=</code> <code class="s1">'Test data'</code><code class="p">,</code> <code class="n">color</code> <code class="o">=</code> <code class="s1">'black'</code><code class="p">,</code> &#13;
         <code class="n">linestyle</code> <code class="o">=</code> <code class="s1">'dashed'</code><code class="p">,</code> <code class="n">linewidth</code> <code class="o">=</code> <code class="mi">2</code><code class="p">)</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">grid</code><code class="p">()</code>&#13;
<code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">()</code>&#13;
</pre>&#13;
&#13;
<p><a data-type="xref" href="#figure-9-12">Figure 9-12</a> shows the predicted data and the test data at this point.</p>&#13;
&#13;
<figure><div class="figure" id="figure-9-12"><img alt="" class="iimagespred_mlp_pmi_directpng" src="assets/dlff_0912.png"/>&#13;
<h6><span class="label">Figure 9-12. </span>Multiperiod forecasts of model versus real values, with some optimization</h6>&#13;
</div></figure>&#13;
&#13;
<p>The interpretation of the model at the time of the forecast was for a consecutive drop in the ISM PMI for 18 months. The model seems to have done a good job at predicting this direction. Note that you may get different results due to the random initialization of the algorithm, which may impact its convergence to a minimum loss function. You can use <code>random_state</code> to get the same results every time (you saw this in <a data-type="xref" href="ch07.html#ch07">Chapter 7</a>).</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>The ISM PMI has a positive correlation with the US gross domestic product (GDP) and a slight positive correlation with the S&amp;P 500. To be more precise, bottoms in the ISM PMI have coincided with bottoms in the equity markets.</p>&#13;
</div>&#13;
&#13;
<p class="fix_tracking">Out of curiosity, let’s try running the model on very simple and basic hyperparameters:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">num_lags</code> <code class="o">=</code> <code class="mi">1</code>&#13;
<code class="n">train_test_split</code> <code class="o">=</code> <code class="mf">0.80</code>&#13;
<code class="n">num_neurons_in_hidden_layers</code> <code class="o">=</code> <code class="mi">2</code>&#13;
<code class="n">num_epochs</code> <code class="o">=</code> <code class="mi">10</code>&#13;
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">1</code>&#13;
<code class="n">forecast_horizon</code> <code class="o">=</code> <code class="mi">18</code></pre>&#13;
&#13;
<p>Obviously, with one lag, the model will only take into account the previous value to learn how to predict the future. The hidden layers will only contain two neurons each and will run for only 10 epochs using a batch size of 1. Naturally, you would not expect satisfying results by using these hyperparameters. <a data-type="xref" href="#figure-9-13">Figure 9-13</a> compares the predicted values to the real values. Notice the huge discrepancy as the model does not pick on the magnitude or the direction.</p>&#13;
&#13;
<figure><div class="figure" id="figure-9-13"><img alt="" class="iimagespred_mlp_pmi_direct_no_optimizationpng" src="assets/dlff_0913.png"/>&#13;
<h6><span class="label">Figure 9-13. </span>Multiperiod forecasts of the model versus real values, using <span class="keep-together">basic hyperparameters</span></h6>&#13;
</div></figure>&#13;
&#13;
<p>This is why hyperparameter optimization is important and a certain degree of complexity is needed. After all, these time series are not simple and carry a significant amount of noise in them.</p>&#13;
&#13;
<p>Finally, let’s have a look at the results of running the following hyperparameters on Basel’s temperature data, as you saw at the beginning of this section:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">num_lags</code> <code class="o">=</code> <code class="mi">500</code>&#13;
<code class="n">train_test_split</code> <code class="o">=</code> <code class="mf">0.80</code>&#13;
<code class="n">num_neurons_in_hidden_layers</code> <code class="o">=</code> <code class="mi">128</code>&#13;
<code class="n">num_epochs</code> <code class="o">=</code> <code class="mi">50</code>&#13;
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">12</code>&#13;
<code class="n">forecast_horizon</code> <code class="o">=</code> <code class="mi">500</code></pre>&#13;
&#13;
<p><a data-type="xref" href="#figure-9-14">Figure 9-14</a> compares the predicted values to the real values using the temperature time series. The number of predicted observations is 500.</p>&#13;
&#13;
<figure><div class="figure" id="figure-9-14"><img alt="" class="iimagespred_mlp_weather_directpng" src="assets/dlff_0914.png"/>&#13;
<h6><span class="label">Figure 9-14. </span>Multiperiod forecasts of the model versus real values, using the temperature time series</h6>&#13;
</div></figure>&#13;
&#13;
<p>Which prediction technique to use depends on your preferences and needs. It is worth mentioning an additional MPF technique referred to as the <em>multioutput model</em>, which is a one-shot forecast of a number of values. This means that the model is trained over the training set with the aim of producing an instant predefined number of outputs (predictions). Obviously, this model may be computationally expensive and would require a sizable amount of data.<a contenteditable="false" data-primary="" data-startref="Chapter_9.html13" data-type="indexterm" id="id753"/><a contenteditable="false" data-primary="" data-startref="Chapter_9.html12a" data-type="indexterm" id="id754"/><a contenteditable="false" data-primary="" data-startref="Chapter_9.html12" data-type="indexterm" id="id755"/></p>&#13;
</div></section>&#13;
&#13;
<section class="pagebreak-before" data-pdf-bookmark="Applying Regularization to MLPs" data-type="sect1"><div class="sect1" id="id76">&#13;
<h1 class="less_space">Applying Regularization to MLPs</h1>&#13;
&#13;
<p><a contenteditable="false" data-primary="MLPs (multilayer perceptrons)" data-type="indexterm" id="Chapter_9.html15a"/><a contenteditable="false" data-primary="multilayer perceptrons (MLPs)" data-type="indexterm" id="Chapter_9.html15"/><a contenteditable="false" data-primary="regularization" data-secondary="applying to MLPs" data-type="indexterm" id="Chapter_9.html16"/><a contenteditable="false" data-primary="time series prediction (deep learning techniques and methods for)" data-secondary="applying regularization to MLPs" data-type="indexterm" id="Chapter_9.html17"/><a data-type="xref" href="ch08.html#ch08">Chapter 8</a> discussed two regularization concepts regarding deep learning:</p>&#13;
&#13;
<ul>&#13;
	<li>Dropout as a regularization technique that randomly deactivates neurons during training to prevent overfitting</li>&#13;
	<li>Early stopping as a method to prevent overfitting by monitoring the model’s performance and stopping training when performance starts to degrade</li>&#13;
</ul>&#13;
&#13;
<p><a contenteditable="false" data-primary="batch normalization" data-type="indexterm" id="Chapter_9.html18"/>Another regularization technique worth discussing is <em>batch normalization</em>, a technique used in deep learning to improve the training and generalization of neural networks. It normalizes the inputs of each layer within a mini batch during training, which helps in stabilizing and accelerating the learning process.</p>&#13;
&#13;
<p>The main idea behind batch normalization is to ensure that the inputs to a layer have zero mean and unit variance. This normalization is applied independently to each feature (or neuron) within the layer. The process can be summarized in the following steps:</p>&#13;
&#13;
<ol>&#13;
	<li>&#13;
	<p>For each feature in a mini batch, calculate the mean and variance across all the samples in the batch.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>Subtract the mean and divide by the standard deviation (the square root of the variance) for each feature.</p>&#13;
	</li>&#13;
	<li>&#13;
	<p>After normalization, the features are scaled and shifted by learnable parameters. These parameters allow the model to learn the optimal scale and shift for each normalized feature.</p>&#13;
	</li>&#13;
</ol>&#13;
&#13;
<p>This section presents a simple forecasting task using LSTMs with the addition of the three regularization techniques. The time series is the S&amp;P 500’s 20-day rolling autocorrelation data. Import the required libraries:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>&#13;
<code class="kn">import</code> <code class="nn">pandas</code> <code class="k">as</code> <code class="nn">pd</code>&#13;
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="k">as</code> <code class="nn">plt</code>&#13;
<code class="kn">from</code> <code class="nn">keras.models</code> <code class="kn">import</code> <code class="n">Sequential</code>&#13;
<code class="kn">from</code> <code class="nn">keras.layers</code> <code class="kn">import</code> <code class="n">LSTM</code><code class="p">,</code> <code class="n">Dense</code><code class="p">,</code> <code class="n">Dropout</code><code class="p">,</code> <code class="n">BatchNormalization</code>&#13;
<code class="kn">from</code> <code class="nn">tensorflow.keras.callbacks</code> <code class="kn">import</code> <code class="n">EarlyStopping</code>&#13;
<code class="kn">import</code> <code class="nn">pandas_datareader</code> <code class="k">as</code> <code class="nn">pdr</code>&#13;
<code class="kn">from</code> <code class="nn">master_function</code> <code class="kn">import</code> <code class="n">data_preprocessing</code><code class="p">,</code> <code class="n">plot_train_test_values</code>&#13;
<code class="kn">from</code> <code class="nn">master_function</code> <code class="kn">import</code> <code class="n">calculate_directional_accuracy</code>&#13;
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">mean_squared_error</code></pre>&#13;
&#13;
<p class="pagebreak-before">Import and preprocess the data:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Set the start and end dates for the data</code>&#13;
<code class="n">start_date</code> <code class="o">=</code> <code class="s1">'1990-01-01'</code>&#13;
<code class="n">end_date</code>   <code class="o">=</code> <code class="s1">'2023-06-01'</code>&#13;
<code class="c1"># Fetch S&amp;P 500 price data</code>&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">((</code><code class="n">pdr</code><code class="o">.</code><code class="n">get_data_fred</code><code class="p">(</code><code class="s1">'SP500'</code><code class="p">,</code> <code class="n">start</code> <code class="o">=</code> <code class="n">start_date</code><code class="p">,</code> &#13;
                                   <code class="n">end</code> <code class="o">=</code> <code class="n">end_date</code><code class="p">))</code><code class="o">.</code><code class="n">dropna</code><code class="p">())</code>&#13;
</pre>&#13;
&#13;
<p>Calculate the 20-day autocorrelation of the close prices:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">rolling_autocorr</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">data</code><code class="p">)</code><code class="o">.</code><code class="n">rolling</code><code class="p">(</code><code class="n">window</code> <code class="o">=</code> &#13;
                                              <code class="mi">20</code><code class="p">)</code><code class="o">.</code><code class="n">apply</code><code class="p">(</code><code class="k">lambda</code> <code class="n">x</code><code class="p">:</code> &#13;
                                              <code class="n">x</code><code class="o">.</code><code class="n">autocorr</code><code class="p">(</code><code class="n">lag</code><code class="o">=</code><code class="mi">1</code><code class="p">))</code><code class="o">.</code><code class="n">dropna</code><code class="p">()</code>&#13;
<code class="n">rolling_autocorr</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="n">rolling_autocorr</code><code class="p">),</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">))</code></pre>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p><a contenteditable="false" data-primary="anonymous (lambda) function" data-type="indexterm" id="id756"/><a contenteditable="false" data-primary="lambda function" data-type="indexterm" id="id757"/>In Python, a <code>lambda</code> function, also known as an <em>anonymous</em> function, is a small, unnamed function that can have any number of arguments but can only have one expression. These functions are often used for creating simple, inline functions without needing to define a full function using the <code>def</code> keyword. Here’s a simple example to illustrate how <code>lambda</code> works:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Create an anonymous function to divide two variables</code>&#13;
<code class="n">divide</code> <code class="o">=</code> <code class="k">lambda</code> <code class="n">x</code><code class="p">,</code> <code class="n">y</code><code class="p">:</code> <code class="n">x</code> <code class="o">/</code> <code class="n">y</code>&#13;
<code class="c1"># Call the function</code>&#13;
<code class="n">result</code> <code class="o">=</code> <code class="n">divide</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">2</code><code class="p">)</code></pre>&#13;
&#13;
<p>The output will be the float 5.0 stored in <code>result</code>.</p>&#13;
&#13;
<p>The <code>apply()</code> function is a method that is available in <em>pandas</em>. It is primarily used to apply a given function along an axis of a <span class="keep-together">dataframe.</span></p>&#13;
</div>&#13;
&#13;
<p>Before continuing, try plotting the S&amp;P 500 price data versus its 20-day autocorrelation that you just calculated. Use this code to generate <a data-type="xref" href="#figure-9-15">Figure 9-15</a>:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">fig</code><code class="p">,</code> <code class="n">axes</code> <code class="o">=</code> <code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">(</code><code class="n">nrows</code> <code class="o">=</code> <code class="mi">2</code><code class="p">,</code> <code class="n">ncols</code> <code class="o">=</code> <code class="mi">1</code><code class="p">)</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="o">-</code><code class="mi">350</code><code class="p">:,],</code> <code class="n">label</code> <code class="o">=</code> <code class="s1">'S&amp;P 500'</code><code class="p">,</code> <code class="n">linewidth</code> <code class="o">=</code> <code class="mf">1.5</code><code class="p">)</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">rolling_autocorr</code><code class="p">[</code><code class="o">-</code><code class="mi">350</code><code class="p">:,],</code> <code class="n">label</code> <code class="o">=</code> <code class="s1">'20-Day Autocorrelation'</code><code class="p">,</code> &#13;
             <code class="n">color</code> <code class="o">=</code> <code class="s1">'orange'</code><code class="p">,</code> <code class="n">linewidth</code> <code class="o">=</code> <code class="mf">1.5</code><code class="p">)</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">legend</code><code class="p">()</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">legend</code><code class="p">()</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">grid</code><code class="p">()</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">grid</code><code class="p">()</code>&#13;
<code class="n">axes</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">axhline</code><code class="p">(</code><code class="n">y</code> <code class="o">=</code> <code class="mf">0.95</code><code class="p">,</code> <code class="n">color</code> <code class="o">=</code> <code class="s1">'black'</code><code class="p">,</code> <code class="n">linestyle</code> <code class="o">=</code> <code class="s1">'dashed'</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<figure><div class="figure" id="figure-9-15"><img alt="" class="iimagesdlf_0915png" src="assets/dlff_0915.png"/>&#13;
<h6><span class="label">Figure 9-15. </span>The S&amp;P 500 versus its 20-day price autocorrelation (lag = 1)</h6>&#13;
</div></figure>&#13;
&#13;
<p>What you should retain from the chart and from the intuition of autocorrelation is that whenever autocorrelation approaches 1.00, the current trend may break, thus leading to a market correction. This is not a perfect assumption, but you can follow these basic rules to interpret the rolling autocorrelation observations:</p>&#13;
&#13;
<ul>&#13;
	<li>A trending market (bullish or bearish) will have its autocorrelation approach 1.00 sooner or later. When this happens, it may signal a pause in the underlying trend, or in rarer occasions, a full reversal.</li>&#13;
	<li>A sideways (ranging) market will have a low autocorrelation. If the autocorrelation approaches historical lows, then it may mean that the market is ready to trend. </li>&#13;
</ul>&#13;
&#13;
<p>Let’s now continue building the algorithm. The next step is to set the hyperparameters and prepare the arrays:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">num_lags</code> <code class="o">=</code> <code class="mi">500</code> &#13;
<code class="n">train_test_split</code> <code class="o">=</code> <code class="mf">0.80</code> &#13;
<code class="n">num_neurons_in_hidden_layers</code> <code class="o">=</code> <code class="mi">128</code> &#13;
<code class="n">num_epochs</code> <code class="o">=</code> <code class="mi">100</code> &#13;
<code class="n">batch_size</code> <code class="o">=</code> <code class="mi">20</code>&#13;
<code class="c1"># Creating the training and test sets</code>&#13;
<code class="n">x_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">x_test</code><code class="p">,</code> <code class="n">y_test</code> <code class="o">=</code> <code class="n">data_preprocessing</code><code class="p">(</code><code class="n">rolling_autocorr</code><code class="p">,</code> &#13;
                                                      <code class="n">num_lags</code><code class="p">,</code> &#13;
                                                      <code class="n">train_test_split</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p class="pagebreak-before">Transform the input arrays into three-dimensional structures so that they are processed into the LSTM architecture with no issues:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">x_train</code> <code class="o">=</code> <code class="n">x_train</code><code class="o">.</code><code class="n">reshape</code><code class="p">((</code><code class="err">–</code><code class="mi">1</code><code class="p">,</code> <code class="n">num_lags</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code>&#13;
<code class="n">x_test</code> <code class="o">=</code> <code class="n">x_test</code><code class="o">.</code><code class="n">reshape</code><code class="p">((</code><code class="err">–</code><code class="mi">1</code><code class="p">,</code> <code class="n">num_lags</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code>&#13;
</pre>&#13;
&#13;
<p>Design the LSTM architecture and add the dropout layer and batch normalization. Add the early stopping implementation while setting <code>restore_best_weights</code> to <code>True</code> so as to keep the best parameters for the prediction over the test data:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Create the LSTM model</code>&#13;
<code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">LSTM</code><code class="p">(</code><code class="n">units</code> <code class="o">=</code> <code class="n">num_neurons_in_hidden_layers</code><code class="p">,</code> <code class="n">input_shape</code> <code class="o">=</code> &#13;
               <code class="p">(</code><code class="n">num_lags</code><code class="p">,</code> <code class="mi">1</code><code class="p">)))</code>&#13;
<code class="c1"># Adding batch normalization and a dropout of 10%</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">BatchNormalization</code><code class="p">())</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dropout</code><code class="p">(</code><code class="mf">0.1</code><code class="p">))</code> &#13;
<code class="c1"># Adding the output layer</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="n">units</code> <code class="o">=</code> <code class="mi">1</code><code class="p">))</code>&#13;
<code class="c1"># Compile the model</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code> <code class="o">=</code> <code class="s1">'mean_squared_error'</code><code class="p">,</code> <code class="n">optimizer</code> <code class="o">=</code> <code class="s1">'adam'</code><code class="p">)</code>&#13;
<code class="c1"># Early stopping implementation</code>&#13;
<code class="n">early_stopping</code> <code class="o">=</code> <code class="n">EarlyStopping</code><code class="p">(</code><code class="n">monitor</code> <code class="o">=</code> <code class="s1">'loss'</code><code class="p">,</code> <code class="n">patience</code> <code class="o">=</code> <code class="mi">15</code><code class="p">,</code> &#13;
 <code class="n">restore_best_weights</code> <code class="o">=</code> <code class="kc">True</code><code class="p">)</code>&#13;
<code class="c1"># Train the model</code>&#13;
<code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x_train</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">epochs</code> <code class="o">=</code> <code class="n">num_epochs</code><code class="p">,</code> &#13;
          <code class="n">batch_size</code> <code class="o">=</code> <code class="n">batch_size</code><code class="p">,</code> <code class="n">callbacks</code> <code class="o">=</code> <code class="p">[</code><code class="n">early_stopping</code><code class="p">])</code>&#13;
</pre>&#13;
&#13;
<p>Predict and plot the results:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="c1"># Predicting in-sample</code>&#13;
<code class="n">y_predicted_train</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x_train</code><code class="p">),</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code>&#13;
<code class="c1"># Predicting out-of-sample</code>&#13;
<code class="n">y_predicted</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x_test</code><code class="p">),</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code>&#13;
<code class="c1"># Plotting</code>&#13;
<code class="n">plot_train_test_values</code><code class="p">(</code><code class="mi">300</code><code class="p">,</code> <code class="mi">50</code><code class="p">,</code> <code class="n">y_train</code><code class="p">,</code> <code class="n">y_test</code><code class="p">,</code> <code class="n">y_predicted</code><code class="p">)</code>&#13;
</pre>&#13;
&#13;
<p><a data-type="xref" href="#figure-9-16">Figure 9-16</a> shows the predictions versus the real values. The model has stopped the training before reaching 100 epochs due to the callback from the early stopping mechanism.</p>&#13;
&#13;
<figure><div class="figure" id="figure-9-16"><img alt="" class="iimagesdlf_0916png" src="assets/dlff_0916.png"/>&#13;
<h6><span class="label">Figure 9-16. </span>Predicting correlation</h6>&#13;
</div></figure>&#13;
&#13;
<p>The results are as follows:</p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">Accuracy</code> <code class="n">Train</code> <code class="o">=</code>  <code class="mf">70.37</code> <code class="o">%</code>&#13;
<code class="n">Accuracy</code> <code class="n">Test</code> <code class="o">=</code>  <code class="mf">68.12</code> <code class="o">%</code>&#13;
<code class="n">RMSE</code> <code class="n">Train</code> <code class="o">=</code>  <code class="mf">0.0658945761</code>&#13;
<code class="n">RMSE</code> <code class="n">Test</code> <code class="o">=</code>  <code class="mf">0.0585669847</code>&#13;
<code class="n">Correlation</code> <code class="n">In</code><code class="o">-</code><code class="n">Sample</code> <code class="n">Predicted</code><code class="o">/</code><code class="n">Train</code> <code class="o">=</code>  <code class="mf">0.945</code>&#13;
<code class="n">Correlation</code> <code class="n">Out</code><code class="o">-</code><code class="n">of</code><code class="o">-</code><code class="n">Sample</code> <code class="n">Predicted</code><code class="o">/</code><code class="n">Test</code> <code class="o">=</code>  <code class="mf">0.936</code></pre>&#13;
&#13;
<p>It’s important to note that using indicators such as rolling autocorrelation should be done with caution. They provide insights into historical patterns, but they don’t guarantee future performance. Additionally, the effectiveness of rolling autocorrelation as a technical indicator depends on the nature of the data and the context in which it’s being used. You can try applying the MPF method on the autocorrelation data.<a contenteditable="false" data-primary="" data-startref="Chapter_9.html18" data-type="indexterm" id="id758"/></p>&#13;
&#13;
<p>Other regularization techniques that exist include the following:</p>&#13;
&#13;
<dl>&#13;
	<dt><a contenteditable="false" data-primary="L1/L2 regularization (weight decay)" data-type="indexterm" id="id759"/><a contenteditable="false" data-primary="weight decay (L1/L2 regularization)" data-type="indexterm" id="id760"/>L1 and L2 regularization</dt><dd><p>Also known as <em>weight decay</em>, L1 and L2 regularization add a penalty term to the loss function based on the magnitude of the weights. <em>L1 regularization</em> adds the absolute values of the weights to the loss, which encourages sparsity in the model. <em>L2 regularization</em> adds the squared values of the weights, which discourages large weight values and tends to distribute the influence of features more evenly.</p>&#13;
	</dd>&#13;
	<dt><a contenteditable="false" data-primary="DropConnect regularization technique" data-type="indexterm" id="id761"/>DropConnect</dt><dd><p>This technique is similar to dropout but is applied to connections rather than neurons. This technique randomly drops connections between layers during training.</p>&#13;
	</dd>&#13;
	<dt><a contenteditable="false" data-primary="weight constraints regularization technique" data-type="indexterm" id="id762"/>Weight constraints</dt><dd><p>Limiting the magnitude of weight values can prevent the model from learning complex patterns from noise and helps regularize the model.</p>&#13;
	</dd>&#13;
	<dt><a contenteditable="false" data-primary="adversarial training" data-type="indexterm" id="id763"/>Adversarial training</dt><dd><p>Training the model using adversarial examples can improve its robustness by making it more resistant to small perturbations in the input data.</p>&#13;
	</dd>&#13;
</dl>&#13;
&#13;
<p>Using these regularization techniques doesn’t guarantee a better result than using the model without them. However, deep learning best practices encourage such techniques to avoid more serious problems like overfitting.</p>&#13;
&#13;
<div data-type="note" epub:type="note"><h6>Note</h6>&#13;
<p>When manually uploading an Excel file (using <em>pandas</em>, for example) that contains historical data, make sure that it has a shape of <code>(n, )</code> and not a shape of <code>(n, 1)</code>. This ensures that when you use the <code>data_preprocessing()</code> function, the four training/test arrays will be created with the proper dimensions.</p>&#13;
&#13;
<p>To transform an <code>(n, 1)</code> array to <code>(n, )</code>, use the following syntax:</p>&#13;
&#13;
<pre class="pre drop-element-attached-top drop-element-attached-center drop-target-attached-bottom drop-target-attached-center" data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">))</code></pre>&#13;
&#13;
<p>To transform an <code>(n, )</code> array to <code>(n, 1)</code>, use the following syntax:<a contenteditable="false" data-primary="" data-startref="Chapter_9.html17" data-type="indexterm" id="id764"/><a contenteditable="false" data-primary="" data-startref="Chapter_9.html16" data-type="indexterm" id="id765"/><a contenteditable="false" data-primary="" data-startref="Chapter_9.html15a" data-type="indexterm" id="id766"/><a contenteditable="false" data-primary="" data-startref="Chapter_9.html15" data-type="indexterm" id="id767"/></p>&#13;
&#13;
<pre data-code-language="python" data-executable="true" data-type="programlisting">&#13;
<code class="n">data</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="n">data</code><code class="p">,</code> <code class="p">(</code><code class="err">–</code><code class="mi">1</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code></pre>&#13;
</div>&#13;
</div></section>&#13;
&#13;
<section data-pdf-bookmark="Summary" data-type="sect1"><div class="sect1" id="id77">&#13;
<h1>Summary</h1>&#13;
&#13;
<p>This chapter presented a few techniques that may improve the different machine and deep learning algorithms. I like to refer to such techniques as <em>satellites </em>since they hover around the main component, that is, neural networks. Optimizations and enhancements are crucial to the success of the analysis. For example, some markets may benefit from the forecasting threshold technique and fractional differentiation. Trial and error is key to understanding your data, and as you begin <a data-type="xref" href="ch10.html#ch10">Chapter 10</a> and learn about reinforcement learning, you will see that trial and error is not just a human task. It can also be a computer task.<a contenteditable="false" data-primary="" data-startref="Chapter_9.html0" data-type="indexterm" id="id768"/></p>&#13;
</div></section>&#13;
</div></section></body></html>