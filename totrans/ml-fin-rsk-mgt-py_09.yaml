- en: Chapter 7\. Liquidity Modeling
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When the music stops, in terms of liquidity, things will be complicated. But
    as long as the music is playing, you’ve got to get up and dance. We’re still dancing.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: ''
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Chuck Prince (2007)
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: Liquidity is another important source of financial risk. However, it has been
    long neglected, and the finance industry has paid a huge price for modeling risk
    without considering liquidity.
  prefs: []
  type: TYPE_NORMAL
- en: The causes of liquidity risk are departures from the complete markets and symmetric
    information paradigm, which can lead to moral hazard and adverse selection. To
    the extent that such conditions persist, liquidity risk is endemic in the financial
    system and can cause a vicious link between funding and market liquidity, prompting
    systemic liquidity risk (Nikolaou 2009).
  prefs: []
  type: TYPE_NORMAL
- en: Tapping into the time lag between a changing value of the variable and its impact
    on the real market turns out to be a success criterion in modeling. For instance,
    interest rates, to some extent, diverge from real market dynamics from time to
    time, and it takes some time to settle. Together with this, uncertainty is the
    solely source of risk in traditional asset pricing models; however, it is far
    from reality. To fill the gap between financial models and real-market dynamics,
    the liquidity dimension stands out. A model with liquidity can better adjust itself
    to developments in the financial markets in that liquidity affects both the required
    returns of assets and also the level of uncertainty. Thus, liquidity is quite
    an important dimension in estimating probability of default (Gaygisiz, Karasan,
    and Hekimoglu 2021).
  prefs: []
  type: TYPE_NORMAL
- en: The importance of liquidity has been highlighted and has gained much attention
    since the global mortgage crisis broke out in 2007–2008\. During this crisis,
    most financial institutions were hit hard by liquidity pressures, resulting in
    several strict measures taken by regulatory authorities and central banks. Since
    then, debates over the need to include liquidity, originating from the lack of
    tradable securities, have intensified.
  prefs: []
  type: TYPE_NORMAL
- en: 'The concept of liquidity is multifaceted. By and large, a *liquid asset* is
    defined by the extent to which a large amount of it is sold without a considerable
    price impact. This is also known as *transaction cost*. This is, however, not
    the only important facet of liquidity. Rather, during a period of stress, resilience
    stands out as investors seek prompt price discovery (Sarr and Lybek 2002). This
    is pointed out by Kyle (1985): “Liquidity is a slippery and elusive concept, in
    part because it encompasses a number of transactional properties of markets.”'
  prefs: []
  type: TYPE_NORMAL
- en: 'With that said, liquidity is an ambiguous concept, and to define it we need
    to focus on its different dimensions. In the literature, different researchers
    come up with different dimensions of liquidity, but for the purposes of this book,
    we will identify four defining characteristics of liquidity:'
  prefs: []
  type: TYPE_NORMAL
- en: Tightness
  prefs: []
  type: TYPE_NORMAL
- en: The ability to trade an asset at the same price at the same time. This refers
    to the transaction cost occurring during a trade. If the transaction cost is high,
    the difference between buy and sell prices will be high or vice versa. So, a narrow
    transaction cost defines how tight the market is.
  prefs: []
  type: TYPE_NORMAL
- en: Immediacy
  prefs: []
  type: TYPE_NORMAL
- en: The speed at which a large amount of buy or sell orders can be traded. This
    dimension of liquidity provides us with valuable information about the financial
    market, as low immediacy refers to malfunctioning of parts of the market such
    as clearing, settlement, and so forth.
  prefs: []
  type: TYPE_NORMAL
- en: Depth
  prefs: []
  type: TYPE_NORMAL
- en: The presence of large numbers of buyers and sellers who are able to cover abundant
    orders at various prices.
  prefs: []
  type: TYPE_NORMAL
- en: Resiliency
  prefs: []
  type: TYPE_NORMAL
- en: A market’s ability to bounce back from nonequilibrium. It can be thought of
    as a price-recovery process in which order imbalance dies out quickly.
  prefs: []
  type: TYPE_NORMAL
- en: Given the definition and interconnectedness of liquidity, it is not hard to
    see that modeling liquidity is a tough task. In the literature, many different
    types of liquidity models are proposed, however, considering the multidimensionality
    of liquidity, it may be wise to cluster the data depending on which dimension
    it captures. To this end, we will come up with different liquidity measures to
    represent all four dimensions. These liquidity measures are volume-based measures,
    transaction cost–based measures, price impact-based measures, and market-impact
    measures. For all these dimensions, several different liquidity proxies will be
    used.
  prefs: []
  type: TYPE_NORMAL
- en: Using clustering analysis, these liquidity measures will be clustered, which
    helps us to understand which part of liquidity an investor should focus on, because
    it is known that different dimensions of liquidity prevail in an economy during
    different time periods. Thus, once we are done with clustering analysis, we end
    up with a smaller number of liquidity measures. For the sake of clustering analysis,
    we will use the Gaussian mixture model (GMM) and the Gaussian mixture copula model
    (GMCM) to tackle this problem. GMM is a widely recognized clustering model that
    works well under elliptical distribution. GMCM is an extension of the GMM in that
    we include a copula analysis to take correlation into account. We will discuss
    these models in detail, so let us start by identifying the liquidity measures
    based on different liquidity dimensions.
  prefs: []
  type: TYPE_NORMAL
- en: Liquidity Measures
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The role of liquidity has finally been recognized by finance practitioners
    and economists, which makes it even more important to understand and develop liquidity
    measurement. Existing literature concentrates on a single measure by which it
    is hard to conceptualize an elusive concept like liquidity. Instead, we will cover
    four dimensions to develop a more comprehensive application:'
  prefs: []
  type: TYPE_NORMAL
- en: Volume
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Transaction cost
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Price impact
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Market impact
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Let’s get started with the volume-based liquidity measures.
  prefs: []
  type: TYPE_NORMAL
- en: Volume-Based Liquidity Measures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Large orders are covered when the market has depth, that is, a deep financial
    market has the ability to meet abundant orders. This, in turn, provides information
    about the market, and if the market lacks depth, order imbalance and discontinuity
    emerge in the market. Given the market’s depth, volume-based liquidity measures
    can be used to distinguish liquid and illiquid assets. Moreover, volume-based
    liquidity measures have a strong association with bid-ask spread: a large bid-ask
    spread implies low volume, while a narrow bid-ask spread implies high volume (Huong
    and Gregoriou 2020).'
  prefs: []
  type: TYPE_NORMAL
- en: As you can imagine, a large portion of the variation in liquidity arises from
    trading activities. The importance of the volume-based approach is stressed by
    Blume, Easley, and O’Hara (1994) saying that volume traded generates information
    that cannot be extracted from alternative statistics.
  prefs: []
  type: TYPE_NORMAL
- en: 'To properly represent the depth dimension of liquidity, the following volume-based
    measures will be introduced:'
  prefs: []
  type: TYPE_NORMAL
- en: Liquidity ratio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Hui-Heubel ratio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Turnover ratio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Liquidity ratio
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This ratio measures the extent to which volume is required to induce a price
    change of 1%:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper L upper R Subscript i t Baseline equals StartFraction
    sigma-summation Underscript t equals 1 Overscript upper T Endscripts upper P Subscript
    i t Baseline upper V Subscript i t Baseline Over sigma-summation Underscript t
    equals 1 Overscript upper T Endscripts StartAbsoluteValue upper P upper C Subscript
    i t Baseline EndAbsoluteValue EndFraction dollar-sign"><mrow><mi>L</mi> <msub><mi>R</mi>
    <mrow><mi>i</mi><mi>t</mi></mrow></msub> <mo>=</mo> <mfrac><mrow><msubsup><mo>∑</mo>
    <mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow> <mi>T</mi></msubsup> <msub><mi>P</mi>
    <mrow><mi>i</mi><mi>t</mi></mrow></msub> <msub><mi>V</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub></mrow>
    <mrow><msubsup><mo>∑</mo> <mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow> <mi>T</mi></msubsup>
    <mrow><mo>|</mo><mi>P</mi><msub><mi>C</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub>
    <mo>|</mo></mrow></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="upper P Subscript i t"><msub><mi>P</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub></math>
    is the total price of stock *i* on day *t*, <math alttext="upper V Subscript i
    t"><msub><mi>V</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub></math> represents
    the volume traded of stock *i* on day *t*, and finally, <math alttext="StartAbsoluteValue
    upper P upper C Subscript i t Baseline EndAbsoluteValue"><mrow><mrow><mo>|</mo>
    <mi>P</mi></mrow> <msub><mi>C</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub> <mrow><mo>|</mo></mrow></mrow></math>
    is the absolute value of difference between price at time *t* and *t* - 1.
  prefs: []
  type: TYPE_NORMAL
- en: The higher the ratio <math alttext="upper L upper R Subscript i t"><mrow><mi>L</mi>
    <msub><mi>R</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub></mrow></math> is, the
    higher the liquidity of asset *i* will be. This implies that higher traded volume,
    <math alttext="upper P Subscript i t Baseline upper V Subscript i t"><mrow><msub><mi>P</mi>
    <mrow><mi>i</mi><mi>t</mi></mrow></msub> <msub><mi>V</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub></mrow></math>
    , and low price difference, <math alttext="StartAbsoluteValue upper P upper C
    Subscript i t Baseline EndAbsoluteValue"><mrow><mrow><mo>|</mo> <mi>P</mi></mrow>
    <msub><mi>C</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub> <mrow><mo>|</mo></mrow></mrow></math>
    , amount to high liquidity level. Conversely, if a low volume is necessary to
    initiate a price change, then this asset is referred to as illiquid. Obviously,
    this conceptual framework focuses more on the price aspect than on the issue of
    time or on the execution costs typically present in a market (Gabrielsen, Marzo,
    and Zagaglia 2011).
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s first import the data and observe it via the following codes. As it is
    readily observable, the main variables in the dataset are ask (`ASKHI`), bid (`BIDLO`),
    open (`OPENPRC`), and trading price (`PRC`) along with the volume (`VOL`), return
    (`RET`), volume-weighted return (`vwretx`) of the stock, and number of shares
    outstanding (`SHROUT`):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'Calculating some liquidity measures requires a rolling-window estimation, such
    as the calculation of the bid price for five days. To accomplish this task, the
    list named `rolling_five` is generated using the following code:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_liquidity_modeling_CO1-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the required statistical measures for five-day window
  prefs: []
  type: TYPE_NORMAL
- en: Now, we have minimum bid price, max ask price, summation of volume traded, mean
    of the number of shares outstanding, and mean of the trading price per five days.
  prefs: []
  type: TYPE_NORMAL
- en: Hui-Heubel ratio
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Another measure that captures the depth is the Hui-Heubel liquidity ratio,
    known as <math alttext="upper L Subscript upper H upper H"><msub><mi>L</mi> <mrow><mi>H</mi><mi>H</mi></mrow></msub></math>
    :'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper L Subscript upper H upper H Baseline equals
    StartFraction upper P Subscript m a x Baseline minus upper P Subscript m i n Baseline
    Over upper P Subscript m i n Baseline EndFraction slash upper V slash upper P
    overbar times shrout dollar-sign"><mrow><msub><mi>L</mi> <mrow><mi>H</mi><mi>H</mi></mrow></msub>
    <mo>=</mo> <mfrac><mrow><msub><mi>P</mi> <mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub>
    <mo>-</mo><msub><mi>P</mi> <mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mrow>
    <msub><mi>P</mi> <mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></mfrac> <mo>/</mo>
    <mi>V</mi> <mo>/</mo> <mover><mi>P</mi> <mo>¯</mo></mover> <mo>×</mo> <mtext>shrout</mtext></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="upper P Subscript m a x"><msub><mi>P</mi> <mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></math>
    and <math alttext="upper P Subscript m i n"><msub><mi>P</mi> <mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></math>
    show maximum and minimum price over the determined period, respectively. <math
    alttext="upper P overbar"><mover><mi>P</mi> <mo>¯</mo></mover></math> is average
    closing price over determined period. What we have in the numerator is the percentage
    change in the stock price, and the volume traded is divided by market capitalization,
    i.e., <math alttext="upper P overbar times shrout"><mrow><mover><mi>P</mi> <mo>¯</mo></mover>
    <mo>×</mo> <mtext>shrout</mtext></mrow></math> in the denominator. One of the
    most distinguish features of Hui-Heubel liquidity measure is that it is applicable
    to a single stock, not only portfolios.
  prefs: []
  type: TYPE_NORMAL
- en: As discussed by Gabrielsen, Marzo, and Zagaglia (2011), <math alttext="upper
    P Subscript m a x"><msub><mi>P</mi> <mrow><mi>m</mi><mi>a</mi><mi>x</mi></mrow></msub></math>
    and <math alttext="upper P Subscript m i n"><msub><mi>P</mi> <mrow><mi>m</mi><mi>i</mi><mi>n</mi></mrow></msub></math>
    can be replaced by bid-ask spread but due to low volatility in bid-ask spread,
    it tends to bias downward.
  prefs: []
  type: TYPE_NORMAL
- en: 'To compute the Hui-Heubel liquidity ratio, we first have the liquidity measures
    in a list, then we add all these measures into the dataframe to have all-encompassing
    data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: Turnover ratio
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Turnover ratio has long been treated as a proxy for liquidity. It is basically
    the ratio of volatility to number of shares outstanding:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper L upper R Subscript i t Baseline equals StartFraction
    1 Over upper D Subscript i t Baseline EndFraction StartFraction sigma-summation
    Underscript t equals 1 Overscript upper T Endscripts upper V o l Subscript i t
    Baseline Over sigma-summation Underscript t equals 1 Overscript upper T Endscripts
    shrout Subscript i t Baseline EndFraction dollar-sign"><mrow><mi>L</mi> <msub><mi>R</mi>
    <mrow><mi>i</mi><mi>t</mi></mrow></msub> <mo>=</mo> <mfrac><mn>1</mn> <msub><mi>D</mi>
    <mrow><mi>i</mi><mi>t</mi></mrow></msub></mfrac> <mfrac><mrow><msubsup><mo>∑</mo>
    <mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow> <mi>T</mi></msubsup> <mi>V</mi><mi>o</mi><msub><mi>l</mi>
    <mrow><mi>i</mi><mi>t</mi></mrow></msub></mrow> <mrow><msubsup><mo>∑</mo> <mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow>
    <mi>T</mi></msubsup> <msub><mtext>shrout</mtext> <mrow><mi>i</mi><mi>t</mi></mrow></msub></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="upper D Subscript i t"><msub><mi>D</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub></math>
    denotes the number of trading days, <math alttext="upper V o l Subscript i t"><mrow><mi>V</mi>
    <mi>o</mi> <msub><mi>l</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub></mrow></math>
    is the number of shares traded at time *t*, and <math alttext="shrout Subscript
    i t"><msub><mtext>shrout</mtext> <mrow><mi>i</mi><mi>t</mi></mrow></msub></math>
    shows the number of shares outstanding at time *t*. A large turnover rate indicates
    a high level of liquidity, in that turnover implies trading frequency. As turnover
    rate incorporates the number of shares outstanding, it makes it a more subtle
    measure of liquidity.
  prefs: []
  type: TYPE_NORMAL
- en: 'Turnover ratio is calculated based on daily data, and then all the volume-based
    liquidity measures are converted into a dataframe and are included in `liq_vol_all`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: Transaction Cost–Based Liquidity Measures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In the real world, buyers and sellers do not magically meet in a frictionless
    environment. Rather, intermediaries (brokers and dealers), equipment (computers
    and the like), patience (trades cannot be realized instantaneously), and a rule
    book that stipulates how orders are to be handled and turned into trades are required.
    Also, the orders of large, institutional investors are big enough to affect market
    prices. All of these imply the existence of trading costs, and just how to structure
    a market (and a broader marketplace) to contain these costs is a subtle and intricate
    challenge (Baker and Kıymaz (2013). This led to the emergence of transaction cost.
  prefs: []
  type: TYPE_NORMAL
- en: '*Transaction cost* is a cost an investor must bear during trade. It is referred
    to as any expenses related to the execution of trade. A distinction of transaction
    cost as explicit and implicit costs is possible. The former relates to order processing,
    taxes, and brokerage fees, while the latter includes more latent costs, such as
    bid-ask spread, timing of execution, and so on.'
  prefs: []
  type: TYPE_NORMAL
- en: Transaction cost is related to the tightness and immediacy dimensions of liquidity.
    High transaction costs discourage investors to trade and this, in turn, decreases
    the number of buyers and sellers in the market so that the trading place diverges
    away from the more centralized market into a fragmented one, which result in a
    shallow market (Sarr and Lybek 2002). To the extent that transaction cost is low,
    investors are willing to trade and this results in a flourished trading environment
    in which markets will be more centralized.
  prefs: []
  type: TYPE_NORMAL
- en: Similarly, an abundance of buyers and sellers in a low transaction cost environment
    refers to the fact that a large number of orders are traded in a short period
    of time. So, immediacy is the other dimension of liquidity, which is closely related
    to the transaction cost.
  prefs: []
  type: TYPE_NORMAL
- en: Even though there is an ongoing debate about the goodness of bid-ask spread
    as well as the assurance that these models provide, bid-ask spread is a widely
    recognized proxy for transaction cost. To the extent that bid-ask spread is a
    good analysis of transaction cost, it is also a good indicator of liquidity by
    which the ease of converting an asset into cash (or a cash equivalent) might be
    determined. Without going into further detail, bid-ask spread can be measured
    by quoted spread, effective spread, and realized spread methods. So at first glance,
    it may seem strange to calculate bid-ask spread, which can be easily calculated
    by these methods. But this is not the case in reality. When the trade cannot be
    realized inside the quotes, then the spread is no longer the observed spread on
    which these methods are based.
  prefs: []
  type: TYPE_NORMAL
- en: Percentage quoted and effective bid-ask spreads
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The other two well-known bid-ask spreads are *percentage quoted* and *percentage
    effective* bid-ask spreads. Quoted spread measures the cost of completing a trade,
    that is, the difference in the bid-ask spread. There are different forms of quoted
    spread but for the sake of scaling, we’ll choose the percentage quoted spread:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign Percentage quoted spread equals StartFraction upper
    P Subscript a s k Baseline minus upper P Subscript b i d Baseline Over upper P
    Subscript m i d Baseline EndFraction dollar-sign"><mrow><mtext>Percentage</mtext>
    <mtext>quoted</mtext> <mtext>spread</mtext> <mo>=</mo> <mfrac><mrow><msub><mi>P</mi>
    <mrow><mi>a</mi><mi>s</mi><mi>k</mi></mrow></msub> <mo>-</mo><msub><mi>P</mi>
    <mrow><mi>b</mi><mi>i</mi><mi>d</mi></mrow></msub></mrow> <msub><mi>P</mi> <mrow><mi>m</mi><mi>i</mi><mi>d</mi></mrow></msub></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="upper P Subscript a s k"><msub><mi>P</mi> <mrow><mi>a</mi><mi>s</mi><mi>k</mi></mrow></msub></math>
    is the ask price of the stock and <math alttext="upper P Subscript b i d"><msub><mi>P</mi>
    <mrow><mi>b</mi><mi>i</mi><mi>d</mi></mrow></msub></math> is the bid price of
    the stock.
  prefs: []
  type: TYPE_NORMAL
- en: 'The effective spread measures the deviation between trading price and the mid-price,
    which is sometimes called the true underlying value of the stock. When trades
    occur either within or outside the quotes, a better measure of trading costs is
    the percentage effective half spread, which is based on the actual trade price,
    and is computed on a percentage basis (Bessembinder and Venkataraman 2010):'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign Effective spread equals StartFraction 2 StartAbsoluteValue
    upper P Subscript t Baseline minus upper P Subscript m i d Baseline EndAbsoluteValue
    Over upper P Subscript m i d Baseline EndFraction dollar-sign"><mrow><mtext>Effective</mtext>
    <mtext>spread</mtext> <mo>=</mo> <mfrac><mrow><mrow><mn>2</mn><mo>|</mo></mrow><msub><mi>P</mi>
    <mi>t</mi></msub> <mo>-</mo><msub><mi>P</mi> <mrow><mi>m</mi><mi>i</mi><mi>d</mi></mrow></msub>
    <mrow><mo>|</mo></mrow></mrow> <msub><mi>P</mi> <mrow><mi>m</mi><mi>i</mi><mi>d</mi></mrow></msub></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="upper P Subscript t"><msub><mi>P</mi> <mi>t</mi></msub></math>
    is the trading price of the stock and <math alttext="upper P Subscript m i d"><msub><mi>P</mi>
    <mrow><mi>m</mi><mi>i</mi><mi>d</mi></mrow></msub></math> is the midpoint of the
    bid-ask offer prevailing at the time of the trade.
  prefs: []
  type: TYPE_NORMAL
- en: 'It is relatively easy to calculate the percentage quoted and effective bid-ask
    spreads, as shown in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: Roll’s spread estimate
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'One of the first and foremost spread measures was proposed by Roll (1984).
    The *Roll spread* can be defined as:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign Roll equals StartRoot minus cov left-parenthesis
    normal upper Delta p Subscript t Baseline comma normal upper Delta p Subscript
    t minus 1 Baseline right-parenthesis EndRoot dollar-sign"><mrow><mtext>Roll</mtext>
    <mo>=</mo> <msqrt><mrow><mo>-</mo> <mtext>cov</mtext> <mo>(</mo> <mi>Δ</mi> <msub><mi>p</mi>
    <mi>t</mi></msub> <mo>,</mo> <mi>Δ</mi> <msub><mi>p</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub>
    <mo>)</mo></mrow></msqrt></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="normal upper Delta p Subscript t"><mrow><mi>Δ</mi> <msub><mi>p</mi>
    <mi>t</mi></msub></mrow></math> and <math alttext="normal upper Delta p Subscript
    t minus 1"><mrow><mi>Δ</mi> <msub><mi>p</mi> <mrow><mi>t</mi><mo>-</mo><mn>1</mn></mrow></msub></mrow></math>
    are the price differences at time *t* and at time *t* – 1, and <math alttext="cov"><mtext>cov</mtext></math>
    denotes the covariance between these price differences.
  prefs: []
  type: TYPE_NORMAL
- en: Assuming that the market is efficient^([1](ch07.html#idm45737216974144)) and
    the probability of distribution of observed price changes is stationary, Roll’s
    spread is motivated by the fact that serial correlation of price changes is a
    good proxy for liquidity.
  prefs: []
  type: TYPE_NORMAL
- en: 'One of the most important things to note in calculating Roll’s spread is that
    positive covariance is not well-defined, and it consists of almost half of the
    cases. The literature puts forth several methods to remedy this shortcoming, and
    we’ll embrace Harris’s (1990) approach in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_liquidity_modeling_CO2-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the covariance between price differences for the five-day window
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_liquidity_modeling_CO2-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Checking the case where the covariance is negative
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_liquidity_modeling_CO2-3)'
  prefs: []
  type: TYPE_NORMAL
- en: In the case of positive covariance, Harris’s approach is applied
  prefs: []
  type: TYPE_NORMAL
- en: The Corwin-Schultz spread
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'The *Corwin-Schultz spread* is rather intuitive and easy to apply. It rests
    mainly on the following assumption: given that the daily high and low prices are
    typically buyer and seller initiated, respectively, the observed price change
    can be split into effective price volatility and bid-ask spread. So the ratio
    of high-to-low prices for a day reflects both the stock’s variance and its bid-ask
    spread (Corwin and Schultz 2012; Abdi and Ranaldo 2017).'
  prefs: []
  type: TYPE_NORMAL
- en: 'This spread proposes an entirely new approach based on the daily high and low
    prices only, and the logic behind it is summarized by Corwin and Schultz (2012)
    as “the sum of the price ranges over 2 consecutive single days reflect 2 days’
    volatility and twice the spread, while the price range over one 2-day period reflects
    2 days’ volatility and one spread”:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper S equals StartFraction 2 left-parenthesis e
    Superscript alpha Baseline minus 1 right-parenthesis Over 1 plus e Superscript
    alpha Baseline EndFraction dollar-sign"><mrow><mi>S</mi> <mo>=</mo> <mfrac><mrow><mn>2</mn><mo>(</mo><msup><mi>e</mi>
    <mi>α</mi></msup> <mo>-</mo><mn>1</mn><mo>)</mo></mrow> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi>
    <mi>α</mi></msup></mrow></mfrac></mrow></math><math alttext="dollar-sign alpha
    equals StartFraction StartRoot 2 beta EndRoot minus StartRoot beta EndRoot Over
    3 minus 2 StartRoot 2 EndRoot EndFraction minus NestedStartRoot StartFraction
    gamma Over 3 minus 2 StartRoot 2 EndRoot EndFraction NestedEndRoot dollar-sign"><mrow><mi>α</mi>
    <mo>=</mo> <mfrac><mrow><msqrt><mrow><mn>2</mn><mi>β</mi></mrow></msqrt><mo>-</mo><msqrt><mi>β</mi></msqrt></mrow>
    <mrow><mn>3</mn><mo>-</mo><mn>2</mn><msqrt><mn>2</mn></msqrt></mrow></mfrac> <mo>-</mo>
    <msqrt><mfrac><mi>γ</mi> <mrow><mn>3</mn><mo>-</mo><mn>2</mn><msqrt><mn>2</mn></msqrt></mrow></mfrac></msqrt></mrow></math><math
    alttext="dollar-sign beta equals double-struck upper E left-parenthesis sigma-summation
    Underscript j equals 0 Overscript 1 Endscripts left-bracket l n left-parenthesis
    StartFraction upper H Subscript t plus j Superscript 0 Baseline Over upper L Subscript
    t plus j Superscript 0 Baseline EndFraction right-parenthesis right-bracket squared
    right-parenthesis dollar-sign"><mrow><mi>β</mi> <mo>=</mo> <mi>𝔼</mi> <mo>(</mo>
    <msubsup><mo>∑</mo> <mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow> <mn>1</mn></msubsup>
    <msup><mrow><mo>[</mo><mi>l</mi><mi>n</mi><mrow><mo>(</mo><mfrac><msubsup><mi>H</mi>
    <mrow><mi>t</mi><mo>+</mo><mi>j</mi></mrow> <mn>0</mn></msubsup> <msubsup><mi>L</mi>
    <mrow><mi>t</mi><mo>+</mo><mi>j</mi></mrow> <mn>0</mn></msubsup></mfrac> <mo>)</mo></mrow><mo>]</mo></mrow>
    <mn>2</mn></msup> <mo>)</mo></mrow></math><math alttext="dollar-sign gamma equals
    double-struck upper E left-parenthesis sigma-summation Underscript j equals 0
    Overscript 1 Endscripts left-bracket l n left-parenthesis StartFraction upper
    H Subscript t plus 1 Superscript 0 Baseline Over upper L Subscript t plus 1 Superscript
    0 Baseline EndFraction right-parenthesis right-bracket squared right-parenthesis
    dollar-sign"><mrow><mi>γ</mi> <mo>=</mo> <mi>𝔼</mi> <mo>(</mo> <msubsup><mo>∑</mo>
    <mrow><mi>j</mi><mo>=</mo><mn>0</mn></mrow> <mn>1</mn></msubsup> <msup><mrow><mo>[</mo><mi>l</mi><mi>n</mi><mrow><mo>(</mo><mfrac><msubsup><mi>H</mi>
    <mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow> <mn>0</mn></msubsup> <msubsup><mi>L</mi>
    <mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow> <mn>0</mn></msubsup></mfrac> <mo>)</mo></mrow><mo>]</mo></mrow>
    <mn>2</mn></msup> <mo>)</mo></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="upper H Subscript t Superscript upper A"><msubsup><mi>H</mi>
    <mi>t</mi> <mi>A</mi></msubsup></math> <math alttext="left-parenthesis upper L
    Subscript t Superscript upper A Baseline right-parenthesis"><mrow><mo>(</mo> <msubsup><mi>L</mi>
    <mi>t</mi> <mi>A</mi></msubsup> <mo>)</mo></mrow></math> denotes actual high (low)
    prices on day *t* and <math alttext="upper H Subscript t Superscript o"><msubsup><mi>H</mi>
    <mi>t</mi> <mi>o</mi></msubsup></math> or <math alttext="upper L Subscript t Superscript
    o"><msubsup><mi>L</mi> <mi>t</mi> <mi>o</mi></msubsup></math> the observed high
    (low) stock price on day *t*.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Corwin-Schultz spread requires multiple steps to calculate, as it includes
    many variables. The following code presents our way of doing this calculation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: Price Impact–Based Liquidity Measures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will introduce price impact–based liquidity measures by
    which we are able to gauge the extent to which price is sensitive to volume and
    turnover ratio. Recall that resiliency refers to the market responsiveness about
    new orders. If the market is responsive to the new order—that is, a new order
    correct the imbalances in the market—then it is said to be resilient. Thus, given
    a change in volume and/or turnover ratio, high price adjustment amounts to resiliency
    or vice versa.
  prefs: []
  type: TYPE_NORMAL
- en: 'We have three price impact–based liquidity measures to discuss:'
  prefs: []
  type: TYPE_NORMAL
- en: The Amihud illiquidity measure
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The Florackis, Andros, and Alexandros (2011) price impact ratio
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Coefficient of elasticity of trading (CET)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Amihud illiquidity
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'This liquidity proxy is a celebrated and widely recognized measure. Amihud
    illiquidity (2002) basically measures the sensitivity of the return to trading
    volume. More concretely, it gives us a sense about a change in absolute return
    as trading volume changes by $1\. The Amihud illiquidity measure, or ILLIQ for
    short, is well known among academics and practitioners:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign ILLIQ equals StartFraction 1 Over upper D Subscript
    i t Baseline EndFraction sigma-summation Underscript d equals 1 Overscript upper
    D Subscript i t Baseline Endscripts StartFraction StartAbsoluteValue upper R Subscript
    i t d Baseline EndAbsoluteValue Over upper V Subscript i t d Baseline EndFraction
    dollar-sign"><mrow><mtext>ILLIQ</mtext> <mo>=</mo> <mfrac><mn>1</mn> <msub><mi>D</mi>
    <mrow><mi>i</mi><mi>t</mi></mrow></msub></mfrac> <msubsup><mo>∑</mo> <mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow>
    <msub><mi>D</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub></msubsup> <mfrac><mrow><mrow><mo>|</mo></mrow><msub><mi>R</mi>
    <mrow><mi>i</mi><mi>t</mi><mi>d</mi></mrow></msub> <mrow><mo>|</mo></mrow></mrow>
    <msub><mi>V</mi> <mrow><mi>i</mi><mi>t</mi><mi>d</mi></mrow></msub></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="upper R Subscript i t d"><msub><mi>R</mi> <mrow><mi>i</mi><mi>t</mi><mi>d</mi></mrow></msub></math>
    is the stock return on day *t* at month *t*, <math alttext="upper V Subscript
    i t d"><msub><mi>V</mi> <mrow><mi>i</mi><mi>t</mi><mi>d</mi></mrow></msub></math>
    represents the dollar volume on day *d* at month *t*, and *D* is the number of
    observation days in month *t*.
  prefs: []
  type: TYPE_NORMAL
- en: The Amihud measure has two advantages over many other liquidity measures. First,
    the Amihud measure has a simple construction that uses the absolute value of the
    daily return-to-volume ratio to capture price impact. Second, the measure has
    a strong positive relation with expected stock return (Lou and Tao 2017).
  prefs: []
  type: TYPE_NORMAL
- en: 'The Amihud illiquidity measure is not hard to calculate. However, before directly
    calculating the Amihud’s measure, the dollar volume of stocks needs to be computed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: The price impact ratio
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'Florackis, Andros, and Alexandros (2011) aimed to improve the Amihud illiquidity
    ratio, and came up with a new liquidity measure, Return-to-Turnover (RtoTR). The
    disadvantages of Amihud’s illiquidity measure are listed by authors as:'
  prefs: []
  type: TYPE_NORMAL
- en: It is not comparable across stocks with different market capitalizations.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: It neglects the investor’s holding horizon.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'To deal with these drawbacks, Florackis, Andros, and Alexandros presented a
    new measure, RtoTR, that replaces the volume ratio of Amihud’s model with turnover
    ratio so that the new measure is able to capture the trading frequency:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign RtoTR equals StartFraction 1 Over upper D Subscript
    i t Baseline EndFraction sigma-summation Underscript d equals 1 Overscript upper
    D Subscript i t Baseline Endscripts StartFraction StartAbsoluteValue upper R Subscript
    i t d Baseline EndAbsoluteValue Over upper T upper R Subscript i t d Baseline
    EndFraction dollar-sign"><mrow><mtext>RtoTR</mtext> <mo>=</mo> <mfrac><mn>1</mn>
    <msub><mi>D</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub></mfrac> <msubsup><mo>∑</mo>
    <mrow><mi>d</mi><mo>=</mo><mn>1</mn></mrow> <msub><mi>D</mi> <mrow><mi>i</mi><mi>t</mi></mrow></msub></msubsup>
    <mfrac><mrow><mrow><mo>|</mo></mrow><msub><mi>R</mi> <mrow><mi>i</mi><mi>t</mi><mi>d</mi></mrow></msub>
    <mrow><mo>|</mo></mrow></mrow> <mrow><mi>T</mi><msub><mi>R</mi> <mrow><mi>i</mi><mi>t</mi><mi>d</mi></mrow></msub></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="upper T upper R Subscript i t d"><mrow><mi>T</mi> <msub><mi>R</mi>
    <mrow><mi>i</mi><mi>t</mi><mi>d</mi></mrow></msub></mrow></math> is the monetary
    volume of stock *i* on day *d* at month *t*, and the rest of the components are
    the same as in Amihud’s illiquidity measure.
  prefs: []
  type: TYPE_NORMAL
- en: The measure is as easy to calculate as Amihud’s measure, and it has no size
    bias because it includes the turnover ratio for capturing the trading frequency.
    This also helps us to examine the price and size effect.
  prefs: []
  type: TYPE_NORMAL
- en: 'The calculation of the price impact ratio is provided below:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Coefficient of elasticity of trading
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: CET is a liquidity measure proposed to remedy the shortcomings of time-related
    liquidity measures such as number of trades and orders per unit of time. These
    measures are adopted to assess the extent to which market immediacy affects the
    liquidity level.
  prefs: []
  type: TYPE_NORMAL
- en: 'Market immediacy and CET go hand in hand as it measures the price elasticity
    of trading volume and if price is responsive (i.e., elastic) to the trading volume,
    that amounts to a greater level of market immediacy:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign CET equals StartFraction percent-sign normal upper
    Delta upper V Over percent-sign normal upper Delta upper P EndFraction dollar-sign"><mrow><mtext>CET</mtext>
    <mo>=</mo> <mfrac><mrow><mo>%</mo><mi>Δ</mi><mi>V</mi></mrow> <mrow><mo>%</mo><mi>Δ</mi><mi>P</mi></mrow></mfrac></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="percent-sign normal upper Delta upper V"><mrow><mo>%</mo>
    <mi>Δ</mi> <mi>V</mi></mrow></math> refers to change in trading volume and <math
    alttext="percent-sign normal upper Delta upper P"><mrow><mo>%</mo> <mi>Δ</mi>
    <mi>P</mi></mrow></math> denotes a change in price.
  prefs: []
  type: TYPE_NORMAL
- en: 'The Python code of the CET formula is provided below. As a first part of this
    application, percentage difference in volume and price are calculated. Then all
    price impact-based liquidity measures are stored in the `liq_vol_all` dataframe:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_liquidity_modeling_CO3-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the percentage volume difference
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_liquidity_modeling_CO3-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Calculating the percentage price difference
  prefs: []
  type: TYPE_NORMAL
- en: Market Impact-Based Liquidity Measures
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Identifying the source of information is a big deal in finance because an unknown
    source of information might mislead investors and lead to unintended consequences.
    A price surge, for instance, arising from the market does not provide the same
    information as one arising from an individual stock. With that being said, a new
    source of information should be identified in a way to capture price movement
    properly.
  prefs: []
  type: TYPE_NORMAL
- en: To accomplish this task, we use the capital asset pricing model (CAPM), by which
    we can distinguish systematic and unsystematic risk. The famous slope coefficient
    in CAPM indicates systematic risks, and the unsystematic risk is attributable
    to individual stocks as long as market risk is removed.
  prefs: []
  type: TYPE_NORMAL
- en: 'As it is referenced in Sarr and Lybek (2002), Hui-Heubel embraces the following
    approach:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper R Subscript i Baseline equals alpha plus beta
    upper R Subscript m Baseline plus u Subscript i dollar-sign"><mrow><msub><mi>R</mi>
    <mi>i</mi></msub> <mo>=</mo> <mi>α</mi> <mo>+</mo> <mi>β</mi> <msub><mi>R</mi>
    <mi>m</mi></msub> <mo>+</mo> <msub><mi>u</mi> <mi>i</mi></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="upper R Subscript i"><msub><mi>R</mi> <mi>i</mi></msub></math>
    is the daily return on <math alttext="i Superscript t h"><msup><mi>i</mi> <mrow><mi>t</mi><mi>h</mi></mrow></msup></math>
    stock, and <math alttext="u Subscript i"><msub><mi>u</mi> <mi>i</mi></msub></math>
    is the idiosyncratic or unsystematic risk.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once we estimate residuals, <math alttext="u Subscript i"><msub><mi>u</mi>
    <mi>i</mi></msub></math> , from the equation, it is regressed over the volatility,
    <math alttext="upper V Subscript i"><msub><mi>V</mi> <mi>i</mi></msub></math>
    , and the estimated coefficient of <math alttext="upper V Subscript i"><msub><mi>V</mi>
    <mi>i</mi></msub></math> gives the liquidity level of the related stock, also
    known as the idiosyncratic risk:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign u Subscript i Superscript 2 Baseline equals gamma
    1 plus gamma 2 upper V Subscript i Baseline plus e Subscript i dollar-sign"><mrow><msubsup><mi>u</mi>
    <mi>i</mi> <mn>2</mn></msubsup> <mo>=</mo> <msub><mi>γ</mi> <mn>1</mn></msub>
    <mo>+</mo> <msub><mi>γ</mi> <mn>2</mn></msub> <msub><mi>V</mi> <mi>i</mi></msub>
    <mo>+</mo> <msub><mi>e</mi> <mi>i</mi></msub></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="u Subscript i Superscript 2"><msubsup><mi>u</mi> <mi>i</mi>
    <mn>2</mn></msubsup></math> denotes the squared residuals, <math alttext="upper
    V Subscript i"><msub><mi>V</mi> <mi>i</mi></msub></math> is the daily percentage
    change in trading volume, and <math alttext="e Subscript i"><msub><mi>e</mi> <mi>i</mi></msub></math>
    is the residual term.
  prefs: []
  type: TYPE_NORMAL
- en: 'Larger <math alttext="gamma 2"><msub><mi>γ</mi> <mn>2</mn></msub></math> implies
    larger price movements, and this gives us a sense about the liquidity of the stock.
    Conversely, the smaller <math alttext="gamma 2"><msub><mi>γ</mi> <mn>2</mn></msub></math>
    leads to smaller price movements, indicating higher liquidity levels. In code,
    we have:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_liquidity_modeling_CO4-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Assigning volume-weighted returns of all tickers as the independent variable
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_liquidity_modeling_CO4-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Assigning returns of all tickers as the dependent variable
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_liquidity_modeling_CO4-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Running the linear regression model with the defined variables
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_liquidity_modeling_CO4-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Storing the residuals coming from the linear regression as an unsystematic factor
  prefs: []
  type: TYPE_NORMAL
- en: 'And then we calculate the market impact-based liquidity ratio:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_liquidity_modeling_CO5-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Assigning percentage change in volume of all tickers as the independent variable
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_liquidity_modeling_CO5-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Market impact the residual of this linear regression
  prefs: []
  type: TYPE_NORMAL
- en: 'Then, we include the market impact in our dataframe and observe the summary
    statistics of all the liquidity measures that we’ve introduced so far:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_liquidity_modeling_CO6-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Appending market impact into the `liq_vol_all` dataframe.
  prefs: []
  type: TYPE_NORMAL
- en: These are the liquidity measures that we take advantage of in the process of
    modeling the liquidity via GMM. Now let’s discuss this via a probabilistic unsupervised
    learning algorithm.
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian Mixture Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: What happens if we have data with several modes that represent different aspects
    of the data? Or let’s put it in the context of liquidity measures, how can you
    model liquidity measures with different mean variance? As you can imagine, data
    consisting of liquidity measures is multimodal, meaning that there exists several
    different high-probability masses and our task is to find out which model fits
    best to this type of data.
  prefs: []
  type: TYPE_NORMAL
- en: It is evident that the proposed model is supposed to include a mixture of several
    components, and without knowing the specific liquidity measure, it should be clustered
    based on the values obtained from the measures. To recap, we will have one big
    dataset that includes all liquidity measures, and assuming for the moment that
    we forgot to assign labels to these measures, we need a model that presents different
    distributions of these measures without knowing the labels. This model is GMM,
    which enables us to model multimodal data without knowing the names of the variables.
  prefs: []
  type: TYPE_NORMAL
- en: Considering the different focus of the liquidity measures introduced before,
    if we somehow manage to model this data, that means we can capture different liquidity
    level at different times. For instance, liquidity in a high-volatility period
    cannot be modeled in the same way as a low-volatility period. In a similar vein,
    given the depth of the market, we need to focus on these different aspects of
    liquidity. GMM provides us with a tool to address this problem.
  prefs: []
  type: TYPE_NORMAL
- en: Long story short, if a market is experiencing a boom period, which coincides
    with high volatility, volume and transaction cost–based measures would be good
    choices, and if a market ends up with price discontinuity, price-based measures
    would be the optimal choice. Of course, we are not talking about one-size-fits-all
    measures—there may be some instances in which a mixture of measures would work
    better.
  prefs: []
  type: TYPE_NORMAL
- en: 'As put by VanderPlas (2016), for K-means to succeed, cluster models must have
    circular characteristics. Nevertheless, many financial variables exhibit non-circular
    shapes that make it hard to model via K-means. As is readily observable, liquidity
    measures overlap and do not have circular shapes, so GMM with its probabilistic
    nature would be a good choice for modeling this type of data, as described by
    Fraley and Raftery (1998):'
  prefs: []
  type: TYPE_NORMAL
- en: One advantage of the mixture-model approach to clustering is that it allows
    the use of approximate Bayes factors to compare models. This gives a systematic
    means of selecting not only the parameterization of the model (and hence the clustering
    method), but also the number of clusters.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: In this part, we would like to import necessary libraries to be used in the
    GMM. Also, scaling is applied, which is an essential step in clustering as we
    have mixed numerical values in the dataframe. In the last part of the code that
    follows, a histogram is drawn to observe the multimodality in the data ([Figure 7-1](#modality_liq)).
    This is a phenomenon that we have discussed in the very first part of this section.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '![modality](assets/mlfr_0701.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-1\. Multimodality of the liquidity measures
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: And now, given the transaction cost, volume, and market-based liquidity measures,
    multimodality (i.e., three peaks) can be easily observed in [Figure 7-1](#modality_liq).
    Due to the scaling issue, the price impact–based liquidity dimension is not included
    in the histogram.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s run GMM and see how we can cluster the liquidity measures. But first,
    a common question arises: how many clusters should we have? To address this question,
    we’ll use BIC again, and generate the plot shown in [Figure 7-2](#scree_gmm):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_liquidity_modeling_CO7-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Generating different BIC values based on different numbers of clusters
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_liquidity_modeling_CO7-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Drawing a line plot for BIC values given number of components
  prefs: []
  type: TYPE_NORMAL
- en: '![opt_cluster](assets/mlfr_0702.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-2\. Optimum number of components
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: '[Figure 7-2](#scree_gmm) shows us that the line seems to flatten out after
    the third cluster, making that an ideal point at which to stop.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Using the following code, we are able to detect the state by which data is
    best represented. The term *state* represents nothing but the cluster with the
    highest posterior probability. It means that this specific state accounts for
    the dynamics of the data most. In this case, State-3 with a probability of 0.55
    is the most likely state to explain the dynamics of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_liquidity_modeling_CO8-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring the GMM
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_liquidity_modeling_CO8-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Fitting GMM with scaled data
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_liquidity_modeling_CO8-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Running prediction
  prefs: []
  type: TYPE_NORMAL
- en: '[![4](assets/4.png)](#co_liquidity_modeling_CO8-4)'
  prefs: []
  type: TYPE_NORMAL
- en: Obtaining the state probabilities
  prefs: []
  type: TYPE_NORMAL
- en: '[![5](assets/5.png)](#co_liquidity_modeling_CO8-5)'
  prefs: []
  type: TYPE_NORMAL
- en: Computing the average of all three state probabilities
  prefs: []
  type: TYPE_NORMAL
- en: All right, does it not make sense to apply GMM to cluster liquidity measures
    and extract the likely state to represent it as one-dimensional data? It literally
    makes our lives easier because at the end of the data, we come up with only one
    cluster with highest probability. But what would you think if we applied PCA to
    fully understand which variables are correlated with the prevailing state? In
    PCA, we are able to build a bridge between components and features using loadings
    so that we can analyze which liquidity measures have the defining characteristics
    of a specific period.
  prefs: []
  type: TYPE_NORMAL
- en: 'As a first step, let’s apply PCA and create a scree plot ([Figure 7-3](#scree_plot_gmm))
    to determine the number of components we are working with:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: '![scree_plot_gmm](assets/mlfr_0703.png)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7-3\. Scree plot
  prefs:
  - PREF_H6
  type: TYPE_NORMAL
- en: Based on [Figure 7-3](#scree_plot_gmm), we’ll decide to stop at component 3.
  prefs: []
  type: TYPE_NORMAL
- en: 'As we now have determined the number of components, let’s rerun PCA with three
    components and GMM. Similar to our previous GMM application, posterior probability
    is calculated and assigned to a variable named `state_probs`:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'In what follows, we find out the state with the highest probability, and it
    turns out to be State-1 with a probability of 73%:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s now turn our attention to finding which liquidity measures matter most
    using loading analysis. This analysis suggests that `turnover_ratio`, `percent_quoted_ba`,
    `percent_effective_ba`, `amihud`, and `florackis` ratios are the liquidity ratios
    composing the State-1\. The following code shows the result:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_liquidity_modeling_CO9-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Calculating loading from PCA
  prefs: []
  type: TYPE_NORMAL
- en: Gaussian Mixture Copula Model
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Given the complexity and sophistication of financial markets, it is not possible
    to suggest one-size-fits-all risk models. Thus, financial institutions develop
    their own models for credit, liquidity, market, and operational risks so that
    they can manage the risks they face more efficiently and realistically. However,
    one of the biggest challenges that these financial institutions come across is
    the correlation, also known as joint distribution, of the risk, as put by Rachev
    and Stein (2009):'
  prefs: []
  type: TYPE_NORMAL
- en: With the emergence of the sub-prime crisis and the following credit crunch,
    academics, practitioners, philosophers and journalists started searching for causes
    and failures that led to the turmoil and (almost) unprecedented market deteriorations...
    the arguments against several methods and models used at Wall Street and throughout
    the world are, in many cases, putting those in the wrong light. Beyond the fact
    that risks and issues were clouded by the securitization, tranching and packaging
    of underlyings in the credit markets as well as by the unfortunate and somehow
    misleading role of rating agencies, mathematical models were used in the markets
    which are now under fire due to their incapability of capturing risks in extreme
    market phases.
  prefs:
  - PREF_BQ
  type: TYPE_NORMAL
- en: The task of modeling “extreme market phases” leads us to the concept of joint
    distribution by which we are allowed to model multiple risks with a single distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'A model disregarding the interaction of risks is destined for failure. In this
    respect, an intuitive yet simple approach is proposed: *copulas*.'
  prefs: []
  type: TYPE_NORMAL
- en: Copula is a function that maps marginal distribution of individual risks to
    multivariate distribution, resulting in a joint distribution of many standard
    uniform random variables. If we are working with a known distribution, such as
    normal distribution, it is easy to model joint distribution of variables, known
    as bivariate normal. However, the challenge here is to define the correlation
    structure between these two variables, and this is the point at which copulas
    come in (Hull 2012).
  prefs: []
  type: TYPE_NORMAL
- en: 'With Sklar’s theorem, let *F* be a marginal continuous cumulative distribution
    function (CDF) of <math alttext="upper X Superscript i"><msup><mi>X</mi> <mi>i</mi></msup></math>
    . A CDF transformation maps a random variable to a scalar that is uniformly distributed
    in [0,1]. However, the joint distribution of all these marginal CDFs does not
    follow uniform distribution and a copula function (Kasa and Rajan 2020):'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper C colon left-bracket 0 comma 1 right-bracket
    Superscript i Baseline right-arrow left-bracket 0 comma 1 right-bracket dollar-sign"><mrow><mi>C</mi>
    <mo>:</mo> <msup><mrow><mo>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>]</mo></mrow>
    <mi>i</mi></msup> <mo>→</mo> <mrow><mo>[</mo> <mn>0</mn> <mo>,</mo> <mn>1</mn>
    <mo>]</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'where *i* shows the number of marginal CDFs. In other words, in the bivariate
    case, *i* takes the value of 2 and the function becomes:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper C colon left-bracket 0 comma 1 right-bracket
    squared right-arrow left-bracket 0 comma 1 right-bracket dollar-sign"><mrow><mi>C</mi>
    <mo>:</mo> <msup><mrow><mo>[</mo><mn>0</mn><mo>,</mo><mn>1</mn><mo>]</mo></mrow>
    <mn>2</mn></msup> <mo>→</mo> <mrow><mo>[</mo> <mn>0</mn> <mo>,</mo> <mn>1</mn>
    <mo>]</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: 'Hence:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper F left-parenthesis x 1 comma x 2 right-parenthesis
    identical-to upper C left-parenthesis upper F 1 left-parenthesis x 1 right-parenthesis
    comma period period period comma upper F Subscript i Baseline left-parenthesis
    x Subscript i Baseline right-parenthesis right-parenthesis dollar-sign"><mrow><mi>F</mi>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>x</mi>
    <mn>2</mn></msub> <mo>)</mo></mrow> <mo>≡</mo> <mi>C</mi> <mrow><mo>(</mo> <msub><mi>F</mi>
    <mn>1</mn></msub> <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>)</mo></mrow>
    <mo>,</mo> <mo>.</mo> <mo>.</mo> <mo>.</mo> <mo>,</mo> <msub><mi>F</mi> <mi>i</mi></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where *C* is copula and unique given the marginal distribution of <math alttext="upper
    F Subscript i"><msub><mi>F</mi> <mi>i</mi></msub></math> s are continuous and
    *F* is joint cumulative distribution.
  prefs: []
  type: TYPE_NORMAL
- en: 'Alternatively, the copula function can be described by individual marginal
    densities:'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign f left-parenthesis x right-parenthesis equals upper
    C left-parenthesis upper F 1 left-parenthesis x 1 right-parenthesis comma period
    period period comma upper F Subscript i Baseline left-parenthesis x Subscript
    i Baseline right-parenthesis right-parenthesis product Underscript j equals 1
    Overscript i Endscripts f Subscript j Baseline left-parenthesis x Subscript j
    Baseline right-parenthesis dollar-sign"><mrow><mi>f</mi> <mrow><mo>(</mo> <mi>x</mi>
    <mo>)</mo></mrow> <mo>=</mo> <mi>C</mi> <mrow><mo>(</mo> <msub><mi>F</mi> <mn>1</mn></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mn>1</mn></msub> <mo>)</mo></mrow> <mo>,</mo>
    <mo>.</mo> <mo>.</mo> <mo>.</mo> <mo>,</mo> <msub><mi>F</mi> <mi>i</mi></msub>
    <mrow><mo>(</mo> <msub><mi>x</mi> <mi>i</mi></msub> <mo>)</mo></mrow> <mo>)</mo></mrow>
    <msubsup><mo>∏</mo> <mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow> <mi>i</mi></msubsup>
    <msub><mi>f</mi> <mi>j</mi></msub> <mrow><mo>(</mo> <msub><mi>x</mi> <mi>j</mi></msub>
    <mo>)</mo></mrow></mrow></math>
  prefs: []
  type: TYPE_NORMAL
- en: where <math alttext="f left-parenthesis x right-parenthesis"><mrow><mi>f</mi>
    <mo>(</mo> <mi>x</mi> <mo>)</mo></mrow></math> denotes multivariate density, and
    <math alttext="f Subscript j"><msub><mi>f</mi> <mi>j</mi></msub></math> is marginal
    density of the <math alttext="j Superscript t h"><msup><mi>j</mi> <mrow><mi>t</mi><mi>h</mi></mrow></msup></math>
    asset.
  prefs: []
  type: TYPE_NORMAL
- en: 'We cannot complete our discussion without stating the assumptions that we need
    to satisfy for copulas. Here are the assumptions from Bouye (2000):'
  prefs: []
  type: TYPE_NORMAL
- en: <math alttext="upper C equals upper S 1 times upper S 2"><mrow><mi>C</mi> <mo>=</mo>
    <msub><mi>S</mi> <mn>1</mn></msub> <mo>×</mo> <msub><mi>S</mi> <mn>2</mn></msub></mrow></math>
    , where <math alttext="upper S 1"><msub><mi>S</mi> <mn>1</mn></msub></math> and
    <math alttext="upper S 2"><msub><mi>S</mi> <mn>2</mn></msub></math> are non-empty
    subsets of [0,1].
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '*C* is an increasing function such that <math alttext="0 less-than-or-equal-to
    u 1 less-than-or-equal-to u 2 less-than-or-equal-to 1"><mrow><mn>0</mn> <mo>≤</mo>
    <msub><mi>u</mi> <mn>1</mn></msub> <mo>≤</mo> <msub><mi>u</mi> <mn>2</mn></msub>
    <mo>≤</mo> <mn>1</mn></mrow></math> and <math alttext="0 less-than-or-equal-to
    v 1 less-than-or-equal-to v 2 less-than-or-equal-to 1"><mrow><mn>0</mn> <mo>≤</mo>
    <msub><mi>v</mi> <mn>1</mn></msub> <mo>≤</mo> <msub><mi>v</mi> <mn>2</mn></msub>
    <mo>≤</mo> <mn>1</mn></mrow></math> .'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: <math alttext="dollar-sign upper C left-parenthesis left-bracket u 1 comma v
    1 right-bracket times left-bracket u 2 comma v 2 right-bracket right-parenthesis
    identical-to upper C left-parenthesis u 2 comma v 2 right-parenthesis minus upper
    C left-parenthesis u 2 comma v 2 right-parenthesis minus upper C left-parenthesis
    u 1 comma v 2 right-parenthesis plus upper C left-parenthesis u 1 comma u 1 right-parenthesis
    greater-than-or-equal-to 0 dollar-sign"><mrow><mi>C</mi> <mrow><mo>(</mo> <mrow><mo>[</mo>
    <msub><mi>u</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>v</mi> <mn>1</mn></msub>
    <mo>]</mo></mrow> <mo>×</mo> <mrow><mo>[</mo> <msub><mi>u</mi> <mn>2</mn></msub>
    <mo>,</mo> <msub><mi>v</mi> <mn>2</mn></msub> <mo>]</mo></mrow> <mo>)</mo></mrow>
    <mo>≡</mo> <mi>C</mi> <mrow><mo>(</mo> <msub><mi>u</mi> <mn>2</mn></msub> <mo>,</mo>
    <msub><mi>v</mi> <mn>2</mn></msub> <mo>)</mo></mrow> <mo>-</mo> <mi>C</mi> <mrow><mo>(</mo>
    <msub><mi>u</mi> <mn>2</mn></msub> <mo>,</mo> <msub><mi>v</mi> <mn>2</mn></msub>
    <mo>)</mo></mrow> <mo>-</mo> <mi>C</mi> <mrow><mo>(</mo> <msub><mi>u</mi> <mn>1</mn></msub>
    <mo>,</mo> <msub><mi>v</mi> <mn>2</mn></msub> <mo>)</mo></mrow> <mo>+</mo> <mi>C</mi>
    <mrow><mo>(</mo> <msub><mi>u</mi> <mn>1</mn></msub> <mo>,</mo> <msub><mi>u</mi>
    <mn>1</mn></msub> <mo>)</mo></mrow> <mo>≥</mo> <mn>0</mn></mrow></math>
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: 'For every *u* in <math alttext="upper S 1"><msub><mi>S</mi> <mn>1</mn></msub></math>
    and for every *v* in <math alttext="upper S 2"><msub><mi>S</mi> <mn>2</mn></msub></math>
    : *C*(*u*, 1) = *u* and *C*(1, *v*) = *v*.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'After a long theoretical discussion about copulas, you may be tempted to think
    about the complexity of its coding in Python. No worries, we have a library for
    that and it is really easy to apply. The name of the Python library for copulas
    is called Copulae, and we will make use of it in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '[![1](assets/1.png)](#co_liquidity_modeling_CO10-1)'
  prefs: []
  type: TYPE_NORMAL
- en: Importing `GaussianMixtureCopula` from `copulae`
  prefs: []
  type: TYPE_NORMAL
- en: '[![2](assets/2.png)](#co_liquidity_modeling_CO10-2)'
  prefs: []
  type: TYPE_NORMAL
- en: Configuring GMCM with the number of clusters and dimensions
  prefs: []
  type: TYPE_NORMAL
- en: '[![3](assets/3.png)](#co_liquidity_modeling_CO10-3)'
  prefs: []
  type: TYPE_NORMAL
- en: Fitting the GMCM
  prefs: []
  type: TYPE_NORMAL
- en: The result suggests that when the correlation is taken into account, State-2
    prevails, but the posterior probabilities are very close to each other, implying
    that when correlation between liquidity measures comes into the picture, commonality
    in liquidity stands out.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Liquidity risk has been under a microscope for over a decade as it is an important
    source of risk by itself and also has high correlation with other financial risks.
  prefs: []
  type: TYPE_NORMAL
- en: This chapter introduces a new method for liquidity modeling based on GMM, which
    allows us to model multivariate data and generate clusters. Given the posterior
    probability of these clusters, we were able to determine which cluster represented
    the defining characteristics of the data. However, without considering the correlation
    structure of the liquidity measures, our model may not have been a good representation
    of reality. Thus, to address this concern, we introduced GMCM, and the defining
    cluster was redefined by taking into account the correlation structure among the
    variables.
  prefs: []
  type: TYPE_NORMAL
- en: 'After completing the liquidity modeling, we are now ready to discuss another
    important source of financial risk: *operational risk*. Operational risk may arise
    for a variety of reasons, but we will discuss operational risk via fraudulent
    activities.'
  prefs: []
  type: TYPE_NORMAL
- en: References
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Articles cited in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Abdi, Farshid, and Angelo Ranaldo. 2017\. “A Simple Estimation of Bid-Ask Spreads
    from Daily Close, High, and Low Prices.” *The Review of Financial Studies* 30
    (12): 4437-4480.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Baker, H. Kent, and Halil Kiymaz, eds. 2013\. *Market Microstructure in Emerging
    and Developed Markets: Price Discovery, Information Flows, and Transaction Costs*.
    Hoboken, New Jersey: John Wiley and Sons.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bessembinder, Hendrik, and Kumar Venkataraman. 2010\. “Bid–Ask Spreads.” in
    *Encyclopedia of Quantitative Finance*, edited b. Rama Cont. Hoboken, NJ: John
    Wiley and Sons.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Blume, Lawrence, David Easley, and Maureen O’Hara. 1994 “Market Statistics
    and Technical Analysis: The Role of Volume.” The Journal of Finance 49 (1): 153-181.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Bouyé, Eric, Valdo Durrleman, Ashkan Nikeghbali, Gaël Riboulet, and Thierry
    Roncalli. 2000\. “Copulas for Finance: A Reading Guide and Some Applications.”
    Available at SSRN 1032533.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Chuck, Prince. 2007\. “Citigroup Chief Stays Bullish on Buy-Outs.” *Financial
    Times*. [*https://oreil.ly/nKOZk*](https://oreil.ly/nKOZk).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Corwin, Shane A., and Paul Schultz. 2012\. “A Simple Way to Estimate Bid‐Ask
    Spreads from Daily High and Low Prices.” *The Journal of Finance* 67 (2): 719-760.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Florackis, Chris, Andros Gregoriou, and Alexandros Kostakis. 2011\. “Trading
    Frequency and Asset Pricing on the London Stock Exchange: Evidence from a New
    Price Impact Ratio.” *Journal of Banking and Finance* 35 (12): 3335-3350.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Fraley, Chris, and Adrian E. Raftery. 1998\. “How Many Clusters? Which Clustering
    Method? Answers via Model-Based Cluster Analysis.” The Computer Journal 41 (8):
    578-588.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gabrielsen, Alexandros, Massimiliano Marzo, and Paolo Zagaglia. 2011\. “Measuring
    Market Liquidity: An Introductory Survey.” *SRN Electronic Journal*.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Harris, Lawrence. 1990\. “Statistical Properties of the Roll Serial Covariance
    Bid/Ask Spread Estimator.” *The Journal of Finance* 45 (2): 579-590.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Gaygisiz, Esma, Abdullah Karasan, and Alper Hekimoglu. 2021\. “Analyses of
    factors of Market Microstructure: Price impact, liquidity, and Volatility.” *Optimization*
    (Forthcoming).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Kasa, Siva Rajesh, and Vaibhav Rajan. 2020\. “Improved Inference of Gaussian
    Mixture Copula Model for Clustering and Reproducibility Analysis using Automatic
    Differentiation.” arXiv preprint arXiv:2010.14359.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Kyle, Albert S. 1985\. “Continuous Auctions and Insider Trading.” *Econometrica*
    53 (6): 1315-1335.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Le, Huong, and Andros Gregoriou. 2020\. “How Do You Capture Liquidity? A Review
    of the Literature on Low‐Frequency Stock Liquidity.” *Journal of Economic Surveys*
    34 (5): 1170-1186.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Lou, Xiaoxia, and Tao Shu. 2017\. “Price Impact or Trading Volume: Why Is the
    Amihud (2002) measure Priced?.” *The Review of Financial Studies* 30 (12): 4481-4520.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Nikolaou, Kleopatra. 2009\. “Liquidity (Risk) concepts: Definitions and Interactions.”
    European Central Bank Working Paper Series 1008.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Rachev, S. T., W. Sun, and M. stein. 2009\. “Copula Concepts in Financial Markets.”
    *Portfolio Institutionell* (4): 12-15.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Roll, Richard. 1984\. “A Simple Implicit Measure of the Effective Bid‐Ask Spread
    in an Efficient Market.” *The Journal of Finance* 29 (4): 1127-1139.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Sarr, Abdourahmane, and Tonny Lybek. 2002\. “Measuring liquidity in financial
    markets.” IMF Working Papers (02/232): 1-64.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Books and online sources cited in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: 'Hull, John. 2012\. *Risk Management and Financial Institutions*. Hoboken, New
    Jersey: John Wiley and Sons.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'VanderPlas, Jake. 2016\. *Python Data Science Handbook: Essential Tools for
    Working with Data*. Sebastopol: O’Reilly.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ^([1](ch07.html#idm45737216974144-marker)) *Efficient market* refers to how
    well and fast current prices reflect all available information about the value
    of the underlying asset(s).
  prefs: []
  type: TYPE_NORMAL
