<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 2. Developing a Machine Learning &#10;Model in Python"><div class="chapter" id="Chapter2">
<h1><span class="label">Chapter 2. </span>Developing a Machine Learning 
<span class="keep-together">Model in Python</span></h1>


<p><a data-type="indexterm" data-primary="Python (generally)" id="ix_Chapter2-asciidoc0"/>In terms of the platforms used for machine learning, there are many algorithms and programming languages. However, the Python ecosystem is one of the most dominant and fastest-growing programming languages for machine learning.</p>

<p>Given the popularity and high adoption rate of Python, we will use it as the main programming language throughout the book. This chapter provides an overview of a Python-based machine learning framework. First, we will review the details of Python-based packages used for machine learning, followed by the model development steps in the Python framework.</p>

<p>The steps of model development in Python presented in this chapter serve as the foundation for the case studies presented in the rest of the book. The Python framework can also be leveraged while developing any machine learning–based model in finance.</p>






<section data-type="sect1" data-pdf-bookmark="Why Python?"><div class="sect1" id="idm45174935561704">
<h1>Why Python?</h1>

<p><a data-type="indexterm" data-primary="Python (generally)" data-secondary="advantages of using" id="idm45174935560504"/>Some reasons for Python’s popularity are as follows:</p>

<ul>
<li>
<p>High-level syntax (compared to lower-level languages of C, Java, and C++). Applications can be developed by writing fewer lines of code, making Python attractive to beginners and advanced programmers alike.</p>
</li>
<li>
<p>Efficient development lifecycle.</p>
</li>
<li>
<p>Large collection of community-managed, open-source libraries.</p>
</li>
<li>
<p>Strong portability.</p>
</li>
</ul>

<p>The simplicity of Python has attracted many developers to create new libraries for machine learning, leading to strong adoption of Python.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Python Packages for Machine Learning"><div class="sect1" id="idm45174935554440">
<h1>Python Packages for Machine Learning</h1>

<p><a data-type="indexterm" data-primary="Python (generally)" data-secondary="machine learning packages" id="idm45174935503480"/>The main Python packages used for machine learning are highlighted in <a data-type="xref" href="#Packages">Figure 2-1</a>.</p>

<figure><div id="Packages" class="figure">
<img src="Images/mlbf_0201.png" alt="mlbf 0201" width="1158" height="652"/>
<h6><span class="label">Figure 2-1. </span>Python packages</h6>
</div></figure>

<p>Here is a brief summary of each of these packages:</p>
<dl>
<dt><a href="https://numpy.org">NumPy</a></dt>
<dd>
<p><a data-type="indexterm" data-primary="NumPy" id="idm45174935496648"/>Provides support for large, multidimensional arrays as well as an extensive collection of mathematical functions.</p>
</dd>
<dt><a href="https://pandas.pydata.org">Pandas</a></dt>
<dd>
<p><a data-type="indexterm" data-primary="Pandas" id="idm45174935494120"/>A library for data manipulation and analysis. Among other features, it offers data structures to handle tables and the tools to manipulate them.</p>
</dd>
<dt><a href="https://matplotlib.org">Matplotlib</a></dt>
<dd>
<p><a data-type="indexterm" data-primary="Matplotlib" id="idm45174935491576"/>A plotting library that allows the creation of 2D charts and plots.</p>
</dd>
<dt><a href="https://www.scipy.org">SciPy</a></dt>
<dd>
<p><a data-type="indexterm" data-primary="SciPy" id="idm45174935489192"/>The combination of NumPy, Pandas, and Matplotlib is generally referred to as SciPy. SciPy is an ecosystem of Python libraries for mathematics, science, and engineering.</p>
</dd>
<dt><a href="https://scikit-learn.org">Scikit-learn</a> (or sklearn)</dt>
<dd>
<p><a data-type="indexterm" data-primary="Scikit-learn" id="idm45174935486440"/><a data-type="indexterm" data-primary="sklearn" id="idm45174935485736"/>A machine learning library offering a wide range of algorithms and utilities.</p>
</dd>
<dt><a href="https://www.statsmodels.org">StatsModels</a></dt>
<dd>
<p><a data-type="indexterm" data-primary="StatsModels" id="idm45174935483368"/>A Python module that provides classes and functions for the estimation of many different statistical models, as well as for conducting statistical tests and statistical data exploration.</p>
</dd>
<dt><a href="https://www.tensorflow.org">TensorFlow</a> and <a href="http://deeplearning.net/software/theano">Theano</a></dt>
<dd>
<p><a data-type="indexterm" data-primary="Keras" id="idm45174935539112"/><a data-type="indexterm" data-primary="TensorFlow" id="idm45174935538408"/><a data-type="indexterm" data-primary="Theano" id="idm45174935537736"/>Dataflow programming libraries that facilitate working with neural networks.</p>
</dd>
<dt><a href="https://keras.io">Keras</a></dt>
<dd>
<p>An artificial neural network library that can act as a simplified interface to TensorFlow/Theano packages.</p>
</dd>
<dt><a href="https://seaborn.pydata.org">Seaborn</a></dt>
<dd>
<p><a data-type="indexterm" data-primary="Seaborn" id="idm45174935533528"/>A data visualization library based on Matplotlib. It provides a high-level interface for drawing attractive and informative statistical graphics.</p>
</dd>
<dt><a href="https://pypi.org/project/pip">pip</a> and <a href="https://docs.conda.io/en/latest">Conda</a></dt>
<dd>
<p><a data-type="indexterm" data-primary="Conda" id="idm45174935530232"/><a data-type="indexterm" data-primary="pip" id="idm45174935529528"/>These are Python package managers. pip is a package manager that facilitates installation, upgrade, and uninstallation of Python packages. Conda is a package manager that handles Python packages as well as library dependencies outside of the Python packages.</p>
</dd>
</dl>








<section data-type="sect2" data-pdf-bookmark="Python and Package Installation"><div class="sect2" id="idm45174935498136">
<h2>Python and Package Installation</h2>

<p><a data-type="indexterm" data-primary="Python (generally)" data-secondary="package installation" id="idm45174935527464"/>There are different ways of installing Python. <a data-type="indexterm" data-primary="Anaconda" id="idm45174935526296"/>However, it is strongly recommended that you install Python through <a href="https://www.anaconda.com">Anaconda</a>. Anaconda contains Python, SciPy, and Scikit-learn.</p>

<p>After installing Anaconda, a Jupyter server can be started locally by opening the machine’s terminal and typing in the following code:</p>

<pre data-type="programlisting">$jupyter notebook</pre>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>All code samples in this book use Python 3 and are presented in Jupyter notebooks. Several Python packages, especially Scikit-learn and Keras, are extensively used in the case studies.</p>
</div>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Steps for Model Development in Python Ecosystem"><div class="sect1" id="idm45174935521944">
<h1>Steps for Model Development in Python Ecosystem</h1>

<p><a data-type="indexterm" data-primary="Python (generally)" data-secondary="steps for model development in Python ecosystem" id="ix_Chapter2-asciidoc1"/>Working through machine learning problems from end to end is critically important. Applied machine learning will not come alive unless the steps from beginning to end are well defined.</p>

<p><a data-type="xref" href="#StepsofML">Figure 2-2</a> provides an outline of the simple seven-step machine learning project template that can be used to jump-start any machine learning model in Python. The first few steps include exploratory data analysis and data preparation, which are typical data science–based steps aimed at extracting meaning and insights from data. These steps are followed by model evaluation, fine-tuning, and finalizing the model.</p>

<figure><div id="StepsofML" class="figure">
<img src="Images/mlbf_0202.png" alt="mlbf 0202" width="1422" height="561"/>
<h6><span class="label">Figure 2-2. </span>Model development steps</h6>
</div></figure>
<div data-type="note" epub:type="note"><h6>Note</h6>
<p>All the case studies in this book follow the standard seven-step model development process. However, there are a few case studies in which some of the steps are skipped, renamed, or reordered based on the appropriateness and intuitiveness of the steps.</p>
</div>








<section data-type="sect2" data-pdf-bookmark="Model Development Blueprint"><div class="sect2" id="idm45174935656600">
<h2>Model Development Blueprint</h2>

<p><a data-type="indexterm" data-primary="Python (generally)" data-secondary="model development blueprint" id="ix_Chapter2-asciidoc3"/>The following section covers the details of each model development step with supporting Python code.</p>










<section data-type="sect3" data-pdf-bookmark="1. Problem definition"><div class="sect3" id="idm45174935653608">
<h3>1. Problem definition</h3>

<p>The first step in any project is defining the problem. Powerful algorithms can be used for solving the problem, but the results will be meaningless if the wrong problem is solved.</p>

<p>The following framework should be used for defining the problem:</p>
<ol>
<li>
<p>Describe the problem informally and formally. List assumptions and similar problems.</p>
</li>
<li>
<p>List the motivation for solving the problem, the benefits a solution provides, and how the solution will be used.</p>
</li>
<li>
<p>Describe how the problem would be solved using the domain knowledge.</p>
</li>

</ol>
</div></section>













<section data-type="sect3" data-pdf-bookmark="2. Loading the data and packages"><div class="sect3" id="idm45174935648088">
<h3>2. Loading the data and packages</h3>

<p><a data-type="indexterm" data-primary="model development" data-secondary="loading data and packages" id="idm45174935646920"/>The second step gives you everything needed to start working on the problem. This includes loading libraries, packages, and individual functions needed for the model development.</p>












<section data-type="sect4" data-pdf-bookmark="2.1. Load libraries"><div class="sect4" id="idm45174935645432">
<h4>2.1. Load libraries</h4>

<p>A sample code for loading libraries is as follows:</p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="c"># Load libraries</code>
<code class="kn">import</code> <code class="nn">pandas</code> <code class="k">as</code> <code class="nn">pd</code>
<code class="kn">from</code> <code class="nn">matplotlib</code> <code class="k">import</code> <code class="n">pyplot</code></pre>

<p>The details of the libraries and modules for specific functionalities are defined further in the individual case studies.</p>
</div></section>













<section data-type="sect4" data-pdf-bookmark="2.2. Load data"><div class="sect4" id="idm45174940082056">
<h4>2.2. Load data</h4>

<p><a data-type="indexterm" data-primary="data, sample code for loading" id="idm45174939121000"/>The following items should be checked and removed before loading the data:</p>

<ul>
<li>
<p>Column headers</p>
</li>
<li>
<p>Comments or special characters</p>
</li>
<li>
<p>Delimiter</p>
</li>
</ul>

<p>There are many ways of loading data. Some of the most common ways are as follows:</p>

<p><code>Load CSV files with Pandas</code></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">from</code> <code class="nn">pandas</code> <code class="k">import</code> <code class="n">read_csv</code>
<code class="n">filename</code> <code class="o">=</code> <code class="s">'xyz.csv'</code>
<code class="n">data</code> <code class="o">=</code> <code class="n">read_csv</code><code class="p">(</code><code class="n">filename</code><code class="p">,</code> <code class="n">names</code><code class="o">=</code><code class="n">names</code><code class="p">)</code></pre>

<p><code>Load file from URL</code></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">from</code> <code class="nn">pandas</code> <code class="k">import</code> <code class="n">read_csv</code>
<code class="n">url</code> <code class="o">=</code> <code class="s">'https://goo.gl/vhm1eU'</code>
<code class="n">names</code> <code class="o">=</code> <code class="p">[</code><code class="s">'age'</code><code class="p">,</code> <code class="s">'class'</code><code class="p">]</code>
<code class="n">data</code> <code class="o">=</code> <code class="n">read_csv</code><code class="p">(</code><code class="n">url</code><code class="p">,</code> <code class="n">names</code><code class="o">=</code><code class="n">names</code><code class="p">)</code></pre>

<p><code>Load file using pandas_datareader</code></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">import</code> <code class="nn">pandas_datareader.data</code> <code class="k">as</code> <code class="nn">web</code>

<code class="n">ccy_tickers</code> <code class="o">=</code> <code class="p">[</code><code class="s">'DEXJPUS'</code><code class="p">,</code> <code class="s">'DEXUSUK'</code><code class="p">]</code>
<code class="n">idx_tickers</code> <code class="o">=</code> <code class="p">[</code><code class="s">'SP500'</code><code class="p">,</code> <code class="s">'DJIA'</code><code class="p">,</code> <code class="s">'VIXCLS'</code><code class="p">]</code>

<code class="n">stk_data</code> <code class="o">=</code> <code class="n">web</code><code class="o">.</code><code class="n">DataReader</code><code class="p">(</code><code class="n">stk_tickers</code><code class="p">,</code> <code class="s">'yahoo'</code><code class="p">)</code>
<code class="n">ccy_data</code> <code class="o">=</code> <code class="n">web</code><code class="o">.</code><code class="n">DataReader</code><code class="p">(</code><code class="n">ccy_tickers</code><code class="p">,</code> <code class="s">'fred'</code><code class="p">)</code>
<code class="n">idx_data</code> <code class="o">=</code> <code class="n">web</code><code class="o">.</code><code class="n">DataReader</code><code class="p">(</code><code class="n">idx_tickers</code><code class="p">,</code> <code class="s">'fred'</code><code class="p">)</code></pre>
</div></section>

</div></section>













<section data-type="sect3" class="pagebreak-before less_space" data-pdf-bookmark="3. Exploratory data analysis"><div class="sect3" id="idm45174935875256">
<h3>3. Exploratory data analysis</h3>

<p>In this step, we look at the dataset.</p>












<section data-type="sect4" data-pdf-bookmark="3.1. Descriptive statistics"><div class="sect4" id="idm45174936831416">
<h4>3.1. Descriptive statistics</h4>

<p><a data-type="indexterm" data-primary="exploratory data analysis, in model development" id="ix_Chapter2-asciidoc4"/><a data-type="indexterm" data-primary="model development" data-secondary="exploratory data analysis" id="ix_Chapter2-asciidoc5"/>Understanding <a data-type="indexterm" data-primary="descriptive statistics, in model development" id="idm45174936827560"/>the dataset is one of the most important steps of model development. The steps to understanding data include:</p>
<ol>
<li>
<p>Viewing the raw data.</p>
</li>
<li>
<p>Reviewing the dimensions of the dataset.</p>
</li>
<li>
<p>Reviewing the data types of attributes.</p>
</li>
<li>
<p>Summarizing the distribution, descriptive statistics, and relationship among the variables in the dataset.</p>
</li>

</ol>

<p>These steps are demonstrated below using sample Python code:</p>

<p><code>Viewing the data</code></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="n">set_option</code><code class="p">(</code><code class="s">'display.width'</code><code class="p">,</code> <code class="mi">100</code><code class="p">)</code>
<code class="n">dataset</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code></pre>

<p><code>Output</code></p>
<table>

<thead>
<tr>
<th/>
<th>Age</th>
<th>Sex</th>
<th>Job</th>
<th>Housing</th>
<th>SavingAccounts</th>
<th>CheckingAccount</th>
<th>CreditAmount</th>
<th>Duration</th>
<th>Purpose</th>
<th>Risk</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>0</p></td>
<td><p>67</p></td>
<td><p>male</p></td>
<td><p>2</p></td>
<td><p>own</p></td>
<td><p>NaN</p></td>
<td><p>little</p></td>
<td><p>1169</p></td>
<td><p>6</p></td>
<td><p>radio/TV</p></td>
<td><p>good</p></td>
</tr>
</tbody>
</table>

<p><code>Reviewing the dimensions of the dataset</code></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="n">dataset</code><code class="o">.</code><code class="n">shape</code></pre>

<p><code>Output</code></p>

<pre data-type="programlisting">(284807, 31)</pre>

<p>The results show the dimension of the dataset and mean that the dataset has 284,807 rows and 31 columns.</p>

<p><code>Reviewing the data types of the attributes in the data</code></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="c"># types</code>
<code class="n">set_option</code><code class="p">(</code><code class="s">'display.max_rows'</code><code class="p">,</code> <code class="mi">500</code><code class="p">)</code>
<code class="n">dataset</code><code class="o">.</code><code class="n">dtypes</code></pre>

<p><code>Summarizing the data using descriptive statistics</code></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="c"># describe data</code>
<code class="n">set_option</code><code class="p">(</code><code class="s">'precision'</code><code class="p">,</code> <code class="mi">3</code><code class="p">)</code>
<code class="n">dataset</code><code class="o">.</code><code class="n">describe</code><code class="p">()</code></pre>

<p class="pagebreak-before"><code>Output</code></p>
<table>

<thead>
<tr>
<th/>
<th>Age</th>
<th>Job</th>
<th>CreditAmount</th>
<th>Duration</th>
</tr>
</thead>
<tbody>
<tr>
<td><p>count</p></td>
<td><p>1000.000</p></td>
<td><p>1000.000</p></td>
<td><p>1000.000</p></td>
<td><p>1000.000</p></td>
</tr>
<tr>
<td><p>mean</p></td>
<td><p>35.546</p></td>
<td><p>1.904</p></td>
<td><p>3271.258</p></td>
<td><p>20.903</p></td>
</tr>
<tr>
<td><p>std</p></td>
<td><p>11.375</p></td>
<td><p>0.654</p></td>
<td><p>2822.737</p></td>
<td><p>12.059</p></td>
</tr>
<tr>
<td><p>min</p></td>
<td><p>19.000</p></td>
<td><p>0.000</p></td>
<td><p>250.000</p></td>
<td><p>4.000</p></td>
</tr>
<tr>
<td><p>25%</p></td>
<td><p>27.000</p></td>
<td><p>2.000</p></td>
<td><p>1365.500</p></td>
<td><p>12.000</p></td>
</tr>
<tr>
<td><p>50%</p></td>
<td><p>33.000</p></td>
<td><p>2.000</p></td>
<td><p>2319.500</p></td>
<td><p>18.000</p></td>
</tr>
<tr>
<td><p>75%</p></td>
<td><p>42.000</p></td>
<td><p>2.000</p></td>
<td><p>3972.250</p></td>
<td><p>24.000</p></td>
</tr>
<tr>
<td><p>max</p></td>
<td><p>75.000</p></td>
<td><p>3.000</p></td>
<td><p>18424.000</p></td>
<td><p>72.000</p></td>
</tr>
</tbody>
</table>
</div></section>













<section data-type="sect4" data-pdf-bookmark="3.2. Data visualization"><div class="sect4" id="idm45174936830824">
<h4>3.2. Data visualization</h4>

<p><a data-type="indexterm" data-primary="data visualization" id="idm45174936640008"/><a data-type="indexterm" data-primary="visualization of data" id="idm45174936639304"/>The fastest way to learn more about the data is to visualize it. Visualization involves independently understanding each attribute of the dataset.</p>

<p>Some of the plot types are as follows:</p>
<dl>
<dt>Univariate plots</dt>
<dd>
<p>Histograms and density plots</p>
</dd>
<dt>Multivariate plots</dt>
<dd>
<p>Correlation matrix plot and scatterplot</p>
</dd>
</dl>

<p><a data-type="indexterm" data-primary="univariate plot types, Python code for" id="idm45174936634600"/>The Python code for univariate plot types is illustrated with examples below:</p>

<p><code>Univariate plot: histogram</code></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">from</code> <code class="nn">matplotlib</code> <code class="k">import</code> <code class="n">pyplot</code>
<code class="n">dataset</code><code class="o">.</code><code class="n">hist</code><code class="p">(</code><code class="n">sharex</code><code class="o">=</code><code class="k">False</code><code class="p">,</code> <code class="n">sharey</code><code class="o">=</code><code class="k">False</code><code class="p">,</code> <code class="n">xlabelsize</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">ylabelsize</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code>\
<code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code class="mi">4</code><code class="p">))</code>
<code class="n">pyplot</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>

<p><code>Univariate plot: density plot</code></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">from</code> <code class="nn">matplotlib</code> <code class="k">import</code> <code class="n">pyplot</code>
<code class="n">dataset</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">kind</code><code class="o">=</code><code class="s">'density'</code><code class="p">,</code> <code class="n">subplots</code><code class="o">=</code><code class="k">True</code><code class="p">,</code> <code class="n">layout</code><code class="o">=</code><code class="p">(</code><code class="mi">3</code><code class="p">,</code><code class="mi">3</code><code class="p">),</code> <code class="n">sharex</code><code class="o">=</code><code class="k">False</code><code class="p">,</code>\
<code class="n">legend</code><code class="o">=</code><code class="k">True</code><code class="p">,</code> <code class="n">fontsize</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code class="mi">4</code><code class="p">))</code>
<code class="n">pyplot</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>

<p class="pagebreak-before"><a data-type="xref" href="#HistDesn">Figure 2-3</a> illustrates the output.</p>

<figure><div id="HistDesn" class="figure">
<img src="Images/mlbf_0203.png" alt="mlbf 0203" width="583" height="507"/>
<h6><span class="label">Figure 2-3. </span>Histogram (top) and density plot (bottom)</h6>
</div></figure>

<p><a data-type="indexterm" data-primary="multivariate plot types, Python code for" id="idm45174937443992"/>The Python code for multivariate plot types is illustrated with examples below:<a data-type="indexterm" data-startref="ix_Chapter2-asciidoc5" id="idm45174937443064"/><a data-type="indexterm" data-startref="ix_Chapter2-asciidoc4" id="idm45174937442392"/></p>

<p><code>Multivariate plot: correlation matrix plot</code></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">from</code> <code class="nn">matplotlib</code> <code class="k">import</code> <code class="n">pyplot</code>
<code class="kn">import</code> <code class="nn">seaborn</code> <code class="k">as</code> <code class="nn">sns</code>
<code class="n">correlation</code> <code class="o">=</code> <code class="n">dataset</code><code class="o">.</code><code class="n">corr</code><code class="p">()</code>
<code class="n">pyplot</code><code class="o">.</code><code class="n">figure</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">5</code><code class="p">,</code><code class="mi">5</code><code class="p">))</code>
<code class="n">pyplot</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s">'Correlation Matrix'</code><code class="p">)</code>
<code class="n">sns</code><code class="o">.</code><code class="n">heatmap</code><code class="p">(</code><code class="n">correlation</code><code class="p">,</code> <code class="n">vmax</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code> <code class="n">square</code><code class="o">=</code><code class="k">True</code><code class="p">,</code><code class="n">annot</code><code class="o">=</code><code class="k">True</code><code class="p">,</code><code class="n">cmap</code><code class="o">=</code><code class="s">'cubehelix'</code><code class="p">)</code></pre>

<p><code>Multivariate plot: scatterplot matrix</code></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">from</code> <code class="nn">pandas.plotting</code> <code class="k">import</code> <code class="n">scatter_matrix</code>
<code class="n">scatter_matrix</code><code class="p">(</code><code class="n">dataset</code><code class="p">)</code></pre>

<p><a data-type="xref" href="#CorrScatter">Figure 2-4</a> illustrates the output.</p>

<figure><div id="CorrScatter" class="figure">
<img src="Images/mlbf_0204.png" alt="mlbf 0204" width="678" height="317"/>
<h6><span class="label">Figure 2-4. </span>Correlation (left) and scatterplot (right)</h6>
</div></figure>
</div></section>

</div></section>













<section data-type="sect3" data-pdf-bookmark="4. Data preparation"><div class="sect3" id="idm45174936640984">
<h3>4. Data preparation</h3>

<p>Data preparation is a preprocessing step in which data from one or more sources is cleaned and transformed to improve its quality prior to its use.</p>












<section data-type="sect4" data-pdf-bookmark="4.1. Data cleaning"><div class="sect4" id="idm45174937351544">
<h4>4.1. Data cleaning</h4>

<p><a data-type="indexterm" data-primary="data cleaning, steps in" id="idm45174937349944"/><a data-type="indexterm" data-primary="data preparation, steps in" id="idm45174937323032"/><a data-type="indexterm" data-primary="model development" data-secondary="data preparation" id="idm45174937322392"/>In machine learning modeling, incorrect data can be costly. Data cleaning involves checking the following:</p>
<dl>
<dt>Validity</dt>
<dd>
<p>The data type, range, etc.</p>
</dd>
<dt>Accuracy</dt>
<dd>
<p>The degree to which the data is close to the true values.</p>
</dd>
<dt>Completeness</dt>
<dd>
<p>The degree to which all required data is known.</p>
</dd>
<dt>Uniformity</dt>
<dd>
<p>The degree to which the data is specified using the same unit of measure.</p>
</dd>
</dl>

<p>The different options for performing data cleaning include:</p>

<p><em>Dropping “NA” values within data</em></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="n">dataset</code><code class="o">.</code><code class="n">dropna</code><code class="p">(</code><code class="n">axis</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code></pre>

<p><em>Filling “NA” with 0</em></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="n">dataset</code><code class="o">.</code><code class="n">fillna</code><code class="p">(</code><code class="mi">0</code><code class="p">)</code></pre>

<p><em>Filling NAs with the mean of the column</em></p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="n">dataset</code><code class="p">[</code><code class="s">'col'</code><code class="p">]</code> <code class="o">=</code> <code class="n">dataset</code><code class="p">[</code><code class="s">'col'</code><code class="p">]</code><code class="o">.</code><code class="n">fillna</code><code class="p">(</code><code class="n">dataset</code><code class="p">[</code><code class="s">'col'</code><code class="p">]</code><code class="o">.</code><code class="n">mean</code><code class="p">())</code></pre>
</div></section>













<section data-type="sect4" data-pdf-bookmark="4.2. Feature selection"><div class="sect4" id="idm45174937160600">
<h4>4.2. Feature selection</h4>

<p><a data-type="indexterm" data-primary="feature selection, in model development" id="idm45174937231784"/><a data-type="indexterm" data-primary="model development" data-secondary="feature selection" id="idm45174937230712"/>The data features used to train the machine learning models have a huge influence on the performance. Irrelevant or partially relevant features can negatively impact model performance. Feature selection<sup><a data-type="noteref" id="idm45174937229416-marker" href="ch02.xhtml#idm45174937229416">1</a></sup> is a process in which features in data that contribute most to the prediction variable or output are automatically selected.</p>

<p>The benefits of performing feature selection before modeling the data are:</p>
<dl>
<dt>Reduces overfitting<sup><a data-type="noteref" id="idm45174937225672-marker" href="ch02.xhtml#idm45174937225672">2</a></sup></dt>
<dd>
<p>Less redundant data means fewer opportunities for the model to make decisions
based on noise.</p>
</dd>
<dt>Improves performance</dt>
<dd>
<p>Less misleading data means improved modeling performance.</p>
</dd>
<dt>Reduces training time and memory footprint</dt>
<dd>
<p>Less data means faster training and lower memory footprint.</p>
</dd>
</dl>

<p>The following sample feature is an example demonstrating when the best two features are selected using the <a href="https://oreil.ly/JDo-F"><code>SelectKBest</code> function</a> under sklearn. The <code>SelectKBest</code> function scores the features using an underlying function and then removes all but the <em>k</em> highest scoring feature:</p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">from</code> <code class="nn">sklearn.feature_selection</code> <code class="k">import</code> <code class="n">SelectKBest</code>
<code class="kn">from</code> <code class="nn">sklearn.feature_selection</code> <code class="k">import</code> <code class="n">chi2</code>
<code class="n">bestfeatures</code> <code class="o">=</code> <code class="n">SelectKBest</code><code class="p">(</code> <code class="n">k</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code>
<code class="n">fit</code> <code class="o">=</code> <code class="n">bestfeatures</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">,</code><code class="n">Y</code><code class="p">)</code>
<code class="n">dfscores</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">fit</code><code class="o">.</code><code class="n">scores_</code><code class="p">)</code>
<code class="n">dfcolumns</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">X</code><code class="o">.</code><code class="n">columns</code><code class="p">)</code>
<code class="n">featureScores</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">concat</code><code class="p">([</code><code class="n">dfcolumns</code><code class="p">,</code><code class="n">dfscores</code><code class="p">],</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="n">featureScores</code><code class="o">.</code><code class="n">nlargest</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code><code class="s">'Score'</code><code class="p">))</code>  <code class="c">#print 2 best features</code></pre>

<p><code>Output</code></p>

<pre data-type="programlisting">                  Specs      Score
2              Variable1  58262.490
3              Variable2    321.031</pre>

<p>When features are irrelevant, they should be dropped. Dropping the irrelevant features is illustrated in the following sample code:</p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="c">#dropping the old features</code>
<code class="n">dataset</code><code class="o">.</code><code class="n">drop</code><code class="p">([</code><code class="s">'Feature1'</code><code class="p">,</code><code class="s">'Feature2'</code><code class="p">,</code><code class="s">'Feature3'</code><code class="p">],</code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code class="n">inplace</code><code class="o">=</code><code class="k">True</code><code class="p">)</code></pre>
</div></section>













<section data-type="sect4" data-pdf-bookmark="4.3. Data transformation"><div class="sect4" id="idm45174937231176">
<h4>4.3. Data transformation</h4>

<p><a data-type="indexterm" data-primary="data transformation, in model development" id="idm45174934858456"/><a data-type="indexterm" data-primary="model development" data-secondary="data transformation" id="idm45174934857720"/>Many machine learning algorithms make assumptions about the data. It is a good practice to perform the data preparation in such a way that exposes the data in the best possible manner to the machine learning algorithms. This can be accomplished through data transformation.</p>

<p>The different data transformation approaches are as follows:</p>
<dl>
<dt>Rescaling</dt>
<dd>
<p><a data-type="indexterm" data-primary="rescaling" id="idm45174934854376"/>When data comprises attributes with varying scales, many machine learning algorithms can benefit from <em>rescaling</em> all the attributes to the same scale. Attributes are often rescaled in the range between zero and one. This is useful for optimization algorithms used in the core of machine learning algorithms, and it also helps to speed up the calculations in an algorithm:</p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="k">import</code> <code class="n">MinMaxScaler</code>
<code class="n">scaler</code> <code class="o">=</code> <code class="n">MinMaxScaler</code><code class="p">(</code><code class="n">feature_range</code><code class="o">=</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">))</code>
<code class="n">rescaledX</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">scaler</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X</code><code class="p">))</code></pre>
</dd>
<dt>Standardization</dt>
<dd>
<p><a data-type="indexterm" data-primary="standardization" id="idm45174934818152"/><em>Standardization</em> is a useful technique to
transform attributes to a standard <a href="https://oreil.ly/4a70f">normal distribution</a> with a mean of zero and a standard deviation of one. It is most suitable for techniques that assume the input variables represent a normal distribution:</p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="k">import</code> <code class="n">StandardScaler</code>
<code class="n">scaler</code> <code class="o">=</code> <code class="n">StandardScaler</code><code class="p">()</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">)</code>
<code class="n">StandardisedX</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">scaler</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X</code><code class="p">))</code></pre>
</dd>
<dt>Normalization</dt>
<dd>
<p><a data-type="indexterm" data-primary="normalization" id="idm45174934738360"/><em>Normalization</em> refers to rescaling each observation (row) to have a length of one (called a unit norm or a vector). This preprocessing method
can be useful for sparse datasets of attributes of varying scales when using
algorithms that weight input values:</p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="k">import</code> <code class="n">Normalizer</code>
<code class="n">scaler</code> <code class="o">=</code> <code class="n">Normalizer</code><code class="p">()</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X</code><code class="p">)</code>
<code class="n">NormalizedX</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">scaler</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X</code><code class="p">))</code></pre>
</dd>
</dl>
</div></section>

</div></section>













<section data-type="sect3" data-pdf-bookmark="5. Evaluate models"><div class="sect3" id="idm45174934682024">
<h3>5. Evaluate models</h3>

<p><a data-type="indexterm" data-primary="evaluation of models, steps in" id="idm45174934680744"/><a data-type="indexterm" data-primary="model evaluation, steps in" id="idm45174934680072"/>Once we estimate the performance of our algorithm, we can retrain the final algorithm on the entire training
dataset and get it ready for operational use.
The best way to do this is to evaluate the performance of the algorithm on a new dataset. Different machine learning techniques require different evaluation metrics. Other than model performance, several other factors such as simplicity, interpretability, and training time are considered when selecting a model. The details regarding these factors are covered in <a data-type="xref" href="ch04.xhtml#Chapter4">Chapter 4</a>.</p>












<section data-type="sect4" data-pdf-bookmark="5.1. Training and test split"><div class="sect4" id="idm45174934647496">
<h4>5.1. Training and test split</h4>

<p><a data-type="indexterm" data-primary="datasets, splitting training/testing" id="idm45174934646328"/><a data-type="indexterm" data-primary="model development" data-secondary="splitting training/testing datasets" id="idm45174934645656"/><a data-type="indexterm" data-primary="testing datasets" id="idm45174934644744"/><a data-type="indexterm" data-primary="training datasets" id="idm45174934644072"/>The simplest method we can use to evaluate the performance of a machine learning algorithm is to use different training and testing datasets. We can take our original dataset and split it into two parts: train the algorithm on the first part, make predictions on the second part, and evaluate the predictions against the expected results. The size of the split can depend on the size and specifics of the dataset, although it is common to use 80% of the data for
training and the remaining 20% for testing.
The differences in the training and test datasets can result in meaningful
differences in the estimate of accuracy.
The data can easily be split into the training and test sets using the <code>train_test_split</code> function available in sklearn:</p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="c"># split out validation dataset for the end</code>
<code class="n">validation_size</code> <code class="o">=</code> <code class="mf">0.2</code>
<code class="n">seed</code> <code class="o">=</code> <code class="mi">7</code>
<code class="n">X_train</code><code class="p">,</code> <code class="n">X_validation</code><code class="p">,</code> <code class="n">Y_train</code><code class="p">,</code> <code class="n">Y_validation</code> <code class="o">=</code>\
<code class="n">train_test_split</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">Y</code><code class="p">,</code> <code class="n">test_size</code><code class="o">=</code><code class="n">validation_size</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="n">seed</code><code class="p">)</code></pre>
</div></section>













<section data-type="sect4" data-pdf-bookmark="5.2. Identify evaluation metrics"><div class="sect4" id="idm45174934589976">
<h4>5.2. Identify evaluation metrics</h4>

<p><a data-type="indexterm" data-primary="evaluation metrics, identifying" id="idm45174934572248"/><a data-type="indexterm" data-primary="model development" data-secondary="identifying evaluation metrics" id="idm45174934571640"/>Choosing which metric to use to evaluate machine learning algorithms is very important. An important aspect of evaluation metrics is the capability to discriminate among model results. Different types of evaluation metrics used for different kinds of ML models are covered in detail across several chapters of this book.</p>
</div></section>













<section data-type="sect4" data-pdf-bookmark="5.3. Compare models and algorithms"><div class="sect4" id="idm45174934570008">
<h4>5.3. Compare models and algorithms</h4>

<p><a data-type="indexterm" data-primary="algorithms, comparing" id="idm45174934568632"/><a data-type="indexterm" data-primary="comparison of algorithms" id="idm45174934567928"/><a data-type="indexterm" data-primary="comparison of models" id="idm45174934567192"/>Selecting a machine learning model or algorithm is both an art and a science. There is no one solution or approach that fits all. There are several factors over and above the model performance that can impact the decision to choose a machine learning algorithm.</p>

<p>Let’s understand the process of model comparison with a simple example. We define two variables, <em>X</em> and <em>Y</em>, and try to build a model to predict <em>Y</em> using <em>X</em>. As a first step, the data is divided into training and test split as mentioned in the preceding section:</p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">import</code> <code class="nn">numpy</code> <code class="k">as</code> <code class="nn">np</code>
<code class="kn">import</code> <code class="nn">matplotlib.pyplot</code> <code class="k">as</code> <code class="nn">plt</code>
<code class="kn">from</code> <code class="nn">sklearn.model_selection</code> <code class="k">import</code> <code class="n">train_test_split</code>
<code class="n">validation_size</code> <code class="o">=</code> <code class="mf">0.2</code>
<code class="n">seed</code> <code class="o">=</code> <code class="mi">7</code>
<code class="n">X</code> <code class="o">=</code> <code class="mi">2</code> <code class="o">-</code> <code class="mi">3</code> <code class="o">*</code> <code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">normal</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">,</code> <code class="mi">20</code><code class="p">)</code>
<code class="n">Y</code> <code class="o">=</code> <code class="n">X</code> <code class="o">-</code> <code class="mi">2</code> <code class="o">*</code> <code class="p">(</code><code class="n">X</code> <code class="o">**</code> <code class="mi">2</code><code class="p">)</code> <code class="o">+</code> <code class="mf">0.5</code> <code class="o">*</code> <code class="p">(</code><code class="n">X</code> <code class="o">**</code> <code class="mi">3</code><code class="p">)</code> <code class="o">+</code> <code class="n">np</code><code class="o">.</code><code class="n">exp</code><code class="p">(</code><code class="o">-</code><code class="n">X</code><code class="p">)</code><code class="o">+</code><code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">normal</code><code class="p">(</code><code class="o">-</code><code class="mi">3</code><code class="p">,</code> <code class="mi">3</code><code class="p">,</code> <code class="mi">20</code><code class="p">)</code>
<code class="c"># transforming the data to include another axis</code>
<code class="n">X</code> <code class="o">=</code> <code class="n">X</code><code class="p">[:,</code> <code class="n">np</code><code class="o">.</code><code class="n">newaxis</code><code class="p">]</code>
<code class="n">Y</code> <code class="o">=</code> <code class="n">Y</code><code class="p">[:,</code> <code class="n">np</code><code class="o">.</code><code class="n">newaxis</code><code class="p">]</code>
<code class="n">X_train</code><code class="p">,</code> <code class="n">X_test</code><code class="p">,</code> <code class="n">Y_train</code><code class="p">,</code> <code class="n">Y_test</code> <code class="o">=</code> <code class="n">train_test_split</code><code class="p">(</code><code class="n">X</code><code class="p">,</code> <code class="n">Y</code><code class="p">,</code>\
<code class="n">test_size</code><code class="o">=</code><code class="n">validation_size</code><code class="p">,</code> <code class="n">random_state</code><code class="o">=</code><code class="n">seed</code><code class="p">)</code></pre>

<p>We have no idea which algorithms will do well on this problem. Let’s design our test now. We will use two models—one linear regression and the second polynomial regression to fit <em>Y</em> against <em>X</em>. <a data-type="indexterm" data-primary="root mean squared error (RMSE)" id="idm45174934556664"/>We will evaluate algorithms using the <em>Root Mean Squared Error (RMSE)</em> metric, which is one of the measures of the model performance. RMSE will give a gross idea of how wrong all predictions are (zero is perfect):</p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="kn">from</code> <code class="nn">sklearn.linear_model</code> <code class="k">import</code> <code class="n">LinearRegression</code>
<code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="k">import</code> <code class="n">mean_squared_error</code><code class="p">,</code> <code class="n">r2_score</code>
<code class="kn">from</code> <code class="nn">sklearn.preprocessing</code> <code class="k">import</code> <code class="n">PolynomialFeatures</code>

<code class="n">model</code> <code class="o">=</code> <code class="n">LinearRegression</code><code class="p">()</code>
<code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train</code><code class="p">,</code> <code class="n">Y_train</code><code class="p">)</code>
<code class="n">Y_pred</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>

<code class="n">rmse_lin</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">mean_squared_error</code><code class="p">(</code><code class="n">Y_train</code><code class="p">,</code><code class="n">Y_pred</code><code class="p">))</code>
<code class="n">r2_lin</code> <code class="o">=</code> <code class="n">r2_score</code><code class="p">(</code><code class="n">Y_train</code><code class="p">,</code><code class="n">Y_pred</code><code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="s">"RMSE for Linear Regression:"</code><code class="p">,</code> <code class="n">rmse_lin</code><code class="p">)</code>

<code class="n">polynomial_features</code><code class="o">=</code> <code class="n">PolynomialFeatures</code><code class="p">(</code><code class="n">degree</code><code class="o">=</code><code class="mi">2</code><code class="p">)</code>
<code class="n">x_poly</code> <code class="o">=</code> <code class="n">polynomial_features</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>

<code class="n">model</code> <code class="o">=</code> <code class="n">LinearRegression</code><code class="p">()</code>
<code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x_poly</code><code class="p">,</code> <code class="n">Y_train</code><code class="p">)</code>
<code class="n">Y_poly_pred</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x_poly</code><code class="p">)</code>

<code class="n">rmse</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">mean_squared_error</code><code class="p">(</code><code class="n">Y_train</code><code class="p">,</code><code class="n">Y_poly_pred</code><code class="p">))</code>
<code class="n">r2</code> <code class="o">=</code> <code class="n">r2_score</code><code class="p">(</code><code class="n">Y_train</code><code class="p">,</code><code class="n">Y_poly_pred</code><code class="p">)</code>
<code class="nb">print</code><code class="p">(</code><code class="s">"RMSE for Polynomial Regression:"</code><code class="p">,</code> <code class="n">rmse</code><code class="p">)</code></pre>

<p><code>Output</code></p>

<pre data-type="programlisting">RMSE for Linear Regression: 6.772942423315028
RMSE for Polynomial Regression: 6.420495127266883</pre>

<p>We can see that the RMSE of the polynomial regression is slightly better than that of the linear regression.<sup><a data-type="noteref" id="idm45174934446200-marker" href="ch02.xhtml#idm45174934446200">3</a></sup> With the former having the better fit, it is the preferred model in this step.</p>
</div></section>

</div></section>













<section data-type="sect3" data-pdf-bookmark="6. Model tuning"><div class="sect3" id="idm45174934255256">
<h3>6. Model tuning</h3>

<p><a data-type="indexterm" data-primary="hyperparameters" data-secondary="model tuning and" id="idm45174934253848"/><a data-type="indexterm" data-primary="model development" data-secondary="model tuning" id="idm45174934252648"/><a data-type="indexterm" data-primary="model tuning" id="idm45174934251704"/><a data-type="indexterm" data-primary="tuning a model" id="idm45174934251032"/>Finding the best combination of hyperparameters of a model can be treated as a search problem.<sup><a data-type="noteref" id="idm45174934250120-marker" href="ch02.xhtml#idm45174934250120">4</a></sup> This searching exercise is often known as <em>model tuning</em> and is one of the most important steps of model development. <a data-type="indexterm" data-primary="grid search" id="idm45174934248904"/>It is achieved by searching for the best parameters of the model by using techniques such as a <em>grid search</em>. In a grid search, you create a grid of all possible hyperparameter combinations and train 
<span class="keep-together">the model</span> using each one of them. Besides a grid search, there are several other 
<span class="keep-together">techniques for</span> model tuning, including randomized search, <a href="https://oreil.ly/ZGVPM">Bayesian optimization</a>, and hyperbrand.</p>

<p>In the case studies presented in this book, we focus primarily on grid search for model tuning.</p>

<p>Continuing on from the preceding example, with the polynomial as the best model: next, run a grid search for the model, refitting the polynomial regression with different degrees. We compare the RMSE results for all the models:</p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="n">Deg</code><code class="o">=</code> <code class="p">[</code><code class="mi">1</code><code class="p">,</code><code class="mi">2</code><code class="p">,</code><code class="mi">3</code><code class="p">,</code><code class="mi">6</code><code class="p">,</code><code class="mi">10</code><code class="p">]</code>
<code class="n">results</code><code class="o">=</code><code class="p">[]</code>
<code class="n">names</code><code class="o">=</code><code class="p">[]</code>
<code class="k">for</code> <code class="n">deg</code> <code class="ow">in</code> <code class="n">Deg</code><code class="p">:</code>
    <code class="n">polynomial_features</code><code class="o">=</code> <code class="n">PolynomialFeatures</code><code class="p">(</code><code class="n">degree</code><code class="o">=</code><code class="n">deg</code><code class="p">)</code>
    <code class="n">x_poly</code> <code class="o">=</code> <code class="n">polynomial_features</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>

    <code class="n">model</code> <code class="o">=</code> <code class="n">LinearRegression</code><code class="p">()</code>
    <code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x_poly</code><code class="p">,</code> <code class="n">Y_train</code><code class="p">)</code>
    <code class="n">Y_poly_pred</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x_poly</code><code class="p">)</code>

    <code class="n">rmse</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">mean_squared_error</code><code class="p">(</code><code class="n">Y_train</code><code class="p">,</code><code class="n">Y_poly_pred</code><code class="p">))</code>
    <code class="n">r2</code> <code class="o">=</code> <code class="n">r2_score</code><code class="p">(</code><code class="n">Y_train</code><code class="p">,</code><code class="n">Y_poly_pred</code><code class="p">)</code>
    <code class="n">results</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">rmse</code><code class="p">)</code>
    <code class="n">names</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">deg</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">names</code><code class="p">,</code> <code class="n">results</code><code class="p">,</code><code class="s">'o'</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">suptitle</code><code class="p">(</code><code class="s">'Algorithm Comparison'</code><code class="p">)</code></pre>

<p><code>Output</code></p>

<figure><div class="figure">
<img src="Images/mlbf_02in01.png" alt="mlbf 02in01" width="363" height="277"/>
<h6/>
</div></figure>

<p>The RMSE decreases when the degree increases, and the lowest RMSE is for the model with degree 10. However, models with degrees lower than 10 performed very well, and the test set will be used to finalize the best model.</p>

<p>While the generic set of input parameters for each algorithm provides a starting point for analysis, it may not have the optimal configurations for the particular dataset and business problem.</p>
</div></section>













<section data-type="sect3" data-pdf-bookmark="7. Finalize the model"><div class="sect3" id="idm45174934075576">
<h3>7. Finalize the model</h3>

<p><a data-type="indexterm" data-primary="finalizing a model, steps in" id="ix_Chapter2-asciidoc6"/><a data-type="indexterm" data-primary="model development" data-secondary="finalizing the model" id="ix_Chapter2-asciidoc7"/><a data-type="indexterm" data-primary="model finalization, steps in" id="ix_Chapter2-asciidoc8"/>Here, we perform the final steps for selecting the model. First, we run predictions on the test dataset with the trained model. Then we try to understand the model intuition and save it for further usage.</p>












<section data-type="sect4" data-pdf-bookmark="7.1. Performance on the test set"><div class="sect4" id="idm45174934070584">
<h4>7.1. Performance on the test set</h4>

<p><a data-type="indexterm" data-primary="model development" data-secondary="performance on test set" id="idm45174934069208"/><a data-type="indexterm" data-primary="testing datasets" id="idm45174934068232"/>The model selected during the training steps is further evaluated on the test set. The test set allows us to compare different models in an unbiased way, by basing the comparisons in data that were not used in any part of the training. The test results for the model developed in the previous step are shown in the following example:</p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="n">Deg</code><code class="o">=</code> <code class="p">[</code><code class="mi">1</code><code class="p">,</code><code class="mi">2</code><code class="p">,</code><code class="mi">3</code><code class="p">,</code><code class="mi">6</code><code class="p">,</code><code class="mi">8</code><code class="p">,</code><code class="mi">10</code><code class="p">]</code>
<code class="k">for</code> <code class="n">deg</code> <code class="ow">in</code> <code class="n">Deg</code><code class="p">:</code>
    <code class="n">polynomial_features</code><code class="o">=</code> <code class="n">PolynomialFeatures</code><code class="p">(</code><code class="n">degree</code><code class="o">=</code><code class="n">deg</code><code class="p">)</code>
    <code class="n">x_poly</code> <code class="o">=</code> <code class="n">polynomial_features</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X_train</code><code class="p">)</code>
    <code class="n">model</code> <code class="o">=</code> <code class="n">LinearRegression</code><code class="p">()</code>
    <code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">x_poly</code><code class="p">,</code> <code class="n">Y_train</code><code class="p">)</code>
    <code class="n">x_poly_test</code> <code class="o">=</code> <code class="n">polynomial_features</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">X_test</code><code class="p">)</code>
    <code class="n">Y_poly_pred_test</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x_poly_test</code><code class="p">)</code>
    <code class="n">rmse</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">sqrt</code><code class="p">(</code><code class="n">mean_squared_error</code><code class="p">(</code><code class="n">Y_test</code><code class="p">,</code><code class="n">Y_poly_pred_test</code><code class="p">))</code>
    <code class="n">r2</code> <code class="o">=</code> <code class="n">r2_score</code><code class="p">(</code><code class="n">Y_test</code><code class="p">,</code><code class="n">Y_poly_pred_test</code><code class="p">)</code>
    <code class="n">results_test</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">rmse</code><code class="p">)</code>
    <code class="n">names_test</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">deg</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">names_test</code><code class="p">,</code> <code class="n">results_test</code><code class="p">,</code><code class="s">'o'</code><code class="p">)</code>
<code class="n">plt</code><code class="o">.</code><code class="n">suptitle</code><code class="p">(</code><code class="s">'Algorithm Comparison'</code><code class="p">)</code></pre>

<p><code>Output</code></p>

<figure><div id="algorithm_comp2" class="figure">
<img src="Images/mlbf_02in02.png" alt="mlbf 02in02" width="382" height="277"/>
<h6/>
</div></figure>

<p>In the training set we saw that the RMSE decreases with an increase in the degree of polynomial model, and the polynomial of degree 10 had the lowest RMSE. However, as shown in the preceding output for the polynomial of degree 10, although the training set had the best results, the results in the test set are poor. For the polynomial of degree 8, the RMSE in the test set is relatively higher. The polynomial of degree 6 shows the best result in the test set (although the difference is small compared to other lower-degree polynomials in the test set) as well as good results in the training set. For these reasons, this is the preferred model.</p>

<p>In addition to the model performance, there are several other factors to consider when selecting a model, such as simplicity, interpretability, and training time. These factors will be covered in the upcoming chapters.</p>
</div></section>













<section data-type="sect4" data-pdf-bookmark="7.2. Model/variable intuition"><div class="sect4" id="idm45174933912120">
<h4>7.2. Model/variable intuition</h4>

<p><a data-type="indexterm" data-primary="intuition, model/variable" id="idm45174933910952"/><a data-type="indexterm" data-primary="model intuition" id="idm45174933910280"/><a data-type="indexterm" data-primary="variable intuition" id="idm45174933909608"/>This step involves considering a holistic view of the approach taken to solve the problem, including the model’s limitations as it relates to the desired outcome, the variables used, and the selected model parameters. Details on model and variable intuition regarding different types of machine learning models are presented in the subsequent chapters and case studies.</p>
</div></section>













<section data-type="sect4" data-pdf-bookmark="7.3. Save/deploy"><div class="sect4" id="idm45174933908168">
<h4>7.3. Save/deploy</h4>

<p><a data-type="indexterm" data-primary="deploying a model" id="idm45174933906760"/><a data-type="indexterm" data-primary="model development" data-secondary="saving and deploying" id="idm45174933906056"/><a data-type="indexterm" data-primary="saving a model" id="idm45174933905112"/>After finding an accurate machine learning model, it must be saved and loaded in order to ensure its usage later.</p>

<p><a data-type="indexterm" data-primary="pickle module" id="idm45174933903928"/><em>Pickle</em> is one of the packages for saving and loading a trained model in Python. Using pickle operations, trained machine learning models can be saved in the <em>serialized</em> format to a file. Later, this serialized file can be loaded to <em>de-serialize</em> the model for its usage. The following sample code demonstrates how to save the model to a file and load it to make predictions on new data:</p>

<pre data-type="programlisting" data-code-language="ipython3"><code class="c"># Save Model Using Pickle</code>
<code class="kn">from</code> <code class="nn">pickle</code> <code class="k">import</code> <code class="n">dump</code>
<code class="kn">from</code> <code class="nn">pickle</code> <code class="k">import</code> <code class="n">load</code>
<code class="c"># save the model to disk</code>
<code class="n">filename</code> <code class="o">=</code> <code class="s">'finalized_model.sav'</code>
<code class="n">dump</code><code class="p">(</code><code class="n">model</code><code class="p">,</code> <code class="nb">open</code><code class="p">(</code><code class="n">filename</code><code class="p">,</code> <code class="s">'wb'</code><code class="p">))</code>
<code class="c"># load the model from disk</code>
<code class="n">loaded_model</code> <code class="o">=</code> <code class="n">load</code><code class="p">(</code><code class="n">filename</code><code class="p">)</code></pre>
<div data-type="tip"><h6>Tip</h6>
<p>In recent years, frameworks such as <a href="https://oreil.ly/ChjFb">AutoML</a> have been built to automate the maximum number of steps in a machine learning model development process. Such frameworks allow the model developers to build ML models with high scale, efficiency, and productivity. Readers are encouraged to explore such <a data-type="indexterm" data-startref="ix_Chapter2-asciidoc8" id="idm45174933869640"/><a data-type="indexterm" data-startref="ix_Chapter2-asciidoc7" id="idm45174933868936"/><a data-type="indexterm" data-startref="ix_Chapter2-asciidoc6" id="idm45174933868264"/>frameworks<a data-type="indexterm" data-startref="ix_Chapter2-asciidoc3" id="idm45174933867464"/>.<a data-type="indexterm" data-startref="ix_Chapter2-asciidoc1" id="idm45174933866632"/></p>
</div>
</div></section>

</div></section>



</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Chapter Summary"><div class="sect1" id="idm45174933865672">
<h1>Chapter Summary</h1>

<p>Given its popularity, rate of adoption, and flexibility, Python is often the preferred language for machine learning development. There are many available Python packages to perform numerous tasks, including data cleaning, visualization, and model development. Some of these key packages are Scikit-learn and Keras.</p>

<p>The seven steps of model development mentioned in this chapter can be leveraged while developing any machine learning–based model in finance.<a data-type="indexterm" data-startref="ix_Chapter2-asciidoc0" id="idm45174933863464"/></p>








<section data-type="sect2" class="notoc" data-pdf-bookmark="Next Steps"><div class="sect2" id="idm45174933862632">
<h2>Next Steps</h2>

<p>In the next chapter, we will cover the key algorithm for machine learning—the artificial neural network. The artificial neural network is another building block of machine learning in finance and is used across all types of machine learning and deep learning algorithms.</p>
</div></section>





</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm45174937229416"><sup><a href="ch02.xhtml#idm45174937229416-marker">1</a></sup> Feature selection is more relevant for supervised learning models and is described in detail in the individual case studies in Chapters <a href="ch05.xhtml#Chapter5">5</a> and <a href="ch06.xhtml#Chapter6">6</a>.</p><p data-type="footnote" id="idm45174937225672"><sup><a href="ch02.xhtml#idm45174937225672-marker">2</a></sup> Overfitting is covered in detail in <a data-type="xref" href="ch04.xhtml#Chapter4">Chapter 4</a>.</p><p data-type="footnote" id="idm45174934446200"><sup><a href="ch02.xhtml#idm45174934446200-marker">3</a></sup> It should be noted that the difference in RMSE is small in this case and may not replicate with a different split of the train/test data.</p><p data-type="footnote" id="idm45174934250120"><sup><a href="ch02.xhtml#idm45174934250120-marker">4</a></sup> Hyperparameters are the external characteristics of the model, can be considered the model’s settings, and are not estimated based on data-like model parameters.</p></div></div></section></div>



  </body></html>