["```py\nIn [1]: import pandas as pd\n        import numpy as np\n        import matplotlib.pyplot as plt\n        import datetime\n        import yfinance as yf\n        from scipy.stats import norm\n        import requests\n        from io import StringIO\n        import seaborn as sns; sns.set()\n        import warnings\n        warnings.filterwarnings('ignore')\n        plt.rcParams['figure.figsize'] = (10,6)\n\nIn [2]: mean = 0\n        std_dev = 1\n        x = np.arange(-5, 5, 0.01)\n        y = norm.pdf(x, mean, std_dev)\n        pdf = plt.plot(x, y)\n        min_ylim, max_ylim = plt.ylim()\n        plt.text(np.percentile(x, 5), max_ylim * 0.9, '95%:${:.4f}'\n                 .format(np.percentile(x, 5)))\n        plt.axvline(np.percentile(x, 5), color='r', linestyle='dashed',\n                    linewidth=4)\n        plt.title('Value at Risk Illustration')\n        plt.show()\nIn [3]: mean = 0\n        std_dev = 1\n        x = np.arange(-5, 5, 0.01)\n        y = norm.pdf(x, mean, std_dev) ![1](assets/1.png)\n        pdf = plt.plot(x, y)\n        min_ylim, max_ylim = plt.ylim() ![2](assets/2.png)\n        plt.text(np.percentile(x, 5), max_ylim * 0.9, '95%:${:.4f}'\n                 .format(np.percentile(x, 5))) ![3](assets/3.png)\n        plt.axvline(np.percentile(x, 5), color='r', linestyle='dashed',\n                    linewidth=4)\n        plt.title('Value at Risk Illustration')\n        plt.show()\n```", "```py\nIn [4]: def getDailyData(symbol):\n                parameters = {'function': 'TIME_SERIES_DAILY_ADJUSTED',\n                              'symbol': symbol,\n                               'outputsize':'full',\n                               'datatype': 'csv',\n                               'apikey': 'insert your api key here'} ![1](assets/1.png)\n\n                response = requests.get('https://www.alphavantage.co/query',\n                                        params=parameters) ![2](assets/2.png)\n\n                csvText = StringIO(response.text) ![3](assets/3.png)\n                data = pd.read_csv(csvText, index_col='timestamp')\n                return data\n\nIn [5]: symbols = [\"IBM\", \"MSFT\", \"INTC\"]\n        stock3 = []\n        for symbol in symbols:\n            stock3.append(getDailyData(symbol)[::-1]['close']\n                          ['2020-01-01': '2020-12-31']) ![4](assets/4.png)\n        stocks = pd.DataFrame(stock3).T\n        stocks.columns = symbols\n\nIn [6]: stocks.head()\nOut[6]:                IBM    MSFT   INTC\n        timestamp\n        2020-01-02  135.42  160.62  60.84\n        2020-01-03  134.34  158.62  60.10\n        2020-01-06  134.10  159.03  59.93\n        2020-01-07  134.19  157.58  58.93\n        2020-01-08  135.31  160.09  58.97\n```", "```py\nIn [7]: stocks_returns = (np.log(stocks) - np.log(stocks.shift(1))).dropna() ![1](assets/1.png)\n        stocks_returns\nOut[7]:                  IBM      MSFT      INTC\n        timestamp\n        2020-01-03 -0.008007 -0.012530 -0.012238\n        2020-01-06 -0.001788  0.002581 -0.002833\n        2020-01-07  0.000671 -0.009160 -0.016827\n        2020-01-08  0.008312  0.015803  0.000679\n        2020-01-09  0.010513  0.012416  0.005580\n        ...              ...       ...       ...\n        2020-12-24  0.006356  0.007797  0.010679\n        2020-12-28  0.001042  0.009873  0.000000\n        2020-12-29 -0.008205 -0.003607  0.048112\n        2020-12-30  0.004352 -0.011081 -0.013043\n        2020-12-31  0.012309  0.003333  0.021711\n\n        [252 rows x 3 columns]\n\nIn [8]: stocks_returns_mean = stocks_returns.mean()\n        weights  = np.random.random(len(stocks_returns.columns)) ![2](assets/2.png)\n        weights /= np.sum(weights) ![3](assets/3.png)\n        cov_var = stocks_returns.cov() ![4](assets/4.png)\n        port_std = np.sqrt(weights.T.dot(cov_var).dot(weights)) ![5](assets/5.png)\n\nIn [9]: initial_investment = 1e6\n        conf_level = 0.95\n\nIn [10]: def VaR_parametric(initial_investment, conf_level):\n             alpha = norm.ppf(1 - conf_level, stocks_returns_mean, port_std) ![6](assets/6.png)\n             for i, j in zip(stocks.columns, range(len(stocks.columns))):\n                 VaR_param = (initial_investment - initial_investment *\n                              (1 + alpha))[j] ![7](assets/7.png)\n                 print(\"Parametric VaR result for {} is {} \"\n                       .format(i, VaR_param))\n             VaR_param = (initial_investment - initial_investment * (1 + alpha))\n             print('--' * 25)\n             return VaR_param\n\nIn [11]: VaR_param = VaR_parametric(initial_investment, conf_level)\n         VaR_param\n         Parametric VaR result for IBM is 42606.16125893139\n         Parametric VaR result for MSFT is 41024.50194348814\n         Parametric VaR result for INTC is 43109.25240851776\n         --------------------------------------------------\n\nOut[11]: array([42606.16125893, 41024.50194349, 43109.25240852])\n```", "```py\nIn [12]: var_horizon = []\n         time_horizon = 30\n         for j in range(len(stocks_returns.columns)):\n             for i in range(1, time_horizon + 1):\n                 var_horizon.append(VaR_param[j] * np.sqrt(i))\n         plt.plot(var_horizon[:time_horizon], \"o\",\n                  c='blue', marker='*', label='IBM')\n         plt.plot(var_horizon[time_horizon:time_horizon + 30], \"o\",\n                  c='green', marker='o', label='MSFT')\n         plt.plot(var_horizon[time_horizon + 30:time_horizon + 60], \"o\",\n                  c='red', marker='v', label='INTC')\n         plt.xlabel(\"Days\")\n         plt.ylabel(\"USD\")\n         plt.title(\"VaR over 30-day period\")\n         plt.legend()\n         plt.show()\n```", "```py\nIn [13]: def VaR_historical(initial_investment, conf_level): ![1](assets/1.png)\n             Hist_percentile95 = []\n             for i, j in zip(stocks_returns.columns,\n                             range(len(stocks_returns.columns))):\n                 Hist_percentile95.append(np.percentile(stocks_returns.loc[:, i],\n                                                        5))\n                 print(\"Based on historical values 95% of {}'s return is {:.4f}\"\n                       .format(i, Hist_percentile95[j]))\n                 VaR_historical = (initial_investment - initial_investment *\n                                   (1 + Hist_percentile95[j]))\n                 print(\"Historical VaR result for {} is {:.2f} \"\n                       .format(i, VaR_historical))\n                 print('--' * 35)\n\nIn [14]: VaR_historical(initial_investment,conf_level) ![2](assets/2.png)\n         Based on historical values 95% of IBM's return is -0.0371\n         Historical VaR result for IBM is 37081.53\n         ----------------------------------------------------------------------\n         Based on historical values 95% of MSFT's return is -0.0426\n         Historical VaR result for MSFT is 42583.68\n         ----------------------------------------------------------------------\n         Based on historical values 95% of INTC's return is -0.0425\n         Historical VaR result for INTC is 42485.39\n         ----------------------------------------------------------------------\n```", "```py\nIn [15]: x = np.random.uniform(-1, 1, 100) ![1](assets/1.png)\n         y = np.random.uniform(-1, 1, 100)\n\nIn [16]: sample = 100\n         def pi_calc(x, y):\n             point_inside_circle = 0\n             for i in range(sample):\n                 if np.sqrt(x[i] ** 2 + y[i] ** 2) <= 1: ![2](assets/2.png)\n                     point_inside_circle += 1\n             print('pi value is {}'.format(4 * point_inside_circle/sample))\n\nIn [17]: pi_calc(x,y)\n         pi value is 3.2\n\nIn [18]: x = np.random.uniform(-1, 1, 1000000)\n         y = np.random.uniform(-1, 1, 1000000)\n\nIn [19]: sample = 1000000\n\n         def pi_calc(x, y):\n             point_inside_circle = 0\n             for i in range(sample):\n                 if np.sqrt(x[i] ** 2 + y[i] ** 2) < 1:\n                     point_inside_circle += 1\n             print('pi value is {:.2f}'.format(4 * point_inside_circle/sample))\n\nIn [20]: pi_calc(x,y)\n         pi value is 3.14\n\nIn [21]: sim_data = pd.DataFrame([])\n         num_reps = 1000\n         n = 100\n         for i in range(len(stocks.columns)):\n             mean = np.random.randn(n).mean()\n             std = np.random.randn(n).std()\n             temp = pd.DataFrame(np.random.normal(mean, std, num_reps))\n             sim_data = pd.concat([sim_data, temp], axis=1)\n         sim_data.columns = ['Simulation 1', 'Simulation 2', 'Simulation 3']\n\nIn [22]: sim_data\nOut[22]:      Simulation 1  Simulation 2  Simulation 3\n         0        1.587297     -0.256668      1.137718\n         1        0.053628     -0.177641     -1.642747\n         2       -1.636260     -0.626633      0.393466\n         3        1.088207      0.847237      0.453473\n         4       -0.479977     -0.114377     -2.108050\n         ..            ...           ...           ...\n         995      1.615190      0.940931      0.172129\n         996     -0.015111     -1.149821     -0.279746\n         997     -0.806576     -0.141932     -1.246538\n         998      1.609327      0.582967     -1.879237\n         999     -0.943749     -0.286847      0.777052\n\n         [1000 rows x 3 columns]\n\nIn [23]: def MC_VaR(initial_investment, conf_level):\n             MC_percentile95 = []\n             for i, j in zip(sim_data.columns, range(len(sim_data.columns))):\n                 MC_percentile95.append(np.percentile(sim_data.loc[:, i], 5)) ![3](assets/3.png)\n                 print(\"Based on simulation 95% of {}'s return is {:.4f}\"\n                       .format(i, MC_percentile95[j]))\n                 VaR_MC = (initial_investment - initial_investment *\n                           (1 + MC_percentile95[j])) ![4](assets/4.png)\n                 print(\"Simulation VaR result for {} is {:.2f} \"\n                       .format(i, VaR_MC))\n                 print('--' * 35)\n\nIn [24]: MC_VaR(initial_investment, conf_level)\n         Based on simulation 95% of Simulation 1's return is -1.7880\n         Simulation VaR result for Simulation 1 is 1787990.69\n         ----------------------------------------------------------------------\n         Based on simulation 95% of Simulation 2's return is -1.6290\n         Simulation VaR result for Simulation 2 is 1628976.68\n         ----------------------------------------------------------------------\n         Based on simulation 95% of Simulation 3's return is -1.5156\n         Simulation VaR result for Simulation 3 is 1515623.93\n         ----------------------------------------------------------------------\n```", "```py\nIn [25]: def mp_pdf(sigma2, q, obs):\n             lambda_plus = sigma2 * (1 + q ** 0.5) ** 2 ![1](assets/1.png)\n             lambda_minus = sigma2 * (1 - q ** 0.5) ** 2 ![2](assets/2.png)\n             l = np.linspace(lambda_minus, lambda_plus, obs)\n             pdf_mp = 1 / (2 * np.pi * sigma2 * q * l) \\\n                      * np.sqrt((lambda_plus  - l)\n                      *  (l - lambda_minus)) ![3](assets/3.png)\n             pdf_mp = pd.Series(pdf_mp, index=l)\n             return pdf_mp\n\nIn [26]: from sklearn.neighbors import KernelDensity\n\n         def kde_fit(bandwidth,obs,x=None):\n             kde = KernelDensity(bandwidth, kernel='gaussian') ![4](assets/4.png)\n             if len(obs.shape) == 1:\n                 kde_fit=kde.fit(np.array(obs).reshape(-1, 1)) ![5](assets/5.png)\n             if x is None:\n                 x=np.unique(obs).reshape(-1, 1)\n             if len(x.shape) == 1:\n                 x = x.reshape(-1, 1)\n             logprob = kde_fit.score_samples(x) ![6](assets/6.png)\n             pdf_kde = pd.Series(np.exp(logprob), index=x.flatten())\n             return pdf_kde\n\nIn [27]: corr_mat = np.random.normal(size=(10000, 1000)) ![7](assets/7.png)\n         corr_coef = np.corrcoef(corr_mat, rowvar=0) ![8](assets/8.png)\n         sigma2 = 1\n         obs = corr_mat.shape[0]\n         q = corr_mat.shape[0] / corr_mat.shape[1]\n\n         def plotting(corr_coef, q):\n             ev, _ = np.linalg.eigh(corr_coef) ![9](assets/9.png)\n             idx = ev.argsort()[::-1]\n             eigen_val = np.diagflat(ev[idx]) ![10](assets/10.png)\n             pdf_mp = mp_pdf(1., q=corr_mat.shape[1] / corr_mat.shape[0],\n                             obs=1000) ![11](assets/11.png)\n             kde_pdf = kde_fit(0.01, np.diag(eigen_val)) ![12](assets/12.png)\n             ax = pdf_mp.plot(title=\"Marchenko-Pastur Theorem\",\n                              label=\"M-P\", style='r--')\n             kde_pdf.plot(label=\"Empirical Density\", style='o-', alpha=0.3)\n             ax.set(xlabel=\"Eigenvalue\", ylabel=\"Frequency\")\n             ax.legend(loc=\"upper right\")\n             plt.show()\n             return plt\n\nIn [28]: plotting(corr_coef, q);\n```", "```py\nIn [29]: import portfoliolab as pl\n\nIn [30]: risk_estimators = pl.estimators.RiskEstimators()\n\nIn [31]: stock_prices = stocks.copy()\n\nIn [32]: cov_matrix = stocks_returns.cov()\n         cov_matrix\nOut[32]:            IBM      MSFT      INTC\n         IBM   0.000672  0.000465  0.000569\n         MSFT  0.000465  0.000770  0.000679\n         INTC  0.000569  0.000679  0.001158\n\nIn [33]: tn_relation = stock_prices.shape[0] / stock_prices.shape[1] ![1](assets/1.png)\n         kde_bwidth = 0.25 ![2](assets/2.png)\n         cov_matrix_denoised = risk_estimators.denoise_covariance(cov_matrix,\n                                                                  tn_relation,\n                                                                  kde_bwidth) ![3](assets/3.png)\n         cov_matrix_denoised = pd.DataFrame(cov_matrix_denoised,\n                                            index=cov_matrix.index,\n                                            columns=cov_matrix.columns)\n         cov_matrix_denoised\nOut[33]:            IBM      MSFT      INTC\n         IBM   0.000672  0.000480  0.000589\n         MSFT  0.000480  0.000770  0.000638\n         INTC  0.000589  0.000638  0.001158\n\nIn [34]: def VaR_parametric_denoised(initial_investment, conf_level):\n             port_std = np.sqrt(weights.T.dot(cov_matrix_denoised)\n                                .dot(weights)) ![4](assets/4.png)\n             alpha = norm.ppf(1 - conf_level, stocks_returns_mean, port_std)\n             for i, j in zip(stocks.columns,range(len(stocks.columns))):\n                 print(\"Parametric VaR result for {} is {} \".format(i,VaR_param))\n             VaR_params = (initial_investment - initial_investment * (1 + alpha))\n             print('--' * 25)\n             return VaR_params\n\nIn [35]: VaR_parametric_denoised(initial_investment, conf_level)\n         Parametric VaR result for IBM is [42606.16125893 41024.50194349\n          43109.25240852]\n         Parametric VaR result for MSFT is [42606.16125893 41024.50194349\n          43109.25240852]\n         Parametric VaR result for INTC is [42606.16125893 41024.50194349\n          43109.25240852]\n         --------------------------------------------------\n\nOut[35]: array([42519.03744155, 40937.37812611, 43022.12859114])\n\nIn [36]: symbols = [\"IBM\", \"MSFT\", \"INTC\"]\n         stock3 = []\n         for symbol in symbols:\n             stock3.append(getDailyData(symbol)[::-1]['close']\n                           ['2007-04-01': '2009-02-01'])\n         stocks_crisis = pd.DataFrame(stock3).T\n         stocks_crisis.columns = symbols\n\nIn [37]: stocks_crisis\nOut[37]:               IBM   MSFT   INTC\n         timestamp\n         2007-04-02  95.21  27.74  19.13\n         2007-04-03  96.10  27.87  19.31\n         2007-04-04  96.21  28.50  19.38\n         2007-04-05  96.52  28.55  19.58\n         2007-04-09  96.62  28.57  20.10\n         ...           ...    ...    ...\n         2009-01-26  91.60  17.63  13.38\n         2009-01-27  91.66  17.66  13.81\n         2009-01-28  94.82  18.04  14.01\n         2009-01-29  92.51  17.59  13.37\n         2009-01-30  91.65  17.10  12.90\n\n         [463 rows x 3 columns]\n\nIn [38]: stock_prices = stocks_crisis.copy()\n\nIn [39]: stocks_returns = (np.log(stocks) - np.log(stocks.shift(1))).dropna()\n\nIn [40]: cov_matrix = stocks_returns.cov()\n\nIn [41]: VaR_parametric(initial_investment, conf_level)\n         Parametric VaR result for IBM is 42606.16125893139\n         Parametric VaR result for MSFT is 41024.50194348814\n         Parametric VaR result for INTC is 43109.25240851776\n         --------------------------------------------------\n\nOut[41]: array([42606.16125893, 41024.50194349, 43109.25240852])\n\nIn [42]: VaR_parametric_denoised(initial_investment, conf_level)\n         Parametric VaR result for IBM is [42606.16125893 41024.50194349\n          43109.25240852]\n         Parametric VaR result for MSFT is [42606.16125893 41024.50194349\n          43109.25240852]\n         Parametric VaR result for INTC is [42606.16125893 41024.50194349\n          43109.25240852]\n         --------------------------------------------------\n\nOut[42]: array([42519.03744155, 40937.37812611, 43022.12859114])\n```", "```py\nIn [43]: asset1 = [-0.5, 0, 0.1, 0.4] ![1](assets/1.png)\n         VaR1 = np.percentile(asset1, 90)\n         print('VaR for the Asset 1 is {:.4f}'.format(VaR1))\n         asset2 = [0, -0.5, 0.01, 0.4] ![2](assets/2.png)\n         VaR2 = np.percentile(asset2, 90)\n         print('VaR for the Asset 2 is {:.4f}'.format(VaR2))\n         VaR_all = np.percentile(asset1 + asset2, 90)\n         print('VaR for the portfolio is {:.4f}'.format(VaR_all))\n         VaR for the Asset 1 is 0.3100\n         VaR for the Asset 2 is 0.2830\n         VaR for the portfolio is 0.4000\n\nIn [44]: asset1 = [-0.5, 0, 0.05, 0.03] ![1](assets/1.png)\n         VaR1 = np.percentile(asset1, 90)\n         print('VaR for the Asset 1 is {:.4f}'.format(VaR1))\n         asset2 = [0, -0.5, 0.02, 0.8] ![2](assets/2.png)\n         VaR2 = np.percentile(asset2,90)\n         print('VaR for the Asset 2 is {:.4f}'.format(VaR2))\n         VaR_all = np.percentile(asset1 + asset2 , 90)\n         print('VaR for the portfolio is {:.4f}'.format(VaR_all))\n         VaR for the Asset 1 is 0.0440\n         VaR for the Asset 2 is 0.5660\n         VaR for the portfolio is 0.2750\n```", "```py\nIn [45]: def ES_parametric(initial_investment , conf_level):\n             alpha = - norm.ppf(1 - conf_level,stocks_returns_mean,port_std)\n             for i, j in zip(stocks.columns, range(len(stocks.columns))):\n                 VaR_param = (initial_investment * alpha)[j] ![1](assets/1.png)\n                 ES_param = (1 / (1 - conf_level)) \\\n                            * initial_investment \\\n                            * norm.expect(lambda x: x,\n                                          lb = norm.ppf(conf_level,\n                                                        stocks_returns_mean[j],\n                                                        port_std),\n                                          loc = stocks_returns_mean[j],\n                                          scale = port_std) ![2](assets/2.png)\n                 print(f\"Parametric ES result for {i} is {ES_param}\")\n\nIn [46]: ES_parametric(initial_investment, conf_level)\n         Parametric ES result for IBM is 52776.42396231898\n         Parametric ES result for MSFT is 54358.083277762125\n         Parametric ES result for INTC is 52273.33281273264\n```", "```py\nIn [47]: def ES_historical(initial_investment, conf_level):\n             for i, j in zip(stocks_returns.columns,\n                             range(len(stocks_returns.columns))):\n                 ES_hist_percentile95 = np.percentile(stocks_returns.loc[:, i],\n                                                      5) ![1](assets/1.png)\n                 ES_historical = stocks_returns[str(i)][stocks_returns[str(i)] <=\n                                                        ES_hist_percentile95]\\\n                                                        .mean() ![2](assets/2.png)\n                 print(\"Historical ES result for {} is {:.4f} \"\n                       .format(i, initial_investment * ES_historical))\n\nIn [48]: ES_historical(initial_investment, conf_level)\n         Historical ES result for IBM is -64802.3898\n         Historical ES result for MSFT is -65765.0848\n         Historical ES result for INTC is -88462.7404\n```", "```py\nIn [49]: bid_ask = pd.read_csv('bid_ask.csv') ![1](assets/1.png)\n\nIn [50]: bid_ask['mid_price'] = (bid_ask['ASKHI'] + bid_ask['BIDLO']) / 2 ![2](assets/2.png)\n         buyer_seller_initiated = []\n         for i in range(len(bid_ask)):\n             if bid_ask['PRC'][i] > bid_ask['mid_price'][i]: ![3](assets/3.png)\n                 buyer_seller_initiated.append(1) ![4](assets/4.png)\n             else:\n                 buyer_seller_initiated.append(0) ![5](assets/5.png)\n\n         bid_ask['buyer_seller_init'] = buyer_seller_initiated\n\nIn [51]: effective_cost = []\n         for i in range(len(bid_ask)):\n             if bid_ask['buyer_seller_init'][i] == 1:\n                 effective_cost.append((bid_ask['PRC'][i] -\n                                        bid_ask['mid_price'][i]) /\n                                        bid_ask['mid_price'][i]) ![6](assets/6.png)\n             else:\n                 effective_cost.append((bid_ask['mid_price'][i] -\n                                        bid_ask['PRC'][i])/\n                                        bid_ask['mid_price'][i]) ![7](assets/7.png)\n         bid_ask['effective_cost'] = effective_cost\n\nIn [52]: bid_ask['quoted'] = bid_ask['ASKHI'] - bid_ask['BIDLO'] ![8](assets/8.png)\n         bid_ask['prop_quoted'] = (bid_ask['ASKHI'] - bid_ask['BIDLO']) /\\\n                                  bid_ask['mid_price'] ![8](assets/8.png)\n         bid_ask['effective'] = 2 * abs(bid_ask['PRC'] - bid_ask['mid_price']) ![8](assets/8.png)\n         bid_ask['prop_effective'] = 2 * abs(bid_ask['PRC'] -\n                                             bid_ask['mid_price']) /\\\n                                             bid_ask['PRC'] ![8](assets/8.png)\n\nIn [53]: spread_meas = bid_ask.iloc[:, -5:]\n         spread_meas.corr()\nOut[53]:                 effective_cost    quoted  prop_quoted  effective  \\\n         effective_cost        1.000000  0.441290     0.727917   0.800894\n         quoted                0.441290  1.000000     0.628526   0.717246\n         prop_quoted           0.727917  0.628526     1.000000   0.514979\n         effective             0.800894  0.717246     0.514979   1.000000\n         prop_effective        0.999847  0.442053     0.728687   0.800713\n\n                         prop_effective\n         effective_cost        0.999847\n         quoted                0.442053\n         prop_quoted           0.728687\n         effective             0.800713\n         prop_effective        1.000000\n\nIn [54]: spread_meas.describe()\nOut[54]:     effective_cost      quoted  prop_quoted   effective  prop_effective\n      count      756.000000  756.000000   756.000000  756.000000      756.000000\n      mean         0.004247    1.592583     0.015869    0.844314        0.008484\n      std          0.003633    0.921321     0.007791    0.768363        0.007257\n      min          0.000000    0.320000     0.003780    0.000000        0.000000\n      25%          0.001517    0.979975     0.010530    0.300007        0.003029\n      50%          0.003438    1.400000     0.013943    0.610000        0.006874\n      75%          0.005854    1.962508     0.019133    1.180005        0.011646\n      max          0.023283    8.110000     0.055451    6.750000        0.047677\n\nIn [55]: high_corr = spread_meas.corr().unstack()\\\n                     .sort_values(ascending=False).drop_duplicates() ![9](assets/9.png)\n         high_corr[(high_corr > 0.80) & (high_corr != 1)] ![10](assets/10.png)\nOut[55]: effective_cost  prop_effective    0.999847\n         effective       effective_cost    0.800894\n         prop_effective  effective         0.800713\n         dtype: float64\n\nIn [56]: sorted_spread_measures = bid_ask.iloc[:, -5:-2]\n\nIn [57]: cross_sec_mean_corr = sorted_spread_measures.mean(axis=1).mean() ![11](assets/11.png)\n         std_corr = sorted_spread_measures.std().sum() / 3 ![12](assets/12.png)\n\nIn [58]: df = pd.DataFrame(index=stocks.columns)\n         last_prices = []\n         for i in symbols:\n             last_prices.append(stocks[i].iloc[-1]) ![13](assets/13.png)\n         df['last_prices'] = last_prices\n\nIn [59]: def ES_parametric(initial_investment, conf_level):\n             ES_params = [ ]\n             alpha = - norm.ppf(1 - conf_level, stocks_returns_mean, port_std)\n             for i,j in zip(stocks.columns,range(len(stocks.columns))):\n                 VaR_param = (initial_investment * alpha)[j]\n                 ES_param = (1 / (1 - conf_level)) \\\n                            * norm.expect(lambda x: VaR_param, lb = conf_level)\n                 ES_params.append(ES_param)\n             return ES_params\n\nIn [60]: ES_params = ES_parametric(initial_investment, conf_level)\n         for i in range(len(symbols)):\n             print(f'The ES result for {symbols[i]} is {ES_params[i]}')\n         The ES result for IBM is 145760.89803654602\n         The ES result for MSFT is 140349.84772375744\n         The ES result for INTC is 147482.03450111256\n\nIn [61]: k = 1.96\n\n         for i, j in zip(range(len(symbols)), symbols):\n             print('The liquidity Adjusted ES of {} is {}'\n                   .format(j, ES_params[i] + (df.loc[j].values[0] / 2) *\n                           (cross_sec_mean_corr + k * std_corr))) ![14](assets/14.png)\n         The liquidity Adjusted ES of IBM is 145833.08767607837\n         The liquidity Adjusted ES of MSFT is 140477.40110495212\n         The liquidity Adjusted ES of INTC is 147510.60526566216\n```", "```py\nIn [62]: from sklearn.decomposition import PCA\n         from sklearn.preprocessing import StandardScaler\n\nIn [63]: scaler = StandardScaler()\n         spread_meas_scaled = scaler.fit_transform(np.abs(spread_meas)) ![1](assets/1.png)\n         pca = PCA(n_components=5) ![2](assets/2.png)\n         prin_comp = pca.fit_transform(spread_meas_scaled) ![3](assets/3.png)\n\nIn [64]: var_expl = np.round(pca.explained_variance_ratio_, decimals=4) ![4](assets/4.png)\n         cum_var = np.cumsum(np.round(pca.explained_variance_ratio_,\n                                      decimals=4)) ![5](assets/5.png)\n         print('Individually Explained Variances are:\\n{}'.format(var_expl))\n         print('=='*30)\n         print('Cumulative Explained Variances are: {}'.format(cum_var))\n         Individually Explained Variances are:\n         [0.7494 0.1461 0.0983 0.0062 0.    ]\n         ============================================================\n         Cumulative Explained Variances are: [0.7494 0.8955 0.9938 1.     1.    ]\n\nIn [65]: plt.plot(pca.explained_variance_ratio_) ![6](assets/6.png)\n         plt.xlabel('Number of Components')\n         plt.ylabel('Variance Explained')\n         plt.title('Scree Plot')\n         plt.show()\nIn [66]: pca = PCA(n_components=2) ![7](assets/7.png)\n         pca.fit(np.abs(spread_meas_scaled))\n         prin_comp = pca.transform(np.abs(spread_meas_scaled))\n         prin_comp = pd.DataFrame(np.abs(prin_comp), columns = ['Component 1',\n                                                                'Component 2'])\n         print(pca.explained_variance_ratio_*100)\n         [65.65640435 19.29704671]\n\nIn [67]: def myplot(score, coeff, labels=None):\n             xs = score[:, 0]\n             ys = score[:, 1]\n             n = coeff.shape[0]\n             scalex = 1.0 / (xs.max() - xs.min())\n             scaley = 1.0 / (ys.max() - ys.min())\n             plt.scatter(xs * scalex * 4, ys * scaley * 4, s=5)\n             for i in range(n):\n                 plt.arrow(0, 0, coeff[i, 0], coeff[i, 1], color = 'r',\n                           alpha=0.5)\n                 if labels is None:\n                     plt.text(coeff[i, 0], coeff[i, 1], \"Var\"+str(i),\n                              color='black')\n                 else:\n                     plt.text(coeff[i,0 ], coeff[i, 1], labels[i],\n                              color='black')\n\n             plt.xlabel(\"PC{}\".format(1))\n             plt.ylabel(\"PC{}\".format(2))\n             plt.grid()\n\nIn [68]: spread_measures_scaled_df = pd.DataFrame(spread_meas_scaled,\n                                                  columns=spread_meas.columns)\n\nIn [69]: myplot(np.array(spread_measures_scaled_df)[:, 0:2],\n                np.transpose(pca.components_[0:2,:]),\n                list(spread_measures_scaled_df.columns)) ![8](assets/8.png)\n         plt.show()\n```", "```py\nIn [70]: prin_comp1_rescaled = prin_comp.iloc[:,0] * prin_comp.iloc[:,0].std()\\\n                               + prin_comp.iloc[:, 0].mean() ![1](assets/1.png)\n         prin_comp2_rescaled = prin_comp.iloc[:,1] * prin_comp.iloc[:,1].std()\\\n                               + prin_comp.iloc[:, 1].mean() ![2](assets/2.png)\n         prin_comp_rescaled = pd.concat([prin_comp1_rescaled,\n                                         prin_comp2_rescaled],\n                                        axis=1)\n         prin_comp_rescaled.head()\nOut[70]:    Component 1  Component 2\n         0     1.766661     1.256192\n         1     4.835170     1.939466\n         2     3.611486     1.551059\n         3     0.962666     0.601529\n         4     0.831065     0.734612\n\nIn [71]: mean_pca_liq = prin_comp_rescaled.mean(axis=1).mean() ![3](assets/3.png)\n         mean_pca_liq\nOut[71]: 1.0647130086973815\n\nIn [72]: k = 1.96\n         for i, j in zip(range(len(symbols)), symbols):\n             print('The liquidity Adjusted ES of {} is {}'\n                   .format(j, ES_params[i] + (df.loc[j].values[0] / 2) *\n                           (mean_pca_liq + k * std_corr))) ![4](assets/4.png)\n         The liquidity Adjusted ES of IBM is 145866.2662997893\n         The liquidity Adjusted ES of MSFT is 140536.02510785797\n         The liquidity Adjusted ES of INTC is 147523.7364940803\n```"]