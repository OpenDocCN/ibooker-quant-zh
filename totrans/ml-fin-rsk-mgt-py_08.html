<html><head></head><body><section data-pdf-bookmark="Chapter 6. Credit Risk Estimation" data-type="chapter" epub:type="chapter"><div class="chapter" id="chapter_6">&#13;
<h1><span class="label">Chapter 6. </span>Credit Risk Estimation</h1>&#13;
&#13;
<blockquote data-type="epigram">&#13;
<p> Although market risk is much better researched, the larger part of banks’ economic capital is generally used for credit risk. The sophistication of traditional standard methods of measurement, analysis, and management of credit risk might, therefore, not be in line with its significance. </p>&#13;
<p data-type="attribution"> Uwe Wehrspohn (2002)</p>&#13;
</blockquote>&#13;
&#13;
<p><a data-primary="credit risk" data-type="indexterm" id="ix_credit_risk_ch6"/>The primary role of financial institutions is to create a channel by which funds move from entities with surplus into ones with deficit. Thereby, financial institutions ensure the capital allocation in the financial system as well as gain profit in exchange for these transactions.</p>&#13;
&#13;
<p>However, there is an important risk for financial institutions to handle, which is credit risk. This is such a big risk that without it capital allocation might be less costly and more efficient. <em>Credit risk</em> is the risk that arises when a borrower is not able to honor their debt. In other words, when a borrower defaults, they fail to pay back their debt, which causes losses for financial institutions.</p>&#13;
&#13;
<p>Credit risk and its goal can be defined in a more formal way (BCBS and BIS 2000):</p>&#13;
<blockquote data-type="epigram">&#13;
<p> Credit risk is most simply defined as the potential that a bank borrower or counterparty will fail to meet its obligations in accordance with agreed terms. The goal of credit risk management is to maximise a bank’s risk-adjusted rate of return by maintaining credit risk exposure within acceptable parameters.</p>&#13;
</blockquote>&#13;
&#13;
<p><a data-primary="Basel Accords" data-type="indexterm" id="idm45737232124528"/>Estimating credit risk is so formidable a task that a regulatory body, Basel, closely monitors recent developments in the financial markets and sets regulations to strengthen bank capital requirements. The importance of having strong capital requirements for a bank rests on the idea that banks should have a capital buffer in turbulent times.</p>&#13;
&#13;
<p>There is a consensus among policy makers that financial institutions should have a minimum capital requirement to ensure the stability of the financial system because a series of defaults may result in a collapse in financial markets, as financial institutions provide collateral to one another. Those looking for a workaround for this capital requirement learned their lessons the hard way during the <a href="https://oreil.ly/OjDw9">2007—2008 mortgage <span class="keep-together">crisis</span></a>.</p>&#13;
&#13;
<p>Of course, ensuring at least a minimum capital requirement is a burden for financial institutions in the sense that capital is an asset they cannot channel to deficit entities to make a profit.&#13;
Consequently, managing credit risk amounts to profitable and efficient transactions.</p>&#13;
&#13;
<p><a data-primary="probability approaches" data-secondary="for default estimation" data-secondary-sortas="default estimation" data-tertiary="ML to model" data-type="indexterm" id="idm45737232120272"/>In this respect, this chapter shows how credit risk can be estimated using cutting-edge ML models. We start our discussion with a theoretical background of credit risk. Needless to say, there are many topics in credit risk analysis, but we confine our focus on probability of default and how we can introduce ML approaches for estimating it. <a data-primary="clustering method" data-secondary="credit risk estimation" data-type="indexterm" id="idm45737232118272"/>For this purpose, customers are segmented via a clustering method so that models can be separately fitted to this data. This provides a better fit in the sense that the distribution of credit risk data changes across different customer segments. Given the clusters obtained, ML and deep learning models, including the Bayesian approach, are introduced to model the credit risk.</p>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Estimating the Credit Risk" data-type="sect1"><div class="sect1" id="idm45737232116672">&#13;
<h1>Estimating the Credit Risk</h1>&#13;
&#13;
<p>Aside from the probability of default (which is the likelihood that a borrower fails to cover their debt), credit risk has three defining characteristics:</p>&#13;
<dl>&#13;
<dt><a data-primary="exposure, credit risk" data-type="indexterm" id="idm45737229222336"/>Exposure</dt>&#13;
<dd>&#13;
<p>This refers to a party that may possibly default or suffer an adverse change in its ability to perform.</p>&#13;
</dd>&#13;
<dt><a data-primary="likelihood, credit risk from default" data-type="indexterm" id="idm45737229220240"/>Likelihood</dt>&#13;
<dd>&#13;
<p>The likelihood that this party will default on its obligations.</p>&#13;
</dd>&#13;
<dt><a data-primary="recovery rate, loan default" data-type="indexterm" id="idm45737229218240"/>Recovery rate</dt>&#13;
<dd>&#13;
<p>How much can be retrieved if a default takes place.</p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>The BCBS put forth the global financial credit management standards, which are known as the <em>Basel Accord</em>. There are currently three Basel Accords. The most distinctive rule set by Basel I in 1988 was the requirement to hold capital equating to at least 8% of risk-weighted assets.</p>&#13;
&#13;
<p><a data-primary="minimum capital requirement" data-type="indexterm" id="ix_min_cap_req_banks"/><a data-primary="capital requirement for banks" data-type="indexterm" id="ix_cap_req_banks"/><a data-primary="Basel Accords" data-type="indexterm" id="ix_basel_accords"/>Basel I includes the very first capital measurement system, which was created following the onset of the <a href="https://oreil.ly/KI5vs">Latin American debt crisis</a>. In Basel I, assets are classified as &#13;
<span class="keep-together">follows</span>:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>0% for risk-free assets</p>&#13;
</li>&#13;
<li>&#13;
<p>20% for loans to other banks</p>&#13;
</li>&#13;
<li>&#13;
<p>50% for residential mortgages</p>&#13;
</li>&#13;
<li>&#13;
<p>100% for corporate debt</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>In 1999, Basel II issued a revision to Basel I based on three main pillars:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Minimum capital requirements, which sought to develop and expand the standardized rules set out in the 1988 Accord</p>&#13;
</li>&#13;
<li>&#13;
<p>Supervisory review of an institution’s capital adequacy and internal assessment process</p>&#13;
</li>&#13;
<li>&#13;
<p>Effective use of disclosure as a lever to strengthen market discipline and encourage sound banking practices</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p><a data-primary="financial ratios, bank requirements" data-type="indexterm" id="idm45737229202480"/>The last accord, Basel III in 2010, was inevitable. as the 2007–2008 mortgage crisis heightened. It introduced a new set of measures to further strengthened liquidity and poor governance practices. <a data-primary="domino effect" data-type="indexterm" id="idm45737229201248"/><a data-primary="equity requirements for banks" data-type="indexterm" id="idm45737229200576"/>For instance, equity requirements were introduced to prevent a serial failure in the financial system, known as <em>domino effect</em>, during times of financial turbulence and crises. Accordingly, Basel III requires the financial ratios for banks listed in <a data-type="xref" href="#table6-1">Table 6-1</a>.<a data-primary="" data-startref="ix_cap_req_banks" data-type="indexterm" id="idm45737229198272"/><a data-primary="" data-startref="ix_min_cap_req_banks" data-type="indexterm" id="idm45737229197296"/></p>&#13;
<table id="table6-1">&#13;
<caption><span class="label">Table 6-1. </span>Financial ratios required by Basel III</caption>&#13;
<thead>&#13;
<tr>&#13;
<th>Financial ratio</th>&#13;
<th>Formula</th>&#13;
</tr>&#13;
</thead>&#13;
<tbody>&#13;
<tr>&#13;
<td><p>Tier 1 capital ratio</p></td>&#13;
<td><p><math alttext="StartFraction Equity capital Over Risk weighted assets EndFraction greater-than equals 4.5 percent-sign">&#13;
  <mrow>&#13;
    <mfrac><mrow><mtext>Equity</mtext><mspace width="4.pt"/><mtext>capital</mtext></mrow> <mrow><mtext>Risk</mtext><mspace width="4.pt"/><mtext>weighted</mtext><mspace width="4.pt"/><mtext>assets</mtext></mrow></mfrac>&#13;
    <mo>&gt;</mo>&#13;
    <mo>=</mo>&#13;
    <mn>4</mn>&#13;
    <mo>.</mo>&#13;
    <mn>5</mn>&#13;
    <mo>%</mo>&#13;
  </mrow>&#13;
</math></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Leverage ratio</p></td>&#13;
<td><p><math alttext="StartFraction Tier 1 capital Over Average total assets EndFraction greater-than equals 3 percent-sign">&#13;
  <mrow>&#13;
    <mfrac><mrow><mtext>Tier</mtext><mspace width="4.pt"/><mtext>1</mtext><mspace width="4.pt"/><mtext>capital</mtext></mrow> <mrow><mtext>Average</mtext><mspace width="4.pt"/><mtext>total</mtext><mspace width="4.pt"/><mtext>assets</mtext></mrow></mfrac>&#13;
    <mo>&gt;</mo>&#13;
    <mo>=</mo>&#13;
    <mn>3</mn>&#13;
    <mo>%</mo>&#13;
  </mrow>&#13;
</math></p></td>&#13;
</tr>&#13;
<tr>&#13;
<td><p>Liquidity coverage ratio</p></td>&#13;
<td><p><math alttext="StartFraction Stock of high quality liquid assets Over Total net cash outflows over the next 30 calendar days EndFraction greater-than equals 100 percent-sign">&#13;
  <mrow>&#13;
    <mfrac><mrow><mtext>Stock</mtext><mspace width="4.pt"/><mtext>of</mtext><mspace width="4.pt"/><mtext>high</mtext><mspace width="4.pt"/><mtext>quality</mtext><mspace width="4.pt"/><mtext>liquid</mtext><mspace width="4.pt"/><mtext>assets</mtext></mrow> <mrow><mtext>Total</mtext><mspace width="4.pt"/><mtext>net</mtext><mspace width="4.pt"/><mtext>cash</mtext><mspace width="4.pt"/><mtext>outflows</mtext><mspace width="4.pt"/><mtext>over</mtext><mspace width="4.pt"/><mtext>the</mtext><mspace width="4.pt"/><mtext>next</mtext><mspace width="4.pt"/><mtext>30</mtext><mspace width="4.pt"/><mtext>calendar</mtext><mspace width="4.pt"/><mtext>days</mtext></mrow></mfrac>&#13;
    <mo>&gt;</mo>&#13;
    <mo>=</mo>&#13;
    <mn>100</mn>&#13;
    <mo>%</mo>&#13;
  </mrow>&#13;
</math></p></td>&#13;
</tr>&#13;
</tbody>&#13;
</table>&#13;
&#13;
<p><a data-primary="IRB (internal-ratings-based) approach to credit risk estimation" data-type="indexterm" id="idm45737227476672"/><a data-primary="standardized approach to credit risk estimation" data-type="indexterm" id="idm45737227476000"/>Basel II suggests banks implement either a standardized approach or an internal ratings–based (IRB) approach to estimate the credit risk. The standardized approach is out of the scope of this book, but interested readers can refer to the “Standardized Approach to Credit Risk” <a href="https://oreil.ly/0Mj7J">consultative document from the BIS</a>.<a data-primary="" data-startref="ix_basel_accords" data-type="indexterm" id="idm45737227474272"/></p>&#13;
&#13;
<p>Let’s now focus on the IRB approach; the key parameters of this internal assessment are:</p>&#13;
<div data-type="equation">&#13;
<math alttext="Expected loss equals EAD times LGD times PD" display="block">&#13;
  <mrow>&#13;
    <mtext>Expected</mtext>&#13;
    <mspace width="4.pt"/>&#13;
    <mtext>loss</mtext>&#13;
    <mo>=</mo>&#13;
    <mtext>EAD</mtext>&#13;
    <mo>×</mo>&#13;
    <mtext>LGD</mtext>&#13;
    <mo>×</mo>&#13;
    <mtext>PD</mtext>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <em>PD</em> is the probability of default, <em>LGD</em> is the expected loss given default taking a value between 0 and 1, and <em>EAD</em> is the exposure at default.</p>&#13;
&#13;
<p><a data-primary="probability approaches" data-secondary="for default estimation" data-secondary-sortas="default estimation" data-tertiary="ML to model" data-type="indexterm" id="idm45737227464400"/>The most important and challenging part of estimating credit risk is to model the probability of default, and the aim of this chapter is mainly to come up with an &#13;
<span class="keep-together">ML model</span> to address this issue. Before moving forward, there is one more important issue in estimating credit risk that is sometimes neglected or overlooked: <em>risk</em> &#13;
<span class="keep-together"><em>bucketing</em></span>.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Risk Bucketing" data-type="sect1"><div class="sect1" id="idm45737232116144">&#13;
<h1>Risk Bucketing</h1>&#13;
&#13;
<p><a data-primary="risk bucketing" data-type="indexterm" id="ix_risk_bucketing"/><a data-primary="credit risk" data-secondary="risk bucketing" data-type="indexterm" id="ix_credit_risk_bucket"/><a data-primary="creditworthiness, grouping customers by" data-type="indexterm" id="idm45737227455824"/>Risk bucketing is nothing but grouping borrowers with similar creditworthiness. The behind-the-scenes story of risk bucketing is to obtain homogenous groups or clusters so that we can better estimate the credit risk. Treating different risky borrowers equally may result in poor predictions because the model cannot capture entirely different characteristics of the data at once. Thus, by dividing the borrowers into different groups based on riskiness, risk bucketing enables us to make accurate predictions.</p>&#13;
&#13;
<p><a data-primary="K-means algorithm for clustering customers" data-type="indexterm" id="ix_k-means-cluster"/>Risk bucketing can be accomplished via different statistical methods, but we will apply a clustering technique to end up with homogeneous clusters using K-means.</p>&#13;
&#13;
<p>We live in the age of data, but that does not necessarily mean that we always find the data we are searching for. Rather, it is rare to find it without applying data-wrangling and cleaning techniques.</p>&#13;
&#13;
<p>Data with dependent variables is, of course, easy to work with and also helps us get more accurate results. However, sometimes we need to unveil the hidden characteristics of the data—that is, if the riskiness of the borrowers is not known, we are supposed to come up with a solution for grouping them based on their riskiness.</p>&#13;
&#13;
<p><a data-primary="clustering method" data-secondary="credit risk estimation" data-type="indexterm" id="ix_cluster_credit_risk"/>Clustering is the method proposed to create these groups or <em>clusters</em>. Optimal clustering has clusters located far away from one another spatially:</p>&#13;
<blockquote data-type="epigram">&#13;
<p> Clustering groups data instances into subsets in such a manner that similar instances are grouped together, while different instances belong to different groups. The instances are thereby organized into an efficient representation that characterizes the population being sampled.</p>&#13;
<p data-type="attribution"> Rokach and Maimon (2005)</p>&#13;
</blockquote>&#13;
&#13;
<p>Different clustering methods are available, but the K-means algorithm serves our purpose, which is to create risk bucketing for credit risk analysis. <a data-primary="centroid, K-means algorithm" data-type="indexterm" id="idm45737229026048"/>In K-means, the distance of observations within the cluster is calculated based on the cluster center, the <em>centroid</em>. Depending on the distance to the centroid, observations are clustered. This distance can be measured via different methods. <a data-primary="Manhattan metric for clustering" data-type="indexterm" id="idm45737229024496"/><a data-primary="Minkowski metric for clustering" data-type="indexterm" id="idm45737229023776"/><a data-primary="Euclidean distance metric" data-secondary="clustering" data-type="indexterm" id="idm45737229023088"/>Of them, the following are the most well-known metrics:</p>&#13;
<dl class="pagebreak-before less_space">&#13;
<dt>Euclidean</dt>&#13;
<dd>&#13;
<p><math alttext="StartRoot sigma-summation Underscript i equals 1 Overscript n Endscripts left-parenthesis p Subscript i Baseline minus q Subscript i Baseline right-parenthesis squared EndRoot">&#13;
  <msqrt>&#13;
    <mrow>&#13;
      <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi> </msubsup>&#13;
      <msup><mrow><mo>(</mo><msub><mi>p</mi> <mi>i</mi> </msub><mo>-</mo><msub><mi>q</mi> <mi>i</mi> </msub><mo>)</mo></mrow> <mn>2</mn> </msup>&#13;
    </mrow>&#13;
  </msqrt>&#13;
</math></p>&#13;
</dd>&#13;
</dl>&#13;
<dl>&#13;
<dt>Minkowski</dt>&#13;
<dd>&#13;
<p>&#13;
<math alttext="left-parenthesis sigma-summation Underscript i equals 1 Overscript n Endscripts StartAbsoluteValue p Subscript i Baseline minus q Subscript i Baseline EndAbsoluteValue Superscript p Baseline right-parenthesis Superscript 1 slash p">&#13;
    <mrow>&#13;
    <msup>&#13;
        <!-- first term -->&#13;
      <mrow>&#13;
        <mo>(</mo>&#13;
        <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi> </msubsup>&#13;
        <msup>&#13;
          <mrow>&#13;
              <mo>|</mo>&#13;
              <msub><mi>p</mi> <mi>i</mi> </msub>&#13;
              <mo>-</mo>&#13;
              <msub><mi>q</mi> <mi>i</mi> </msub>&#13;
              <mo>|</mo>&#13;
          </mrow>&#13;
            <mi>p</mi>&#13;
        </msup>&#13;
        <mo>)</mo>&#13;
        </mrow>&#13;
          <!-- second term -->&#13;
        <mrow><mn>1</mn><mo>/</mo><mi>p</mi></mrow>&#13;
    </msup>&#13;
    </mrow>&#13;
  </math>&#13;
</p>&#13;
</dd>&#13;
<dt>Manhattan</dt>&#13;
<dd>&#13;
<p><math alttext="StartRoot sigma-summation Underscript i equals 1 Overscript n Endscripts StartAbsoluteValue p Subscript i Baseline minus q Subscript i Baseline EndAbsoluteValue EndRoot">&#13;
  <msqrt>&#13;
    <mrow>&#13;
      <msubsup><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>n</mi> </msubsup>&#13;
      <mrow>&#13;
        <mo>|</mo>&#13;
        <msub><mi>p</mi> <mi>i</mi> </msub>&#13;
        <mo>-</mo>&#13;
        <msub><mi>q</mi> <mi>i</mi> </msub>&#13;
        <mo>|</mo>&#13;
      </mrow>&#13;
    </mrow>&#13;
  </msqrt>&#13;
</math></p>&#13;
</dd>&#13;
</dl>&#13;
&#13;
<p>The aim in clustering is to minimize the distance between the centroid and observations so that similar observations will be on the same cluster. This logic rests on the intuition that the more similar observations are, the smaller the distance between them. So we are seeking to minimize the distance between observations and the centroid, which is another way of saying that we are minimizing the sum of the squared error between the centroid and the observations:</p>&#13;
<div data-type="equation">&#13;
<math alttext="sigma-summation Underscript i equals 1 Overscript upper K Endscripts sigma-summation Underscript x element-of upper C Subscript i Endscripts left-parenthesis upper C Subscript i Baseline minus x right-parenthesis squared" display="block">&#13;
  <mrow>&#13;
    <munderover><mo>∑</mo> <mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow> <mi>K</mi> </munderover>&#13;
    <munder><mo>∑</mo> <mrow><mi>x</mi><mo>∈</mo><msub><mi>C</mi> <mi>i</mi> </msub></mrow> </munder>&#13;
    <msup><mrow><mo>(</mo><msub><mi>C</mi> <mi>i</mi> </msub><mo>-</mo><mi>x</mi><mo>)</mo></mrow> <mn>2</mn> </msup>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <em>x</em> is observation and <math alttext="upper C Subscript i">&#13;
  <msub><mi>C</mi> <mi>i</mi> </msub>&#13;
</math> is the centroid of <math alttext="i Superscript t h">&#13;
  <msup><mi>i</mi> <mrow><mi>t</mi><mi>h</mi></mrow> </msup>&#13;
</math> cluster. However, considering the number of observations and the combinations of clusters, the search area might be too big to handle. <a data-primary="E-M (expectation-maximization) algorithm" data-type="indexterm" id="idm45737230658240"/>It may sound intimidating, but don’t worry: we have the <em>expectation-maximization</em> <em>(E-M)</em> algorithm behind our clustering. As K-means does not have a closed-form solution, we are searching for an approximate one, and E-M provides this solution. In the E-M algorithm, <em>E</em> refers to assigning observations to the nearest centroid, and <em>M</em> denotes completion of the data generation process by updating the parameters.</p>&#13;
&#13;
<p>In the E-M algorithm, the distances between observations and the  centroid is iteratively minimized. The algorithm works as follows:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Pick <em>k</em> random points to be centroids.</p>&#13;
</li>&#13;
<li>&#13;
<p>Based on the distance metric chosen, calculate the distances between observations and <em>n</em> centroids.&#13;
Based on these distances, assign each observation to the closest cluster.</p>&#13;
</li>&#13;
<li>&#13;
<p>Update cluster centers based on the assignment.</p>&#13;
</li>&#13;
<li>&#13;
<p>Repeat the process from step 2 until the centroid does not change.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p><a data-primary="risk bucketing" data-secondary="elbow method" data-type="indexterm" id="idm45737230650112"/><a data-primary="K-means algorithm for clustering customers" data-secondary="elbow method" data-type="indexterm" id="idm45737230649136"/><a data-primary="elbow method, K-means clustering" data-type="indexterm" id="idm45737230648224"/><a data-primary="credit risk" data-secondary="risk bucketing" data-tertiary="elbow method" data-type="indexterm" id="idm45737230647488"/>Now, we apply risk bucketing using K-means clustering. To decide the optimal number of clusters, different techniques will be employed. First, we use the <em>elbow method</em>, which is based on the <em>inertia</em>.</p>&#13;
&#13;
<p><a data-primary="risk bucketing" data-secondary="inertia" data-type="indexterm" id="idm45737230644848"/><a data-primary="K-means algorithm for clustering customers" data-secondary="inertia" data-type="indexterm" id="idm45737230643712"/><a data-primary="inertia, K-means clustering" data-type="indexterm" id="idm45737230642800"/><a data-primary="credit risk" data-secondary="risk bucketing" data-tertiary="inertia" data-type="indexterm" id="idm45737230642112"/>Inertia is computed as the sum of the squared distances of observations to their closest centroid. <a data-primary="risk bucketing" data-secondary="Silhouette score method" data-type="indexterm" id="idm45737230640656"/><a data-primary="K-means algorithm for clustering customers" data-secondary="Silhouette score method" data-type="indexterm" id="idm45737230639712"/><a data-primary="credit risk" data-secondary="risk bucketing" data-tertiary="Silhouette score method" data-type="indexterm" id="idm45737230638800"/><a data-primary="Silhouette score method, K-means clustering" data-type="indexterm" id="idm45737230637584"/>Second, the <em>Silhouette score</em> is introduced as a tool to decide the optimal number of clusters. This takes a value between 1 and -1. A value of 1 indicates that an observation is close to the correct centroid and correctly classified.  However, -1 shows that an observation is not correctly clustered. The strength of the Silhouette score rests on taking into account both the intracluster distance and the intercluster distance. The formula for Silhouette score is as follows:</p>&#13;
<div data-type="equation">&#13;
<math alttext="Silhouette score equals StartFraction x minus y Over max left-parenthesis x comma y right-parenthesis EndFraction" display="block">&#13;
  <mrow>&#13;
    <mtext>Silhouette</mtext>&#13;
    <mspace width="4.pt"/>&#13;
    <mtext>score</mtext>&#13;
    <mo>=</mo>&#13;
    <mfrac><mrow><mi>x</mi><mo>-</mo><mi>y</mi></mrow> <mrow><mtext>max</mtext><mo>(</mo><mi>x</mi><mo>,</mo><mi>y</mi><mo>)</mo></mrow></mfrac>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <em>x</em> is the average intercluster distance between clusters, and <em>y</em> is the mean intracluster distance.</p>&#13;
&#13;
<p><a data-primary="CH (Calinski-Harabasz) method, K-means clustering" data-type="indexterm" id="idm45737230626944"/><a data-primary="K-means algorithm for clustering customers" data-secondary="CH method" data-type="indexterm" id="idm45737230626112"/><a data-primary="credit risk" data-secondary="risk bucketing" data-tertiary="variance ratio criterion" data-type="indexterm" id="idm45737230625200"/><a data-primary="K-means algorithm for clustering customers" data-secondary="variance ratio criterion" data-type="indexterm" id="idm45737230623968"/><a data-primary="risk bucketing" data-secondary="variance ratio criterion" data-type="indexterm" id="idm45737230623040"/><a data-primary="variance ratio criterion, K-means clustering" data-type="indexterm" id="idm45737230622080"/>The third method is <em>Calinski-Harabasz</em> <em>(CH)</em>, which is known as the <em>variance ratio criterion</em>. The formula for the CH method is as follows:</p>&#13;
<div data-type="equation">&#13;
<math alttext="CH equals StartFraction upper S upper S Subscript upper B Baseline Over upper S upper S Subscript upper W Baseline EndFraction times StartFraction upper N minus k Over k minus 1 EndFraction" display="block">&#13;
  <mrow>&#13;
    <mtext>CH</mtext>&#13;
    <mo>=</mo>&#13;
    <mfrac><mrow><mi>S</mi><msub><mi>S</mi> <mi>B</mi> </msub></mrow> <mrow><mi>S</mi><msub><mi>S</mi> <mi>W</mi> </msub></mrow></mfrac>&#13;
    <mo>×</mo>&#13;
    <mfrac><mrow><mi>N</mi><mo>-</mo><mi>k</mi></mrow> <mrow><mi>k</mi><mo>-</mo><mn>1</mn></mrow></mfrac>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <math alttext="upper S upper S Subscript upper B">&#13;
  <mrow>&#13;
    <mi>S</mi>&#13;
    <msub><mi>S</mi> <mi>B</mi> </msub>&#13;
  </mrow>&#13;
</math> denotes between-cluster variance, <math alttext="upper S upper S Subscript upper W">&#13;
  <mrow>&#13;
    <mi>S</mi>&#13;
    <msub><mi>S</mi> <mi>W</mi> </msub>&#13;
  </mrow>&#13;
</math> represents within cluster variance, <em>N</em> is number of observations, and <em>k</em> is the number of clusters. Given this information, we are seeking a high CH score, as the larger (lower) the between-cluster variance (within cluster variance), the better it is for finding the optimal number of clusters.</p>&#13;
&#13;
<p><a data-primary="risk bucketing" data-secondary="gap analysis" data-type="indexterm" id="ix_risk_bucket_gap"/><a data-primary="gap analysis, K-means clustering" data-type="indexterm" id="ix_gap_analysis_k-means"/><a data-primary="K-means algorithm for clustering customers" data-secondary="gap analysis" data-type="indexterm" id="ix_k-means-cluster_gap"/><a data-primary="credit risk" data-secondary="risk bucketing" data-tertiary="gap analysis" data-type="indexterm" id="ix_credit_risk_bucket_gap"/>The final approach is <em>gap analysis</em>. Tibshirani et al. (2001) came up with a unique idea by which we are able to find the optimal number of clusters based on reference distribution. Following the similar notations of Tibshirani et al., let <math alttext="d Subscript i i Sub Superscript e">&#13;
  <msub><mi>d</mi> <mrow><mi>i</mi><msup><mi>i</mi> <mi>e</mi> </msup></mrow> </msub>&#13;
</math> be a Euclidean distance between <math alttext="x Subscript i j">&#13;
  <msub><mi>x</mi> <mrow><mi>i</mi><mi>j</mi></mrow> </msub>&#13;
</math> and <math alttext="x Subscript i Sub Superscript e j">&#13;
  <msub><mi>x</mi> <msup><mi>i</mi> <mrow><mi>e</mi><mi>j</mi></mrow> </msup> </msub>&#13;
</math> and let <math alttext="upper C Subscript r">&#13;
  <msub><mi>C</mi> <mi>r</mi> </msub>&#13;
</math> be the <math alttext="i Subscript t h">&#13;
  <msub><mi>i</mi> <mrow><mi>t</mi><mi>h</mi></mrow> </msub>&#13;
</math> cluster denoting the number of observations in cluster <em>r</em>:</p>&#13;
<div data-type="equation">&#13;
<math alttext="sigma-summation Underscript j Endscripts left-parenthesis x Subscript i j Baseline minus x Subscript i Sub Superscript e j Subscript Baseline right-parenthesis squared" display="block">&#13;
  <mrow>&#13;
    <munder><mo>∑</mo> <mi>j</mi> </munder>&#13;
    <msup><mrow><mo>(</mo><msub><mi>x</mi> <mrow><mi>i</mi><mi>j</mi></mrow> </msub><mo>-</mo><msub><mi>x</mi> <msup><mi>i</mi> <mrow><mi>e</mi><mi>j</mi></mrow> </msup> </msub><mo>)</mo></mrow> <mn>2</mn> </msup>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>The sum of pairwise distances for all observations in cluster <em>r</em> is:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper D Subscript r Baseline equals sigma-summation Underscript i comma i Superscript e Baseline element-of upper C Subscript r Baseline Endscripts d Subscript i comma i Sub Superscript e" display="block">&#13;
  <mrow>&#13;
    <msub><mi>D</mi> <mi>r</mi> </msub>&#13;
    <mo>=</mo>&#13;
    <munder><mo>∑</mo> <mrow><mi>i</mi><mo>,</mo><msup><mi>i</mi> <mi>e</mi> </msup><mo>∈</mo><msub><mi>C</mi> <mi>r</mi> </msub></mrow> </munder>&#13;
    <msub><mi>d</mi> <mrow><mi>i</mi><mo>,</mo><msup><mi>i</mi> <mi>e</mi> </msup></mrow> </msub>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p class="pagebreak-before less_space">The within-cluster sum of squares, <math alttext="upper W Subscript k">&#13;
  <msub><mi>W</mi> <mi>k</mi> </msub>&#13;
</math>, is:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper W Subscript k Baseline equals sigma-summation Underscript r equals 1 Overscript k Endscripts StartFraction 1 Over 2 Subscript n Sub Subscript r Subscript Baseline EndFraction upper D Subscript r" display="block">&#13;
  <mrow>&#13;
    <msub><mi>W</mi> <mi>k</mi> </msub>&#13;
    <mo>=</mo>&#13;
    <munderover><mo>∑</mo> <mrow><mi>r</mi><mo>=</mo><mn>1</mn></mrow> <mi>k</mi> </munderover>&#13;
    <mfrac><mn>1</mn> <msub><mn>2</mn> <msub><mi>n</mi> <mi>r</mi> </msub> </msub></mfrac>&#13;
    <msub><mi>D</mi> <mi>r</mi> </msub>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <em>n</em> is the sample size and expectation of <math alttext="upper W Subscript k">&#13;
  <msub><mi>W</mi> <mi>k</mi> </msub>&#13;
</math> is:</p>&#13;
<div data-type="equation">&#13;
<math alttext="upper W Subscript k Baseline equals l o g left-parenthesis p n slash 12 right-parenthesis minus left-parenthesis 2 slash p right-parenthesis l o g left-parenthesis k right-parenthesis plus c o n s t a n t" display="block">&#13;
  <mrow>&#13;
    <msub><mi>W</mi> <mi>k</mi> </msub>&#13;
    <mo>=</mo>&#13;
    <mi>l</mi>&#13;
    <mi>o</mi>&#13;
    <mi>g</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>p</mi>&#13;
      <mi>n</mi>&#13;
      <mo>/</mo>&#13;
      <mn>12</mn>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>-</mo>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mn>2</mn>&#13;
      <mo>/</mo>&#13;
      <mi>p</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mi>l</mi>&#13;
    <mi>o</mi>&#13;
    <mi>g</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mi>k</mi>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>+</mo>&#13;
    <mi>c</mi>&#13;
    <mi>o</mi>&#13;
    <mi>n</mi>&#13;
    <mi>s</mi>&#13;
    <mi>t</mi>&#13;
    <mi>a</mi>&#13;
    <mi>n</mi>&#13;
    <mi>t</mi>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>where <em>p</em> and <em>k</em> are dimension and centroids, respectively. Let’s create a practice exercise using German credit risk data. The data is gathered from the <a href="https://oreil.ly/4NgIy">Kaggle platform</a>, and the explanations of the variables are shown here:</p>&#13;
&#13;
<ul>&#13;
<li>&#13;
<p>Age: Numerical</p>&#13;
</li>&#13;
<li>&#13;
<p>Sex: Male, female</p>&#13;
</li>&#13;
<li>&#13;
<p>Job: 0—unskilled and non-resident, 1—unskilled and resident, 2—skilled, &#13;
<span class="keep-together">3—highly skilled</span></p>&#13;
</li>&#13;
<li>&#13;
<p>Housing: Own, rent, free</p>&#13;
</li>&#13;
<li>&#13;
<p>Saving accounts: Little, moderate, quite rich, rich</p>&#13;
</li>&#13;
<li>&#13;
<p>Checking account: Numerical</p>&#13;
</li>&#13;
<li>&#13;
<p>Credit amount: Numerical</p>&#13;
</li>&#13;
<li>&#13;
<p>Duration: Numerical</p>&#13;
</li>&#13;
<li>&#13;
<p>Purpose: Car, furniture/equipment, radio/TV, domestic appliances, repairs, education, business, vacation/others</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>The estimate of the optimal clusters will be the value that maximizes the gap statistic, as the gap statistic is the difference between the total within-intracluster variation for different values of <em>k</em> and their expected values under null reference distribution of the respective data. The decision is made when we get the highest gap value.<a data-primary="" data-startref="ix_credit_risk_bucket_gap" data-type="indexterm" id="idm45737227362544"/><a data-primary="" data-startref="ix_gap_analysis_k-means" data-type="indexterm" id="idm45737227361552"/><a data-primary="" data-startref="ix_k-means-cluster_gap" data-type="indexterm" id="idm45737227360608"/><a data-primary="" data-startref="ix_risk_bucket_gap" data-type="indexterm" id="idm45737227359664"/></p>&#13;
&#13;
<p>In the following code block, we import the German credit dataset and drop the unnecessary columns. The dataset includes both categorical and numerical values, which need to be treated differently, and we will do this soon:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">import</code><code> </code><code class="nn">pandas</code><code> </code><code class="kn">as</code><code> </code><code class="nn">pd</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">2</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">credit</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="s1">'</code><code class="s1">credit_data_risk.csv</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">3</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">credit</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code class="n">Out</code><code class="p">[</code><code class="mi">3</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">Unnamed</code><code class="p">:</code><code> </code><code class="mi">0</code><code>  </code><code class="n">Age</code><code>     </code><code class="n">Sex</code><code>  </code><code class="n">Job</code><code> </code><code class="n">Housing</code><code> </code><code class="n">Saving</code><code> </code><code class="n">accounts</code><code> </code><code class="n">Checking</code><code> </code><code class="n">account</code><code>  </code><code>\&#13;
</code><code>        </code><code class="mi">0</code><code>           </code><code class="mi">0</code><code>   </code><code class="mi">67</code><code>    </code><code class="n">male</code><code>    </code><code class="mi">2</code><code>     </code><code class="n">own</code><code>             </code><code class="n">NaN</code><code>           </code><code class="n">little</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="mi">1</code><code>           </code><code class="mi">1</code><code>   </code><code class="mi">22</code><code>  </code><code class="n">female</code><code>    </code><code class="mi">2</code><code>     </code><code class="n">own</code><code>          </code><code class="n">little</code><code>         </code><code class="n">moderate</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="mi">2</code><code>           </code><code class="mi">2</code><code>   </code><code class="mi">49</code><code>    </code><code class="n">male</code><code>    </code><code class="mi">1</code><code>     </code><code class="n">own</code><code>          </code><code class="n">little</code><code>              </code><code class="n">NaN</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="mi">3</code><code>           </code><code class="mi">3</code><code>   </code><code class="mi">45</code><code>    </code><code class="n">male</code><code>    </code><code class="mi">2</code><code>    </code><code class="n">free</code><code>          </code><code class="n">little</code><code>           </code><code class="n">little</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="mi">4</code><code>           </code><code class="mi">4</code><code>   </code><code class="mi">53</code><code>    </code><code class="n">male</code><code>    </code><code class="mi">2</code><code>    </code><code class="n">free</code><code>          </code><code class="n">little</code><code>           </code><code class="n">little</code><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><code>           </code><code class="n">Credit</code><code> </code><code class="n">amount</code><code>  </code><code class="n">Duration</code><code>              </code><code class="n">Purpose</code><code>  </code><code class="n">Risk</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="mi">0</code><code>           </code><code class="mi">1169</code><code>         </code><code class="mi">6</code><code>             </code><code class="n">radio</code><code class="o">/</code><code class="n">TV</code><code>  </code><code class="n">good</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="mi">1</code><code>           </code><code class="mi">5951</code><code>        </code><code class="mi">48</code><code>             </code><code class="n">radio</code><code class="o">/</code><code class="n">TV</code><code>   </code><code class="n">bad</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="mi">2</code><code>           </code><code class="mi">2096</code><code>        </code><code class="mi">12</code><code>            </code><code class="n">education</code><code>  </code><code class="n">good</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="mi">3</code><code>           </code><code class="mi">7882</code><code>        </code><code class="mi">42</code><code>  </code><code class="n">furniture</code><code class="o">/</code><code class="n">equipment</code><code>  </code><code class="n">good</code><code>&#13;
</code><code>&#13;
</code><code>        </code><code class="mi">4</code><code>           </code><code class="mi">4870</code><code>        </code><code class="mi">24</code><code>                  </code><code class="n">car</code><code>   </code><code class="n">bad</code><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">4</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">del</code><code> </code><code class="n">credit</code><code class="p">[</code><code class="s1">'</code><code class="s1">Unnamed: 0</code><code class="s1">'</code><code class="p">]</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO1-1" id="co_credit_risk_estimation_CO1-1"><img alt="1" src="assets/1.png"/></a></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO1-1" id="callout_credit_risk_estimation_CO1-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Dropping unnecessary column named <code>Unnamed: 0</code></p></dd>&#13;
</dl>&#13;
&#13;
<p>The summary statistics are given in the following code. Accordingly, the average age of the customers is roughly 35, average job type is skilled, average credit amount and duration are nearly 3,271 and 21, respectively. Additionally, the summary statistics tell us that the <code>credit amount</code> variable shows a relatively high standard deviation as expected. The <code>duration</code> and <code>age</code> variables have a very similar standard deviation, but the duration moves within a narrower interval as its minimum and maximum values are 4 and 72, respectively. As <code>job</code> is a discrete variable, it is natural to expect low dispersion and we have it:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">5</code><code class="p">]:</code> <code class="n">credit</code><code class="o">.</code><code class="n">describe</code><code class="p">()</code>&#13;
<code class="n">Out</code><code class="p">[</code><code class="mi">5</code><code class="p">]:</code>                <code class="n">Age</code>          <code class="n">Job</code>  <code class="n">Credit</code> <code class="n">amount</code>     <code class="n">Duration</code>&#13;
        <code class="n">count</code>  <code class="mf">1000.000000</code>  <code class="mf">1000.000000</code>    <code class="mf">1000.000000</code>  <code class="mf">1000.000000</code>&#13;
        <code class="n">mean</code>     <code class="mf">35.546000</code>     <code class="mf">1.904000</code>    <code class="mf">3271.258000</code>    <code class="mf">20.903000</code>&#13;
        <code class="n">std</code>      <code class="mf">11.375469</code>     <code class="mf">0.653614</code>    <code class="mf">2822.736876</code>    <code class="mf">12.058814</code>&#13;
        <code class="nb">min</code>      <code class="mf">19.000000</code>     <code class="mf">0.000000</code>     <code class="mf">250.000000</code>     <code class="mf">4.000000</code>&#13;
        <code class="mi">25</code><code class="o">%</code>      <code class="mf">27.000000</code>     <code class="mf">2.000000</code>    <code class="mf">1365.500000</code>    <code class="mf">12.000000</code>&#13;
        <code class="mi">50</code><code class="o">%</code>      <code class="mf">33.000000</code>     <code class="mf">2.000000</code>    <code class="mf">2319.500000</code>    <code class="mf">18.000000</code>&#13;
        <code class="mi">75</code><code class="o">%</code>      <code class="mf">42.000000</code>     <code class="mf">2.000000</code>    <code class="mf">3972.250000</code>    <code class="mf">24.000000</code>&#13;
        <code class="nb">max</code>      <code class="mf">75.000000</code>     <code class="mf">3.000000</code>   <code class="mf">18424.000000</code>    <code class="mf">72.000000</code></pre>&#13;
&#13;
<p>In what follows, the distribution of the numerical variables in the dataset are examined via histogram and it turns out none of the variables follow a normal distribution. The <code>age</code>, <code>credit amount</code>, and <code>duration</code> variables are positively skewed as we can see in <a data-type="xref" href="#credit_risk_hist">Figure 6-1</a>, generated by the following:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">6</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">import</code><code> </code><code class="nn">matplotlib.pyplot</code><code> </code><code class="kn">as</code><code> </code><code class="nn">plt</code><code>&#13;
</code><code>        </code><code class="kn">import</code><code> </code><code class="nn">seaborn</code><code> </code><code class="kn">as</code><code> </code><code class="nn">sns</code><code class="p">;</code><code> </code><code class="n">sns</code><code class="o">.</code><code class="n">set</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>        </code><code class="n">plt</code><code class="o">.</code><code class="n">rcParams</code><code class="p">[</code><code class="s2">"</code><code class="s2">figure.figsize</code><code class="s2">"</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code class="mi">6</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO2-1" id="co_credit_risk_estimation_CO2-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">7</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">numerical_credit</code><code> </code><code class="o">=</code><code> </code><code class="n">credit</code><code class="o">.</code><code class="n">select_dtypes</code><code class="p">(</code><code class="n">exclude</code><code class="o">=</code><code class="s1">'</code><code class="s1">O</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO2-2" id="co_credit_risk_estimation_CO2-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">8</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code> </code><code class="mi">8</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>        </code><code class="n">k</code><code> </code><code class="o">=</code><code> </code><code class="mi">0</code><code>&#13;
</code><code>        </code><code class="n">cols</code><code> </code><code class="o">=</code><code> </code><code class="n">numerical_credit</code><code class="o">.</code><code class="n">columns</code><code>&#13;
</code><code>        </code><code class="k">for</code><code> </code><code class="n">i</code><code class="p">,</code><code> </code><code class="n">j</code><code> </code><code class="ow">in</code><code> </code><code class="nb">zip</code><code class="p">(</code><code class="nb">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">cols</code><code class="p">)</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">cols</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>            </code><code class="n">k</code><code> </code><code class="o">+</code><code class="o">=</code><code class="mi">1</code><code>&#13;
</code><code>            </code><code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code><code> </code><code class="mi">2</code><code class="p">,</code><code> </code><code class="n">k</code><code class="p">)</code><code>&#13;
</code><code>            </code><code class="n">plt</code><code class="o">.</code><code class="n">hist</code><code class="p">(</code><code class="n">numerical_credit</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="p">:</code><code class="p">,</code><code> </code><code class="n">i</code><code class="p">]</code><code class="p">)</code><code>&#13;
</code><code>            </code><code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="n">j</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO2-1" id="callout_credit_risk_estimation_CO2-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Setting a fix figure size</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO2-2" id="callout_credit_risk_estimation_CO2-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Dropping the object type variables to obtain all numerical variables</p></dd>&#13;
</dl>&#13;
&#13;
<figure><div class="figure" id="credit_risk_hist">&#13;
<img alt="credit_risk" src="assets/mlfr_0601.png"/>&#13;
<h6><span class="label">Figure 6-1. </span>Credit risk data histogram</h6>&#13;
</div></figure>&#13;
&#13;
<p><a data-type="xref" href="#credit_risk_hist">Figure 6-1</a> shows the distribution of age, job, credit amount, and duration variables. Aside from the <code>job</code> variable, which is a discrete variable, all other variables have skewed distributions.</p>&#13;
&#13;
<p><a data-primary="risk bucketing" data-secondary="elbow method" data-type="indexterm" id="ix_risk_budcket_elbow"/><a data-primary="elbow method, K-means clustering" data-type="indexterm" id="ix_elbow_k-means_clustering"/><a data-primary="K-means algorithm for clustering customers" data-secondary="elbow method" data-type="indexterm" id="ix_k-means-cluster_elbow"/><a data-primary="credit risk" data-secondary="risk bucketing" data-tertiary="elbow method" data-type="indexterm" id="ix_credit_risk_bucket_elbow"/>The elbow method, as a first method, is introduced in the following code snippet and the resulting <a data-type="xref" href="#elbow_kmeans">Figure 6-2</a>. To find the optimal number of clusters, we observe the slope of the curve and decide the cut-off point at which the curve gets flatter—that is, the slope of the curve gets lower. <a data-primary="credit risk" data-secondary="risk bucketing" data-tertiary="inertia" data-type="indexterm" id="idm45737227275424"/><a data-primary="inertia, K-means clustering" data-type="indexterm" id="idm45737227274208"/><a data-primary="K-means algorithm for clustering customers" data-secondary="inertia" data-type="indexterm" id="idm45737227273568"/><a data-primary="risk bucketing" data-secondary="inertia" data-type="indexterm" id="idm45737227272656"/>As it gets flatter, the inertia, telling us how far away the points within a cluster are located, decreases, which is nice for the purpose of clustering. On the other hand, as we allow inertia to decrease, the number of clusters increases, which makes the analysis more complicated. Given that trade-off, the stopping criteria is the point where the curve gets flatter. In code:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">9</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">sklearn.preprocessing</code><code> </code><code class="kn">import</code><code> </code><code class="n">StandardScaler</code><code>&#13;
</code><code>        </code><code class="kn">from</code><code> </code><code class="nn">sklearn.cluster</code><code> </code><code class="kn">import</code><code> </code><code class="n">KMeans</code><code>&#13;
</code><code>        </code><code class="kn">import</code><code> </code><code class="nn">numpy</code><code> </code><code class="kn">as</code><code> </code><code class="nn">np</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">10</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">scaler</code><code> </code><code class="o">=</code><code> </code><code class="n">StandardScaler</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">scaled_credit</code><code> </code><code class="o">=</code><code> </code><code class="n">scaler</code><code class="o">.</code><code class="n">fit_transform</code><code class="p">(</code><code class="n">numerical_credit</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO3-1" id="co_credit_risk_estimation_CO3-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">11</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">distance</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="p">]</code><code>&#13;
</code><code>         </code><code class="k">for</code><code> </code><code class="n">k</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">10</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">kmeans</code><code> </code><code class="o">=</code><code> </code><code class="n">KMeans</code><code class="p">(</code><code class="n">n_clusters</code><code class="o">=</code><code class="n">k</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO3-2" id="co_credit_risk_estimation_CO3-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>             </code><code class="n">kmeans</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">scaled_credit</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">distance</code><code class="o">.</code><code class="n">append</code><code class="p">(</code><code class="n">kmeans</code><code class="o">.</code><code class="n">inertia_</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO3-3" id="co_credit_risk_estimation_CO3-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">12</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="nb">range</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">10</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">distance</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">bx-</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">xlabel</code><code class="p">(</code><code class="s1">'</code><code class="s1">k</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">ylabel</code><code class="p">(</code><code class="s1">'</code><code class="s1">Inertia</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'</code><code class="s1">The Elbow Method</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO3-1" id="callout_credit_risk_estimation_CO3-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Applying standardization for scaling purpose</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO3-2" id="callout_credit_risk_estimation_CO3-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Running K-means algorithm</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO3-3" id="callout_credit_risk_estimation_CO3-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Calculating <code>inertia</code> and storing into a list named <code>distance</code></p></dd>&#13;
</dl>&#13;
&#13;
<p><a data-type="xref" href="#elbow_kmeans">Figure 6-2</a> shows that the curve gets flatter after four clusters. Thus, the elbow method suggests that we stop at four clusters.</p>&#13;
&#13;
<figure><div class="figure" id="elbow_kmeans">&#13;
<img alt="elbow" src="assets/mlfr_0602.png"/>&#13;
<h6><span class="label">Figure 6-2. </span>Elbow method</h6>&#13;
</div></figure>&#13;
&#13;
<p>The following code, <a data-primary="credit risk" data-secondary="risk bucketing" data-tertiary="Silhouette score method" data-type="indexterm" id="idm45737224644480"/><a data-primary="K-means algorithm for clustering customers" data-secondary="Silhouette score method" data-type="indexterm" id="idm45737224583488"/><a data-primary="risk bucketing" data-secondary="Silhouette score method" data-type="indexterm" id="idm45737224582640"/><a data-primary="Silhouette score method, K-means clustering" data-type="indexterm" id="idm45737224581792"/>resulting in <a data-type="xref" href="#silhouette_kmeans">Figure 6-3</a>, presents Silhouette scores on the x-axis for clusters 2 to 10. Given the average Silhouette score represented by the dashed line, the optimal number of clusters can be two:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">13</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">sklearn.metrics</code><code> </code><code class="kn">import</code><code> </code><code class="n">silhouette_score</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO4-1" id="co_credit_risk_estimation_CO4-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">yellowbrick.cluster</code><code> </code><code class="kn">import</code><code> </code><code class="n">SilhouetteVisualizer</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO4-2" id="co_credit_risk_estimation_CO4-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">14</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">fig</code><code class="p">,</code><code> </code><code class="n">ax</code><code> </code><code class="o">=</code><code> </code><code class="n">plt</code><code class="o">.</code><code class="n">subplots</code><code class="p">(</code><code class="mi">4</code><code class="p">,</code><code> </code><code class="mi">2</code><code class="p">,</code><code> </code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">25</code><code class="p">,</code><code> </code><code class="mi">20</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="k">for</code><code> </code><code class="n">i</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code><code> </code><code class="mi">10</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">km</code><code> </code><code class="o">=</code><code> </code><code class="n">KMeans</code><code class="p">(</code><code class="n">n_clusters</code><code class="o">=</code><code class="n">i</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">q</code><code class="p">,</code><code> </code><code class="n">r</code><code> </code><code class="o">=</code><code> </code><code class="nb">divmod</code><code class="p">(</code><code class="n">i</code><code class="p">,</code><code> </code><code class="mi">2</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO4-3" id="co_credit_risk_estimation_CO4-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>             </code><code class="n">visualizer</code><code> </code><code class="o">=</code><code> </code><code class="n">SilhouetteVisualizer</code><code class="p">(</code><code class="n">km</code><code class="p">,</code><code> </code><code class="n">colors</code><code class="o">=</code><code class="s1">'</code><code class="s1">yellowbrick</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                                               </code><code class="n">ax</code><code class="o">=</code><code class="n">ax</code><code class="p">[</code><code class="n">q</code><code> </code><code class="o">-</code><code> </code><code class="mi">1</code><code class="p">]</code><code class="p">[</code><code class="n">r</code><code class="p">]</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO4-4" id="co_credit_risk_estimation_CO4-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code>             </code><code class="n">visualizer</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">scaled_credit</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">ax</code><code class="p">[</code><code class="n">q</code><code> </code><code class="o">-</code><code> </code><code class="mi">1</code><code class="p">]</code><code class="p">[</code><code class="n">r</code><code class="p">]</code><code class="o">.</code><code class="n">set_title</code><code class="p">(</code><code class="s2">"</code><code class="s2">For Cluster_</code><code class="s2">"</code><code class="o">+</code><code class="nb">str</code><code class="p">(</code><code class="n">i</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">ax</code><code class="p">[</code><code class="n">q</code><code> </code><code class="o">-</code><code> </code><code class="mi">1</code><code class="p">]</code><code class="p">[</code><code class="n">r</code><code class="p">]</code><code class="o">.</code><code class="n">set_xlabel</code><code class="p">(</code><code class="s2">"</code><code class="s2">Silhouette Score</code><code class="s2">"</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO4-1" id="callout_credit_risk_estimation_CO4-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Importing the <code>silhouette_score</code> module to calculate Silhouette score</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO4-2" id="callout_credit_risk_estimation_CO4-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Importing the <code>SilhouetteVisualizer</code> module to draw Silhouette plots</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO4-3" id="callout_credit_risk_estimation_CO4-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Using <code>divmod</code> for configuring labels, as it returns the quotient (<code>q</code>) and remainder (<code>r</code>)</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO4-4" id="callout_credit_risk_estimation_CO4-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Plotting the Silhouette scores</p></dd>&#13;
</dl>&#13;
&#13;
<figure><div class="figure" id="silhouette_kmeans">&#13;
<img alt="silhouette" src="assets/mlfr_0603.png"/>&#13;
<h6><span class="label">Figure 6-3. </span>Silhouette score</h6>&#13;
</div></figure>&#13;
&#13;
<p><a data-primary="CH (Calinski-Harabasz) method, K-means clustering" data-type="indexterm" id="ix_ch_k-means_cluster"/><a data-primary="K-means algorithm for clustering customers" data-secondary="CH method" data-type="indexterm" id="ix_k-means-cluster_ch"/>As mentioned, the CH method is a convenient tool for finding optimal clustering, and the following code shows how we can use this method in Python, resulting in <a data-type="xref" href="#CH_analysis">Figure 6-4</a>. We are looking for the highest CH score, and we’ll see that it is obtained at cluster 2:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">15</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">yellowbrick.cluster</code><code> </code><code class="kn">import</code><code> </code><code class="n">KElbowVisualizer</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO5-1" id="co_credit_risk_estimation_CO5-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">KMeans</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">visualizer</code><code> </code><code class="o">=</code><code> </code><code class="n">KElbowVisualizer</code><code class="p">(</code><code class="n">model</code><code class="p">,</code><code> </code><code class="n">k</code><code class="o">=</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code><code> </code><code class="mi">10</code><code class="p">)</code><code class="p">,</code><code>&#13;
</code><code>                                       </code><code class="n">metric</code><code class="o">=</code><code class="s1">'</code><code class="s1">calinski_harabasz</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                                       </code><code class="n">timings</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO5-2" id="co_credit_risk_estimation_CO5-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>         </code><code class="n">visualizer</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">scaled_credit</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">visualizer</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code class="n">Out</code><code class="p">[</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">Figure</code><code> </code><code class="n">size</code><code> </code><code class="mi">576</code><code class="n">x396</code><code> </code><code class="k">with</code><code> </code><code class="mi">0</code><code> </code><code class="n">Axes</code><code class="o">&gt;</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO5-1" id="callout_credit_risk_estimation_CO5-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Importing <code>KElbowVisualizer</code> to draw the CH score</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO5-2" id="callout_credit_risk_estimation_CO5-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Visualizing the CH metric</p></dd>&#13;
</dl>&#13;
&#13;
<figure><div class="figure" id="CH_analysis">&#13;
<img alt="CH_analysis" src="assets/mlfr_0604.png"/>&#13;
<h6><span class="label">Figure 6-4. </span>The CH method</h6>&#13;
</div></figure>&#13;
&#13;
<p><a data-type="xref" href="#CH_analysis">Figure 6-4</a> shows that the elbow occurs at the second cluster, indicating that stopping at two clusters is the optimum decision.<a data-primary="" data-startref="ix_k-means-cluster_ch" data-type="indexterm" id="idm45737224285904"/><a data-primary="" data-startref="ix_ch_k-means_cluster" data-type="indexterm" id="idm45737224284960"/></p>&#13;
&#13;
<p><a data-primary="risk bucketing" data-secondary="gap analysis" data-type="indexterm" id="ix_risk_bucket_gap2"/><a data-primary="gap analysis, K-means clustering" data-type="indexterm" id="ix_gap_analysis2_k-means"/><a data-primary="K-means algorithm for clustering customers" data-secondary="gap analysis" data-type="indexterm" id="ix_k-means_gap2"/><a data-primary="credit risk" data-secondary="risk bucketing" data-tertiary="gap analysis" data-type="indexterm" id="ix_credit_risk_bucket_gap2"/>The last step for finding the optimal number of clusters is gap analysis, resulting in <a data-type="xref" href="#gap_cluster">Figure 6-5</a>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">16</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">gap_statistic.optimalK</code><code> </code><code class="kn">import</code><code> </code><code class="n">OptimalK</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO6-1" id="co_credit_risk_estimation_CO6-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">17</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">optimalK</code><code> </code><code class="o">=</code><code> </code><code class="n">OptimalK</code><code class="p">(</code><code class="n">n_jobs</code><code class="o">=</code><code class="mi">8</code><code class="p">,</code><code> </code><code class="n">parallel_backend</code><code class="o">=</code><code class="s1">'</code><code class="s1">joblib</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO6-2" id="co_credit_risk_estimation_CO6-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>         </code><code class="n">n_clusters</code><code> </code><code class="o">=</code><code> </code><code class="n">optimalK</code><code class="p">(</code><code class="n">scaled_credit</code><code class="p">,</code><code> </code><code class="n">cluster_array</code><code class="o">=</code><code class="n">np</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">10</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO6-3" id="co_credit_risk_estimation_CO6-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">18</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">gap_result</code><code> </code><code class="o">=</code><code> </code><code class="n">optimalK</code><code class="o">.</code><code class="n">gap_df</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO6-4" id="co_credit_risk_estimation_CO6-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code>         </code><code class="n">gap_result</code><code class="o">.</code><code class="n">head</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code class="n">Out</code><code class="p">[</code><code class="mi">18</code><code class="p">]</code><code class="p">:</code><code>    </code><code class="n">n_clusters</code><code>  </code><code class="n">gap_value</code><code>         </code><code class="n">gap</code><code class="o">*</code><code>  </code><code class="n">ref_dispersion_std</code><code>        </code><code class="n">sk</code><code>  </code><code>\&#13;
</code><code>         </code><code class="mi">0</code><code>         </code><code class="mf">1.0</code><code>   </code><code class="mf">0.889755</code><code>  </code><code class="mf">5738.286952</code><code>           </code><code class="mf">54.033596</code><code>  </code><code class="mf">0.006408</code><code>&#13;
</code><code>         </code><code class="mi">1</code><code>         </code><code class="mf">2.0</code><code>   </code><code class="mf">0.968585</code><code>  </code><code class="mf">4599.736451</code><code>          </code><code class="mf">366.047394</code><code>  </code><code class="mf">0.056195</code><code>&#13;
</code><code>         </code><code class="mi">2</code><code>         </code><code class="mf">3.0</code><code>   </code><code class="mf">1.003974</code><code>  </code><code class="mf">3851.032471</code><code>           </code><code class="mf">65.026259</code><code>  </code><code class="mf">0.012381</code><code>&#13;
</code><code>         </code><code class="mi">3</code><code>         </code><code class="mf">4.0</code><code>   </code><code class="mf">1.044347</code><code>  </code><code class="mf">3555.819296</code><code>          </code><code class="mf">147.396138</code><code>  </code><code class="mf">0.031187</code><code>&#13;
</code><code>         </code><code class="mi">4</code><code>         </code><code class="mf">5.0</code><code>   </code><code class="mf">1.116450</code><code>  </code><code class="mf">3305.617917</code><code>           </code><code class="mf">27.894622</code><code>  </code><code class="mf">0.006559</code><code>&#13;
</code><code>&#13;
</code><code>                    </code><code class="n">sk</code><code class="o">*</code><code>      </code><code class="n">diff</code><code>        </code><code class="n">diff</code><code class="o">*</code><code>&#13;
</code><code>         </code><code class="mi">0</code><code>  </code><code class="mf">6626.296782</code><code> </code><code class="o">-</code><code class="mf">0.022635</code><code>  </code><code class="mf">6466.660374</code><code>&#13;
</code><code>         </code><code class="mi">1</code><code>  </code><code class="mf">5328.109873</code><code> </code><code class="o">-</code><code class="mf">0.023008</code><code>  </code><code class="mf">5196.127130</code><code>&#13;
</code><code>         </code><code class="mi">2</code><code>  </code><code class="mf">4447.423150</code><code> </code><code class="o">-</code><code class="mf">0.009186</code><code>  </code><code class="mf">4404.645656</code><code>&#13;
</code><code>         </code><code class="mi">3</code><code>  </code><code class="mf">4109.432481</code><code> </code><code class="o">-</code><code class="mf">0.065543</code><code>  </code><code class="mf">4067.336067</code><code>&#13;
</code><code>         </code><code class="mi">4</code><code>  </code><code class="mf">3817.134689</code><code>  </code><code class="mf">0.141622</code><code>  </code><code class="mf">3729.880829</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">19</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">gap_result</code><code class="o">.</code><code class="n">n_clusters</code><code class="p">,</code><code> </code><code class="n">gap_result</code><code class="o">.</code><code class="n">gap_value</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">min_ylim</code><code class="p">,</code><code> </code><code class="n">max_ylim</code><code> </code><code class="o">=</code><code> </code><code class="n">plt</code><code class="o">.</code><code class="n">ylim</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">axhline</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">max</code><code class="p">(</code><code class="n">gap_result</code><code class="o">.</code><code class="n">gap_value</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">color</code><code class="o">=</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                     </code><code class="n">linestyle</code><code class="o">=</code><code class="s1">'</code><code class="s1">dashed</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">linewidth</code><code class="o">=</code><code class="mi">2</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'</code><code class="s1">Gap Analysis</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">xlabel</code><code class="p">(</code><code class="s1">'</code><code class="s1">Number of Cluster</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">ylabel</code><code class="p">(</code><code class="s1">'</code><code class="s1">Gap Value</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO6-1" id="callout_credit_risk_estimation_CO6-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Importing the <code>OptimalK</code> module for calculating the gap statistic</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO6-2" id="callout_credit_risk_estimation_CO6-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Running gap statistic using parallelization</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO6-3" id="callout_credit_risk_estimation_CO6-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Identifying the number of clusters based on the gap statistic</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO6-4" id="callout_credit_risk_estimation_CO6-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Storing the result of gap analysis</p></dd>&#13;
</dl>&#13;
&#13;
<figure><div class="figure" id="gap_cluster">&#13;
<img alt="gap_cluster" src="assets/mlfr_0605.png"/>&#13;
<h6><span class="label">Figure 6-5. </span>Gap analysis</h6>&#13;
</div></figure>&#13;
&#13;
<p>What we observe in <a data-type="xref" href="#gap_cluster">Figure 6-5</a> is a sharp increase to the point at which the gap value reaches its peak, and the analysis suggests stopping at the maximum value at which we find the optimal number for clustering. In this case, we find the value at cluster 5, so this is the cut-off point.<a data-primary="" data-startref="ix_credit_risk_bucket_gap2" data-type="indexterm" id="idm45737223909536"/><a data-primary="" data-startref="ix_gap_analysis2_k-means" data-type="indexterm" id="idm45737223908624"/><a data-primary="" data-startref="ix_k-means_gap2" data-type="indexterm" id="idm45737223907712"/><a data-primary="" data-startref="ix_risk_bucket_gap2" data-type="indexterm" id="idm45737223906768"/></p>&#13;
&#13;
<p>In light of these discussions, two clusters are chosen to be the optimal number of clusters, and the K-means clustering analysis is conducted accordingly. To illustrate, given the clustering analysis, let us visualize 2-D clusters with the following, resulting in <a data-type="xref" href="#all_clusters">Figure 6-6</a>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">20</code><code class="p">]:</code> <code class="n">kmeans</code> <code class="o">=</code> <code class="n">KMeans</code><code class="p">(</code><code class="n">n_clusters</code><code class="o">=</code><code class="mi">2</code><code class="p">)</code>&#13;
         <code class="n">clusters</code> <code class="o">=</code> <code class="n">kmeans</code><code class="o">.</code><code class="n">fit_predict</code><code class="p">(</code><code class="n">scaled_credit</code><code class="p">)</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">21</code><code class="p">]:</code> <code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">12</code><code class="p">))</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="mi">311</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">scatter</code><code class="p">(</code><code class="n">scaled_credit</code><code class="p">[:,</code> <code class="mi">0</code><code class="p">],</code> <code class="n">scaled_credit</code><code class="p">[:,</code> <code class="mi">2</code><code class="p">],</code>&#13;
                     <code class="n">c</code><code class="o">=</code><code class="n">kmeans</code><code class="o">.</code><code class="n">labels_</code><code class="p">,</code> <code class="n">cmap</code><code class="o">=</code><code class="s1">'viridis'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">scatter</code><code class="p">(</code><code class="n">kmeans</code><code class="o">.</code><code class="n">cluster_centers_</code><code class="p">[:,</code> <code class="mi">0</code><code class="p">],</code>&#13;
                     <code class="n">kmeans</code><code class="o">.</code><code class="n">cluster_centers_</code><code class="p">[:,</code> <code class="mi">2</code><code class="p">],</code> <code class="n">s</code> <code class="o">=</code> <code class="mi">80</code><code class="p">,</code>&#13;
                     <code class="n">marker</code><code class="o">=</code> <code class="s1">'x'</code><code class="p">,</code> <code class="n">color</code> <code class="o">=</code> <code class="s1">'k'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'Age vs Credit'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="mi">312</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">scatter</code><code class="p">(</code><code class="n">scaled_credit</code><code class="p">[:,</code> <code class="mi">0</code><code class="p">],</code> <code class="n">scaled_credit</code><code class="p">[:,</code> <code class="mi">2</code><code class="p">],</code>&#13;
                     <code class="n">c</code><code class="o">=</code><code class="n">kmeans</code><code class="o">.</code><code class="n">labels_</code><code class="p">,</code> <code class="n">cmap</code><code class="o">=</code><code class="s1">'viridis'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">scatter</code><code class="p">(</code><code class="n">kmeans</code><code class="o">.</code><code class="n">cluster_centers_</code><code class="p">[:,</code> <code class="mi">0</code><code class="p">],</code>&#13;
                     <code class="n">kmeans</code><code class="o">.</code><code class="n">cluster_centers_</code><code class="p">[:,</code> <code class="mi">2</code><code class="p">],</code> <code class="n">s</code> <code class="o">=</code> <code class="mi">80</code><code class="p">,</code>&#13;
                     <code class="n">marker</code><code class="o">=</code> <code class="s1">'x'</code><code class="p">,</code> <code class="n">color</code> <code class="o">=</code> <code class="s1">'k'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'Credit vs Duration'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">subplot</code><code class="p">(</code><code class="mi">313</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">scatter</code><code class="p">(</code><code class="n">scaled_credit</code><code class="p">[:,</code> <code class="mi">2</code><code class="p">],</code> <code class="n">scaled_credit</code><code class="p">[:,</code> <code class="mi">3</code><code class="p">],</code>&#13;
                     <code class="n">c</code><code class="o">=</code><code class="n">kmeans</code><code class="o">.</code><code class="n">labels_</code><code class="p">,</code> <code class="n">cmap</code><code class="o">=</code><code class="s1">'viridis'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">scatter</code><code class="p">(</code><code class="n">kmeans</code><code class="o">.</code><code class="n">cluster_centers_</code><code class="p">[:,</code> <code class="mi">2</code><code class="p">],</code>&#13;
                     <code class="n">kmeans</code><code class="o">.</code><code class="n">cluster_centers_</code><code class="p">[:,</code> <code class="mi">3</code><code class="p">],</code> <code class="n">s</code> <code class="o">=</code> <code class="mi">120</code><code class="p">,</code>&#13;
                     <code class="n">marker</code><code class="o">=</code> <code class="s1">'x'</code><code class="p">,</code> <code class="n">color</code> <code class="o">=</code> <code class="s1">'k'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'Age vs Duration'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>&#13;
&#13;
<p><a data-type="xref" href="#all_clusters">Figure 6-6</a> presents the behavior of the observations and cross sign <code>x</code> indicates the cluster center, i.e., the centroid. Age represents the more dispersed data, and the centroid of the <code>age</code> variable is located above the <code>credit</code> variable. Two continuous variables, namely <code>credit</code> and <code>duration</code>, are shown in the second subplot of <a data-type="xref" href="#all_clusters">Figure 6-6</a>, where we observe clearly separated clusters. This figure suggests that the duration variable is more volatile compared to the credit variable. In the last subplot, the relationship between <code>age</code> and <code>duration</code> is examined via scatter analysis. It turns out that there are many overlapping observations across these two variables.<a data-primary="" data-startref="ix_cluster_credit_risk" data-type="indexterm" id="idm45737223582256"/><a data-primary="" data-startref="ix_credit_risk_bucket" data-type="indexterm" id="idm45737223581408"/><a data-primary="" data-startref="ix_k-means-cluster" data-type="indexterm" id="idm45737223580560"/><a data-primary="" data-startref="ix_risk_bucketing" data-type="indexterm" id="idm45737223579712"/></p>&#13;
&#13;
<figure><div class="figure" id="all_clusters">&#13;
<img alt="clusters" src="assets/mlfr_0606.png"/>&#13;
<h6><span class="label">Figure 6-6. </span>K-means clusters</h6>&#13;
</div></figure>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Probability of Default Estimation with Logistic Regression" data-type="sect1"><div class="sect1" id="idm45737227459008">&#13;
<h1>Probability of Default Estimation with Logistic Regression</h1>&#13;
&#13;
<p><a data-primary="probability approaches" data-secondary="for default estimation" data-secondary-sortas="default estimation" data-tertiary="logistic regression" data-type="indexterm" id="ix_prob_app_def_est_logis"/><a data-primary="probability approaches" data-secondary="for default estimation" data-secondary-sortas="default estimation" data-type="indexterm" id="ix_prob_app_def_est"/><a data-primary="credit risk" data-secondary="probability of default estimation" data-type="indexterm" id="ix_credit_risk_prob_def_est"/>Having obtained the clusters, we are able to treat customers with similar characteristics the same way—that is, the model learns in an easier and more stable way if data with similar distributions is provided. Conversely, using all the customers for the entire sample might result in poor and unstable predictions.</p>&#13;
&#13;
<p>This section is ultimately about calculating the probability of default with Bayesian estimation, but let’s first look at logistic regression for the sake of comparison.<sup><a data-type="noteref" href="ch06.html#idm45737223570832" id="idm45737223570832-marker">1</a></sup></p>&#13;
&#13;
<p><a data-primary="logistic regression" data-secondary="probability of default estimation" data-type="indexterm" id="ix_log_reg_prob_def_est"/>Logistic regression is a classification algorithm, widely applicable in the finance industry. In other words, it proposes a regression approach to the classification problem. Logistic regression seeks to predict discrete output, taking into account some independent variables.</p>&#13;
&#13;
<p>Let <em>X</em> be the set of independent variables and <em>Y</em> be a binary (or multinomial) output. Then, the conditional probability becomes:</p>&#13;
<div data-type="equation">&#13;
<math alttext="probability left-parenthesis upper Y equals 1 vertical-bar upper X equals x right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mo form="prefix">Pr</mo>&#13;
    <mo>(</mo>&#13;
    <mi>Y</mi>&#13;
    <mo>=</mo>&#13;
    <mn>1</mn>&#13;
    <mo>|</mo>&#13;
    <mi>X</mi>&#13;
    <mo>=</mo>&#13;
    <mi>x</mi>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>This can be read as: given the values of <em>X</em>, what is the probability of having <em>Y</em> as 1? As the dependent variable of logistic regression is of the probabilistic type, we need to make sure the dependent variable cannot take on values other than between 0 and 1.</p>&#13;
&#13;
<p><a data-primary="logit (logistic) transformation" data-type="indexterm" id="idm45737223559488"/>To this aim, a modification is applied known as <em>logistic (logit) transformation</em>, which is simply the log of the odds ratio (<em>p</em> / 1 - <em>p</em>):</p>&#13;
<div data-type="equation">&#13;
<math alttext="l o g left-parenthesis StartFraction p Over 1 minus p EndFraction right-parenthesis" display="block">&#13;
  <mrow>&#13;
    <mi>l</mi>&#13;
    <mi>o</mi>&#13;
    <mi>g</mi>&#13;
    <mo>(</mo>&#13;
    <mfrac><mi>p</mi> <mrow><mn>1</mn><mo>-</mo><mi>p</mi></mrow></mfrac>&#13;
    <mo>)</mo>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>And the logistic regression model takes the following form:</p>&#13;
<div data-type="equation">&#13;
<math alttext="l o g left-parenthesis StartFraction p Over 1 minus p EndFraction right-parenthesis equals beta 0 plus beta 1 x" display="block">&#13;
  <mrow>&#13;
    <mi>l</mi>&#13;
    <mi>o</mi>&#13;
    <mi>g</mi>&#13;
    <mrow>&#13;
      <mo>(</mo>&#13;
      <mfrac><mi>p</mi> <mrow><mn>1</mn><mo>-</mo><mi>p</mi></mrow></mfrac>&#13;
      <mo>)</mo>&#13;
    </mrow>&#13;
    <mo>=</mo>&#13;
    <msub><mi>β</mi> <mn>0</mn> </msub>&#13;
    <mo>+</mo>&#13;
    <msub><mi>β</mi> <mn>1</mn> </msub>&#13;
    <mi>x</mi>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>Solving <em>p</em> results in:</p>&#13;
<div data-type="equation">&#13;
<math alttext="p equals StartFraction e Superscript beta 0 plus beta 1 x Baseline Over 1 plus e Superscript beta 0 plus beta 1 x Baseline EndFraction" display="block">&#13;
  <mrow>&#13;
    <mi>p</mi>&#13;
    <mo>=</mo>&#13;
    <mfrac><msup><mi>e</mi> <mrow><msub><mi>β</mi> <mn>0</mn> </msub><mo>+</mo><msub><mi>β</mi> <mn>1</mn> </msub><mi>x</mi></mrow> </msup> <mrow><mn>1</mn><mo>+</mo><msup><mi>e</mi> <mrow><msub><mi>β</mi> <mn>0</mn> </msub><mo>+</mo><msub><mi>β</mi> <mn>1</mn> </msub><mi>x</mi></mrow> </msup></mrow></mfrac>&#13;
  </mrow>&#13;
</math>&#13;
</div>&#13;
&#13;
<p>Let’s start off our application by preparing the data. First, we distinguish the clusters as 0 and 1. The credit data has a column named <code>risk</code>, suggesting the risk level of the customers. Next, the number of observations per risk in cluster 0 and cluster 1 are examined; it turns out we have 571 and 129 good customers in the cluster 0 and 1, respectively. In code:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">22</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">clusters</code><code class="p">,</code><code> </code><code class="n">counts</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">unique</code><code class="p">(</code><code class="n">kmeans</code><code class="o">.</code><code class="n">labels_</code><code class="p">,</code><code> </code><code class="n">return_counts</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO7-1" id="co_credit_risk_estimation_CO7-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">23</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">cluster_dict</code><code> </code><code class="o">=</code><code> </code><code class="p">{</code><code class="p">}</code><code>&#13;
</code><code>         </code><code class="k">for</code><code> </code><code class="n">i</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">clusters</code><code class="p">)</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">cluster_dict</code><code class="p">[</code><code class="n">i</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">scaled_credit</code><code class="p">[</code><code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">kmeans</code><code class="o">.</code><code class="n">labels_</code><code class="o">==</code><code class="n">i</code><code class="p">)</code><code class="p">]</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO7-2" id="co_credit_risk_estimation_CO7-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">24</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">credit</code><code class="p">[</code><code class="s1">'</code><code class="s1">clusters</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">kmeans</code><code class="o">.</code><code class="n">labels_</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO7-3" id="co_credit_risk_estimation_CO7-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">25</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">df_scaled</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">scaled_credit</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">df_scaled</code><code class="p">[</code><code class="s1">'</code><code class="s1">clusters</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">credit</code><code class="p">[</code><code class="s1">'</code><code class="s1">clusters</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">26</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">df_scaled</code><code class="p">[</code><code class="s1">'</code><code class="s1">Risk</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">credit</code><code class="p">[</code><code class="s1">'</code><code class="s1">Risk</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>         </code><code class="n">df_scaled</code><code class="o">.</code><code class="n">columns</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="s1">'</code><code class="s1">Age</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">Job</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">Credit amount</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                              </code><code class="s1">'</code><code class="s1">Duration</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">Clusters</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">Risk</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">27</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">df_scaled</code><code class="p">[</code><code class="n">df_scaled</code><code class="o">.</code><code class="n">Clusters</code><code> </code><code class="o">==</code><code> </code><code class="mi">0</code><code class="p">]</code><code class="p">[</code><code class="s1">'</code><code class="s1">Risk</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO7-4" id="co_credit_risk_estimation_CO7-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code class="n">Out</code><code class="p">[</code><code class="mi">27</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">good</code><code>    </code><code class="mi">571</code><code>&#13;
</code><code>         </code><code class="n">bad</code><code>     </code><code class="mi">193</code><code>&#13;
</code><code>         </code><code class="n">Name</code><code class="p">:</code><code> </code><code class="n">Risk</code><code class="p">,</code><code> </code><code class="n">dtype</code><code class="p">:</code><code> </code><code class="n">int64</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">28</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">df_scaled</code><code class="p">[</code><code class="n">df_scaled</code><code class="o">.</code><code class="n">Clusters</code><code> </code><code class="o">==</code><code> </code><code class="mi">1</code><code class="p">]</code><code class="p">[</code><code class="s1">'</code><code class="s1">Risk</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO7-5" id="co_credit_risk_estimation_CO7-5"><img alt="5" src="assets/5.png"/></a><code>&#13;
</code><code class="n">Out</code><code class="p">[</code><code class="mi">28</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">good</code><code>    </code><code class="mi">129</code><code>&#13;
</code><code>         </code><code class="n">bad</code><code>     </code><code class="mi">107</code><code>&#13;
</code><code>         </code><code class="n">Name</code><code class="p">:</code><code> </code><code class="n">Risk</code><code class="p">,</code><code> </code><code class="n">dtype</code><code class="p">:</code><code> </code><code class="n">int64</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO7-1" id="callout_credit_risk_estimation_CO7-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Obtaining cluster numbers</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO7-2" id="callout_credit_risk_estimation_CO7-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Based on the cluster numbers, differentiating the clusters and storing them in a dictionary called <code>cluster_dict</code></p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO7-3" id="callout_credit_risk_estimation_CO7-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Creating a <code>clusters</code> column using K-means labels</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO7-4" id="callout_credit_risk_estimation_CO7-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Observing the number of observations of categories within a cluster</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO7-5" id="callout_credit_risk_estimation_CO7-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>Finding number of observations per category</p></dd>&#13;
</dl>&#13;
&#13;
<p>Next, we draw a couple of bar plots to show the difference of the number of observations per risk level category (Figures <a data-type="xref" data-xrefstyle="select:labelnumber" href="#risk_level1">6-7</a> and&#13;
<a data-type="xref" data-xrefstyle="select:labelnumber" href="#risk_level2">6-8</a>):</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">29</code><code class="p">]:</code> <code class="n">df_scaled</code><code class="p">[</code><code class="n">df_scaled</code><code class="o">.</code><code class="n">Clusters</code> <code class="o">==</code> <code class="mi">0</code><code class="p">][</code><code class="s1">'Risk'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">()</code>\&#13;
                                             <code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">kind</code><code class="o">=</code><code class="s1">'bar'</code><code class="p">,</code>&#13;
                                             <code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code>&#13;
                                             <code class="n">title</code><code class="o">=</code><code class="s2">"Frequency of Risk Level"</code><code class="p">);</code>&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">30</code><code class="p">]:</code> <code class="n">df_scaled</code><code class="p">[</code><code class="n">df_scaled</code><code class="o">.</code><code class="n">Clusters</code> <code class="o">==</code> <code class="mi">1</code><code class="p">][</code><code class="s1">'Risk'</code><code class="p">]</code><code class="o">.</code><code class="n">value_counts</code><code class="p">()</code>\&#13;
                                             <code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">kind</code><code class="o">=</code><code class="s1">'bar'</code><code class="p">,</code>&#13;
                                             <code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code>&#13;
                                             <code class="n">title</code><code class="o">=</code><code class="s2">"Frequency of Risk Level"</code><code class="p">);</code></pre>&#13;
&#13;
<figure><div class="figure" id="risk_level1">&#13;
<img alt="cluster_2" src="assets/mlfr_0607.png"/>&#13;
<h6><span class="label">Figure 6-7. </span>Frequency of risk level of the first cluster</h6>&#13;
</div></figure>&#13;
&#13;
<figure><div class="figure" id="risk_level2">&#13;
<img alt="cluster_2" src="assets/mlfr_0608.png"/>&#13;
<h6><span class="label">Figure 6-8. </span>Frequency of risk level of the second cluster</h6>&#13;
</div></figure>&#13;
&#13;
<p>Based on the clusters we defined previously, we can analyze the frequency of risk level by histogram. <a data-type="xref" href="#risk_level1">Figure 6-7</a> shows that there is an imbalance distribution across risk level in the first cluster, whereas the frequency of good and bad risk levels are more balanced, if not perfectly balanced, in <a data-type="xref" href="#risk_level2">Figure 6-8</a>.</p>&#13;
&#13;
<p><a data-primary="class imbalance" data-secondary="credit risk analysis" data-type="indexterm" id="idm45737223079584"/>At this point, let’s take a step back and focus on an entirely different problem: <em>class imbalance</em>. In credit risk analysis, it is not uncommon to have a class imbalance problem. Class imbalance arises when one class dominates over another. To illustrate, in our case, given the data obtained from the first cluster, we have 571 customers with a good credit record and 193 customers with a bad one. As can be readily observed, customers with good credit records dominate over customers with bad records; that is basically what we refer to as a class imbalance.</p>&#13;
&#13;
<p><a data-primary="ENN (edited nearest neighbor rule)" data-type="indexterm" id="idm45737223077488"/><a data-primary="SMOTE (synthetic minority over-sampling technique)" data-type="indexterm" id="idm45737223076880"/>There are numerous ways to handle this issue: up-sampling, down-sampling, the synthetic minority oversampling technique (SMOTE), and the edited nearest neighbor (ENN) rule. To take advantage of a hybrid approach, we’ll incorporate a combination of SMOTE and ENN so we can clean the unwanted overlapping observations between classes, which will help us detect the optimal balancing ratio and, in turn, boost the predictive performance (Tuong et al. 2018). Converting imbalanced data into balanced data will be our first step in predicting the probability of default,&#13;
but please note that we will merely apply this technique to the data obtained from the first cluster.</p>&#13;
&#13;
<p>Now, we next apply a train-test split. To do that, we need to convert the categorical variable <code>Risk</code> into a discrete variable. The category <code>good</code> takes a value of 1, and <code>bad</code> takes a value of 0. In a train-test split, 80% of the data is devoted to training samples and 20% of is allocated to the test sample:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">31</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">sklearn.model_selection</code><code> </code><code class="kn">import</code><code> </code><code class="n">train_test_split</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">32</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">df_scaled</code><code class="p">[</code><code class="s1">'</code><code class="s1">Risk</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">df_scaled</code><code class="p">[</code><code class="s1">'</code><code class="s1">Risk</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">replace</code><code class="p">(</code><code class="p">{</code><code class="s1">'</code><code class="s1">good</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="mi">1</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">bad</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="mi">0</code><code class="p">}</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO8-1" id="co_credit_risk_estimation_CO8-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">33</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">X</code><code> </code><code class="o">=</code><code> </code><code class="n">df_scaled</code><code class="o">.</code><code class="n">drop</code><code class="p">(</code><code class="s1">'</code><code class="s1">Risk</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">axis</code><code class="o">=</code><code class="mi">1</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">y</code><code> </code><code class="o">=</code><code> </code><code class="n">df_scaled</code><code class="o">.</code><code class="n">loc</code><code class="p">[</code><code class="p">:</code><code class="p">,</code><code> </code><code class="p">[</code><code class="s1">'</code><code class="s1">Risk</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">Clusters</code><code class="s1">'</code><code class="p">]</code><code class="p">]</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">34</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">X_train</code><code class="p">,</code><code> </code><code class="n">X_test</code><code class="p">,</code><code> </code><code class="n">y_train</code><code class="p">,</code><code> </code><code class="n">y_test</code><code> </code><code class="o">=</code><code> </code><code class="n">train_test_split</code><code class="p">(</code><code class="n">X</code><code class="p">,</code><code> </code><code class="n">y</code><code class="p">,</code><code>&#13;
</code><code>                                                             </code><code class="n">test_size</code><code class="o">=</code><code class="mf">0.2</code><code class="p">,</code><code>&#13;
</code><code>                                                             </code><code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">35</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">first_cluster_train</code><code> </code><code class="o">=</code><code> </code><code class="n">X_train</code><code class="p">[</code><code class="n">X_train</code><code class="o">.</code><code class="n">Clusters</code><code> </code><code class="o">==</code><code> </code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="p">:</code><code class="p">,</code><code> </code><code class="p">:</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO8-2" id="co_credit_risk_estimation_CO8-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>         </code><code class="n">second_cluster_train</code><code> </code><code class="o">=</code><code> </code><code class="n">X_train</code><code class="p">[</code><code class="n">X_train</code><code class="o">.</code><code class="n">Clusters</code><code> </code><code class="o">==</code><code> </code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="p">:</code><code class="p">,</code><code> </code><code class="p">:</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO8-3" id="co_credit_risk_estimation_CO8-3"><img alt="3" src="assets/3.png"/></a></pre>&#13;
<dl class="calloutlist pagebreak-before less_space">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO8-1" id="callout_credit_risk_estimation_CO8-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Discretization of the variable</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO8-2" id="callout_credit_risk_estimation_CO8-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Creating data based on the first cluster and dropping last column from <code>X_train</code></p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO8-3" id="callout_credit_risk_estimation_CO8-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Creating data based on the second cluster and dropping last column from <code>X_train</code></p></dd>&#13;
</dl>&#13;
&#13;
<p>After these preparations, we are ready to move ahead and run the logistic regression to predict the probability of default. The library that we’ll make use of is called &#13;
<span class="keep-together"><code>statsmodels</code></span>, and it is allowed to have a summary table. The following result is based on the first cluster data. According to the result, the <code>age</code>, <code>credit amount</code>, and <code>job</code> variables are positively related with the creditworthiness of customer, while a negative association emerges between the <code>dependent</code> and  <code>duration</code> variables. This finding suggests that all the estimated coefficients reveal statistically significant results at a 1% significance level. A general interpretation would be that a slide in duration and a surge in credit amount, age, and job imply a high probability of default:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">36</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">import</code><code> </code><code class="nn">statsmodels.api</code><code> </code><code class="kn">as</code><code> </code><code class="nn">sm</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">sklearn.linear_model</code><code> </code><code class="kn">import</code><code> </code><code class="n">LogisticRegression</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">sklearn.metrics</code><code> </code><code class="kn">import</code><code> </code><code class="n">roc_auc_score</code><code class="p">,</code><code> </code><code class="n">roc_curve</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">imblearn.combine</code><code> </code><code class="kn">import</code><code> </code><code class="n">SMOTEENN</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO9-1" id="co_credit_risk_estimation_CO9-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="kn">import</code><code> </code><code class="nn">warnings</code><code>&#13;
</code><code>         </code><code class="n">warnings</code><code class="o">.</code><code class="n">filterwarnings</code><code class="p">(</code><code class="s1">'</code><code class="s1">ignore</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">37</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">X_train1</code><code> </code><code class="o">=</code><code> </code><code class="n">first_cluster_train</code><code>&#13;
</code><code>         </code><code class="n">y_train1</code><code> </code><code class="o">=</code><code> </code><code class="n">y_train</code><code class="p">[</code><code class="n">y_train</code><code class="o">.</code><code class="n">Clusters</code><code> </code><code class="o">==</code><code> </code><code class="mi">0</code><code class="p">]</code><code class="p">[</code><code class="s1">'</code><code class="s1">Risk</code><code class="s1">'</code><code class="p">]</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO9-2" id="co_credit_risk_estimation_CO9-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>         </code><code class="n">smote</code><code> </code><code class="o">=</code><code> </code><code class="n">SMOTEENN</code><code class="p">(</code><code class="n">random_state</code><code> </code><code class="o">=</code><code> </code><code class="mi">2</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO9-3" id="co_credit_risk_estimation_CO9-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>         </code><code class="n">X_train1</code><code class="p">,</code><code> </code><code class="n">y_train1</code><code> </code><code class="o">=</code><code> </code><code class="n">smote</code><code class="o">.</code><code class="n">fit_resample</code><code class="p">(</code><code class="n">X_train1</code><code class="p">,</code><code> </code><code class="n">y_train1</code><code class="o">.</code><code class="n">ravel</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO9-4" id="co_credit_risk_estimation_CO9-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code>         </code><code class="n">logit</code><code> </code><code class="o">=</code><code> </code><code class="n">sm</code><code class="o">.</code><code class="n">Logit</code><code class="p">(</code><code class="n">y_train1</code><code class="p">,</code><code> </code><code class="n">X_train1</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO9-5" id="co_credit_risk_estimation_CO9-5"><img alt="5" src="assets/5.png"/></a><code>&#13;
</code><code>         </code><code class="n">logit_fit1</code><code> </code><code class="o">=</code><code> </code><code class="n">logit</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO9-6" id="co_credit_risk_estimation_CO9-6"><img alt="6" src="assets/6.png"/></a><code>&#13;
</code><code>         </code><code class="k">print</code><code class="p">(</code><code class="n">logit_fit1</code><code class="o">.</code><code class="n">summary</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">Optimization</code><code> </code><code class="n">terminated</code><code> </code><code class="n">successfully</code><code class="o">.</code><code>&#13;
</code><code>         </code><code class="n">Current</code><code> </code><code class="n">function</code><code> </code><code class="n">value</code><code class="p">:</code><code> </code><code class="mf">0.479511</code><code>&#13;
</code><code>         </code><code class="n">Iterations</code><code> </code><code class="mi">6</code><code>&#13;
</code><code>                           </code><code class="n">Logit</code><code> </code><code class="n">Regression</code><code> </code><code class="n">Results</code><code>&#13;
</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code>&#13;
</code><code class="n">Dep</code><code class="o">.</code><code> </code><code class="n">Variable</code><code class="p">:</code><code>                      </code><code class="n">y</code><code>   </code><code class="n">No</code><code class="o">.</code><code> </code><code class="n">Observations</code><code class="p">:</code><code>                  </code><code class="mi">370</code><code>&#13;
</code><code class="n">Model</code><code class="p">:</code><code>                          </code><code class="n">Logit</code><code>   </code><code class="n">Df</code><code> </code><code class="n">Residuals</code><code class="p">:</code><code>                      </code><code class="mi">366</code><code>&#13;
</code><code class="n">Method</code><code class="p">:</code><code>                           </code><code class="n">MLE</code><code>   </code><code class="n">Df</code><code> </code><code class="n">Model</code><code class="p">:</code><code>                            </code><code class="mi">3</code><code>&#13;
</code><code class="n">Date</code><code class="p">:</code><code>                </code><code class="n">Wed</code><code class="p">,</code><code> </code><code class="mo">01</code><code> </code><code class="n">Dec</code><code> </code><code class="mi">2021</code><code>   </code><code class="n">Pseudo</code><code> </code><code class="n">R</code><code class="o">-</code><code class="n">squ</code><code class="o">.</code><code class="p">:</code><code>                  </code><code class="mf">0.2989</code><code>&#13;
</code><code class="n">Time</code><code class="p">:</code><code>                        </code><code class="mi">20</code><code class="p">:</code><code class="mi">34</code><code class="p">:</code><code class="mi">31</code><code>   </code><code class="n">Log</code><code class="o">-</code><code class="n">Likelihood</code><code class="p">:</code><code>                </code><code class="o">-</code><code class="mf">177.42</code><code>&#13;
</code><code class="n">converged</code><code class="p">:</code><code>                       </code><code class="bp">True</code><code>   </code><code class="n">LL</code><code class="o">-</code><code class="n">Null</code><code class="p">:</code><code>                       </code><code class="o">-</code><code class="mf">253.08</code><code>&#13;
</code><code class="n">Covariance</code><code> </code><code class="n">Type</code><code class="p">:</code><code>            </code><code class="n">nonrobust</code><code>   </code><code class="n">LLR</code><code> </code><code class="n">p</code><code class="o">-</code><code class="n">value</code><code class="p">:</code><code>                 </code><code class="mf">1.372e-32</code><code>&#13;
</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code>&#13;
</code><code>                    </code><code class="n">coef</code><code>   </code><code class="n">std</code><code> </code><code class="n">err</code><code>          </code><code class="n">z</code><code>      </code><code class="n">P</code><code class="o">&gt;</code><code class="o">|</code><code class="n">z</code><code class="o">|</code><code>      </code><code class="p">[</code><code class="mf">0.025</code><code>      </code><code class="mf">0.975</code><code class="p">]</code><code>&#13;
</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code class="o">-</code><code>&#13;
</code><code class="n">Age</code><code>               </code><code class="mf">1.3677</code><code>     </code><code class="mf">0.164</code><code>      </code><code class="mf">8.348</code><code>      </code><code class="mf">0.000</code><code>       </code><code class="mf">1.047</code><code>       </code><code class="mf">1.689</code><code>&#13;
</code><code class="n">Job</code><code>               </code><code class="mf">0.4393</code><code>     </code><code class="mf">0.153</code><code>      </code><code class="mf">2.873</code><code>      </code><code class="mf">0.004</code><code>       </code><code class="mf">0.140</code><code>       </code><code class="mf">0.739</code><code>&#13;
</code><code class="n">Credit</code><code> </code><code class="n">amount</code><code>     </code><code class="mf">1.3290</code><code>     </code><code class="mf">0.305</code><code>      </code><code class="mf">4.358</code><code>      </code><code class="mf">0.000</code><code>       </code><code class="mf">0.731</code><code>       </code><code class="mf">1.927</code><code>&#13;
</code><code class="n">Duration</code><code>         </code><code class="o">-</code><code class="mf">1.2709</code><code>     </code><code class="mf">0.246</code><code>     </code><code class="o">-</code><code class="mf">5.164</code><code>      </code><code class="mf">0.000</code><code>      </code><code class="o">-</code><code class="mf">1.753</code><code>      </code><code class="o">-</code><code class="mf">0.789</code><code>&#13;
</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO9-1" id="callout_credit_risk_estimation_CO9-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Importing <code>SMOTEENN</code> to deal with the class imbalance problem</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO9-2" id="callout_credit_risk_estimation_CO9-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Creating <code>y_train</code> based on cluster 0 and risk level</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO9-3" id="callout_credit_risk_estimation_CO9-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Running the <code>SMOTEENN</code> method with a random state of 2</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO9-4" id="callout_credit_risk_estimation_CO9-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Turning the imbalanced data into balanced data</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO9-5" id="callout_credit_risk_estimation_CO9-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>Configuring the logistic regression model</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO9-6" id="callout_credit_risk_estimation_CO9-6"><img alt="6" src="assets/6.png"/></a></dt>&#13;
<dd><p>Running the logistic regression model</p></dd>&#13;
</dl>&#13;
&#13;
<p>In what follows, prediction analysis is conducted by creating different datasets based on clusters. For the sake of testing, the following analysis is done with test data, and results in <a data-type="xref" href="#roc_auc_curve1_first">Figure 6-9</a>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">38</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">first_cluster_test</code><code> </code><code class="o">=</code><code> </code><code class="n">X_test</code><code class="p">[</code><code class="n">X_test</code><code class="o">.</code><code class="n">Clusters</code><code> </code><code class="o">==</code><code> </code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="p">:</code><code class="p">,</code><code> </code><code class="p">:</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO10-1" id="co_credit_risk_estimation_CO10-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="n">second_cluster_test</code><code> </code><code class="o">=</code><code> </code><code class="n">X_test</code><code class="p">[</code><code class="n">X_test</code><code class="o">.</code><code class="n">Clusters</code><code> </code><code class="o">==</code><code> </code><code class="mi">1</code><code class="p">]</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="p">:</code><code class="p">,</code><code> </code><code class="p">:</code><code class="o">-</code><code class="mi">1</code><code class="p">]</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO10-2" id="co_credit_risk_estimation_CO10-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">39</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">X_test1</code><code> </code><code class="o">=</code><code> </code><code class="n">first_cluster_test</code><code>&#13;
</code><code>         </code><code class="n">y_test1</code><code> </code><code class="o">=</code><code> </code><code class="n">y_test</code><code class="p">[</code><code class="n">y_test</code><code class="o">.</code><code class="n">Clusters</code><code> </code><code class="o">==</code><code> </code><code class="mi">0</code><code class="p">]</code><code class="p">[</code><code class="s1">'</code><code class="s1">Risk</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>         </code><code class="n">pred_prob1</code><code> </code><code class="o">=</code><code> </code><code class="n">logit_fit1</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test1</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO10-3" id="co_credit_risk_estimation_CO10-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">40</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">false_pos</code><code class="p">,</code><code> </code><code class="n">true_pos</code><code class="p">,</code><code> </code><code class="n">_</code><code> </code><code class="o">=</code><code> </code><code class="n">roc_curve</code><code class="p">(</code><code class="n">y_test1</code><code class="o">.</code><code class="n">values</code><code class="p">,</code><code>  </code><code class="n">pred_prob1</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO10-4" id="co_credit_risk_estimation_CO10-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code>         </code><code class="n">auc</code><code> </code><code class="o">=</code><code> </code><code class="n">roc_auc_score</code><code class="p">(</code><code class="n">y_test1</code><code class="p">,</code><code> </code><code class="n">pred_prob1</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO10-5" id="co_credit_risk_estimation_CO10-5"><img alt="5" src="assets/5.png"/></a><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">false_pos</code><code class="p">,</code><code class="n">true_pos</code><code class="p">,</code><code> </code><code class="n">label</code><code class="o">=</code><code class="s2">"</code><code class="s2">AUC for cluster 1={:.4f} </code><code class="s2">"</code><code>&#13;
</code><code>                  </code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">auc</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">]</code><code class="p">,</code><code> </code><code class="p">[</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">linestyle</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">--</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">label</code><code class="o">=</code><code class="s1">'</code><code class="s1">45 degree line</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s1">'</code><code class="s1">best</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'</code><code class="s1">ROC-AUC Curve 1</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="p">)</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO10-1" id="callout_credit_risk_estimation_CO10-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Creating first test data based on cluster 0</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO10-2" id="callout_credit_risk_estimation_CO10-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Creating second test data based on cluster 1</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO10-3" id="callout_credit_risk_estimation_CO10-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Running prediction using <code>X_test1</code></p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO10-4" id="callout_credit_risk_estimation_CO10-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Obtaining false and true positives using <code>roc_curve</code> function</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO10-5" id="callout_credit_risk_estimation_CO10-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>Compute the <code>roc-auc</code> score</p></dd>&#13;
</dl>&#13;
&#13;
<figure><div class="figure" id="roc_auc_curve1_first">&#13;
<img alt="roc_auc1" src="assets/mlfr_0609.png"/>&#13;
<h6><span class="label">Figure 6-9. </span>ROC-AUC curve of the first cluster</h6>&#13;
</div></figure>&#13;
&#13;
<p><a data-primary="ROC-AUC curve" data-type="indexterm" id="ix_roc-auc_curve"/><a data-primary="clustering method" data-secondary="ROC-AUC curve" data-type="indexterm" id="ix_cluster_roc-auc"/>The ROC-AUC curve is a convenient tool in the presence of imbalanced data. The ROC-AUC curve in <a data-type="xref" href="#roc_auc_curve1_first">Figure 6-9</a> suggests that the performance of the model is not very good, because it moves just above the 45-degree line. Generally speaking, given the test results, a good ROC-AUC curve should be close to 1, implying that there is a close-to-perfect separation.</p>&#13;
&#13;
<p>Moving on to the second set of training samples obtained from the second cluster, the signs of the estimated coefficients of <code>job</code>, <code>duration</code>, and <code>age</code> are positive, suggesting that customers with <code>job</code> type of <code>1</code> and having larger duration tend to default, and the <code>credit amount</code> variable shows a negative relation with dependent variable.&#13;
However, all the estimated coefficients are statistically insignificant at 95% confidence interval; therefore, it makes no sense to further interpret the findings.</p>&#13;
&#13;
<p>Similar to what we did with the first set of test data, we create a second set of test data to run the prediction to draw the ROC-AUC curve, resulting in <a data-type="xref" href="#roc_auc_curve1_second">Figure 6-10</a>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">41</code><code class="p">]:</code> <code class="n">X_train2</code> <code class="o">=</code> <code class="n">second_cluster_train</code>&#13;
         <code class="n">y_train2</code> <code class="o">=</code> <code class="n">y_train</code><code class="p">[</code><code class="n">y_train</code><code class="o">.</code><code class="n">Clusters</code> <code class="o">==</code> <code class="mi">1</code><code class="p">][</code><code class="s1">'Risk'</code><code class="p">]</code>&#13;
         <code class="n">logit</code> <code class="o">=</code> <code class="n">sm</code><code class="o">.</code><code class="n">Logit</code><code class="p">(</code><code class="n">y_train2</code><code class="p">,</code> <code class="n">X_train2</code><code class="p">)</code>&#13;
         <code class="n">logit_fit2</code> <code class="o">=</code> <code class="n">logit</code><code class="o">.</code><code class="n">fit</code><code class="p">()</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="n">logit_fit2</code><code class="o">.</code><code class="n">summary</code><code class="p">())</code>&#13;
         <code class="n">Optimization</code> <code class="n">terminated</code> <code class="n">successfully</code><code class="o">.</code>&#13;
         <code class="n">Current</code> <code class="n">function</code> <code class="n">value</code><code class="p">:</code> <code class="mf">0.688152</code>&#13;
         <code class="n">Iterations</code> <code class="mi">4</code>&#13;
                           <code class="n">Logit</code> <code class="n">Regression</code> <code class="n">Results</code>&#13;
<code class="o">==============================================================================</code>&#13;
<code class="n">Dep</code><code class="o">.</code> <code class="n">Variable</code><code class="p">:</code>                   <code class="n">Risk</code>   <code class="n">No</code><code class="o">.</code> <code class="n">Observations</code><code class="p">:</code>                  <code class="mi">199</code>&#13;
<code class="n">Model</code><code class="p">:</code>                          <code class="n">Logit</code>   <code class="n">Df</code> <code class="n">Residuals</code><code class="p">:</code>                      <code class="mi">195</code>&#13;
<code class="n">Method</code><code class="p">:</code>                           <code class="n">MLE</code>   <code class="n">Df</code> <code class="n">Model</code><code class="p">:</code>                            <code class="mi">3</code>&#13;
<code class="n">Date</code><code class="p">:</code>                <code class="n">Wed</code><code class="p">,</code> <code class="mo">01</code> <code class="n">Dec</code> <code class="mi">2021</code>   <code class="n">Pseudo</code> <code class="n">R</code><code class="o">-</code><code class="n">squ</code><code class="o">.</code><code class="p">:</code>              <code class="o">-</code><code class="mf">0.0008478</code>&#13;
<code class="n">Time</code><code class="p">:</code>                        <code class="mi">20</code><code class="p">:</code><code class="mi">34</code><code class="p">:</code><code class="mi">33</code>   <code class="n">Log</code><code class="o">-</code><code class="n">Likelihood</code><code class="p">:</code>                <code class="o">-</code><code class="mf">136.94</code>&#13;
<code class="n">converged</code><code class="p">:</code>                       <code class="bp">True</code>   <code class="n">LL</code><code class="o">-</code><code class="n">Null</code><code class="p">:</code>                       <code class="o">-</code><code class="mf">136.83</code>&#13;
<code class="n">Covariance</code> <code class="n">Type</code><code class="p">:</code>            <code class="n">nonrobust</code>   <code class="n">LLR</code> <code class="n">p</code><code class="o">-</code><code class="n">value</code><code class="p">:</code>                     <code class="mf">1.000</code>&#13;
<code class="o">================================================================================</code>&#13;
                    <code class="n">coef</code>   <code class="n">std</code> <code class="n">err</code>          <code class="n">z</code>      <code class="n">P</code><code class="o">&gt;|</code><code class="n">z</code><code class="o">|</code>      <code class="p">[</code><code class="mf">0.025</code>      <code class="mf">0.975</code><code class="p">]</code>&#13;
<code class="o">--------------------------------------------------------------------------------</code>&#13;
<code class="n">Age</code>               <code class="mf">0.0281</code>     <code class="mf">0.146</code>      <code class="mf">0.192</code>      <code class="mf">0.848</code>      <code class="o">-</code><code class="mf">0.259</code>       <code class="mf">0.315</code>&#13;
<code class="n">Job</code>               <code class="mf">0.1536</code>     <code class="mf">0.151</code>      <code class="mf">1.020</code>      <code class="mf">0.308</code>      <code class="o">-</code><code class="mf">0.142</code>       <code class="mf">0.449</code>&#13;
<code class="n">Credit</code> <code class="n">amount</code>    <code class="o">-</code><code class="mf">0.1090</code>     <code class="mf">0.115</code>     <code class="o">-</code><code class="mf">0.945</code>      <code class="mf">0.345</code>      <code class="o">-</code><code class="mf">0.335</code>       <code class="mf">0.117</code>&#13;
<code class="n">Duration</code>          <code class="mf">0.1046</code>     <code class="mf">0.126</code>      <code class="mf">0.833</code>      <code class="mf">0.405</code>      <code class="o">-</code><code class="mf">0.142</code>       <code class="mf">0.351</code>&#13;
<code class="o">================================================================================</code>&#13;
&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">42</code><code class="p">]:</code> <code class="n">X_test2</code> <code class="o">=</code> <code class="n">second_cluster_test</code>&#13;
         <code class="n">y_test2</code> <code class="o">=</code> <code class="n">y_test</code><code class="p">[</code><code class="n">y_test</code><code class="o">.</code><code class="n">Clusters</code> <code class="o">==</code> <code class="mi">1</code><code class="p">][</code><code class="s1">'Risk'</code><code class="p">]</code>&#13;
         <code class="n">pred_prob2</code> <code class="o">=</code> <code class="n">logit_fit2</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test2</code><code class="p">)</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">43</code><code class="p">]:</code> <code class="n">false_pos</code><code class="p">,</code> <code class="n">true_pos</code><code class="p">,</code> <code class="n">_</code> <code class="o">=</code> <code class="n">roc_curve</code><code class="p">(</code><code class="n">y_test2</code><code class="o">.</code><code class="n">values</code><code class="p">,</code>  <code class="n">pred_prob2</code><code class="p">)</code>&#13;
         <code class="n">auc</code> <code class="o">=</code> <code class="n">roc_auc_score</code><code class="p">(</code><code class="n">y_test2</code><code class="p">,</code> <code class="n">pred_prob2</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">false_pos</code><code class="p">,</code><code class="n">true_pos</code><code class="p">,</code><code class="n">label</code><code class="o">=</code><code class="s2">"AUC for cluster 2={:.4f} "</code>&#13;
                  <code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">auc</code><code class="p">))</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">([</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="p">[</code><code class="mi">0</code><code class="p">,</code> <code class="mi">1</code><code class="p">],</code> <code class="n">linestyle</code> <code class="o">=</code> <code class="s1">'--'</code><code class="p">,</code> <code class="n">label</code><code class="o">=</code><code class="s1">'45 degree line'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="n">loc</code><code class="o">=</code><code class="s1">'best'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">title</code><code class="p">(</code><code class="s1">'ROC-AUC Curve 2'</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code></pre>&#13;
&#13;
<p>Given the test data, the result shown in <a data-type="xref" href="#roc_auc_curve1_second">Figure 6-10</a> is worse than the previous application,&#13;
as can be confirmed by the AUC score of 0.4064. Considering this data, we are far from saying that logistic regression is doing a good job of modeling probability of default using the German credit risk dataset.</p>&#13;
&#13;
<p>We will now use different models to see how good the logistic regression is in modeling this type of problem&#13;
relative to other methods. <a data-primary="MCMC (Markov chain Monte Carlo) method" data-type="indexterm" id="idm45737222403920"/>Thus, in the following part, we will take a look at Bayesian estimation with maximum a posteriori (MAP) probability and Markov Chain Monte Carlo (MCMC) approaches. We will then explore those approaches using a few well-known ML models—SVM, random forest, and neural networks using <code>MLPRegressor</code>—and we will test the deep learning model with <a data-primary="TensorFlow" data-type="indexterm" id="idm45737222402400"/>TensorFlow. This application will show us which model works better in modeling the probability of default.<a data-primary="" data-startref="ix_log_reg_prob_def_est" data-type="indexterm" id="idm45737222401440"/><a data-primary="" data-startref="ix_prob_app_def_est_logis" data-type="indexterm" id="idm45737221872800"/><a data-primary="" data-startref="ix_cluster_roc-auc" data-type="indexterm" id="idm45737221871888"/><a data-primary="" data-startref="ix_roc-auc_curve" data-type="indexterm" id="idm45737221870944"/></p>&#13;
&#13;
<figure><div class="figure" id="roc_auc_curve1_second">&#13;
<img alt="roc_auc2" src="assets/mlfr_0610.png"/>&#13;
<h6><span class="label">Figure 6-10. </span>ROC-AUC curve of the second cluster</h6>&#13;
</div></figure>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Probability of Default Estimation with the Bayesian Model" data-type="sect2"><div class="sect2" id="idm45737221868064">&#13;
<h2>Probability of Default Estimation with the Bayesian Model</h2>&#13;
&#13;
<p><a data-primary="credit risk" data-secondary="probability of default estimation" data-tertiary="Bayesian model" data-type="indexterm" id="ix_credit_risk_prob_def_est_bayes"/><a data-primary="probability approaches" data-secondary="for default estimation" data-secondary-sortas="default estimation" data-tertiary="with Bayesian model" data-tertiary-sortas="Bayesian model" data-type="indexterm" id="ix_prob_def_est_bayes"/><a data-primary="Bayesian approach" data-secondary="probability of default estimation" data-type="indexterm" id="ix_bayesian_prob_def_est"/><a data-primary="PYMC3 package" data-type="indexterm" id="ix_PYMC3_package"/>In this part, we’ll use the <code>PYMC3</code> package, which is a Python package for Bayesian estimation, to predict the probability of default. However, there are several approaches for running Bayesian analysis using <code>PYMC3</code>, and for the first application,&#13;
we’ll use the MAP distribution discussed in <a data-type="xref" href="ch04.html#chapter_4">Chapter 4</a>.&#13;
<a data-primary="MAP (maximum a posteriori) probability" data-type="indexterm" id="ix_map_prob"/>As a quick reminder, given the representative posterior distribution, MAP becomes an efficient model in this case.&#13;
Moreover, we select the Bayesian model with a deterministic variable (<em>p</em>) that is entirely determined by its parents—that is, <code>age</code>, <code>job</code>, <code>credit amount</code>, and <code>duration</code>.</p>&#13;
&#13;
<p>Let’s compare the results obtained from Bayesian analysis with that of logistic &#13;
<span class="keep-together">regression</span>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">44</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">import</code><code> </code><code class="nn">pymc3</code><code> </code><code class="kn">as</code><code> </code><code class="nn">pm</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO11-1" id="co_credit_risk_estimation_CO11-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="kn">import</code><code> </code><code class="nn">arviz</code><code> </code><code class="kn">as</code><code> </code><code class="nn">az</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO11-2" id="co_credit_risk_estimation_CO11-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">45</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">with</code><code> </code><code class="n">pm</code><code class="o">.</code><code class="n">Model</code><code class="p">(</code><code class="p">)</code><code> </code><code class="k">as</code><code> </code><code class="n">logistic_model1</code><code class="p">:</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO11-3" id="co_credit_risk_estimation_CO11-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>             </code><code class="n">beta_age</code><code> </code><code class="o">=</code><code> </code><code class="n">pm</code><code class="o">.</code><code class="n">Normal</code><code class="p">(</code><code class="s1">'</code><code class="s1">coeff_age</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">mu</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="n">sd</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO11-4" id="co_credit_risk_estimation_CO11-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code>             </code><code class="n">beta_job</code><code> </code><code class="o">=</code><code> </code><code class="n">pm</code><code class="o">.</code><code class="n">Normal</code><code class="p">(</code><code class="s1">'</code><code class="s1">coeff_job</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">mu</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="n">sd</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">beta_credit</code><code> </code><code class="o">=</code><code> </code><code class="n">pm</code><code class="o">.</code><code class="n">Normal</code><code class="p">(</code><code class="s1">'</code><code class="s1">coeff_credit_amount</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">mu</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="n">sd</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">beta_dur</code><code> </code><code class="o">=</code><code> </code><code class="n">pm</code><code class="o">.</code><code class="n">Normal</code><code class="p">(</code><code class="s1">'</code><code class="s1">coeff_duration</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">mu</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="n">sd</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">p</code><code> </code><code class="o">=</code><code> </code><code class="n">pm</code><code class="o">.</code><code class="n">Deterministic</code><code class="p">(</code><code class="s1">'</code><code class="s1">p</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">pm</code><code class="o">.</code><code class="n">math</code><code class="o">.</code><code class="n">sigmoid</code><code class="p">(</code><code class="n">beta_age</code><code> </code><code class="o">*</code><code>&#13;
</code><code>                                       </code><code class="n">X_train1</code><code class="p">[</code><code class="s1">'</code><code class="s1">Age</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">+</code><code> </code><code class="n">beta_job</code><code> </code><code class="o">*</code><code>&#13;
</code><code>                                       </code><code class="n">X_train1</code><code class="p">[</code><code class="s1">'</code><code class="s1">Job</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">+</code><code> </code><code class="n">beta_credit</code><code> </code><code class="o">*</code><code>&#13;
</code><code>                                       </code><code class="n">X_train1</code><code class="p">[</code><code class="s1">'</code><code class="s1">Credit amount</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">+</code><code> </code><code class="n">beta_dur</code><code> </code><code class="o">*</code><code>&#13;
</code><code>                                       </code><code class="n">X_train1</code><code class="p">[</code><code class="s1">'</code><code class="s1">Duration</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO11-5" id="co_credit_risk_estimation_CO11-5"><img alt="5" src="assets/5.png"/></a><code>&#13;
</code><code>         </code><code class="k">with</code><code> </code><code class="n">logistic_model1</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">observed</code><code> </code><code class="o">=</code><code> </code><code class="n">pm</code><code class="o">.</code><code class="n">Bernoulli</code><code class="p">(</code><code class="s2">"</code><code class="s2">risk</code><code class="s2">"</code><code class="p">,</code><code> </code><code class="n">p</code><code class="p">,</code><code> </code><code class="n">observed</code><code class="o">=</code><code class="n">y_train1</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO11-6" id="co_credit_risk_estimation_CO11-6"><img alt="6" src="assets/6.png"/></a><code>&#13;
</code><code>             </code><code class="n">map_estimate</code><code> </code><code class="o">=</code><code> </code><code class="n">pm</code><code class="o">.</code><code class="n">find_MAP</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO11-7" id="co_credit_risk_estimation_CO11-7"><img alt="7" src="assets/7.png"/></a><code>&#13;
</code><code class="n">Out</code><code class="p">[</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">IPython</code><code class="o">.</code><code class="n">core</code><code class="o">.</code><code class="n">display</code><code class="o">.</code><code class="n">HTML</code><code> </code><code class="nb">object</code><code class="o">&gt;</code><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">46</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">param_list</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="s1">'</code><code class="s1">coeff_age</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">coeff_job</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                       </code><code class="s1">'</code><code class="s1">coeff_credit_amount</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">coeff_duration</code><code class="s1">'</code><code class="p">]</code><code>&#13;
</code><code>         </code><code class="n">params</code><code> </code><code class="o">=</code><code> </code><code class="p">{</code><code class="p">}</code><code>&#13;
</code><code>         </code><code class="k">for</code><code> </code><code class="n">i</code><code> </code><code class="ow">in</code><code> </code><code class="n">param_list</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">params</code><code class="p">[</code><code class="n">i</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="n">np</code><code class="o">.</code><code class="n">round</code><code class="p">(</code><code class="n">map_estimate</code><code class="p">[</code><code class="n">i</code><code class="p">]</code><code class="p">,</code><code> </code><code class="mi">6</code><code class="p">)</code><code class="p">]</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO11-8" id="co_credit_risk_estimation_CO11-8"><img alt="8" src="assets/8.png"/></a><code>&#13;
</code><code>&#13;
</code><code>         </code><code class="n">bayesian_params</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="o">.</code><code class="n">from_dict</code><code class="p">(</code><code class="n">params</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">The result of Bayesian estimation:</code><code class="se">\n</code><code class="s1"> {}</code><code class="s1">'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">bayesian_params</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">result</code><code> </code><code class="n">of</code><code> </code><code class="n">Bayesian</code><code> </code><code class="n">estimation</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">coeff_age</code><code>  </code><code class="n">coeff_job</code><code>  </code><code class="n">coeff_credit_amount</code><code>  </code><code class="n">coeff_duration</code><code>&#13;
</code><code>         </code><code class="mi">0</code><code>   </code><code class="mf">1.367247</code><code>   </code><code class="mf">0.439128</code><code>              </code><code class="mf">1.32721</code><code>       </code><code class="o">-</code><code class="mf">1.269345</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO11-1" id="callout_credit_risk_estimation_CO11-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Importing <code>PYMC3</code></p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO11-2" id="callout_credit_risk_estimation_CO11-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Importing <code>arviz</code> for exploratory analysis of Bayesian models</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO11-3" id="callout_credit_risk_estimation_CO11-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Identifying Bayesian model as <code>logistic_model1</code></p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO11-4" id="callout_credit_risk_estimation_CO11-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Identifying the assumed distributions of the variables as normal with defined <code>mu</code> and <code>sigma</code> parameters</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO11-5" id="callout_credit_risk_estimation_CO11-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>Running a deterministic model using the first sample</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO11-6" id="callout_credit_risk_estimation_CO11-6"><img alt="6" src="assets/6.png"/></a></dt>&#13;
<dd><p>Running a Bernoulli distribution to model the dependent variable</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO11-7" id="callout_credit_risk_estimation_CO11-7"><img alt="7" src="assets/7.png"/></a></dt>&#13;
<dd><p>Fitting the MAP model to data</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO11-8" id="callout_credit_risk_estimation_CO11-8"><img alt="8" src="assets/8.png"/></a></dt>&#13;
<dd><p>Storing all the results of the estimated coefficients into <code>param</code>s with six &#13;
<span class="keep-together">decimals</span></p></dd>&#13;
</dl>&#13;
&#13;
<p>The most striking observation is that the differences between estimated coefficients are so small that they can be ignored. The difference occurs in the decimals.&#13;
Taking the estimated coefficient of the credit amount variable as an example, we have estimated the coefficient to be 1.3290 in logistic regression and&#13;
1.3272 in Bayesian analysis.</p>&#13;
&#13;
<p>The story is more or less the same when it comes to comparing the analysis result based on the second cluster data:</p>&#13;
&#13;
<pre class="pagebreak-before less_space" data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">47</code><code class="p">]:</code> <code class="k">with</code> <code class="n">pm</code><code class="o">.</code><code class="n">Model</code><code class="p">()</code> <code class="k">as</code> <code class="n">logistic_model2</code><code class="p">:</code>&#13;
             <code class="n">beta_age</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">Normal</code><code class="p">(</code><code class="s1">'coeff_age'</code><code class="p">,</code> <code class="n">mu</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code> <code class="n">sd</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code>&#13;
             <code class="n">beta_job</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">Normal</code><code class="p">(</code><code class="s1">'coeff_job'</code><code class="p">,</code> <code class="n">mu</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code> <code class="n">sd</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code>&#13;
             <code class="n">beta_credit</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">Normal</code><code class="p">(</code><code class="s1">'coeff_credit_amount'</code><code class="p">,</code> <code class="n">mu</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code> <code class="n">sd</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code>&#13;
             <code class="n">beta_dur</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">Normal</code><code class="p">(</code><code class="s1">'coeff_duration'</code><code class="p">,</code> <code class="n">mu</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code> <code class="n">sd</code><code class="o">=</code><code class="mi">10</code><code class="p">)</code>&#13;
             <code class="n">p</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">Deterministic</code><code class="p">(</code><code class="s1">'p'</code><code class="p">,</code> <code class="n">pm</code><code class="o">.</code><code class="n">math</code><code class="o">.</code><code class="n">sigmoid</code><code class="p">(</code><code class="n">beta_age</code> <code class="o">*</code>&#13;
                                       <code class="n">second_cluster_train</code><code class="p">[</code><code class="s1">'Age'</code><code class="p">]</code> <code class="o">+</code>&#13;
                                       <code class="n">beta_job</code> <code class="o">*</code> <code class="n">second_cluster_train</code><code class="p">[</code><code class="s1">'Job'</code><code class="p">]</code> <code class="o">+</code>&#13;
                                       <code class="n">beta_credit</code> <code class="o">*</code>&#13;
                                       <code class="n">second_cluster_train</code><code class="p">[</code><code class="s1">'Credit amount'</code><code class="p">]</code> <code class="o">+</code>&#13;
                                       <code class="n">beta_dur</code> <code class="o">*</code>&#13;
                                       <code class="n">second_cluster_train</code><code class="p">[</code><code class="s1">'Duration'</code><code class="p">]))</code>&#13;
         <code class="k">with</code> <code class="n">logistic_model2</code><code class="p">:</code>&#13;
             <code class="n">observed</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">Bernoulli</code><code class="p">(</code><code class="s2">"risk"</code><code class="p">,</code> <code class="n">p</code><code class="p">,</code>&#13;
                                     <code class="n">observed</code><code class="o">=</code><code class="n">y_train</code><code class="p">[</code><code class="n">y_train</code><code class="o">.</code><code class="n">Clusters</code> <code class="o">==</code> <code class="mi">1</code><code class="p">]</code>&#13;
                                     <code class="p">[</code><code class="s1">'Risk'</code><code class="p">])</code>&#13;
             <code class="n">map_estimate</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">find_MAP</code><code class="p">()</code>&#13;
<code class="n">Out</code><code class="p">[]:</code> <code class="o">&lt;</code><code class="n">IPython</code><code class="o">.</code><code class="n">core</code><code class="o">.</code><code class="n">display</code><code class="o">.</code><code class="n">HTML</code> <code class="nb">object</code><code class="o">&gt;</code>&#13;
&#13;
&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">48</code><code class="p">]:</code> <code class="n">param_list</code> <code class="o">=</code> <code class="p">[</code> <code class="s1">'coeff_age'</code><code class="p">,</code> <code class="s1">'coeff_job'</code><code class="p">,</code>&#13;
                       <code class="s1">'coeff_credit_amount'</code><code class="p">,</code> <code class="s1">'coeff_duration'</code><code class="p">]</code>&#13;
         <code class="n">params</code> <code class="o">=</code> <code class="p">{}</code>&#13;
         <code class="k">for</code> <code class="n">i</code> <code class="ow">in</code> <code class="n">param_list</code><code class="p">:</code>&#13;
             <code class="n">params</code><code class="p">[</code><code class="n">i</code><code class="p">]</code> <code class="o">=</code> <code class="p">[</code><code class="n">np</code><code class="o">.</code><code class="n">round</code><code class="p">(</code><code class="n">map_estimate</code><code class="p">[</code><code class="n">i</code><code class="p">],</code> <code class="mi">6</code><code class="p">)]</code>&#13;
&#13;
         <code class="n">bayesian_params</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="o">.</code><code class="n">from_dict</code><code class="p">(</code><code class="n">params</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'The result of Bayesian estimation:</code><code class="se">\n</code><code class="s1"> {}'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">bayesian_params</code><code class="p">))</code>&#13;
         <code class="n">The</code> <code class="n">result</code> <code class="n">of</code> <code class="n">Bayesian</code> <code class="n">estimation</code><code class="p">:</code>&#13;
             <code class="n">coeff_age</code>  <code class="n">coeff_job</code>  <code class="n">coeff_credit_amount</code>  <code class="n">coeff_duration</code>&#13;
         <code class="mi">0</code>   <code class="mf">0.028069</code>   <code class="mf">0.153599</code>            <code class="o">-</code><code class="mf">0.109003</code>        <code class="mf">0.104581</code></pre>&#13;
&#13;
<p>The most remarkable difference occurs in the <code>duration</code> variable. The estimated coefficients of this variable are 0.1046 and 0.1045 in logistic regression and Bayesian estimation, respectively.<a data-primary="" data-startref="ix_map_prob" data-type="indexterm" id="idm45737221013536"/></p>&#13;
&#13;
<p><a data-primary="M-H (Metropolis–Hastings) algorithm for MCMC" data-type="indexterm" id="ix_m-h_algorithm2"/><a data-primary="ML (machine learning)" data-secondary="Bayesian approach" data-type="indexterm" id="ix_ml_bayes_approach_ch6"/><a data-primary="MCMC (Markov chain Monte Carlo) method" data-type="indexterm" id="ix_mcmc_method2"/>Instead of finding the local maximum, which is sometimes difficult to get, we look for an approximate expectation based on the sampling procedure. This is referred to as MCMC in the Bayesian setting. As we discussed in <a data-type="xref" href="ch04.html#chapter_4">Chapter 4</a>, one of the most well known methods is the Metropolis-Hastings (M-H) algorithm.</p>&#13;
&#13;
<p>The Python code that applies Bayesian estimation based on the M-H algorithm is shown in the following and results in <a data-type="xref" href="#MCMC_risk_cluster1">Figure 6-11</a>. Accordingly, we draw 10,000 posterior samples to simulate the posterior distribution for two independent Markov chains. The summary table for the estimated coefficients is provided in the code as well:</p>&#13;
&#13;
<pre class="pagebreak-before less_space" data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">49</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">import</code><code> </code><code class="nn">logging</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO12-1" id="co_credit_risk_estimation_CO12-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="n">logger</code><code> </code><code class="o">=</code><code> </code><code class="n">logging</code><code class="o">.</code><code class="n">getLogger</code><code class="p">(</code><code class="s1">'</code><code class="s1">pymc3</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO12-2" id="co_credit_risk_estimation_CO12-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>         </code><code class="n">logger</code><code class="o">.</code><code class="n">setLevel</code><code class="p">(</code><code class="n">logging</code><code class="o">.</code><code class="n">ERROR</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO12-3" id="co_credit_risk_estimation_CO12-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">50</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">with</code><code> </code><code class="n">logistic_model1</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">step</code><code> </code><code class="o">=</code><code> </code><code class="n">pm</code><code class="o">.</code><code class="n">Metropolis</code><code class="p">(</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO12-4" id="co_credit_risk_estimation_CO12-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code>             </code><code class="n">trace</code><code> </code><code class="o">=</code><code> </code><code class="n">pm</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="mi">10000</code><code class="p">,</code><code> </code><code class="n">step</code><code class="o">=</code><code class="n">step</code><code class="p">,</code><code class="n">progressbar</code><code> </code><code class="o">=</code><code> </code><code class="bp">False</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO12-5" id="co_credit_risk_estimation_CO12-5"><img alt="5" src="assets/5.png"/></a><code>&#13;
</code><code>         </code><code class="n">az</code><code class="o">.</code><code class="n">plot_trace</code><code class="p">(</code><code class="n">trace</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO12-6" id="co_credit_risk_estimation_CO12-6"><img alt="6" src="assets/6.png"/></a><code>&#13;
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">51</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">with</code><code> </code><code class="n">logistic_model1</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">display</code><code class="p">(</code><code class="n">az</code><code class="o">.</code><code class="n">summary</code><code class="p">(</code><code class="n">trace</code><code class="p">,</code><code> </code><code class="n">round_to</code><code class="o">=</code><code class="mi">6</code><code class="p">)</code><code class="p">[</code><code class="p">:</code><code class="mi">4</code><code class="p">]</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO12-7" id="co_credit_risk_estimation_CO12-7"><img alt="7" src="assets/7.png"/></a><code>&#13;
</code><code class="n">Out</code><code class="p">[</code><code class="p">]</code><code class="p">:</code><code>                          </code><code class="n">mean</code><code>        </code><code class="n">sd</code><code>    </code><code class="n">hdi_3</code><code class="o">%</code><code>   </code><code class="n">hdi_97</code><code class="o">%</code><code>  </code><code class="n">mcse_mean</code><code>  </code><code>\&#13;
</code><code>       </code><code class="n">coeff_age</code><code>            </code><code class="mf">1.392284</code><code>  </code><code class="mf">0.164607</code><code>  </code><code class="mf">1.086472</code><code>  </code><code class="mf">1.691713</code><code>   </code><code class="mf">0.003111</code><code>&#13;
</code><code>       </code><code class="n">coeff_job</code><code>            </code><code class="mf">0.448694</code><code>  </code><code class="mf">0.155060</code><code>  </code><code class="mf">0.138471</code><code>  </code><code class="mf">0.719332</code><code>   </code><code class="mf">0.002925</code><code>&#13;
</code><code>       </code><code class="n">coeff_credit_amount</code><code>  </code><code class="mf">1.345549</code><code>  </code><code class="mf">0.308100</code><code>  </code><code class="mf">0.779578</code><code>  </code><code class="mf">1.928159</code><code>   </code><code class="mf">0.008017</code><code>&#13;
</code><code>       </code><code class="n">coeff_duration</code><code>      </code><code class="o">-</code><code class="mf">1.290292</code><code>  </code><code class="mf">0.252505</code><code> </code><code class="o">-</code><code class="mf">1.753565</code><code> </code><code class="o">-</code><code class="mf">0.802707</code><code>   </code><code class="mf">0.006823</code><code>&#13;
</code><code>&#13;
</code><code>                             </code><code class="n">mcse_sd</code><code>     </code><code class="n">ess_bulk</code><code>     </code><code class="n">ess_tail</code><code>     </code><code class="n">r_hat</code><code>&#13;
</code><code>       </code><code class="n">coeff_age</code><code>            </code><code class="mf">0.002200</code><code>  </code><code class="mf">2787.022099</code><code>  </code><code class="mf">3536.314548</code><code>  </code><code class="mf">1.000542</code><code>&#13;
</code><code>       </code><code class="n">coeff_job</code><code>            </code><code class="mf">0.002090</code><code>  </code><code class="mf">2818.973167</code><code>  </code><code class="mf">3038.790307</code><code>  </code><code class="mf">1.001246</code><code>&#13;
</code><code>       </code><code class="n">coeff_credit_amount</code><code>  </code><code class="mf">0.005670</code><code>  </code><code class="mf">1476.746667</code><code>  </code><code class="mf">2289.532062</code><code>  </code><code class="mf">1.001746</code><code>&#13;
</code><code>       </code><code class="n">coeff_duration</code><code>       </code><code class="mf">0.004826</code><code>  </code><code class="mf">1369.393339</code><code>  </code><code class="mf">2135.308468</code><code>  </code><code class="mf">1.001022</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO12-1" id="callout_credit_risk_estimation_CO12-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Importing the <code>logging</code> package to suppress the warning messages</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO12-2" id="callout_credit_risk_estimation_CO12-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Naming the package for logging</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO12-3" id="callout_credit_risk_estimation_CO12-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Suppressing errors without raising exceptions</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO12-4" id="callout_credit_risk_estimation_CO12-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Initiating the M-H model</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO12-5" id="callout_credit_risk_estimation_CO12-5"><img alt="5" src="assets/5.png"/></a></dt>&#13;
<dd><p>Running the model with 10,000 samples and ignoring the progress bar</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO12-6" id="callout_credit_risk_estimation_CO12-6"><img alt="6" src="assets/6.png"/></a></dt>&#13;
<dd><p>Creating a simple posterior plot using <code>plot_trace</code></p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO12-7" id="callout_credit_risk_estimation_CO12-7"><img alt="7" src="assets/7.png"/></a></dt>&#13;
<dd><p>Printing the first four rows of the summary result</p></dd>&#13;
</dl>&#13;
&#13;
<figure><div class="figure" id="MCMC_risk_cluster1">&#13;
<img alt="MCMC_risk_cluster1" src="assets/mlfr_0611.png"/>&#13;
<h6><span class="label">Figure 6-11. </span>Bayesian estimation with M—H with first cluster</h6>&#13;
</div></figure>&#13;
&#13;
<p>The result suggests that the predictive performances are supposed be very close to that of logistic regression, as the estimated coefficients of these two models are quite similar.<a data-primary="" data-startref="ix_PYMC3_package" data-type="indexterm" id="idm45737220614560"/></p>&#13;
&#13;
<p>In <a data-type="xref" href="#MCMC_risk_cluster1">Figure 6-11</a>, we see the dashed and solid lines. Given the first cluster data, the plot located on the lefthand side of <a data-type="xref" href="#MCMC_risk_cluster1">Figure 6-11</a> shows the sample values of the related parameters. Though it is not our present focus, we can observe the deterministic variable, <em>p</em>, located in the last plot.</p>&#13;
&#13;
<p>In a similar vein, the result of Bayesian estimation with M-H based on the second cluster performs very closely to the logistic regression. However, the results obtained from MAP application are better, which is expected primarily because M-H works with random sampling.&#13;
It is not, however, the only potential reason for this small deviation that we’ll discuss.</p>&#13;
&#13;
<p>As for the data that we obtained from the second cluster, the result of Bayesian estimation with M-H can be seen in the following code, which also creates the plot shown in <a data-type="xref" href="#MCMC_risk_cluster2">Figure 6-12</a>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">52</code><code class="p">]:</code> <code class="k">with</code> <code class="n">logistic_model2</code><code class="p">:</code>&#13;
             <code class="n">step</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">Metropolis</code><code class="p">()</code>&#13;
             <code class="n">trace</code> <code class="o">=</code> <code class="n">pm</code><code class="o">.</code><code class="n">sample</code><code class="p">(</code><code class="mi">10000</code><code class="p">,</code> <code class="n">step</code><code class="o">=</code><code class="n">step</code><code class="p">,</code><code class="n">progressbar</code> <code class="o">=</code> <code class="bp">False</code><code class="p">)</code>&#13;
         <code class="n">az</code><code class="o">.</code><code class="n">plot_trace</code><code class="p">(</code><code class="n">trace</code><code class="p">)</code>&#13;
         <code class="n">plt</code><code class="o">.</code><code class="n">show</code><code class="p">()</code>&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">53</code><code class="p">]:</code> <code class="k">with</code> <code class="n">logistic_model2</code><code class="p">:</code>&#13;
             <code class="n">display</code><code class="p">(</code><code class="n">az</code><code class="o">.</code><code class="n">summary</code><code class="p">(</code><code class="n">trace</code><code class="p">,</code> <code class="n">round_to</code><code class="o">=</code><code class="mi">6</code><code class="p">)[:</code><code class="mi">4</code><code class="p">])</code>&#13;
<code class="n">Out</code><code class="p">[]:</code>                          <code class="n">mean</code>        <code class="n">sd</code>    <code class="n">hdi_3</code><code class="o">%</code>   <code class="n">hdi_97</code><code class="o">%</code>  <code class="n">mcse_mean</code>  \&#13;
       <code class="n">coeff_age</code>            <code class="mf">0.029953</code>  <code class="mf">0.151466</code> <code class="o">-</code><code class="mf">0.262319</code>  <code class="mf">0.309050</code>   <code class="mf">0.002855</code>&#13;
       <code class="n">coeff_job</code>            <code class="mf">0.158140</code>  <code class="mf">0.153030</code> <code class="o">-</code><code class="mf">0.125043</code>  <code class="mf">0.435734</code>   <code class="mf">0.003513</code>&#13;
       <code class="n">coeff_credit_amount</code> <code class="o">-</code><code class="mf">0.108844</code>  <code class="mf">0.116542</code> <code class="o">-</code><code class="mf">0.328353</code>  <code class="mf">0.105858</code>   <code class="mf">0.003511</code>&#13;
       <code class="n">coeff_duration</code>       <code class="mf">0.103149</code>  <code class="mf">0.128264</code> <code class="o">-</code><code class="mf">0.142609</code>  <code class="mf">0.339575</code>   <code class="mf">0.003720</code>&#13;
&#13;
                             <code class="n">mcse_sd</code>     <code class="n">ess_bulk</code>     <code class="n">ess_tail</code>     <code class="n">r_hat</code>&#13;
       <code class="n">coeff_age</code>            <code class="mf">0.002019</code>  <code class="mf">2823.255277</code>  <code class="mf">3195.005913</code>  <code class="mf">1.000905</code>&#13;
       <code class="n">coeff_job</code>            <code class="mf">0.002485</code>  <code class="mf">1886.026245</code>  <code class="mf">2336.516309</code>  <code class="mf">1.000594</code>&#13;
       <code class="n">coeff_credit_amount</code>  <code class="mf">0.002483</code>  <code class="mf">1102.228318</code>  <code class="mf">1592.047959</code>  <code class="mf">1.002032</code>&#13;
       <code class="n">coeff_duration</code>       <code class="mf">0.002631</code>  <code class="mf">1188.042552</code>  <code class="mf">1900.179695</code>  <code class="mf">1.000988</code></pre>&#13;
&#13;
<figure><div class="figure" id="MCMC_risk_cluster2">&#13;
<img alt="MCMC_risk_cluster2" src="assets/mlfr_0612.png"/>&#13;
<h6><span class="label">Figure 6-12. </span>Bayesian estimation with M—H with second cluster</h6>&#13;
</div></figure>&#13;
&#13;
<p>Let’s now discuss the limitations of the M-H model, which may shed some light on the discrepancies across the model results. One disadvantage of the M-H algorithm is its sensitivity to step size. Small steps hinder the convergence process. Conversely, big steps may cause a high rejection rate.&#13;
Besides, M-H may suffer from rare events—as the probability of these events are low, requiring a large sample to obtain a reliable estimation—and that is our focus in this case.<a data-primary="" data-startref="ix_mcmc_method2" data-type="indexterm" id="idm45737220323744"/><a data-primary="" data-startref="ix_m-h_algorithm2" data-type="indexterm" id="idm45737220322896"/></p>&#13;
&#13;
<p><a data-primary="logistic regression" data-secondary="probability of default estimation" data-type="indexterm" id="ix_log_reg_prob_def_est2"/><a data-primary="probability approaches" data-secondary="for default estimation" data-secondary-sortas="default estimation" data-tertiary="logistic regression" data-type="indexterm" id="ix_prob_def_est_log_reg2"/>Now, let’s consider what happens if we use SVM to predict probability of default and compare its performance with logistic regression.<a data-primary="" data-startref="ix_bayesian_prob_def_est" data-type="indexterm" id="idm45737220318848"/><a data-primary="" data-startref="ix_credit_risk_prob_def_est_bayes" data-type="indexterm" id="idm45737220318000"/><a data-primary="" data-startref="ix_prob_def_est_bayes" data-type="indexterm" id="idm45737220317152"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Probability of Default Estimation with Support Vector Machines" data-type="sect2"><div class="sect2" id="idm45737221867120">&#13;
<h2>Probability of Default Estimation with Support Vector Machines</h2>&#13;
&#13;
<p><a data-primary="probability approaches" data-secondary="for default estimation" data-secondary-sortas="default estimation" data-tertiary="with support vector machines" data-tertiary-sortas="support vector machines" data-type="indexterm" id="ix_prob_app_def_est_svm"/><a data-primary="SVMs (support vector machines)" data-type="indexterm" id="ix_svm_ch6"/><a data-primary="parametric modeling" data-type="indexterm" id="ix_param_mod"/><a data-primary="ML (machine learning)" data-secondary="support vector machines" data-type="indexterm" id="ix_ml_svm_ch6"/><a data-primary="credit risk" data-secondary="probability of default estimation" data-tertiary="support vector machines" data-type="indexterm" id="ix_credit_risk_prob_def_est_svm"/>SVM is thought to be a parametric model, and it works well with high-dimensional data. The probability of default case in a multivariate setting may provide fertile ground for running SVM. <a data-primary="hyperparameter tuning" data-type="indexterm" id="ix_hyperparam_tune"/><a data-primary="HalvingRandomSearchCV" data-type="indexterm" id="ix_HalvingRandomSearchCV"/>Before proceeding, it would be a good idea to briefly &#13;
<span class="keep-together">discuss</span> a new approach that we will use to run hyperparameter tuning, namely &#13;
<span class="keep-together"><code>HalvingRandomSearchCV</code>.</span></p>&#13;
&#13;
<p><code>HalvingRandomSearchCV</code> works with iterative selection so that it uses fewer resources, thereby boosting performance and getting you some time back. <code>HalvingRandomSearchCV</code> tries to find the optimal parameters using successive halving to identify candidate parameters. The logic behind this process is as follows:</p>&#13;
<ol>&#13;
<li>&#13;
<p>Evaluate all parameter combinations, exploiting a certain number of training samples at first iteration.</p>&#13;
</li>&#13;
<li>&#13;
<p>Use some of the selected parameters in the second iteration with a large number of training samples.</p>&#13;
</li>&#13;
<li>&#13;
<p>Only include the top-scoring candidates in the model until the last iteration.</p>&#13;
</li>&#13;
&#13;
</ol>&#13;
&#13;
<p><a data-primary="SVC (support vector classification)" data-type="indexterm" id="idm45737220301136"/>Using the credit dataset, we predict the probability of default with support vector classification (SVC). Again, we use two different datasets based on the clustering we performed at the very first part of this chapter. The results are provided in the &#13;
<span class="keep-together">following</span>:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">54</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">sklearn.svm</code><code> </code><code class="kn">import</code><code> </code><code class="n">SVC</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">sklearn.experimental</code><code> </code><code class="kn">import</code><code> </code><code class="n">enable_halving_search_cv</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO13-1" id="co_credit_risk_estimation_CO13-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">sklearn.model_selection</code><code> </code><code class="kn">import</code><code> </code><code class="n">HalvingRandomSearchCV</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO13-2" id="co_credit_risk_estimation_CO13-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>         </code><code class="kn">import</code><code> </code><code class="nn">time</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">55</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">param_svc</code><code> </code><code class="o">=</code><code> </code><code class="p">{</code><code class="s1">'</code><code class="s1">gamma</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="p">[</code><code class="mf">1e-6</code><code class="p">,</code><code> </code><code class="mf">1e-2</code><code class="p">]</code><code class="p">,</code><code>&#13;
</code><code>                      </code><code class="s1">'</code><code class="s1">C</code><code class="s1">'</code><code class="p">:</code><code class="p">[</code><code class="mf">0.001</code><code class="p">,</code><code class="o">.</code><code class="mi">09</code><code class="p">,</code><code class="mi">1</code><code class="p">,</code><code class="mi">5</code><code class="p">,</code><code class="mi">10</code><code class="p">]</code><code class="p">,</code><code>&#13;
</code><code>                      </code><code class="s1">'</code><code class="s1">kernel</code><code class="s1">'</code><code class="p">:</code><code class="p">(</code><code class="s1">'</code><code class="s1">linear</code><code class="s1">'</code><code class="p">,</code><code class="s1">'</code><code class="s1">rbf</code><code class="s1">'</code><code class="p">)</code><code class="p">}</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">56</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">svc</code><code> </code><code class="o">=</code><code> </code><code class="n">SVC</code><code class="p">(</code><code class="n">class_weight</code><code class="o">=</code><code class="s1">'</code><code class="s1">balanced</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">halve_SVC</code><code> </code><code class="o">=</code><code> </code><code class="n">HalvingRandomSearchCV</code><code class="p">(</code><code class="n">svc</code><code class="p">,</code><code> </code><code class="n">param_svc</code><code class="p">,</code><code>&#13;
</code><code>                                           </code><code class="n">scoring</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">roc_auc</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">n_jobs</code><code class="o">=</code><code class="o">-</code><code class="mi">1</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO13-3" id="co_credit_risk_estimation_CO13-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>         </code><code class="n">halve_SVC</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train1</code><code class="p">,</code><code> </code><code class="n">y_train1</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">Best hyperparameters for first cluster in SVC {} with {}</code><code class="s1">'</code><code class="o">.</code><code>&#13;
</code><code>               </code><code class="n">format</code><code class="p">(</code><code class="n">halve_SVC</code><code class="o">.</code><code class="n">best_score_</code><code class="p">,</code><code> </code><code class="n">halve_SVC</code><code class="o">.</code><code class="n">best_params_</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">Best</code><code> </code><code class="n">hyperparameters</code><code> </code><code class="k">for</code><code> </code><code class="n">first</code><code> </code><code class="n">cluster</code><code> </code><code class="ow">in</code><code> </code><code class="n">SVC</code><code> </code><code class="mf">0.8273860106443562</code><code> </code><code class="k">with</code><code>&#13;
</code><code>         </code><code class="p">{</code><code class="s1">'</code><code class="s1">kernel</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="s1">'</code><code class="s1">rbf</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">gamma</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="mf">0.01</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">C</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="mi">1</code><code class="p">}</code><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">57</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">y_pred_SVC1</code><code> </code><code class="o">=</code><code> </code><code class="n">halve_SVC</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test1</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO13-4" id="co_credit_risk_estimation_CO13-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code>         </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">The ROC AUC score of SVC for first cluster is {:.4f}</code><code class="s1">'</code><code class="o">.</code><code>&#13;
</code><code>               </code><code class="n">format</code><code class="p">(</code><code class="n">roc_auc_score</code><code class="p">(</code><code class="n">y_test1</code><code class="p">,</code><code> </code><code class="n">y_pred_SVC1</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">The</code><code> </code><code class="n">ROC</code><code> </code><code class="n">AUC</code><code> </code><code class="n">score</code><code> </code><code class="n">of</code><code> </code><code class="n">SVC</code><code> </code><code class="k">for</code><code> </code><code class="n">first</code><code> </code><code class="n">cluster</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.5179</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO13-1" id="callout_credit_risk_estimation_CO13-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Importing the library to enable successive halving search</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO13-2" id="callout_credit_risk_estimation_CO13-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Importing the library to run the halving search</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO13-3" id="callout_credit_risk_estimation_CO13-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Running the halving search using parallel processing</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO13-4" id="callout_credit_risk_estimation_CO13-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Running a prediction analysis</p></dd>&#13;
</dl>&#13;
&#13;
<p>An important step to take in SVM is hyperparameter tuning. Using a halving search approach, we try to find out the best combination of <code>kernel</code>, <code>gamma</code>, and <code>C</code>. It turns out that the only difference across the two different samples occurs in the <code>gamma</code> and <code>C</code> hyperparameters. In the first cluster, the optimal <code>C</code> score is 1, whereas it is 0.001 in the second one. The higher <code>C</code> value indicates that we should choose a smaller margin to make a better classification. As for the <code>gamma</code> hyperparameter, both clusters take the same value. Having a lower <code>gamma</code> amounts to a larger influence of the support vector on the decision. The optimal kernel is Gaussian, and the <code>gamma</code> value is 0.01 for both &#13;
<span class="keep-together">clusters</span>.</p>&#13;
&#13;
<p>The AUC performance criteria indicates that the predictive performance of SVC is slightly below that of logistic regression. More precisely, AUC of the SVC is 0.5179, and that implies that  SVC performs worse than logistic regression for the first cluster. <a data-primary="" data-startref="ix_HalvingRandomSearchCV" data-type="indexterm" id="idm45737220258944"/><a data-primary="" data-startref="ix_hyperparam_tune" data-type="indexterm" id="idm45737220257904"/><a data-primary="" data-startref="ix_log_reg_prob_def_est2" data-type="indexterm" id="idm45737220256960"/><a data-primary="" data-startref="ix_prob_def_est_log_reg2" data-type="indexterm" id="idm45737220256000"/></p>&#13;
&#13;
<p>The second cluster shows that the performance of SVC is even slightly worse than that of the first cluster, and this indicates the SVC does not perform well on this data, as it is not clearly separable data, this implies that SVC does not work well with low-dimensional spaces:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">58</code><code class="p">]:</code> <code class="n">halve_SVC</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train2</code><code class="p">,</code> <code class="n">y_train2</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Best hyperparameters for second cluster in SVC {} with {}'</code><code class="o">.</code>&#13;
               <code class="n">format</code><code class="p">(</code><code class="n">halve_SVC</code><code class="o">.</code><code class="n">best_score_</code><code class="p">,</code> <code class="n">halve_SVC</code><code class="o">.</code><code class="n">best_params_</code><code class="p">))</code>&#13;
         <code class="n">Best</code> <code class="n">hyperparameters</code> <code class="k">for</code> <code class="n">second</code> <code class="n">cluster</code> <code class="ow">in</code> <code class="n">SVC</code> <code class="mf">0.5350758636788049</code> <code class="k">with</code>&#13;
         <code class="p">{</code><code class="s1">'kernel'</code><code class="p">:</code> <code class="s1">'rbf'</code><code class="p">,</code> <code class="s1">'gamma'</code><code class="p">:</code> <code class="mf">0.01</code><code class="p">,</code> <code class="s1">'C'</code><code class="p">:</code> <code class="mf">0.001</code><code class="p">}</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">59</code><code class="p">]:</code> <code class="n">y_pred_SVC2</code> <code class="o">=</code> <code class="n">halve_SVC</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test2</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'The ROC AUC score of SVC for first cluster is {:.4f}'</code><code class="o">.</code>&#13;
               <code class="n">format</code><code class="p">(</code><code class="n">roc_auc_score</code><code class="p">(</code><code class="n">y_test2</code><code class="p">,</code> <code class="n">y_pred_SVC2</code><code class="p">)))</code>&#13;
         <code class="n">The</code> <code class="n">ROC</code> <code class="n">AUC</code> <code class="n">score</code> <code class="n">of</code> <code class="n">SVC</code> <code class="k">for</code> <code class="n">first</code> <code class="n">cluster</code> <code class="ow">is</code> <code class="mf">0.5000</code></pre>&#13;
&#13;
<p><a data-primary="nonparametric modeling" data-type="indexterm" id="idm45737219973072"/>Well, maybe we’ve had enough of parametric methods—let’s move on to nonparametric methods. Now, the word <em>nonparametric</em> may sound confusing, but it is nothing but a model with an infinite number of parameters, and one that becomes more complex as the number of observations increases. Random forest is one of the most applicable nonparametric models in ML, and we’ll discuss that next.<a data-primary="" data-startref="ix_credit_risk_prob_def_est_svm" data-type="indexterm" id="idm45737219861648"/><a data-primary="" data-startref="ix_ml_svm_ch6" data-type="indexterm" id="idm45737219860800"/><a data-primary="" data-startref="ix_param_mod" data-type="indexterm" id="idm45737219859952"/><a data-primary="" data-startref="ix_svm_ch6" data-type="indexterm" id="idm45737219859104"/><a data-primary="" data-startref="ix_prob_app_def_est_svm" data-type="indexterm" id="idm45737219858256"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Probability of Default Estimation with Random Forest" data-type="sect2"><div class="sect2" id="idm45737220316048">&#13;
<h2>Probability of Default Estimation with Random Forest</h2>&#13;
&#13;
<p><a data-primary="probability approaches" data-secondary="for default estimation" data-secondary-sortas="default estimation" data-tertiary="with random forest" data-tertiary-sortas="random forest" data-type="indexterm" id="ix_prob_app_def_est_ran_for"/><a data-primary="random forest model" data-secondary="probability of default estimation" data-type="indexterm" id="ix_random_for_def_est"/><a data-primary="credit risk" data-secondary="probability of default estimation" data-tertiary="random forest" data-type="indexterm" id="ix_credit_risk_prob_def_ran_for"/>The random forest classifier is another model we can employ to model the probability of default. Although random forest fails in high-dimensional cases, our data is not that complex, and the beauty of random forest lies in its good predictive performance in the presence of a large number of samples, so it’s plausible to think that the random forest model might outperform the&#13;
SVC model.</p>&#13;
&#13;
<p>Using halving search approach, we try to find out the best combination of <code>n_estimators</code>, <code>criterion</code>, <code>max_features</code>, <code>max_depth</code>, <code>min_samples_split</code>. The result suggests that we use <code>n_estimators</code> of 300, <code>min_samples_split</code> of 10, <code>max_depth</code> of 6 with a gini criterion, and <code>sqrt</code> <code>max_features</code> for the first cluster. As for the second cluster, we have two different optimal hyperparameters as can be seen in the following. Having larger depth in a tree-based model amounts to having a more complex model. With that said, the model proposed for the second cluster is a bit more complex. The <code>max_features</code> hyperparameter seems to be different across samples; in the first cluster, the maximum number of features is picked via <math alttext="StartRoot number of features EndRoot">&#13;
  <msqrt>&#13;
    <mrow>&#13;
      <mtext>number</mtext>&#13;
      <mspace width="4.pt"/>&#13;
      <mtext>of</mtext>&#13;
      <mspace width="4.pt"/>&#13;
      <mtext>features</mtext>&#13;
    </mrow>&#13;
  </msqrt>&#13;
</math>.</p>&#13;
&#13;
<p>Given the first cluster data, the AUC score of 0.5387 indicates that random forest has a better performance compared to the other models:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">60</code><code class="p">]:</code> <code class="kn">from</code> <code class="nn">sklearn.ensemble</code> <code class="kn">import</code> <code class="n">RandomForestClassifier</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">61</code><code class="p">]:</code> <code class="n">rfc</code> <code class="o">=</code> <code class="n">RandomForestClassifier</code><code class="p">(</code><code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">62</code><code class="p">]:</code> <code class="n">param_rfc</code> <code class="o">=</code> <code class="p">{</code><code class="s1">'n_estimators'</code><code class="p">:</code> <code class="p">[</code><code class="mi">100</code><code class="p">,</code> <code class="mi">300</code><code class="p">],</code>&#13;
             <code class="s1">'criterion'</code> <code class="p">:[</code><code class="s1">'gini'</code><code class="p">,</code> <code class="s1">'entropy'</code><code class="p">],</code>&#13;
             <code class="s1">'max_features'</code><code class="p">:</code> <code class="p">[</code><code class="s1">'auto'</code><code class="p">,</code> <code class="s1">'sqrt'</code><code class="p">,</code> <code class="s1">'log2'</code><code class="p">],</code>&#13;
             <code class="s1">'max_depth'</code> <code class="p">:</code> <code class="p">[</code><code class="mi">3</code><code class="p">,</code> <code class="mi">4</code><code class="p">,</code> <code class="mi">5</code><code class="p">,</code> <code class="mi">6</code><code class="p">],</code>&#13;
             <code class="s1">'min_samples_split'</code><code class="p">:[</code><code class="mi">5</code><code class="p">,</code> <code class="mi">10</code><code class="p">]}</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">63</code><code class="p">]:</code> <code class="n">halve_RF</code> <code class="o">=</code> <code class="n">HalvingRandomSearchCV</code><code class="p">(</code><code class="n">rfc</code><code class="p">,</code> <code class="n">param_rfc</code><code class="p">,</code>&#13;
                                          <code class="n">scoring</code> <code class="o">=</code> <code class="s1">'roc_auc'</code><code class="p">,</code> <code class="n">n_jobs</code><code class="o">=-</code><code class="mi">1</code><code class="p">)</code>&#13;
         <code class="n">halve_RF</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train1</code><code class="p">,</code> <code class="n">y_train1</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Best hyperparameters for first cluster in RF {} with {}'</code><code class="o">.</code>&#13;
               <code class="n">format</code><code class="p">(</code><code class="n">halve_RF</code><code class="o">.</code><code class="n">best_score_</code><code class="p">,</code> <code class="n">halve_RF</code><code class="o">.</code><code class="n">best_params_</code><code class="p">))</code>&#13;
         <code class="n">Best</code> <code class="n">hyperparameters</code> <code class="k">for</code> <code class="n">first</code> <code class="n">cluster</code> <code class="ow">in</code> <code class="n">RF</code> <code class="mf">0.8890871444218126</code> <code class="k">with</code>&#13;
         <code class="p">{</code><code class="s1">'n_estimators'</code><code class="p">:</code> <code class="mi">300</code><code class="p">,</code> <code class="s1">'min_samples_split'</code><code class="p">:</code> <code class="mi">10</code><code class="p">,</code> <code class="s1">'max_features'</code><code class="p">:</code> <code class="s1">'sqrt'</code><code class="p">,</code>&#13;
         <code class="s1">'max_depth'</code><code class="p">:</code> <code class="mi">6</code><code class="p">,</code> <code class="s1">'criterion'</code><code class="p">:</code> <code class="s1">'gini'</code><code class="p">}</code>&#13;
&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">64</code><code class="p">]:</code> <code class="n">y_pred_RF1</code> <code class="o">=</code> <code class="n">halve_RF</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test1</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'The ROC AUC score of RF for first cluster is {:.4f}'</code><code class="o">.</code>&#13;
               <code class="n">format</code><code class="p">(</code><code class="n">roc_auc_score</code><code class="p">(</code><code class="n">y_test1</code><code class="p">,</code> <code class="n">y_pred_RF1</code><code class="p">)))</code>&#13;
         <code class="n">The</code> <code class="n">ROC</code> <code class="n">AUC</code> <code class="n">score</code> <code class="n">of</code> <code class="n">RF</code> <code class="k">for</code> <code class="n">first</code> <code class="n">cluster</code> <code class="ow">is</code> <code class="mf">0.5387</code></pre>&#13;
&#13;
<p>The following code shows a random forest run based on the second cluster:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">65</code><code class="p">]:</code> <code class="n">halve_RF</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train2</code><code class="p">,</code> <code class="n">y_train2</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Best hyperparameters for second cluster in RF {} with {}'</code><code class="o">.</code>&#13;
               <code class="n">format</code><code class="p">(</code><code class="n">halve_RF</code><code class="o">.</code><code class="n">best_score_</code><code class="p">,</code> <code class="n">halve_RF</code><code class="o">.</code><code class="n">best_params_</code><code class="p">))</code>&#13;
         <code class="n">Best</code> <code class="n">hyperparameters</code> <code class="k">for</code> <code class="n">second</code> <code class="n">cluster</code> <code class="ow">in</code> <code class="n">RF</code> <code class="mf">0.6565</code> <code class="k">with</code>&#13;
         <code class="p">{</code><code class="s1">'n_estimators'</code><code class="p">:</code> <code class="mi">100</code><code class="p">,</code> <code class="s1">'min_samples_split'</code><code class="p">:</code> <code class="mi">5</code><code class="p">,</code> <code class="s1">'max_features'</code><code class="p">:</code> <code class="s1">'auto'</code><code class="p">,</code>&#13;
         <code class="s1">'max_depth'</code><code class="p">:</code> <code class="mi">5</code><code class="p">,</code> <code class="s1">'criterion'</code><code class="p">:</code> <code class="s1">'entropy'</code><code class="p">}</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">66</code><code class="p">]:</code> <code class="n">y_pred_RF2</code> <code class="o">=</code> <code class="n">halve_RF</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test2</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'The ROC AUC score of RF for first cluster is {:.4f}'</code><code class="o">.</code>&#13;
               <code class="n">format</code><code class="p">(</code><code class="n">roc_auc_score</code><code class="p">(</code><code class="n">y_test2</code><code class="p">,</code> <code class="n">y_pred_RF2</code><code class="p">)))</code>&#13;
         <code class="n">The</code> <code class="n">ROC</code> <code class="n">AUC</code> <code class="n">score</code> <code class="n">of</code> <code class="n">RF</code> <code class="k">for</code> <code class="n">first</code> <code class="n">cluster</code> <code class="ow">is</code> <code class="mf">0.5906</code></pre>&#13;
&#13;
<p>Random forest has a much better predictive performance in the second cluster, with an AUC score of 0.5906. Given the predictive performance of&#13;
random forest, we can conclude that random forest does a better job of fitting the data. This is partly because of the low-dimensional characteristics of the data, as random forest turns &#13;
<span class="keep-together">out to</span> be a good choice when data has low dimensionality and a large number of &#13;
<span class="keep-together">observations</span>. <a data-primary="" data-startref="ix_credit_risk_prob_def_ran_for" data-type="indexterm" id="idm45737219481504"/><a data-primary="" data-startref="ix_prob_app_def_est_ran_for" data-type="indexterm" id="idm45737219480528"/><a data-primary="" data-startref="ix_random_for_def_est" data-type="indexterm" id="idm45737219479568"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Probability of Default Estimation with Neural Network" data-type="sect2"><div class="sect2" id="idm45737219478496">&#13;
<h2>Probability of Default Estimation with Neural Network</h2>&#13;
&#13;
<p><a data-primary="NNs (neural networks)" data-secondary="in probability of default estimation" data-secondary-sortas="probability of default estimation" data-type="indexterm" id="idm45737219477152"/><a data-primary="probability approaches" data-secondary="for default estimation" data-secondary-sortas="default estimation" data-tertiary="with neural network" data-tertiary-sortas="neural network" data-type="indexterm" id="idm45737219475872"/><a data-primary="credit risk" data-secondary="probability of default estimation" data-tertiary="neural network" data-type="indexterm" id="idm45737219474112"/>Given the complexity of the probability of default estimation, unveiling the hidden structure of the data is a tough task, but the NN structure does a good job handling this, so it would be an ideal candidate model for such tasks. <a data-primary="GridSearchCV" data-type="indexterm" id="idm45737219472512"/>&#13;
In setting up the NN model, <code>GridSearchCV</code> is used to optimize the number of hidden layers, optimization technique, and learning rate.</p>&#13;
&#13;
<p><a data-primary="MLP library" data-type="indexterm" id="idm45737219470928"/>In running the model, we first employ the <code>MLP</code> library, which allows us to control for many parameters, including hidden layer size, optimization technique (solver), and learning rate. Comparing the optimized hyperparameters of the two clusters indicates that&#13;
the only difference is in the number of neurons in the hidden layer. Accordingly, we have larger number of neurons in the first hidden layer in cluster one. However, the neuron number is larger in the second hidden layer in the second cluster.</p>&#13;
&#13;
<p>The following code suggests that data based on the first cluster is only a marginal improvement. In other words, the AUC moves to 0.5263, only slightly worse than&#13;
random forest:</p>&#13;
&#13;
<pre class="pagebreak-before less_space" data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">67</code><code class="p">]:</code> <code class="kn">from</code> <code class="nn">sklearn.neural_network</code> <code class="kn">import</code> <code class="n">MLPClassifier</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">68</code><code class="p">]:</code> <code class="n">param_NN</code> <code class="o">=</code> <code class="p">{</code><code class="s2">"hidden_layer_sizes"</code><code class="p">:</code> <code class="p">[(</code><code class="mi">100</code><code class="p">,</code> <code class="mi">50</code><code class="p">),</code> <code class="p">(</code><code class="mi">50</code><code class="p">,</code> <code class="mi">50</code><code class="p">),</code> <code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">100</code><code class="p">)],</code>&#13;
                     <code class="s2">"solver"</code><code class="p">:</code> <code class="p">[</code><code class="s2">"lbfgs"</code><code class="p">,</code> <code class="s2">"sgd"</code><code class="p">,</code> <code class="s2">"adam"</code><code class="p">],</code>&#13;
                     <code class="s2">"learning_rate_init"</code><code class="p">:</code> <code class="p">[</code><code class="mf">0.001</code><code class="p">,</code> <code class="mf">0.05</code><code class="p">]}</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">69</code><code class="p">]:</code> <code class="n">MLP</code> <code class="o">=</code> <code class="n">MLPClassifier</code><code class="p">(</code><code class="n">random_state</code><code class="o">=</code><code class="mi">42</code><code class="p">)</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">70</code><code class="p">]:</code> <code class="n">param_halve_NN</code> <code class="o">=</code> <code class="n">HalvingRandomSearchCV</code><code class="p">(</code><code class="n">MLP</code><code class="p">,</code> <code class="n">param_NN</code><code class="p">,</code>&#13;
                                                <code class="n">scoring</code> <code class="o">=</code> <code class="s1">'roc_auc'</code><code class="p">)</code>&#13;
         <code class="n">param_halve_NN</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train1</code><code class="p">,</code> <code class="n">y_train1</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Best hyperparameters for first cluster in NN are {}'</code><code class="o">.</code>&#13;
               <code class="n">format</code><code class="p">(</code><code class="n">param_halve_NN</code><code class="o">.</code><code class="n">best_params_</code><code class="p">))</code>&#13;
         <code class="n">Best</code> <code class="n">hyperparameters</code> <code class="k">for</code> <code class="n">first</code> <code class="n">cluster</code> <code class="ow">in</code> <code class="n">NN</code> <code class="n">are</code> <code class="p">{</code><code class="s1">'solver'</code><code class="p">:</code> <code class="s1">'lbfgs'</code><code class="p">,</code>&#13;
         <code class="s1">'learning_rate_init'</code><code class="p">:</code> <code class="mf">0.05</code><code class="p">,</code> <code class="s1">'hidden_layer_sizes'</code><code class="p">:</code> <code class="p">(</code><code class="mi">100</code><code class="p">,</code> <code class="mi">50</code><code class="p">)}</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">71</code><code class="p">]:</code> <code class="n">y_pred_NN1</code> <code class="o">=</code> <code class="n">param_halve_NN</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test1</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'The ROC AUC score of NN for first cluster is {:.4f}'</code><code class="o">.</code>&#13;
               <code class="n">format</code><code class="p">(</code><code class="n">roc_auc_score</code><code class="p">(</code><code class="n">y_test1</code><code class="p">,</code> <code class="n">y_pred_NN1</code><code class="p">)))</code>&#13;
         <code class="n">The</code> <code class="n">ROC</code> <code class="n">AUC</code> <code class="n">score</code> <code class="n">of</code> <code class="n">NN</code> <code class="k">for</code> <code class="n">first</code> <code class="n">cluster</code> <code class="ow">is</code> <code class="mf">0.5263</code></pre>&#13;
&#13;
<p>The ROC-AUC score obtained from the second cluster is 0.6155, with two hidden layers endowed with 10 and 100 neurons, respectively. Moreover, the best optimization technique is <code>adam</code>, and optimum initial learning rate is 0.05. This is the highest AUC score we’ve obtained, implying that the NN is able to capture the dynamics of the complex and nonlinear data, as shown here:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">72</code><code class="p">]:</code> <code class="n">param_halve_NN</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train2</code><code class="p">,</code> <code class="n">y_train2</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Best hyperparameters for first cluster in NN are {}'</code><code class="o">.</code>&#13;
               <code class="n">format</code><code class="p">(</code><code class="n">param_halve_NN</code><code class="o">.</code><code class="n">best_params_</code><code class="p">))</code>&#13;
         <code class="n">Best</code> <code class="n">hyperparameters</code> <code class="k">for</code> <code class="n">first</code> <code class="n">cluster</code> <code class="ow">in</code> <code class="n">NN</code> <code class="n">are</code> <code class="p">{</code><code class="s1">'solver'</code><code class="p">:</code> <code class="s1">'lbfgs'</code><code class="p">,</code>&#13;
         <code class="s1">'learning_rate_init'</code><code class="p">:</code> <code class="mf">0.05</code><code class="p">,</code> <code class="s1">'hidden_layer_sizes'</code><code class="p">:</code> <code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">100</code><code class="p">)}</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">73</code><code class="p">]:</code> <code class="n">y_pred_NN2</code> <code class="o">=</code> <code class="n">param_halve_NN</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test2</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'The ROC AUC score of NN for first cluster is {:.4f}'</code><code class="o">.</code>&#13;
               <code class="n">format</code><code class="p">(</code><code class="n">roc_auc_score</code><code class="p">(</code><code class="n">y_test2</code><code class="p">,</code> <code class="n">y_pred_NN2</code><code class="p">)))</code>&#13;
         <code class="n">The</code> <code class="n">ROC</code> <code class="n">AUC</code> <code class="n">score</code> <code class="n">of</code> <code class="n">NN</code> <code class="k">for</code> <code class="n">first</code> <code class="n">cluster</code> <code class="ow">is</code> <code class="mf">0.6155</code></pre>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="Probability of Default Estimation with Deep Learning" data-type="sect2"><div class="sect2" id="idm45737219242592">&#13;
<h2>Probability of Default Estimation with Deep Learning</h2>&#13;
&#13;
<p><a data-primary="deep learning" data-secondary="probability of default estimation" data-type="indexterm" id="ix_dl_prob_def_est"/><a data-primary="probability approaches" data-secondary="for default estimation" data-secondary-sortas="default estimation" data-tertiary="with deep learning" data-tertiary-sortas="deep learning" data-type="indexterm" id="ix_prob_app_def_est_dl"/><a data-primary="TensorFlow" data-type="indexterm" id="ix_tensorflow1"/><a data-primary="credit risk" data-secondary="probability of default estimation" data-tertiary="deep learning" data-type="indexterm" id="ix_credit_risk_prob_def_est_dl"/><a data-primary="KerasClassifier" data-type="indexterm" id="ix_keras_class"/>Let’s now take a look at the performance of a deep learning model using TensorFlow via <code>KerasClassifier</code>, which enables us to control for the hyperparameters.</p>&#13;
&#13;
<p>The hyperparameters that we tune in this model are batch size, epoch, and dropout rate. As probability of default is a classification problem, the sigmoid activation function appears to be the optimal function to use.&#13;
Deep learning is based on the &#13;
<span class="keep-together">structure</span> of NNs, but provides a more complex structure, so it is expected to better capture the dynamics of data in a way that enables us to have better predictive &#13;
<span class="keep-together">performance</span>.</p>&#13;
&#13;
<p>As we can see in the following code, the predictive performance of the second sample stumbles, however, with an AUC score of 0.5628:</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">74</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">tensorflow</code><code> </code><code class="kn">import</code><code> </code><code class="n">keras</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">tensorflow.keras.wrappers.scikit_learn</code><code> </code><code class="kn">import</code><code> </code><code class="n">KerasClassifier</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO14-1" id="co_credit_risk_estimation_CO14-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">tensorflow.keras.layers</code><code> </code><code class="kn">import</code><code> </code><code class="n">Dense</code><code class="p">,</code><code> </code><code class="n">Dropout</code><code>&#13;
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">sklearn.model_selection</code><code> </code><code class="kn">import</code><code> </code><code class="n">GridSearchCV</code><code>&#13;
</code><code>         </code><code class="kn">import</code><code> </code><code class="nn">tensorflow</code><code> </code><code class="kn">as</code><code> </code><code class="nn">tf</code><code>&#13;
</code><code>         </code><code class="kn">import</code><code> </code><code class="nn">logging</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO14-2" id="co_credit_risk_estimation_CO14-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>         </code><code class="n">tf</code><code class="o">.</code><code class="n">get_logger</code><code class="p">(</code><code class="p">)</code><code class="o">.</code><code class="n">setLevel</code><code class="p">(</code><code class="n">logging</code><code class="o">.</code><code class="n">ERROR</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO14-3" id="co_credit_risk_estimation_CO14-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">75</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">DL_risk</code><code class="p">(</code><code class="n">dropout_rate</code><code class="p">,</code><code class="n">verbose</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code><code class="p">:</code><code>&#13;
</code><code>             </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">keras</code><code class="o">.</code><code class="n">Sequential</code><code class="p">(</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">128</code><code class="p">,</code><code class="n">kernel_initializer</code><code class="o">=</code><code class="s1">'</code><code class="s1">normal</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                 </code><code class="n">activation</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">input_dim</code><code class="o">=</code><code class="mi">4</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">64</code><code class="p">,</code><code> </code><code class="n">kernel_initializer</code><code class="o">=</code><code class="s1">'</code><code class="s1">normal</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                 </code><code class="n">activation</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">8</code><code class="p">,</code><code class="n">kernel_initializer</code><code class="o">=</code><code class="s1">'</code><code class="s1">normal</code><code class="s1">'</code><code class="p">,</code><code>&#13;
</code><code>                 </code><code class="n">activation</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dropout</code><code class="p">(</code><code class="n">dropout_rate</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s2">"</code><code class="s2">sigmoid</code><code class="s2">"</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">loss</code><code class="o">=</code><code class="s1">'</code><code class="s1">binary_crossentropy</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">optimizer</code><code class="o">=</code><code class="s1">'</code><code class="s1">rmsprop</code><code class="s1">'</code><code class="p">)</code><code>&#13;
</code><code>             </code><code class="k">return</code><code> </code><code class="n">model</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO14-1" id="callout_credit_risk_estimation_CO14-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Importing <code>KerasClassifier</code>  to run grid search</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO14-2" id="callout_credit_risk_estimation_CO14-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Importing <code>logging</code>  to suppress the warning messages</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO14-3" id="callout_credit_risk_estimation_CO14-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Naming TensorFlow for logging</p></dd>&#13;
</dl>&#13;
&#13;
<p>Given the optimized hyperparameters of dropout, batch size, and epoch, the deep learning model produces the best performance among the models we have employed so far, with an AUC score of 0.5614. <a data-primary="NNs (neural networks)" data-secondary="and deep learning" data-secondary-sortas="deep learning" data-type="indexterm" id="idm45737219037232"/>The difference between MLPClassifier and deep learning models used in this chapter is the number of neurons in the hidden layer. Technically, these two models are deep learning models with different structures.</p>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">76</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">parameters</code><code> </code><code class="o">=</code><code> </code><code class="p">{</code><code class="s1">'</code><code class="s1">batch_size</code><code class="s1">'</code><code class="p">:</code><code>  </code><code class="p">[</code><code class="mi">10</code><code class="p">,</code><code> </code><code class="mi">50</code><code class="p">,</code><code> </code><code class="mi">100</code><code class="p">]</code><code class="p">,</code><code>&#13;
</code><code>                   </code><code class="s1">'</code><code class="s1">epochs</code><code class="s1">'</code><code class="p">:</code><code>  </code><code class="p">[</code><code class="mi">50</code><code class="p">,</code><code> </code><code class="mi">100</code><code class="p">,</code><code> </code><code class="mi">150</code><code class="p">]</code><code class="p">,</code><code>&#13;
</code><code>                      </code><code class="s1">'</code><code class="s1">dropout_rate</code><code class="s1">'</code><code class="p">:</code><code class="p">[</code><code class="mf">0.2</code><code class="p">,</code><code> </code><code class="mf">0.4</code><code class="p">]</code><code class="p">}</code><code>&#13;
</code><code>         </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">KerasClassifier</code><code class="p">(</code><code class="n">build_fn</code><code> </code><code class="o">=</code><code> </code><code class="n">DL_risk</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO15-1" id="co_credit_risk_estimation_CO15-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>         </code><code class="n">gs</code><code> </code><code class="o">=</code><code> </code><code class="n">GridSearchCV</code><code class="p">(</code><code class="n">estimator</code><code> </code><code class="o">=</code><code> </code><code class="n">model</code><code class="p">,</code><code>&#13;
</code><code>                                </code><code class="n">param_grid</code><code> </code><code class="o">=</code><code> </code><code class="n">parameters</code><code class="p">,</code><code>&#13;
</code><code>                                   </code><code class="n">scoring</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">roc_auc</code><code class="s1">'</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO15-2" id="co_credit_risk_estimation_CO15-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>&#13;
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">77</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">gs</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train1</code><code class="p">,</code><code> </code><code class="n">y_train1</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">Best hyperparameters for first cluster in DL are {}</code><code class="s1">'</code><code class="o">.</code><code>&#13;
</code><code>               </code><code class="n">format</code><code class="p">(</code><code class="n">gs</code><code class="o">.</code><code class="n">best_params_</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">Best</code><code> </code><code class="n">hyperparameters</code><code> </code><code class="k">for</code><code> </code><code class="n">first</code><code> </code><code class="n">cluster</code><code> </code><code class="ow">in</code><code> </code><code class="n">DL</code><code> </code><code class="n">are</code><code> </code><code class="p">{</code><code class="s1">'</code><code class="s1">batch_size</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="mi">10</code><code class="p">,</code><code>&#13;
</code><code>         </code><code class="s1">'</code><code class="s1">dropout_rate</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="mf">0.2</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">epochs</code><code class="s1">'</code><code class="p">:</code><code> </code><code class="mi">50</code><code class="p">}</code></pre>&#13;
<dl class="calloutlist pagebreak-before less_space">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO15-1" id="callout_credit_risk_estimation_CO15-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Calling a predefined function named <code>DL_risk</code> to run with optimized &#13;
<span class="keep-together">hyperparameters</span></p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO15-2" id="callout_credit_risk_estimation_CO15-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Applying the grid search</p></dd>&#13;
</dl>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">78</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">KerasClassifier</code><code class="p">(</code><code class="n">build_fn</code><code> </code><code class="o">=</code><code> </code><code class="n">DL_risk</code><code class="p">,</code><code>                    </code><a class="co" href="#callout_credit_risk_estimation_CO16-1" id="co_credit_risk_estimation_CO16-1"><img alt="1" src="assets/1.png"/></a><code>&#13;
</code><code>                                 </code><code class="n">dropout_rate</code><code> </code><code class="o">=</code><code> </code><code class="n">gs</code><code class="o">.</code><code class="n">best_params_</code><code class="p">[</code><code class="s1">'</code><code class="s1">dropout_rate</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code>&#13;
</code><code>                                 </code><code class="n">verbose</code><code> </code><code class="o">=</code><code> </code><code class="mi">0</code><code class="p">,</code><code>&#13;
</code><code>                                 </code><code class="n">batch_size</code><code> </code><code class="o">=</code><code> </code><code class="n">gs</code><code class="o">.</code><code class="n">best_params_</code><code class="p">[</code><code class="s1">'</code><code class="s1">batch_size</code><code class="s1">'</code><code class="p">]</code><code class="p">,</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO16-2" id="co_credit_risk_estimation_CO16-2"><img alt="2" src="assets/2.png"/></a><code>&#13;
</code><code>                                 </code><code class="n">epochs</code><code> </code><code class="o">=</code><code> </code><code class="n">gs</code><code class="o">.</code><code class="n">best_params_</code><code class="p">[</code><code class="s1">'</code><code class="s1">epochs</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code> </code><a class="co" href="#callout_credit_risk_estimation_CO16-3" id="co_credit_risk_estimation_CO16-3"><img alt="3" src="assets/3.png"/></a><code>&#13;
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train1</code><code class="p">,</code><code> </code><code class="n">y_train1</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">DL_predict1</code><code> </code><code class="o">=</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test1</code><code class="p">)</code><code>                           </code><a class="co" href="#callout_credit_risk_estimation_CO16-4" id="co_credit_risk_estimation_CO16-4"><img alt="4" src="assets/4.png"/></a><code>&#13;
</code><code>         </code><code class="n">DL_ROC_AUC</code><code> </code><code class="o">=</code><code> </code><code class="n">roc_auc_score</code><code class="p">(</code><code class="n">y_test1</code><code class="p">,</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">DL_predict1</code><code class="o">.</code><code class="n">flatten</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="k">print</code><code class="p">(</code><code class="s1">'</code><code class="s1">DL_ROC_AUC is {:.4f}</code><code class="s1">'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">DL_ROC_AUC</code><code class="p">)</code><code class="p">)</code><code>&#13;
</code><code>         </code><code class="n">DL_ROC_AUC</code><code> </code><code class="ow">is</code><code> </code><code class="mf">0.5628</code></pre>&#13;
<dl class="calloutlist">&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO16-1" id="callout_credit_risk_estimation_CO16-1"><img alt="1" src="assets/1.png"/></a></dt>&#13;
<dd><p>Running deep learning algorithm with optimum hyperparameter of dropout rate</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO16-2" id="callout_credit_risk_estimation_CO16-2"><img alt="2" src="assets/2.png"/></a></dt>&#13;
<dd><p>Running deep learning algorithm with optimum hyperparameter of batch size</p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO16-3" id="callout_credit_risk_estimation_CO16-3"><img alt="3" src="assets/3.png"/></a></dt>&#13;
<dd><p>Running deep learning algorithm with optimum hyperparameter of epoch &#13;
<span class="keep-together">number</span></p></dd>&#13;
<dt><a class="co" href="#co_credit_risk_estimation_CO16-4" id="callout_credit_risk_estimation_CO16-4"><img alt="4" src="assets/4.png"/></a></dt>&#13;
<dd><p>Computing the ROC-AUC score after flattening the prediction</p></dd>&#13;
</dl>&#13;
&#13;
<pre data-code-language="python" data-type="programlisting"><code class="n">In</code> <code class="p">[</code><code class="mi">79</code><code class="p">]:</code> <code class="n">gs</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train2</code><code class="o">.</code><code class="n">values</code><code class="p">,</code> <code class="n">y_train2</code><code class="o">.</code><code class="n">values</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="mi">0</code><code class="p">)</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'Best parameters for second cluster in DL are {}'</code><code class="o">.</code>&#13;
               <code class="n">format</code><code class="p">(</code><code class="n">gs</code><code class="o">.</code><code class="n">best_params_</code><code class="p">))</code>&#13;
         <code class="n">Best</code> <code class="n">parameters</code> <code class="k">for</code> <code class="n">second</code> <code class="n">cluster</code> <code class="ow">in</code> <code class="n">DL</code> <code class="n">are</code> <code class="p">{</code><code class="s1">'batch_size'</code><code class="p">:</code> <code class="mi">10</code><code class="p">,</code>&#13;
         <code class="s1">'dropout_rate'</code><code class="p">:</code> <code class="mf">0.2</code><code class="p">,</code> <code class="s1">'epochs'</code><code class="p">:</code> <code class="mi">150</code><code class="p">}</code>&#13;
&#13;
<code class="n">In</code> <code class="p">[</code><code class="mi">80</code><code class="p">]:</code> <code class="n">model</code> <code class="o">=</code> <code class="n">KerasClassifier</code><code class="p">(</code><code class="n">build_fn</code> <code class="o">=</code> <code class="n">DL_risk</code><code class="p">,</code>&#13;
                                 <code class="n">dropout_rate</code><code class="o">=</code> <code class="n">gs</code><code class="o">.</code><code class="n">best_params_</code><code class="p">[</code><code class="s1">'dropout_rate'</code><code class="p">],</code>&#13;
                                 <code class="n">verbose</code> <code class="o">=</code> <code class="mi">0</code><code class="p">,</code>&#13;
                                 <code class="n">batch_size</code> <code class="o">=</code> <code class="n">gs</code><code class="o">.</code><code class="n">best_params_</code><code class="p">[</code><code class="s1">'batch_size'</code><code class="p">],</code>&#13;
                                 <code class="n">epochs</code> <code class="o">=</code> <code class="n">gs</code><code class="o">.</code><code class="n">best_params_</code><code class="p">[</code><code class="s1">'epochs'</code><code class="p">])</code>&#13;
         <code class="n">model</code><code class="o">.</code><code class="n">fit</code><code class="p">(</code><code class="n">X_train2</code><code class="p">,</code> <code class="n">y_train2</code><code class="p">)</code>&#13;
         <code class="n">DL_predict2</code> <code class="o">=</code>  <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">X_test2</code><code class="p">)</code>&#13;
         <code class="n">DL_ROC_AUC</code> <code class="o">=</code> <code class="n">roc_auc_score</code><code class="p">(</code><code class="n">y_test2</code><code class="p">,</code> <code class="n">DL_predict2</code><code class="o">.</code><code class="n">flatten</code><code class="p">())</code>&#13;
         <code class="k">print</code><code class="p">(</code><code class="s1">'DL_ROC_AUC is {:.4f}'</code><code class="o">.</code><code class="n">format</code><code class="p">(</code><code class="n">DL_ROC_AUC</code><code class="p">))</code>&#13;
         <code class="n">DL_ROC_AUC</code> <code class="ow">is</code> <code class="mf">0.5614</code></pre>&#13;
&#13;
<p>This finding confirms that DL models have become increasingly&#13;
popular in financial modeling. In the industry, however, due to the opaque nature of network structure, this method is suggested for use in conjunction with traditional models.<a data-primary="" data-startref="ix_credit_risk_prob_def_est" data-type="indexterm" id="idm45737218468928"/><a data-primary="" data-startref="ix_prob_app_def_est" data-type="indexterm" id="idm45737218467984"/><a data-primary="" data-startref="ix_keras_class" data-type="indexterm" id="idm45737218467104"/><a data-primary="" data-startref="ix_tensorflow1" data-type="indexterm" id="idm45737218293248"/><a data-primary="" data-startref="ix_credit_risk_prob_def_est_dl" data-type="indexterm" id="idm45737218292304"/><a data-primary="" data-startref="ix_dl_prob_def_est" data-type="indexterm" id="idm45737218291344"/><a data-primary="" data-startref="ix_prob_app_def_est_dl" data-type="indexterm" id="idm45737218290400"/></p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section class="pagebreak-before less_space" data-pdf-bookmark="Conclusion" data-type="sect1"><div class="sect1" id="idm45737223576064">&#13;
<h1>Conclusion</h1>&#13;
&#13;
<p>Credit risk analysis has a long tradition but is also still a challenging task to accomplish. This chapter attempted to present a brand new ML-based approach to tackling this problem and to getting better predictive performance. In the first part of the chapter, the main concepts related to credit risk were provided. Then, we applied a well-known parametric model, logistic regression, to German credit risk data. The performance of logistic regression was then compared with Bayesian estimation based on MAP and M-H. Finally, core machine learning models—namely SVC, random forest, and NNs with deep learning—were employed, and the performance of all models was compared.<a data-primary="" data-startref="ix_credit_risk_ch6" data-type="indexterm" id="idm45737218288384"/></p>&#13;
&#13;
<p>In the next chapter, a neglected dimension risk will be introduced: liquidity risk.&#13;
The appreciation of liquidity risk has grown considerably since the 2007–2008 financial crisis and has turned out to be an important part of risk management.</p>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<section data-pdf-bookmark="References" data-type="sect1"><div class="sect1" id="idm45737218286512">&#13;
<h1>References</h1>&#13;
&#13;
<p>Articles cited in this chapter:</p>&#13;
&#13;
<ul class="author-date-bib">&#13;
<li>&#13;
<p>Basel Committee on Banking Supervision, and Bank for International Settlements. 2000. “Principles for the Management of Credit Risk.” Bank for International &#13;
<span class="keep-together">Settlements</span>.</p>&#13;
</li>&#13;
<li>&#13;
<p>Le, Tuong, Mi Young Lee, Jun Ryeol Park, and Sung Wook Baik. 2018. “Oversampling Techniques for Bankruptcy Prediction: Novel Features from a Transaction Dataset.” <em>Symmetry</em> 10 (4): 79.</p>&#13;
</li>&#13;
<li>&#13;
<p>Tibshirani, Robert, Guenther Walther, and Trevor Hastie. 2001. “Estimating the Number of Clusters in a Data Set via the Gap Statistic.” <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em> 63 (2): 411-423.</p>&#13;
</li>&#13;
</ul>&#13;
&#13;
<p>Books and PhD theses cited in this chapter:</p>&#13;
&#13;
<ul class="author-date-bib">&#13;
<li>&#13;
<p>Rokach, Lior, and Oded Maimon. 2005. “Clustering methods.” In <em>Data Mining and Knowledge Discovery Handbook</em>, 321-352. Boston: Springer.</p>&#13;
</li>&#13;
<li>&#13;
<p>Wehrspohn, Uwe. 2002. “Credit Risk Evaluation: Modeling-Analysis-Management.” PhD dissertation. Harvard.</p>&#13;
</li>&#13;
</ul>&#13;
</div></section>&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
&#13;
<div data-type="footnotes"><p data-type="footnote" id="idm45737223570832"><sup><a href="ch06.html#idm45737223570832-marker">1</a></sup> It is useful to run logistic regression to initialize results for priors in Bayesian estimation.</p></div></div></section></body></html>