- en: 'Chapter 6\. Supervised Learning: Classification'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Here are some of the key questions that financial analysts attempt to solve:'
  prefs: []
  type: TYPE_NORMAL
- en: Is a borrower going to repay their loan or default on it?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Will the instrument price go up or down?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Is this credit card transaction a fraud or not?
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All of these problem statements, in which the goal is to predict the categorical
    class labels, are inherently suitable for classification-based machine learning.
  prefs: []
  type: TYPE_NORMAL
- en: Classification-based algorithms have been used across many areas within finance
    that require predicting a qualitative response. These include fraud detection,
    default prediction, credit scoring, directional forecasting of asset price movement,
    and buy/sell recommendations. There are many other use cases of classification-based
    supervised learning in portfolio management and algorithmic trading.
  prefs: []
  type: TYPE_NORMAL
- en: In this chapter we cover three such classification-based case studies that span
    a diverse set of areas, including fraud detection, loan default probability, and
    formulating a trading strategy.
  prefs: []
  type: TYPE_NORMAL
- en: 'In [“Case Study 1: Fraud Detection”](#CaseStudy1SC), we use a classification-based
    algorithm to predict whether a transaction is fraudulent. The focus of this case
    study is also to deal with an unbalanced dataset, given that the fraud dataset
    is highly unbalanced with a small number of fraudulent observations.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In [“Case Study 2: Loan Default Probability”](#CaseStudy2SC), we use a classification-based
    algorithm to predict whether a loan will default. The case study focuses on various
    techniques and concepts of data processing, feature selection, and exploratory
    analysis.'
  prefs: []
  type: TYPE_NORMAL
- en: 'In [“Case Study 3: Bitcoin Trading Strategy”](#CaseStudy3SC), we use classification-based
    algorithms to predict whether the current trading signal of bitcoin is to buy
    or sell depending on the relationship between the short-term and long-term price.
    We predict the trend of bitcoin’s price using technical indicators. The prediction
    model can easily be transformed into a trading bot that can perform buy, sell,
    or hold actions without human intervention.'
  prefs: []
  type: TYPE_NORMAL
- en: This Chapter’s Code Repository
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A Python-based master template for supervised classification model, along with
    the Jupyter notebook for the case studies presented in this chapter, is included
    in the folder [*Chapter 6 - Sup. Learning - Classification models*](https://oreil.ly/y19Yc)
    in the code repository for this book. All of the case studies presented in this
    chapter use the standardized seven-step model development process presented in
    [Chapter 2](ch02.xhtml#Chapter2).^([1](ch06.xhtml#idm45174924215160))
  prefs: []
  type: TYPE_NORMAL
- en: For any new classification-based problem, the master template from the code
    repository can be modified with the elements specific to the problem. The templates
    are designed to run on cloud infrastructure (e.g., Kaggle, Google Colab, or AWS).
    In order to run the template on the local machine, all the packages used within
    the template must be installed successfully.
  prefs: []
  type: TYPE_NORMAL
- en: 'Case Study 1: Fraud Detection'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Fraud is one of the most significant issues the finance sector faces. It is
    incredibly costly. According to one study, it is estimated that the typical organization
    loses 5% of its annual revenue to fraud each year. When applied to the 2017 estimated
    Gross World Product of $79.6 trillion, this translates to potential global losses
    of up to $4 trillion.
  prefs: []
  type: TYPE_NORMAL
- en: Fraud detection is a task inherently suitable for machine learning, as machine
    learning–based models can scan through huge transactional datasets, detect unusual
    activity, and identify all cases that might be prone to fraud. Also, the computations
    of these models are faster compared to traditional rule-based approaches. By collecting
    data from various sources and then mapping them to trigger points, machine learning
    solutions are able to discover the rate of defaulting or fraud propensity for
    each potential customer and transaction, providing key alerts and insights for
    the financial institutions.
  prefs: []
  type: TYPE_NORMAL
- en: In this case study, we will use various classification-based models to detect
    whether a transaction is a normal payment or a fraud.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/bracket_top.png)'
  prefs: []
  type: TYPE_IMG
- en: Blueprint for Using Classification Models to Determine Whether a Transaction
    Is Fraudulent
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 1\. Problem definition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the classification framework defined for this case study, the response (or
    target) variable has the column name “Class.” This column has a value of 1 in
    the case of fraud and a value of 0 otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset used is obtained from [Kaggle](https://oreil.ly/CeFRs). This dataset
    holds transactions by European cardholders that occurred over two days in September
    2013, with 492 cases of fraud out of 284,807 transactions.
  prefs: []
  type: TYPE_NORMAL
- en: The dataset has been anonymized for privacy reasons. Given that certain feature
    names are not provided (i.e., they are called V1, V2, V3, etc.), the visualization
    and feature importance will not give much insight into the behavior of the model.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this case study, readers will be familiar with a general approach
    to fraud modeling, from gathering and cleaning data to building and tuning a classifier.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Getting started—loading the data and Python packages
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 2.1\. Loading the Python packages
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The list of the libraries used for data loading, data analysis, data preparation,
    model evaluation, and model tuning are shown below. The packages used for different
    purposes have been separated in the Python code below. The details of most of
    these packages and functions have been provided in [Chapter 2](ch02.xhtml#Chapter2)
    and [Chapter 4](ch04.xhtml#Chapter4):'
  prefs: []
  type: TYPE_NORMAL
- en: '`Packages for data loading, data analysis, and data preparation`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: '`Packages for model evaluation and classification models`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: '`Packages for deep learning models`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: '`Packages for saving the model`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 3\. Exploratory data analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The following sections walk through some high-level data inspection.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1\. Descriptive statistics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The first thing we must do is gather a basic sense of our data. Remember, except
    for the transaction and amount, we do not know the names of other columns. The
    only thing we know is that the values of those columns have been scaled. Let’s
    look at the shape and columns of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in01](Images/mlbf_06in01.png)'
  prefs: []
  type: TYPE_IMG
- en: '`5 rows × 31 columns`'
  prefs: []
  type: TYPE_NORMAL
- en: As shown, the variable names are nondescript (*V1*, *V2*, etc.). Also, the data
    type for the entire dataset is `float`, except `Class`, which is of type integer.
  prefs: []
  type: TYPE_NORMAL
- en: 'How many are fraud and how many are not fraud? Let us check:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: Notice the stark imbalance of the data labels. Most of the transactions are
    nonfraud. If we use this dataset as the base for our modeling, most models will
    not place enough emphasis on the fraud signals; the nonfraud data points will
    drown out any weight the fraud signals provide. As is, we may encounter difficulties
    modeling the prediction of fraud, with this imbalance leading the models to simply
    assume *all* transactions are nonfraud. This would be an unacceptable result.
    We will explore some ways of dealing with this issue in the subsequent sections.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2\. Data visualization
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Since the feature descriptions are not provided, visualizing the data will not
    lead to much insight. This step will be skipped in this case study.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Data preparation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This data is from Kaggle and is already in a cleaned format without any empty
    rows or columns. Data cleaning or categorization is unnecessary.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Evaluate models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now we are ready to split the data and evaluate the models.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1\. Train-test split and evaluation metrics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As described in [Chapter 2](ch02.xhtml#Chapter2), it is a good idea to partition
    the original dataset into training and test sets. The test set is a sample of
    the data that we hold back from our analysis and modeling. We use it at the end
    of our project to confirm the accuracy of our final model. It is the final test
    that gives us confidence in our estimates of accuracy on unseen data. We will
    use 80% of the dataset for model training and 20% for testing:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 5.2\. Checking models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this step, we will evaluate different machine learning models. To optimize
    the various hyperparameters of the models, we use ten-fold cross validation and
    recalculate the results ten times to account for the inherent randomness in some
    of the models and the CV process. All of these models, including cross validation,
    are described in [Chapter 4](ch04.xhtml#Chapter4).
  prefs: []
  type: TYPE_NORMAL
- en: Let us design our test harness. We will evaluate algorithms using the *accuracy
    metric*. This is a gross metric that will give us a quick idea of how correct
    a given model is. It is useful on binary classification problems.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s create a baseline of performance for this problem and spot-check a number
    of different algorithms. The selected algorithms include:'
  prefs: []
  type: TYPE_NORMAL
- en: Linear algorithms
  prefs: []
  type: TYPE_NORMAL
- en: Logistic regression (LR) and linear discriminant analysis (LDA).
  prefs: []
  type: TYPE_NORMAL
- en: Nonlinear algorithms
  prefs: []
  type: TYPE_NORMAL
- en: Classification and regression trees (CART) and *K*-nearest neighbors (KNN).
  prefs: []
  type: TYPE_NORMAL
- en: There are good reasons for selecting these models. These models are simpler
    and faster models with good interpretation for problems with large datasets. CART
    and KNN will be able to discern any nonlinear relationships between the variables.
    The key problem here is using an unbalanced sample. Unless we resolve that, more
    complex models, such as ensemble and ANNs, will have poor prediction. We will
    focus on addressing this later in the case study and then will evaluate the performance
    of these types of models.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: All the algorithms use default tuning parameters. We will display the mean and
    standard deviation of accuracy for each algorithm as we calculate and collect
    the results for use later.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: '![mlbf 06in02](Images/mlbf_06in02.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The accuracy of the overall result is quite high. But let us check how well
    it predicts the fraud cases. Choosing one of the model CART from the results above
    and looking at the result on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: 'And producing the confusion matrix yields:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: '![mlbf 06in03](Images/mlbf_06in03.png)'
  prefs: []
  type: TYPE_IMG
- en: Overall accuracy is strong, but the confusion metrics tell a different story.
    Despite the high accuracy level, 21 out of 100 instances of fraud are missed and
    incorrectly predicted as nonfraud. The *false negative* rate is substantial.
  prefs: []
  type: TYPE_NORMAL
- en: The intention of a fraud detection model is to minimize these false negatives.
    To do so, the first step would be to choose the right evaluation metric.
  prefs: []
  type: TYPE_NORMAL
- en: In [Chapter 4](ch04.xhtml#Chapter4), we covered the evaluation metrics, such
    as accuracy, precision, and recall, for a classification-based problem. Accuracy
    is the number of correct predictions made as a ratio of all predictions made.
    Precision is the number of items correctly identified as positive out of total
    items identified as positive by the model. Recall is the total number of items
    correctly identified as positive out of total true positives.
  prefs: []
  type: TYPE_NORMAL
- en: For this type of problem, we should focus on recall, the ratio of true positives
    to the sum of true positives and false negatives. So if false negatives are high,
    then the value of recall will be low.
  prefs: []
  type: TYPE_NORMAL
- en: In the next step, we perform model tuning, select the model using the recall
    metric, and perform under-sampling.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Model tuning
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The purpose of the model tuning step is to perform the grid search on the model
    selected in the previous step. However, since we encountered poor model performance
    in the previous section due to the unbalanced dataset, we will focus our attention
    on that. We will analyze the impact of choosing the correct evaluation metric
    and see the impact of using an adjusted, balanced sample.
  prefs: []
  type: TYPE_NORMAL
- en: 6.1\. Model tuning by choosing the correct evaluation metric
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As mentioned in the preceding step, if false negatives are high, then the value
    of recall will be low. Models are ranked according to this metric:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us spot-check some basic classification algorithms for recall:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE19]'
  prefs: []
  type: TYPE_PRE
- en: 'Running cross validation:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE20]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE21]'
  prefs: []
  type: TYPE_PRE
- en: 'We see that the LDA model has the best recall of the four models. We continue
    by evaluating the test set using the trained LDA:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE22]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE23]'
  prefs: []
  type: TYPE_PRE
- en: '![mlbf 06in04](Images/mlbf_06in04.png)'
  prefs: []
  type: TYPE_IMG
- en: LDA performs better, missing only 18 out of 100 cases of fraud. Additionally,
    we find fewer false positives as well. However, there is still improvement to
    be made.
  prefs: []
  type: TYPE_NORMAL
- en: 6.2\. Model tuning—balancing the sample by random under-sampling
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The current data exhibits a significant class imbalance, where there are very
    few data points labeled “fraud.” The issue of such class imbalance can result
    in a serious bias toward the majority class, reducing the classification performance
    and increasing the number of false negatives.
  prefs: []
  type: TYPE_NORMAL
- en: One of the remedies to handle such situations is to *under-sample* the data.
    A simple technique is to under-sample the majority class randomly and uniformly.
    This might lead to a loss of information, but it may yield strong results by modeling
    the minority class well.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will implement random under-sampling, which consists of removing data
    to have a more balanced dataset. This will help ensure that our models avoid overfitting.
  prefs: []
  type: TYPE_NORMAL
- en: 'The steps to implement random under-sampling are:'
  prefs: []
  type: TYPE_NORMAL
- en: First, we determine the severity of the class imbalance by using `value_counts()`
    on the class column. We determine how many instances are considered fraud transactions
    (*fraud = 1*).
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: We bring the nonfraud transaction observation count to the same amount as fraud
    transactions. Assuming we want a 50/50 ratio, this will be equivalent to 492 cases
    of fraud and 492 cases of nonfraud transactions.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We now have a subsample of our dataframe with a 50/50 ratio with regards to
    our classes. We train the models on this subsample. Then we perform this iteration
    again to shuffle the nonfraud observations in the training sample. We keep track
    of the model performance to see whether our models can maintain a certain accuracy
    every time we repeat this process:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE24]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us look at the distribution of the classes in the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE25]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE26]'
  prefs: []
  type: TYPE_PRE
- en: '![mlbf 06in05](Images/mlbf_06in05.png)'
  prefs: []
  type: TYPE_IMG
- en: 'The data is now balanced, with close to 1,000 observations. We will train all
    the models again, including an ANN. Now that the data is balanced, we will focus
    on accuracy as our main evaluation metric, since it considers both false positives
    and false negatives. Recall can always be produced if needed:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE27]'
  prefs: []
  type: TYPE_PRE
- en: The steps to define and compile an ANN-based deep learning model in Keras, along
    with all the terms (neurons, activation, momentum, etc.) mentioned in the following
    code, have been described in [Chapter 3](ch03.xhtml#Chapter3). This code can be
    leveraged for any deep learning–based classification model.
  prefs: []
  type: TYPE_NORMAL
- en: '`Keras-based deep learning model:`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE28]'
  prefs: []
  type: TYPE_PRE
- en: 'Running the cross validation on the new set of models results in the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in06](Images/mlbf_06in06.png)'
  prefs: []
  type: TYPE_IMG
- en: Although a couple of models, including random forest (RF) and logistic regression
    (LR), perform well, GBM slightly edges out the other models. We select this for
    further analysis. Note that the result of the deep learning model using Keras
    (i.e., “DNN”) is poor.
  prefs: []
  type: TYPE_NORMAL
- en: A grid search is performed for the GBM model by varying the number of estimators
    and maximum depth. The details of the GBM model and the parameters to tune for
    this model are described in [Chapter 4](ch04.xhtml#Chapter4).
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE29]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE30]'
  prefs: []
  type: TYPE_PRE
- en: 'In the next step, the final model is prepared, and the result on the test set
    is checked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE31]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE32]'
  prefs: []
  type: TYPE_PRE
- en: 'The accuracy of the model is high. Let’s look at the confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in07](Images/mlbf_06in07.png)'
  prefs: []
  type: TYPE_IMG
- en: The results on the test set are impressive, with a high accuracy and, importantly,
    no false negatives. However, we see that an outcome of using our under-sampled
    data is a propensity for false positives—cases in which nonfraud transactions
    are misclassified as fraudulent. This is a trade-off the financial institution
    would have to consider. There is an inherent cost balance between the operational
    overhead, and possible customer experience impact, from processing false positives
    and the financial loss resulting from missing fraud cases through false negatives.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this case study, we performed fraud detection on credit card transactions.
    We illustrated how different classification machine learning models stack up against
    each other and demonstrated that choosing the right metric can make an important
    difference in model evaluation. Under-sampling was shown to lead to a significant
    improvement, as all fraud cases in the test set were correctly identified after
    applying under-sampling. This came with a trade-off, though. The reduction in
    false negatives came with an increase in false positives.
  prefs: []
  type: TYPE_NORMAL
- en: Overall, by using different machine learning models, choosing the right evaluation
    metrics, and handling unbalanced data, we demonstrated how the implementation
    of a simple classification-based model can produce robust results for fraud detection.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/bracket_bottom.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Case Study 2: Loan Default Probability'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Lending is one of the most important activities of the finance industry. Lenders
    provide loans to borrowers in exchange for the promise of repayment with interest.
    That means the lender makes a profit only if the borrower pays off the loan. Hence,
    the two most critical questions in the lending industry are:'
  prefs: []
  type: TYPE_NORMAL
- en: How risky is the borrower?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Given the borrower’s risk, should we lend to them?
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Default prediction could be described as a perfect job for machine learning,
    as the algorithms can be trained on millions of examples of consumer data. Algorithms
    can perform automated tasks such as matching data records, identifying exceptions,
    and calculating whether an applicant qualifies for a loan. The underlying trends
    can be assessed with algorithms and continuously analyzed to detect trends that
    might influence lending and underwriting risk in the future.
  prefs: []
  type: TYPE_NORMAL
- en: The goal of this case study is to build a machine learning model to predict
    the probability that a loan will default.
  prefs: []
  type: TYPE_NORMAL
- en: In most real-life cases, including loan default modeling, we are unable to work
    with clean, complete data. Some of the potential problems we are bound to encounter
    are missing values, incomplete categorical data, and irrelevant features. Although
    data cleaning may not be mentioned often, it is critical for the success of machine
    learning applications. The algorithms that we use can be powerful, but without
    the relevant or appropriate data, the system may fail to yield ideal results.
    So one of the focus areas of this case study will be data preparation and cleaning.
    Various techniques and concepts of data processing, feature selection, and exploratory
    analysis are used for data cleaning and organizing the feature space.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/bracket_top.png)'
  prefs: []
  type: TYPE_IMG
- en: Blueprint for Creating a Machine Learning Model for Predicting Loan Default
    Probability
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 1\. Problem definition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In the classification framework for this case study, the predicted variable
    is *charge-off*, a debt that a creditor has given up trying to collect on after
    a borrower has missed payments for several months. The predicted variable takes
    a value of 1 in case of charge-off and a value of 0 otherwise.
  prefs: []
  type: TYPE_NORMAL
- en: We will analyze data for loans from 2007 to 2017Q3 from Lending Club, [available
    on Kaggle](https://oreil.ly/DG9j5). Lending Club is a US peer-to-peer lending
    company. It operates an online lending platform that enables borrowers to obtain
    a loan and investors to purchase notes backed by payments made on these loans.
    The dataset contains more than 887,000 observations with 150 variables containing
    complete loan data for all loans issued over the specified time period. The features
    include income, age, credit scores, home ownership, borrower location, collections,
    and many others. We will investigate these 150 predictor variables for feature
    selection.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this case study, readers will be familiar with a general approach
    to loan default modeling, from gathering and cleaning data to building and tuning
    a classifier.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Getting started—loading the data and Python packages
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 2.1\. Loading the Python packages
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The standard Python packages are loaded in this step. The details have been
    presented in the previous case studies. Please refer to the Jupyter notebook for
    this case study for more details.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Loading the data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The loan data for the time period from 2007 to 2017Q3 is loaded:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE33]'
  prefs: []
  type: TYPE_PRE
- en: 3\. Data preparation and feature selection
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the first step, let us look at the size of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE34]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE35]'
  prefs: []
  type: TYPE_PRE
- en: Given that there are 150 features for each loan, we will first focus on limiting
    the feature space, followed by the exploratory analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1\. Preparing the predicted variable
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Here, we look at the details of the predicted variable and prepare it. The predicted
    variable will be derived from the `loan_status` column. Let’s check the value
    distributions:^([2](ch06.xhtml#idm45174922143032))
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE36]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE37]'
  prefs: []
  type: TYPE_PRE
- en: 'From the data definition documentation:'
  prefs: []
  type: TYPE_NORMAL
- en: Fully Paid
  prefs: []
  type: TYPE_NORMAL
- en: Loans that have been fully repaid.
  prefs: []
  type: TYPE_NORMAL
- en: Default
  prefs: []
  type: TYPE_NORMAL
- en: Loans that have not been current for 121 days or more.
  prefs: []
  type: TYPE_NORMAL
- en: Charged Off
  prefs: []
  type: TYPE_NORMAL
- en: Loans for which there is no longer a reasonable expectation of further payments.
  prefs: []
  type: TYPE_NORMAL
- en: 'A large proportion of observations show a status of `Current`, and we do not
    know whether those will be `Charged Off`, `Fully Paid`, or `Default` in the future.
    The observations for `Default` are tiny in number compared to `Fully Paid` or
    `Charged Off` and are not considered. The remaining categories of `loan status`
    are not of prime importance for this analysis. So, in order to convert this to
    a binary classification problem and to analyze in detail the effect of important
    variables on the loan status, we will consider only two major categories—Charged
    Off and Fully Paid:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE38]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE39]'
  prefs: []
  type: TYPE_PRE
- en: About 79% of the remaining loans have been fully paid and 21% have been charged
    off, so we have a somewhat unbalanced classification problem, but it is not as
    unbalanced as the dataset of fraud detection we saw in the previous case study.
  prefs: []
  type: TYPE_NORMAL
- en: 'In the next step, we create a new binary column in the dataset, where we categorize
    Fully Paid as 0 and Charged Off as 1\. This column represents the predicted variable
    for this classification problem. A value of 1 in this column indicates the borrower
    has defaulted:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE40]'
  prefs: []
  type: TYPE_PRE
- en: 3.2\. Feature selection—limit the feature space
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The full dataset has 150 features for each loan, but not all features contribute
    to the prediction variable. Removing features of low importance can improve accuracy
    and reduce both model complexity and overfitting. Training time can also be reduced
    for very large datasets. We’ll eliminate features in the following steps using
    three different approaches:'
  prefs: []
  type: TYPE_NORMAL
- en: Eliminating features that have more than 30% missing values.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eliminating features that are unintuitive based on subjective judgment.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Eliminating features with low correlation with the predicted variable.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 3.2.1\. Feature elimination based on significant missing values
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'First, we calculate the percentage of missing data for each feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE41]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE42]'
  prefs: []
  type: TYPE_PRE
- en: This dataset has 92 columns remaining once some of the columns with a significant
    number of missing values are dropped.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.2\. Feature elimination based on intuitiveness
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: To filter the features further we check the description in the data dictionary
    and keep the features that intuitively contribute to the prediction of default.
    We keep features that contain the relevant credit detail of the borrower, including
    annual income, FICO score, and debt-to-income ratio. We also keep those features
    that are available to investors when considering an investment in the loan. These
    include features in the loan application and any features added by Lending Club
    when the loan listing was accepted, such as loan grade and interest rate.
  prefs: []
  type: TYPE_NORMAL
- en: 'The list of the features retained are shown in the following code snippet:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE43]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE44]'
  prefs: []
  type: TYPE_PRE
- en: After removing the features in this step, 39 columns remain.
  prefs: []
  type: TYPE_NORMAL
- en: 3.2.3\. Feature elimination based on the correlation
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The next step is to check the correlation with the predicted variable. Correlation
    gives us the interdependence between the predicted variable and the feature. We
    select features with a moderate-to-strong relationship with the target variable
    and drop those that have a correlation of less than 3% with the predicted variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE45]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE46]'
  prefs: []
  type: TYPE_PRE
- en: 'The columns with low correlation are dropped from the dataset, and we are left
    with only 35 columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE47]'
  prefs: []
  type: TYPE_PRE
- en: 4\. Feature selection and exploratory analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this step, we perform the exploratory data analysis of the feature selection.
    Given that many features had to be eliminated, it is preferable that we perform
    the exploratory data analysis after feature selection to better visualize the
    relevant features. We will also continue the feature elimination by visually screening
    and dropping those features deemed irrelevant.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1\. Feature analysis and exploration
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In the following sections, we take a deeper dive into the dataset features.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.1\. Analyzing the categorical features
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Let us look at the some of the categorical features in the dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 'First, let’s look at the `id`, `emp_title`, `title`, and `zip_code` features:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE48]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | id | emp_title | title | zip_code |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| count | 814986 | 766415 | 807068 | 814986 |'
  prefs: []
  type: TYPE_TB
- en: '| unique | 814986 | 280473 | 60298 | 925 |'
  prefs: []
  type: TYPE_TB
- en: '| top | 14680062 | Teacher | Debt consolidation | 945xx |'
  prefs: []
  type: TYPE_TB
- en: '| freq | 1 | 11351 | 371874 | 9517 |'
  prefs: []
  type: TYPE_TB
- en: IDs are all unique and irrelevant for modeling. There are too many unique values
    for employment titles and titles. Occupation and job title may provide some information
    for default modeling; however, we assume much of this information is embedded
    in the verified income of the customer. Moreover, additional cleaning steps on
    these features, such as standardizing or grouping the titles, would be necessary
    to extract any marginal information. This work is outside the scope of this case
    study but could be explored in subsequent iterations of the model.
  prefs: []
  type: TYPE_NORMAL
- en: Geography could play a role in credit determination, and zip codes provide a
    granular view of this dimension. Again, additional work would be necessary to
    prepare this feature for modeling and was deemed outside the scope of this case
    study.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE49]'
  prefs: []
  type: TYPE_PRE
- en: Let’s look at the `term` feature.
  prefs: []
  type: TYPE_NORMAL
- en: '*Term* refers to the number of payments on the loan. Values are in months and
    can be either 36 or 60\. The 60-month loans are more likely to charge off.'
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s convert term to integers and group by the term for further analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE50]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE51]'
  prefs: []
  type: TYPE_PRE
- en: Loans with five-year periods are more than twice as likely to charge-off as
    loans with three-year periods. This feature seems to be important for the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at the `emp_length` feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE52]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in08](Images/mlbf_06in08.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Loan status does not appear to vary much with employment length (on average);
    hence this feature is dropped:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE53]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at the `sub_grade` feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE54]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in09](Images/mlbf_06in09.png)'
  prefs: []
  type: TYPE_IMG
- en: As shown in the chart, there’s a clear trend of higher probability of charge-off
    as the sub-grade worsens, and so it is considered to be a key feature.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1.2\. Analyzing the continuous features
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let’s look at the `annual_inc` feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE55]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | annual_inc |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| count | 8.149860e+05 |'
  prefs: []
  type: TYPE_TB
- en: '| mean | 7.523039e+04 |'
  prefs: []
  type: TYPE_TB
- en: '| std | 6.524373e+04 |'
  prefs: []
  type: TYPE_TB
- en: '| min | 0.000000e+00 |'
  prefs: []
  type: TYPE_TB
- en: '| 25% | 4.500000e+04 |'
  prefs: []
  type: TYPE_TB
- en: '| 50% | 6.500000e+04 |'
  prefs: []
  type: TYPE_TB
- en: '| 75% | 9.000000e+04 |'
  prefs: []
  type: TYPE_TB
- en: '| max | 9.550000e+06 |'
  prefs: []
  type: TYPE_TB
- en: 'Annual income ranges from $0 to $9,550,000, with a median of $65,000\. Because
    of the large range of incomes, we use a log transform of the annual income variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE56]'
  prefs: []
  type: TYPE_PRE
- en: 'Let’s look at the FICO score (`fico_range_low`, `fico_range_high`) feature:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE57]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | fico_range_low | fico_range_high |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| fico_range_low | 1.0 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: '| fico_range_high | 1.0 | 1.0 |'
  prefs: []
  type: TYPE_TB
- en: 'Given that the correlation between FICO low and high is 1, it is preferred
    that we keep only one feature, which we take as the average of FICO scores:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE58]'
  prefs: []
  type: TYPE_PRE
- en: 4.2\. Encoding categorical data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In order to use a feature in the classification models, we need to convert
    the categorical data (i.e., text features) to its numeric representation. This
    process is called encoding. There can be different ways of encoding. However,
    for this case study we will use a *label encoder*, which encodes labels with a
    value between 0 and *n*, where *n* is the number of distinct labels. The `LabelEncoder`
    function from sklearn is used in the following step, and all the categorical columns
    are encoded at once:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE59]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us look at the categorical columns:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE60]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE61]'
  prefs: []
  type: TYPE_PRE
- en: 4.3\. Sampling data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: Given that the loan data is skewed, it is sampled to have an equal number of
    charge-off and no charge-off observations. Sampling leads to a more balanced dataset
    and avoids overfitting:^([3](ch06.xhtml#idm45174920856536))
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE62]'
  prefs: []
  type: TYPE_PRE
- en: Although sampling may have its advantages, there might be some disadvantages
    as well. Sampling may exclude some data that might not be homogeneous to the data
    that is taken. This affects the level of accuracy in the results. Also, selection
    of the proper size of samples is a difficult job. Hence, sampling should be performed
    with caution and should generally be avoided in the case of a relatively balanced
    dataset.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Evaluate algorithms and models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 5.1\. Train-test split
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Splitting out the validation dataset for the model evaluation is the next step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE63]'
  prefs: []
  type: TYPE_PRE
- en: 5.2\. Test options and evaluation metrics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this step, the test options and evaluation metrics are selected. The `roc_auc`
    evaluation metric is selected for this classification. The details of this metric
    were provided in [Chapter 4](ch04.xhtml#Chapter4). This metric represents a model’s
    ability to discriminate between positive and negative classes. An `roc_auc` of
    1.0 represents a model that made all predictions perfectly, and a value of 0.5
    represents a model that is as good as random.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE64]'
  prefs: []
  type: TYPE_PRE
- en: The model cannot afford to have a high amount of false negatives as that leads
    to a negative impact on the investors and the credibility of the company. So we
    can use recall as we did in the fraud detection use case.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3\. Compare models and algorithms
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let us spot-check the classification algorithms. We include ANN and ensemble
    models in the list of models to be checked:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE65]'
  prefs: []
  type: TYPE_PRE
- en: 'After performing the *k*-fold cross validation on the models shown above, the
    overall performance is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in10](Images/mlbf_06in10.png)'
  prefs: []
  type: TYPE_IMG
- en: The gradient boosting method (GBM) model performs best, and we select it for
    grid search in the next step. The details of GBM along with the model parameters
    are described in [Chapter 4](ch04.xhtml#Chapter4).
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Model tuning and grid search
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'We tune the number of estimator and maximum depth hyperparameters, which were
    discussed in [Chapter 4](ch04.xhtml#Chapter4):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE66]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE67]'
  prefs: []
  type: TYPE_PRE
- en: A GBM model with `max_depth` of 5 and number of estimators of 150 results in
    the best model.
  prefs: []
  type: TYPE_NORMAL
- en: 7\. Finalize the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Now, we perform the final steps for selecting a model.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1\. Results on the test dataset
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let us prepare the GBM model with the parameters found during the grid search
    step and check the results on the test dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE68]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE69]'
  prefs: []
  type: TYPE_PRE
- en: 'The accuracy of the model is a reasonable 89% on the test set. Let us examine
    the confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in11](Images/mlbf_06in11.png)'
  prefs: []
  type: TYPE_IMG
- en: Looking at the confusion matrix and the overall result of the test set, both
    the rate of false positives and the rate of false negatives are lower; the overall
    model performance looks good and is in line with the training set results.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2\. Variable intuition/feature importance
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this step, we compute and display the variable importance of our trained
    model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE70]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in12](Images/mlbf_06in12.png)'
  prefs: []
  type: TYPE_IMG
- en: The results of the model importance are intuitive. The last payment amount seems
    to be the most important feature, followed by loan term and sub-grade.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this case study, we introduced the classification-based tree algorithm applied
    to loan default prediction. We showed that data preparation is one of the most
    important steps. We addressed this by performing feature elimination using different
    techniques, such as feature intuition, correlation analysis, visualization, and
    data quality checks of the features. We illustrated that there can be different
    ways of handling and analyzing the categorical data and converting categorical
    data into a usable format for the models.
  prefs: []
  type: TYPE_NORMAL
- en: We emphasized that performing data processing and establishing an understanding
    of variable importance is key in the model development process. A focus on these
    steps led to the implementation of a simple classification-based model that produced
    robust results for default prediction.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/bracket_bottom.png)'
  prefs: []
  type: TYPE_IMG
- en: 'Case Study 3: Bitcoin Trading Strategy'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: First released as open source in 2009 by the pseudonymous Satoshi Nakamoto,
    bitcoin is the longest-running and most well-known cryptocurrency.
  prefs: []
  type: TYPE_NORMAL
- en: A major drawback of cryptocurrency trading is the volatility of the market.
    Since cryptocurrency markets trade 24/7, tracking cryptocurrency positions against
    quickly changing market dynamics can rapidly become an impossible task to manage.
    This is where automated trading algorithms and trading bots can assist.
  prefs: []
  type: TYPE_NORMAL
- en: 'Various machine learning algorithms can be used to generate trading signals
    in an attempt to predict the market’s movement. One could use machine learning
    algorithms to classify the next day’s movement into three categories: market will
    rise (take a long position), market will fall (take a short position), or market
    will move sideways (take no position). Since we know the market direction, we
    can decide the optimum entry and exit points.'
  prefs: []
  type: TYPE_NORMAL
- en: Machine learning has one key aspect called *feature engineering*. It means that
    we can create new, intuitive features and feed them to a machine learning algorithm
    in order to achieve better results. We can introduce different technical indicators
    as features to help predict future prices of an asset. These technical indicators
    are derived from market variables such as price or volume and have additional
    information or signals embedded in them. There are many different categories of
    technical indicators, including trend, volume, volatility, and momentum indicators.
  prefs: []
  type: TYPE_NORMAL
- en: In this case study, we will use various classification-based models to predict
    whether the current position signal is buy or sell. We will create additional
    trend and momentum indicators from market prices to leverage as additional features
    in the prediction.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/bracket_top.png)'
  prefs: []
  type: TYPE_IMG
- en: Blueprint for Using Classification-Based Models to Predict Whether to Buy or
    Sell in the Bitcoin Market
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 1\. Problem definition
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: The problem of predicting a buy or sell signal for a trading strategy is defined
    in the classification framework, where the predicted variable has a value of 1
    for buy and 0 for sell. This signal is decided through the comparison of the short-term
    and long-term price trends.
  prefs: []
  type: TYPE_NORMAL
- en: The data used is from one of the largest bitcoin exchanges in terms of average
    daily volume, [Bitstamp](https://www.bitstamp.com). The data covers prices from
    January 2012 to May 2017\. Different trend and momentum indicators are created
    from the data and are added as features to enhance the performance of the prediction
    model.
  prefs: []
  type: TYPE_NORMAL
- en: By the end of this case study, readers will be familiar with a general approach
    to building a trading strategy, from cleaning data and feature engineering to
    model tuning and developing a backtesting framework.
  prefs: []
  type: TYPE_NORMAL
- en: 2\. Getting started—loading the data and Python packages
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s load the packages and the data.
  prefs: []
  type: TYPE_NORMAL
- en: 2.1\. Loading the Python packages
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: The standard Python packages are loaded in this step. The details have been
    presented in the previous case studies. Refer to the Jupyter notebook for this
    case study for more details.
  prefs: []
  type: TYPE_NORMAL
- en: 2.2\. Loading the data
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'The bitcoin data fetched from the Bitstamp website is loaded in this step:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE71]'
  prefs: []
  type: TYPE_PRE
- en: 3\. Exploratory data analysis
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this step, we will take a detailed look at this data.
  prefs: []
  type: TYPE_NORMAL
- en: 3.1\. Descriptive statistics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'First, let us look at the shape of the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE72]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE73]'
  prefs: []
  type: TYPE_PRE
- en: '[PRE74]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '|  | Timestamp | Open | High | Low | Close | Volume_(BTC) | Volume_(Currency)
    | Weighted_Price |'
  prefs: []
  type: TYPE_TB
- en: '| --- | --- | --- | --- | --- | --- | --- | --- | --- |'
  prefs: []
  type: TYPE_TB
- en: '| 2841372 | 1496188560 | 2190.49 | 2190.49 | 2181.37 | 2181.37 | 1.700166 |
    3723.784755 | 2190.247337 |'
  prefs: []
  type: TYPE_TB
- en: '| 2841373 | 1496188620 | 2190.50 | 2197.52 | 2186.17 | 2195.63 | 6.561029 |
    14402.811961 | 2195.206304 |'
  prefs: []
  type: TYPE_TB
- en: The dataset has minute-by-minute data of OHLC (Open, High, Low, Close) and traded
    volume of bitcoin. The dataset is large, with approximately 2.8 million total
    observations.
  prefs: []
  type: TYPE_NORMAL
- en: 4\. Data preparation
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this part, we will clean the data to prepare for modeling.
  prefs: []
  type: TYPE_NORMAL
- en: 4.1\. Data cleaning
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We clean the data by filling the NaNs with the last available values:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE75]'
  prefs: []
  type: TYPE_PRE
- en: 'The `Timestamp` column is not useful for modeling and is dropped from the dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE76]'
  prefs: []
  type: TYPE_PRE
- en: 4.2\. Preparing the data for classification
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'As a first step, we will create the target variable for our model. This is
    the column that will indicate whether the trading signal is buy or sell. We define
    the short-term price as the 10-day rolling average and the long-term price as
    the 60-day rolling average. We attach a label of `1` `(0)` if the short-term price
    is higher (lower) than the long-term price:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE77]'
  prefs: []
  type: TYPE_PRE
- en: 4.3\. Feature engineering
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: We begin feature engineering by analyzing the features we expect may influence
    the performance of the prediction model. Based on a conceptual understanding of
    key factors that drive investment strategies, the task at hand is to identify
    and construct new features that may capture the risks or characteristics embodied
    by these return drivers. For this case study, we will explore the efficacy of
    specific momentum technical indicators.
  prefs: []
  type: TYPE_NORMAL
- en: 'The current data of the bitcoin consists of date, open, high, low, close, and
    volume. Using this data, we calculate the following momentum indicators:'
  prefs: []
  type: TYPE_NORMAL
- en: Moving average
  prefs: []
  type: TYPE_NORMAL
- en: A moving average provides an indication of a price trend by cutting down the
    amount of noise in the series.
  prefs: []
  type: TYPE_NORMAL
- en: Stochastic oscillator %K
  prefs: []
  type: TYPE_NORMAL
- en: A stochastic oscillator is a momentum indicator that compares the closing price
    of a security to a range of its previous prices over a certain period of time.
    *%K* and *%D* are slow and fast indicators. The fast indicator is more sensitive
    than the slow indicator to changes in the price of the underlying security and
    will likely result in many transaction signals.
  prefs: []
  type: TYPE_NORMAL
- en: Relative strength index (RSI)
  prefs: []
  type: TYPE_NORMAL
- en: This is a momentum indicator that measures the magnitude of recent price changes
    to evaluate overbought or oversold conditions in the price of a stock or other
    asset. The RSI ranges from 0 to 100\. An asset is deemed to be overbought once
    the RSI approaches 70, meaning that the asset may be getting overvalued and is
    a good candidate for a pullback. Likewise, if the RSI approaches 30, it is an
    indication that the asset may be getting oversold and is therefore likely to become
    undervalued.
  prefs: []
  type: TYPE_NORMAL
- en: Rate of change (ROC)
  prefs: []
  type: TYPE_NORMAL
- en: This is a momentum oscillator that measures the percentage change between the
    current price and the *n* period past prices. Assets with higher ROC values are
    considered more likely to be overbought; those with lower ROC, more likely to
    be oversold.
  prefs: []
  type: TYPE_NORMAL
- en: Momentum (MOM)
  prefs: []
  type: TYPE_NORMAL
- en: This is the rate of acceleration of a security’s price or volume—that is, the
    speed at which the price is changing.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following steps show how to generate some useful features for prediction.
    The features for trend and momentum can be leveraged for other trading strategy
    models:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE78]'
  prefs: []
  type: TYPE_PRE
- en: With our features completed, we’ll prepare them for use.
  prefs: []
  type: TYPE_NORMAL
- en: 4.4\. Data visualization
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this step, we visualize different properties of the features and the predicted
    variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE79]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in13](Images/mlbf_06in13.png)'
  prefs: []
  type: TYPE_IMG
- en: The chart illustrates a sharp rise in the price of bitcoin, increasing from
    close to $0 to around $2,500 in 2017\. Also, high price volatility is readily
    visible.
  prefs: []
  type: TYPE_NORMAL
- en: 'Let us look at the distribution of the predicted variable:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE80]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in14](Images/mlbf_06in14.png)'
  prefs: []
  type: TYPE_IMG
- en: The predicted variable is 1 more than 52% of the time, meaning there are more
    buy signals than sell signals. The predicted variable is relatively balanced,
    especially as compared to the fraud dataset we saw in the first case study.
  prefs: []
  type: TYPE_NORMAL
- en: 5\. Evaluate algorithms and models
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: In this step, we will evaluate different algorithms.
  prefs: []
  type: TYPE_NORMAL
- en: 5.1\. Train-test split
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'We first split the dataset into training (80%) and test (20%) sets. For this
    case study we use 100,000 observations for a faster calculation. The next steps
    would be same in the event we want to use the entire dataset:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE81]'
  prefs: []
  type: TYPE_PRE
- en: 5.2\. Test options and evaluation metrics
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Accuracy can be used as the evaluation metric since there is not a significant
    class imbalance in the data:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE82]'
  prefs: []
  type: TYPE_PRE
- en: 5.3\. Compare models and algorithms
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In order to know which algorithm is best for our strategy, we evaluate the linear,
    nonlinear, and ensemble models.
  prefs: []
  type: TYPE_NORMAL
- en: 5.3.1\. Models
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Checking the classification algorithms:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE83]'
  prefs: []
  type: TYPE_PRE
- en: 'After performing the *k*-fold cross validation, the comparison of the models
    is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in15](Images/mlbf_06in15.png)'
  prefs: []
  type: TYPE_IMG
- en: Although some of the models show promising results, we prefer an ensemble model
    given the huge size of the dataset, the large number of features, and an expected
    nonlinear relationship between the predicted variable and the features. Random
    forest has the best performance among the ensemble models.
  prefs: []
  type: TYPE_NORMAL
- en: 6\. Model tuning and grid search
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'A grid search is performed for the random forest model by varying the number
    of estimators and maximum depth. The details of the random forest model and the
    parameters to tune are discussed in [Chapter 4](ch04.xhtml#Chapter4):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE84]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE85]'
  prefs: []
  type: TYPE_PRE
- en: 7\. Finalize the model
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let us finalize the model with the best parameters found during the tuning step
    and perform the variable intuition.
  prefs: []
  type: TYPE_NORMAL
- en: 7.1\. Results on the test dataset
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this step, we evaluate the selected model on the test set:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE86]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE87]'
  prefs: []
  type: TYPE_PRE
- en: 'The selected model performs quite well, with an accuracy of 90.75%. Let us
    look at the confusion matrix:'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in16](Images/mlbf_06in16.png)'
  prefs: []
  type: TYPE_IMG
- en: The overall model performance is reasonable and is in line with the training
    set results.
  prefs: []
  type: TYPE_NORMAL
- en: 7.2\. Variable intuition/feature importance
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Let us look into the feature importance of the model:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE88]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in17](Images/mlbf_06in17.png)'
  prefs: []
  type: TYPE_IMG
- en: The result of the variable importance looks intuitive, and the momentum indicators
    of RSI and MOM over the last 30 days seem to be the two most important features.
    The feature importance chart corroborates the fact that introducing new features
    leads to an improvement in the model performance.
  prefs: []
  type: TYPE_NORMAL
- en: 7.3\. Backtesting results
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: In this additional step, we perform a backtest on the model we’ve developed.
    We create a column for strategy returns by multiplying the daily returns by the
    position that was held at the close of business the previous day and compare it
    against the actual returns.
  prefs: []
  type: TYPE_NORMAL
- en: Backtesting Trading Strategies
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A backtesting approach similar to the one presented in this case study can be
    used to quickly backtest any trading strategy.
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE89]'
  prefs: []
  type: TYPE_PRE
- en: '`Output`'
  prefs: []
  type: TYPE_NORMAL
- en: '![mlbf 06in18](Images/mlbf_06in18.png)![mlbf 06in19](Images/mlbf_06in19.png)'
  prefs: []
  type: TYPE_IMG
- en: Looking at the backtesting results, we do not deviate significantly from the
    actual market return. Indeed, the achieved momentum trading strategy made us better
    at predicting the price direction to buy or sell in order to make profits. However,
    as our accuracy is not 100% (but more than 96%), we made relatively few losses
    compared to the actual returns.
  prefs: []
  type: TYPE_NORMAL
- en: Conclusion
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: This case study demonstrated that framing the problem is a key step when tackling
    a finance problem with machine learning. In doing so, it was detemined that transforming
    the labels according to an investment objective and performing feature engineering
    were required for this trading strategy. We demonstrated the efficiency of using
    intuitive features related to the trend and momentum of the price movement. This
    helped increase the predictive power of the model. Finally, we introduced a backtesting
    framework, which allowed us to simulate a trading strategy using historical data.
    This enabled us to generate results and analyze risk and profitability before
    risking any actual capital.
  prefs: []
  type: TYPE_NORMAL
- en: '![](Images/bracket_bottom.png)'
  prefs: []
  type: TYPE_IMG
- en: Chapter Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'In [“Case Study 1: Fraud Detection”](#CaseStudy1SC), we explored the issue
    of an unbalanced dataset and the importance of having the right evaluation metric.
    In [“Case Study 2: Loan Default Probability”](#CaseStudy2SC), various techniques
    and concepts of data processing, feature selection, and exploratory analysis were
    covered. In [“Case Study 3: Bitcoin Trading Strategy”](#CaseStudy3SC), we looked
    at ways to create technical indicators as features in order to use them for model
    enhancement. We also prepared a backtesting framework for a trading strategy.'
  prefs: []
  type: TYPE_NORMAL
- en: Overall, the concepts in Python, machine learning, and finance presented in
    this chapter can used as a blueprint for any other classification-based problem
    in finance.
  prefs: []
  type: TYPE_NORMAL
- en: Exercises
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Predict whether a stock price will go up or down using the features related
    to the stock or macroeconomic variables (use the ideas from the bitcoin-based
    case study presented in this chapter).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Create a model to detect money laundering using the features of a transaction.
    A sample dataset for this exercise can be obtained from [Kaggle](https://oreil.ly/GcinN).
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Perform a credit rating analysis of corporations using the features related
    to creditworthiness.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: ^([1](ch06.xhtml#idm45174924215160-marker)) There may be reordering or renaming
    of the steps or substeps based on the appropriateness and intuitiveness of the
    steps/substeps.
  prefs: []
  type: TYPE_NORMAL
- en: ^([2](ch06.xhtml#idm45174922143032-marker)) The predicted variable is further
    used for correlation-based feature reduction.
  prefs: []
  type: TYPE_NORMAL
- en: '^([3](ch06.xhtml#idm45174920856536-marker)) Sampling is covered in detail in
    [“Case Study 1: Fraud Detection”](#CaseStudy1SC).'
  prefs: []
  type: TYPE_NORMAL
