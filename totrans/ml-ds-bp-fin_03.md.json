["```py\n$jupyter notebook\n```", "```py\n# Load libraries\nimport pandas as pd\nfrom matplotlib import pyplot\n```", "```py\nfrom pandas import read_csv\nfilename = 'xyz.csv'\ndata = read_csv(filename, names=names)\n```", "```py\nfrom pandas import read_csv\nurl = 'https://goo.gl/vhm1eU'\nnames = ['age', 'class']\ndata = read_csv(url, names=names)\n```", "```py\nimport pandas_datareader.data as web\n\nccy_tickers = ['DEXJPUS', 'DEXUSUK']\nidx_tickers = ['SP500', 'DJIA', 'VIXCLS']\n\nstk_data = web.DataReader(stk_tickers, 'yahoo')\nccy_data = web.DataReader(ccy_tickers, 'fred')\nidx_data = web.DataReader(idx_tickers, 'fred')\n```", "```py\nset_option('display.width', 100)\ndataset.head(1)\n```", "```py\ndataset.shape\n```", "```py\n(284807, 31)\n```", "```py\n# types\nset_option('display.max_rows', 500)\ndataset.dtypes\n```", "```py\n# describe data\nset_option('precision', 3)\ndataset.describe()\n```", "```py\nfrom matplotlib import pyplot\ndataset.hist(sharex=False, sharey=False, xlabelsize=1, ylabelsize=1,\\\nfigsize=(10,4))\npyplot.show()\n```", "```py\nfrom matplotlib import pyplot\ndataset.plot(kind='density', subplots=True, layout=(3,3), sharex=False,\\\nlegend=True, fontsize=1, figsize=(10,4))\npyplot.show()\n```", "```py\nfrom matplotlib import pyplot\nimport seaborn as sns\ncorrelation = dataset.corr()\npyplot.figure(figsize=(5,5))\npyplot.title('Correlation Matrix')\nsns.heatmap(correlation, vmax=1, square=True,annot=True,cmap='cubehelix')\n```", "```py\nfrom pandas.plotting import scatter_matrix\nscatter_matrix(dataset)\n```", "```py\ndataset.dropna(axis=0)\n```", "```py\ndataset.fillna(0)\n```", "```py\ndataset['col'] = dataset['col'].fillna(dataset['col'].mean())\n```", "```py\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nbestfeatures = SelectKBest( k=5)\nfit = bestfeatures.fit(X,Y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\nfeatureScores = pd.concat([dfcolumns,dfscores],axis=1)\nprint(featureScores.nlargest(2,'Score'))  #print 2 best features\n```", "```py\n                  Specs      Score\n2              Variable1  58262.490\n3              Variable2    321.031\n```", "```py\n#dropping the old features\ndataset.drop(['Feature1','Feature2','Feature3'],axis=1,inplace=True)\n```", "```py\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))\nrescaledX = pd.DataFrame(scaler.fit_transform(X))\n```", "```py\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler().fit(X)\nStandardisedX = pd.DataFrame(scaler.fit_transform(X))\n```", "```py\nfrom sklearn.preprocessing import Normalizer\nscaler = Normalizer().fit(X)\nNormalizedX = pd.DataFrame(scaler.fit_transform(X))\n```", "```py\n# split out validation dataset for the end\nvalidation_size = 0.2\nseed = 7\nX_train, X_validation, Y_train, Y_validation =\\\ntrain_test_split(X, Y, test_size=validation_size, random_state=seed)\n```", "```py\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nvalidation_size = 0.2\nseed = 7\nX = 2 - 3 * np.random.normal(0, 1, 20)\nY = X - 2 * (X ** 2) + 0.5 * (X ** 3) + np.exp(-X)+np.random.normal(-3, 3, 20)\n# transforming the data to include another axis\nX = X[:, np.newaxis]\nY = Y[:, np.newaxis]\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y,\\\ntest_size=validation_size, random_state=seed)\n```", "```py\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import PolynomialFeatures\n\nmodel = LinearRegression()\nmodel.fit(X_train, Y_train)\nY_pred = model.predict(X_train)\n\nrmse_lin = np.sqrt(mean_squared_error(Y_train,Y_pred))\nr2_lin = r2_score(Y_train,Y_pred)\nprint(\"RMSE for Linear Regression:\", rmse_lin)\n\npolynomial_features= PolynomialFeatures(degree=2)\nx_poly = polynomial_features.fit_transform(X_train)\n\nmodel = LinearRegression()\nmodel.fit(x_poly, Y_train)\nY_poly_pred = model.predict(x_poly)\n\nrmse = np.sqrt(mean_squared_error(Y_train,Y_poly_pred))\nr2 = r2_score(Y_train,Y_poly_pred)\nprint(\"RMSE for Polynomial Regression:\", rmse)\n```", "```py\nRMSE for Linear Regression: 6.772942423315028\nRMSE for Polynomial Regression: 6.420495127266883\n```", "```py\nDeg= [1,2,3,6,10]\nresults=[]\nnames=[]\nfor deg in Deg:\n    polynomial_features= PolynomialFeatures(degree=deg)\n    x_poly = polynomial_features.fit_transform(X_train)\n\n    model = LinearRegression()\n    model.fit(x_poly, Y_train)\n    Y_poly_pred = model.predict(x_poly)\n\n    rmse = np.sqrt(mean_squared_error(Y_train,Y_poly_pred))\n    r2 = r2_score(Y_train,Y_poly_pred)\n    results.append(rmse)\n    names.append(deg)\nplt.plot(names, results,'o')\nplt.suptitle('Algorithm Comparison')\n```", "```py\nDeg= [1,2,3,6,8,10]\nfor deg in Deg:\n    polynomial_features= PolynomialFeatures(degree=deg)\n    x_poly = polynomial_features.fit_transform(X_train)\n    model = LinearRegression()\n    model.fit(x_poly, Y_train)\n    x_poly_test = polynomial_features.fit_transform(X_test)\n    Y_poly_pred_test = model.predict(x_poly_test)\n    rmse = np.sqrt(mean_squared_error(Y_test,Y_poly_pred_test))\n    r2 = r2_score(Y_test,Y_poly_pred_test)\n    results_test.append(rmse)\n    names_test.append(deg)\nplt.plot(names_test, results_test,'o')\nplt.suptitle('Algorithm Comparison')\n```", "```py\n# Save Model Using Pickle\nfrom pickle import dump\nfrom pickle import load\n# save the model to disk\nfilename = 'finalized_model.sav'\ndump(model, open(filename, 'wb'))\n# load the model from disk\nloaded_model = load(filename)\n```"]