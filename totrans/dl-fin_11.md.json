["```py\npip install cot_reports\n```", "```py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom master_function import import_cot_data\n```", "```py\ndef import_cot_data(start_year, end_year, market):\n    df = pd.DataFrame()\n    for i in range(start_year, end_year + 1):\n        single_year = pd.DataFrame(cot.cot_year(i, \n                      cot_report_type='traders_in_financial_futures_fut'))\n        df = pd.concat([single_year, df], ignore_index=True)\n    new_df = df.loc[:, ['Market_and_Exchange_Names',\n                        'Report_Date_as_YYYY-MM-DD',\n                        'Pct_of_OI_Dealer_Long_All',\n                        'Pct_of_OI_Dealer_Short_All',\n                        'Pct_of_OI_Lev_Money_Long_All',                    \n                        'Pct_of_OI_Lev_Money_Short_All']]\n    new_df['Report_Date_as_YYYY-MM-DD'] = \n                       pd.to_datetime(new_df['Report_Date_as_YYYY-MM-DD'])\n    new_df = new_df.sort_values(by='Report_Date_as_YYYY-MM-DD')\n    data = new_df[new_df['Market_and_Exchange_Names'] == market]\n    data['Net_COT'] = (data['Pct_of_OI_Lev_Money_Long_All'] – \\\n                       data['Pct_of_OI_Lev_Money_Short_All']) – \\\n                      (data['Pct_of_OI_Dealer_Long_All'] –\\\n                       data['Pct_of_OI_Dealer_Short_All'])                \n    return data\n\n```", "```py\nCAD = 'CANADIAN DOLLAR - CHICAGO MERCANTILE EXCHANGE'\ndata = import_cot_data(2015, 2023, CAD)\ndata = np.array(data.iloc[:, –1], dtype = np.float64)\n\n```", "```py\nEUR = 'EURO FX - CHICAGO MERCANTILE EXCHANGE'\nGBP = 'BRITISH POUND STERLING - CHICAGO MERCANTILE EXCHANGE'\nJPY = 'JAPANESE YEN - CHICAGO MERCANTILE EXCHANGE'\nCHF = 'SWISS FRANC - CHICAGO MERCANTILE EXCHANGE'\nAUD = 'AUSTRALIAN DOLLAR - CHICAGO MERCANTILE EXCHANGE'\nMXN = 'MEXICAN PESO - CHICAGO MERCANTILE EXCHANGE'\nBRL = 'BRAZILIAN REAL - CHICAGO MERCANTILE EXCHANGE'\nBTC = 'BITCOIN - CHICAGO MERCANTILE EXCHANGE'\nSPX = 'E-MINI S&P 500 - CHICAGO MERCANTILE EXCHANGE'\n\n```", "```py\nfrom proxy_requests.proxy_requests import ProxyRequests\nreq = ProxyRequests(\"https://api.ipify.org\")\nreq.get()\n```", "```py\nfrom statsmodels.tsa.stattools import adfuller\nprint('p-value: %f' % adfuller(raw_data)[1])\n```", "```py\np-value: 0.000717\n```", "```py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom master_function import import_cot_data, data_preprocessing\nfrom master_function import plot_train_test_values, \nfrom master_function import calculate_directional_accuracy\nfrom sklearn.metrics import mean_squared_error\n```", "```py\nCAD = 'CANADIAN DOLLAR - CHICAGO MERCANTILE EXCHANGE'\ndata = import_cot_data(2015, 2023, CAD)\ndata = np.array(data.iloc[:, –1], dtype = np.float64)\n```", "```py\nnum_lags = 100\ntrain_test_split = 0.80\nnum_neurons_in_hidden_layers = 200\nnum_epochs = 200\nbatch_size = 4\n# Creating the training and test sets\nx_train, y_train, x_test, y_test = data_preprocessing(data, \n                                                      num_lags, \n                                                      train_test_split)\n\n```", "```py\nx_train = x_train.reshape((–1, num_lags, 1))\nx_test = x_test.reshape((–1, num_lags, 1))\n```", "```py\n# Create the LSTM model\nmodel = Sequential()\n# Adding a first layer\nmodel.add(LSTM(units = neurons, input_shape = (num_lags, 1)))\n# Adding a second layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding the output layer\nmodel.add(Dense(units = 1))\n# Compiling the model\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n# Fitting the model\nmodel.fit(x_train, y_train, epochs = num_epochs, batch_size = batch_size)\n# Predicting in the training set for illustrative purposes\ny_predicted_train = model.predict(x_train)\n# Predicting in the test set\ny_predicted = model.predict(x_test)\n```", "```py\nplot_train_test_values(100, 50, y_train, y_test, y_predicted)\n```", "```py\nDirectional Accuracy Train =  86.18 %\nDirectional Accuracy Test =  60.87 %\nRMSE Train =  5.3655332132\nRMSE Test =  14.7772701349\nCorrelation In-Sample Predicted/Train =  0.995\nCorrelation Out-of-Sample Predicted/Test =  0.88\n\n```", "```py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom master_function import import_cot_data, direct_mpf\nfrom master_function import calculate_directional_accuracy\nfrom sklearn.metrics import mean_squared_error\n\n```", "```py\n# Setting the hyperparameters\nnum_lags = 100\ntrain_test_split = 0.80\nneurons = 400\nnum_epochs = 200\nbatch_size = 10\nforecast_horizon = 50\n# Creating the training and test sets\nx_train, y_train, x_test, y_test = direct_mpf(data, \n                                              num_lags, \n                                              train_test_split, \n                                              forecast_horizon)\n\n```", "```py\nx_train = x_train.reshape((–1, num_lags, 1))\nx_test = x_test.reshape((–1, num_lags, 1))\n\n```", "```py\n# Create the LSTM model\nmodel = Sequential()\n# Adding a first layer\nmodel.add(LSTM(units = neurons, input_shape = (num_lags, 1)))\n# Adding a second layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding the output layer \nmodel.add(Dense(units = forecast_horizon))\n# Compiling the model\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n# Fitting the model\nmodel.fit(x_train, y_train, epochs = num_epochs, batch_size = batch_size)\n# Predicting in the test set\ny_predicted = model.predict(x_test)\n\n```", "```py\nplt.plot(y_predicted[–1], label = 'Predicted data', color = 'red', \n         linewidth = 1)\nplt.plot(y_test[–1], label = 'Test data', color = 'black', \n         linestyle = 'dashed', linewidth = 2)\nplt.grid()\nplt.legend()\n\n```", "```py\nDirectional Accuracy Test =  57.14 %\nRMSE Test =  26.4021245739\nCorrelation Out-of-Sample Predicted/Test =  0.426\n\n```", "```py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom master_function import data_preprocessing, import_cot_data\nfrom master_function import plot_train_test_values, recursive_mpf\nfrom master_function import calculate_directional_accuracy\n\n```", "```py\nnum_lags = 100\ntrain_test_split = 0.80\nneurons = 100\nnum_epochs = 200\nbatch_size = 2\n# Creating the training and test sets\nx_train, y_train, x_test, y_test = data_preprocessing(data,\n                                                      num_lags,\n                                                      train_test_split)\n\n```", "```py\nx_train = x_train.reshape((–1, num_lags, 1))\nx_test = x_test.reshape((–1, num_lags, 1))\n```", "```py\n# Create the LSTM model\nmodel = Sequential()\n# Adding a first layer\nmodel.add(LSTM(units = neurons, input_shape = (num_lags, 1)))\n# Adding a second layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding the output layer \nmodel.add(Dense(units = 1))\n# Compiling the model\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n# Fitting the model\nmodel.fit(x_train, y_train, epochs = num_epochs, batch_size = batch_size)\n# Predicting in the test set on a recursive basis\nx_test, y_predicted = recursive_mpf(x_test, y_test, num_lags, model)\n\n```", "```py\nplot_train_test_values(100, 50, y_train, y_test, y_predicted)\n```", "```py\nDirectional Accuracy Test =  52.17 %\nRMSE Test =  40.3120541504\nCorrelation Out-of-Sample Predicted/Test =  0.737\n\n```", "```py\nimport pandas as pd\nimport numpy as np\n# Import the data using pandas\ndata = pd.read_excel('name_of_file.xlsx')\n\n```", "```py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom master_function import mass_import, rsi, ma, calculate_accuracy\nfrom master_function import plot_train_test_values, \nfrom master_function import multiple_data_preprocessing\nfrom sklearn.metrics import mean_squared_error\nfrom master_function import add_column, delete_column\n\n```", "```py\ndata = mass_import(0, 'W1')[:, –1]\ndata = rsi(np.reshape(data, (–1, 1)), 5, 0, 1)\ndata = ma(data, 5, 0, 2)\ndata[:, 2] = data[:, 0] – data[:, 2]\ndata = add_column(data, 1)\nfor i in range(len(data)):\n    data[i, 3] = data[i, 0] – data[i – 1, 0]\ndata[:, 0] = data[:, –1]\ndata = delete_column(data, 3, 1)\n```", "```py\ndef multiple_data_preprocessing(data, train_test_split):\n    data = add_column(data, 4)\n    data[:, 1] = np.roll(data[:, 1], 1, axis = 0)\n    data[:, 2] = np.roll(data[:, 2], 1, axis = 0)\n    data[:, 3] = np.roll(data[:, 1], 1, axis = 0)\n    data[:, 4] = np.roll(data[:, 2], 1, axis = 0)\n    data[:, 5] = np.roll(data[:, 3], 1, axis = 0)\n    data[:, 6] = np.roll(data[:, 4], 1, axis = 0)\n    data = data[1:, ]\n    x = data[:, 1:]\n    y = data[:, 0]\n    split_index = int(train_test_split * len(x))\n    x_train = x[:split_index]\n    y_train = y[:split_index]\n    x_test = x[split_index:]\n    y_test = y[split_index:]\n    return x_train, y_train, x_test, y_test\n```", "```py\nnum_lags = 6 # Must equal the number of the lagged values you create\ntrain_test_split = 0.80\nneurons = 500\nnum_epochs = 500\nbatch_size = 200\n# Creating the training and test sets\nx_train, y_train, x_test, y_test = multiple_data_preprocessing(data, \n                                                   train_test_split)\n\n```", "```py\nx_train = x_train.reshape((–1, num_lags, 1))\nx_test = x_test.reshape((–1, num_lags, 1))\n```", "```py\n# Create the LSTM model\nmodel = Sequential()\n# Adding a first layer\nmodel.add(LSTM(units = neurons, input_shape = (num_lags, 1)))\n# Adding a second layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding a third layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding a fourth layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding a fifth layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding the output layer \nmodel.add(Dense(units = 1))\n# Compiling the model\nmodel.compile(loss = 'mean_squared_error', optimizer = 'ada\n# Fitting the model\nmodel.fit(x_train, y_train, epochs = num_epochs, batch_size = batch_size)\n# Predicting in the training set for illustrative purposes\ny_predicted_train = model.predict(x_train)\n# Predicting in the test set\ny_predicted = model.predict(x_test)\n\n```", "```py\nplot_train_test_values(100, 50, y_train, y_test, y_predicted)\n```", "```py\nAccuracy Train =  59.39 %\nAccuracy Test =  51.82 %\nRMSE Train =  0.0163232045\nRMSE Test =  0.0122093494\nCorrelation In-Sample Predicted/Train =  0.255\nCorrelation Out-of-Sample Predicted/Test =  0.015\n```", "```py\nimport pandas as pd\n# Manually importing BTCUSD values\nmy_data = pd.read_excel('Bitcoin_Daily_Historical_Data.xlsx')\n# Renaming the columns\nmy_data.columns = ['Date', 'Open', 'High', 'Low', 'Close']\n# Setting the date column\nmy_data['Date'] = pd.to_datetime(my_data['Date'])\n# Charting\nplt.plot(my_data['Date'], my_data['Close'], label = 'BTCUSD', \n         color = 'black')\nplt.legend()\nplt.grid()\n\n```", "```py\nplt.semilogy(my_data['Date'], my_data['Close'], label = 'BTCUSD', \n             color = 'black')\nplt.legend()\nplt.grid()\n\n```", "```py\nimport requests\nimport json\nimport pandas as pd\nimport numpy as np  \nimport datetime as dt\n\n# Selecting the time frame\nfrequency = '1h'\n# Defining the import function\ndef import_crypto(symbol, interval = frequency):\n    # Getting the original link from Binance\n    url = 'https://api.binance.com/api/v1/klines'\n    # Linking the link with the cryptocurrency and the time frame\n    link = url + '?symbol=' + symbol + '&interval=' + interval\n    # Requesting the data in the form of text\n    data = json.loads(requests.get(link).text)\n    # Converting the text data to a dataframe\n    data = np.array(data)\n    data = data.astype(np.float)\n    data = data[:, 1:5]\n    return data\n# Importing hourly BTCUSD data\ndata = import_crypto('BTCUSDT')\n\n```", "```py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom master_function import add_column, delete_row, volatility\nfrom master_function import data_preprocessing, plot_train_test_values\nfrom master_function import calculate_directional_accuracy\nfrom sklearn.metrics import mean_squared_error\nfrom statsmodels.tsa.stattools import adfuller\n\n```", "```py\ndata = pd.read_excel('Bitcoin_Daily_Historical_Data.xlsx').values\n\n```", "```py\ndata = volatility(data, 10, 0, 1)\ndata = data[:, –1]\n```", "```py\nprint('p-value: %f' % adfuller(data)[1])\n```", "```py\np-value: 0.120516\n```", "```py\ndata = np.diff(data)\n```", "```py\nnum_lags = 300\ntrain_test_split = 0.80\nneurons = 80\nnum_epochs = 100\nbatch_size = 500\n# Prepare the arrays\nx_train, y_train, x_test, y_test = direct_mpf(data, \n                                              num_lags, \n                                              train_test_split, \n                                              forecast_horizon)\n\n```", "```py\nx_train = x_train.reshape((–1, num_lags, 1))\nx_test = x_test.reshape((–1, num_lags, 1))\n```", "```py\n# Create the LSTM model\nmodel = Sequential()\n# Adding a first layer\nmodel.add(LSTM(units = neurons, input_shape = (num_lags, 1)))\n# Adding a second layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding a third layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding a fourth layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding the output layer \nmodel.add(Dense(units = forecast_horizon))\n# Compiling the model\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n\n```", "```py\nmodel.fit(x_train, y_train, epochs = num_epochs, batch_size = batch_size)\ny_predicted = model.predict(x_test)\n\n```", "```py\nAccuracy Train =  66.56 %\nAccuracy Test =  63.59 %\nRMSE Train =  95.6086778521\nRMSE Test =  186.1401365824\nCorrelation In-Sample Predicted/Train =  0.807\nCorrelation Out-of-Sample Predicted/Test =  0.56\n```", "```py\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM\nfrom master_function import data_preprocessing\nfrom master_function import calculate_directional_accuracy\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf\nimport random\n\n```", "```py\n data = np.diff(np.reshape(pd.read_excel('ISM_PMI.xlsx').values, (–1)))\n```", "```py\nnum_lags = 100\ntrain_test_split = 0.80\nneurons = 200\nnum_epochs = 200\nbatch_size = 4\n# Creating the training and test sets\nx_train, y_train, x_test, y_test = data_preprocessing(data, \n                                                      num_lags, \n                                                      train_test_split)\n\n```", "```py\nx_train = x_train.reshape((–1, num_lags, 1))\nx_test = x_test.reshape((–1, num_lags, 1))\n```", "```py\n# Create the LSTM model\nmodel = Sequential()\n# Adding a first layer\nmodel.add(LSTM(units = neurons, input_shape = (num_lags, 1)))\n# Adding a second layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding a third layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding a fourth layer\nmodel.add(Dense(neurons, activation = 'relu')) \n# Adding the output layer \nmodel.add(Dense(units = 1))\n# Compiling the model\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam')\n\n```", "```py\ndef update_plot(epoch, logs):\n    if epoch % 1 == 0:\n        plt.cla()\n        y_predicted_train = model.predict(x_train)\n        plt.plot(y_train, label = 'Training data', \n                 color = 'black', linewidth = 2.5)\n        plt.plot(y_predicted_train, label = 'Predicted data', \n                 color = 'red', linewidth = 1)\n        plt.title(f'Training Epoch: {epoch}')\n        plt.xlabel('Time')\n        plt.ylabel('Value')\n        plt.legend()\n        plt.savefig(str(random.randint(1, 1000)))\n# Create the dynamic plot\nfig = plt.figure()\n# Train the model using the on_epoch_end callback\nclass PlotCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs = None):\n        update_plot(epoch, logs)\n        plt.pause(0.001)\nplot_callback = PlotCallback()\nhistory = model.fit(x_train, y_train, epochs = num_epochs, \n                    batch_size = batch_size, callbacks = [plot_callback])\n\n```", "```py\npip install pydot\npip install pydotplus\npip install graphviz\n```", "```py\nfrom tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file = 'Architecture.png', \n           show_shapes = True, \n           show_layer_names = True)\nImage('Architecture.png')\n\n```"]