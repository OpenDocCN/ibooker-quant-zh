["```py\nIn [1]: import os\n        import random\n        import numpy as np  ![1](assets/1.png)\n        from pylab import mpl, plt  ![2](assets/2.png)\n        plt.style.use('seaborn')\n        mpl.rcParams['savefig.dpi'] = 300\n        mpl.rcParams['font.family'] = 'serif'\n        os.environ['PYTHONHASHSEED'] = '0'\n\nIn [2]: x = np.linspace(0, 10)  ![3](assets/3.png)\n\nIn [3]: def set_seeds(seed=100):\n            random.seed(seed)\n            np.random.seed(seed)\n        set_seeds() ![4](assets/4.png)\n\nIn [4]: y = x + np.random.standard_normal(len(x))  ![5](assets/5.png)\n\nIn [5]: reg = np.polyfit(x, y, deg=1)  ![6](assets/6.png)\n\nIn [6]: reg  ![7](assets/7.png)\nOut[6]: array([0.94612934, 0.22855261])\n\nIn [7]: plt.figure(figsize=(10, 6))  ![8](assets/8.png)\n        plt.plot(x, y, 'bo', label='data')  ![9](assets/9.png)\n        plt.plot(x, np.polyval(reg, x), 'r', lw=2.5,\n                 label='linear regression')  ![10](assets/10.png)\n        plt.legend(loc=0);  ![11](assets/11.png)\n```", "```py\nIn [8]: plt.figure(figsize=(10, 6))\n        plt.plot(x, y, 'bo', label='data')\n        xn = np.linspace(0, 20)  ![1](assets/1.png)\n        plt.plot(xn, np.polyval(reg, xn), 'r', lw=2.5,\n                 label='linear regression')\n        plt.legend(loc=0);\n```", "```py\nIn [9]: x = np.arange(12)\n\nIn [10]: x\nOut[10]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n```", "```py\nIn [11]: lags = 3  ![1](assets/1.png)\n\nIn [12]: m = np.zeros((lags + 1, len(x) - lags))  ![2](assets/2.png)\n\nIn [13]: m[lags] = x[lags:]  ![3](assets/3.png)\n         for i in range(lags):  ![4](assets/4.png)\n             m[i] = x[i:i - lags]  ![5](assets/5.png)\n\nIn [14]: m.T  ![6](assets/6.png)\nOut[14]: array([[ 0.,  1.,  2.,  3.],\n                [ 1.,  2.,  3.,  4.],\n                [ 2.,  3.,  4.,  5.],\n                [ 3.,  4.,  5.,  6.],\n                [ 4.,  5.,  6.,  7.],\n                [ 5.,  6.,  7.,  8.],\n                [ 6.,  7.,  8.,  9.],\n                [ 7.,  8.,  9., 10.],\n                [ 8.,  9., 10., 11.]])\n```", "```py\nIn [15]: reg = np.linalg.lstsq(m[:lags].T, m[lags], rcond=None)[0]  ![1](assets/1.png)\n\nIn [16]: reg  ![2](assets/2.png)\nOut[16]: array([-0.66666667,  0.33333333,  1.33333333])\n\nIn [17]: np.dot(m[:lags].T, reg)  ![3](assets/3.png)\nOut[17]: array([ 3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n```", "```py\nIn [18]: import pandas as pd  ![1](assets/1.png)\n\nIn [19]: raw = pd.read_csv('http://hilpisch.com/pyalgo_eikon_eod_data.csv',\n                           index_col=0, parse_dates=True).dropna()  ![2](assets/2.png)\n\nIn [20]: raw.info()  ![2](assets/2.png)\n         <class 'pandas.core.frame.DataFrame'>\n         DatetimeIndex: 2516 entries, 2010-01-04 to 2019-12-31\n         Data columns (total 12 columns):\n          #   Column  Non-Null Count  Dtype\n         ---  ------  --------------  -----\n          0   AAPL.O  2516 non-null   float64\n          1   MSFT.O  2516 non-null   float64\n          2   INTC.O  2516 non-null   float64\n          3   AMZN.O  2516 non-null   float64\n          4   GS.N    2516 non-null   float64\n          5   SPY     2516 non-null   float64\n          6   .SPX    2516 non-null   float64\n          7   .VIX    2516 non-null   float64\n          8   EUR=    2516 non-null   float64\n          9   XAU=    2516 non-null   float64\n          10  GDX     2516 non-null   float64\n          11  GLD     2516 non-null   float64\n         dtypes: float64(12)\n         memory usage: 255.5 KB\n\nIn [21]: symbol = 'EUR='\n\nIn [22]: data = pd.DataFrame(raw[symbol])  ![3](assets/3.png)\n\nIn [23]: data.rename(columns={symbol: 'price'}, inplace=True)  ![4](assets/4.png)\n```", "```py\nIn [24]: lags = 5\n\nIn [25]: cols = []\n         for lag in range(1, lags + 1):\n             col = f'lag_{lag}'\n             data[col] = data['price'].shift(lag) ![1](assets/1.png)\n             cols.append(col)\n         data.dropna(inplace=True)\n\nIn [26]: reg = np.linalg.lstsq(data[cols], data['price'],\n                               rcond=None)[0]\n\nIn [27]: reg\nOut[27]: array([ 0.98635864,  0.02292172, -0.04769849,  0.05037365,\n          -0.01208135])\n```", "```py\nIn [28]: data['prediction'] = np.dot(data[cols], reg)  ![1](assets/1.png)\n\nIn [29]: data[['price', 'prediction']].plot(figsize=(10, 6));  ![2](assets/2.png)\n```", "```py\nIn [30]: data[['price', 'prediction']].loc['2019-10-1':].plot(\n                     figsize=(10, 6));\n```", "```py\nIn [31]: data['return'] = np.log(data['price'] /\n                                  data['price'].shift(1))  ![1](assets/1.png)\n\nIn [32]: data.dropna(inplace=True)  ![2](assets/2.png)\n\nIn [33]: cols = []\n         for lag in range(1, lags + 1):\n             col = f'lag_{lag}'\n             data[col] = data['return'].shift(lag) ![3](assets/3.png)\n             cols.append(col)\n         data.dropna(inplace=True)\n\nIn [34]: reg = np.linalg.lstsq(data[cols], data['return'],\n                               rcond=None)[0]\n\nIn [35]: reg\nOut[35]: array([-0.015689  ,  0.00890227, -0.03634858,  0.01290924,\n          -0.00636023])\n```", "```py\nIn [36]: data['prediction'] = np.dot(data[cols], reg)\n\nIn [37]: data[['return', 'prediction']].iloc[lags:].plot(figsize=(10, 6));\n```", "```py\nIn [38]: hits = np.sign(data['return'] *\n                        data['prediction']).value_counts()  ![1](assets/1.png)\n\nIn [39]: hits  ![2](assets/2.png)\nOut[39]:  1.0    1250\n         -1.0    1242\n          0.0      13\n         dtype: int64\n\nIn [40]: hits.values[0] / sum(hits)  ![3](assets/3.png)\nOut[40]: 0.499001996007984\n```", "```py\nIn [41]: reg = np.linalg.lstsq(data[cols], np.sign(data['return']),\n                               rcond=None)[0]  ![1](assets/1.png)\n\nIn [42]: reg\nOut[42]: array([-5.11938725, -2.24077248, -5.13080606, -3.03753232,\n          -2.14819119])\n\nIn [43]: data['prediction'] = np.sign(np.dot(data[cols], reg))  ![2](assets/2.png)\n\nIn [44]: data['prediction'].value_counts()\nOut[44]:  1.0    1300\n         -1.0    1205\n         Name: prediction, dtype: int64\n\nIn [45]: hits = np.sign(data['return'] *\n                        data['prediction']).value_counts()\n\nIn [46]: hits\nOut[46]:  1.0    1301\n         -1.0    1191\n          0.0      13\n         dtype: int64\n\nIn [47]: hits.values[0] / sum(hits)\nOut[47]: 0.5193612774451097\n```", "```py\nIn [48]: data.head()\nOut[48]:              price     lag_1     lag_2     lag_3     lag_4     lag_5  \\\n         Date\n         2010-01-20  1.4101 -0.005858 -0.008309 -0.000551  0.001103 -0.001310\n         2010-01-21  1.4090 -0.013874 -0.005858 -0.008309 -0.000551  0.001103\n         2010-01-22  1.4137 -0.000780 -0.013874 -0.005858 -0.008309 -0.000551\n         2010-01-25  1.4150  0.003330 -0.000780 -0.013874 -0.005858 -0.008309\n         2010-01-26  1.4073  0.000919  0.003330 -0.000780 -0.013874 -0.005858\n\n                     prediction    return\n         Date\n         2010-01-20         1.0 -0.013874\n         2010-01-21         1.0 -0.000780\n         2010-01-22         1.0  0.003330\n         2010-01-25         1.0  0.000919\n         2010-01-26         1.0 -0.005457\n\nIn [49]: data['strategy'] = data['prediction'] * data['return']  ![1](assets/1.png)\n\nIn [50]: data[['return', 'strategy']].sum().apply(np.exp)  ![2](assets/2.png)\nOut[50]: return      0.784026\n         strategy    1.654154\n         dtype: float64\n\nIn [51]: data[['return', 'strategy']].dropna().cumsum(\n                 ).apply(np.exp).plot(figsize=(10, 6));  ![3](assets/3.png)\n```", "```py\nIn [52]: import LRVectorBacktester as LR  ![1](assets/1.png)\n\nIn [53]: lrbt = LR.LRVectorBacktester('EUR=', '2010-1-1', '2019-12-31',\n                                              10000, 0.0)  ![2](assets/2.png)\n\nIn [54]: lrbt.run_strategy('2010-1-1', '2019-12-31',\n                           '2010-1-1', '2019-12-31', lags=5)  ![3](assets/3.png)\nOut[54]: (17166.53, 9442.42)\n\nIn [55]: lrbt.run_strategy('2010-1-1', '2017-12-31',\n                           '2018-1-1', '2019-12-31', lags=5)  ![4](assets/4.png)\nOut[55]: (10160.86, 791.87)\n\nIn [56]: lrbt.plot_results()  ![5](assets/5.png)\n```", "```py\nIn [57]: lrbt = LR.LRVectorBacktester('GDX', '2010-1-1', '2019-12-31',\n                                              10000, 0.002)  ![1](assets/1.png)\n\nIn [58]: lrbt.run_strategy('2010-1-1', '2019-12-31',\n                           '2010-1-1', '2019-12-31', lags=7)\nOut[58]: (23642.32, 17649.69)\n\nIn [59]: lrbt.run_strategy('2010-1-1', '2014-12-31',\n                           '2015-1-1', '2019-12-31', lags=7)\nOut[59]: (28513.35, 14888.41)\n\nIn [60]: lrbt.plot_results()\n```", "```py\nIn [61]: x = np.arange(12)\n\nIn [62]: x\nOut[62]: array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])\n\nIn [63]: lags = 3\n\nIn [64]: m = np.zeros((lags + 1, len(x) - lags))\n\nIn [65]: m[lags] = x[lags:]\n         for i in range(lags):\n             m[i] = x[i:i - lags]\n```", "```py\nIn [66]: from sklearn import linear_model  ![1](assets/1.png)\n\nIn [67]: lm = linear_model.LinearRegression()  ![2](assets/2.png)\n\nIn [68]: lm.fit(m[:lags].T, m[lags])  ![3](assets/3.png)\nOut[68]: LinearRegression()\n\nIn [69]: lm.coef_  ![4](assets/4.png)\nOut[69]: array([0.33333333, 0.33333333, 0.33333333])\n\nIn [70]: lm.intercept_  ![5](assets/5.png)\nOut[70]: 2.0\n\nIn [71]: lm.predict(m[:lags].T)  ![6](assets/6.png)\nOut[71]: array([ 3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n```", "```py\nIn [72]: lm = linear_model.LinearRegression(fit_intercept=False)  ![1](assets/1.png)\n\nIn [73]: lm.fit(m[:lags].T, m[lags])\nOut[73]: LinearRegression(fit_intercept=False)\n\nIn [74]: lm.coef_\nOut[74]: array([-0.66666667,  0.33333333,  1.33333333])\n\nIn [75]: lm.intercept_\nOut[75]: 0.0\n\nIn [76]: lm.predict(m[:lags].T)\nOut[76]: array([ 3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])\n```", "```py\nIn [77]: hours = np.array([0.5, 0.75, 1., 1.25, 1.5, 1.75, 1.75, 2.,\n                           2.25, 2.5, 2.75, 3., 3.25, 3.5, 4., 4.25,\n                           4.5, 4.75, 5., 5.5])  ![1](assets/1.png)\n\nIn [78]: success = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n                             0, 1, 1, 1, 1, 1, 1])  ![2](assets/2.png)\n\nIn [79]: plt.figure(figsize=(10, 6))\n         plt.plot(hours, success, 'ro')  ![3](assets/3.png)\n         plt.ylim(-0.2, 1.2);  ![4](assets/4.png)\n```", "```py\nIn [80]: reg = np.polyfit(hours, success, deg=1)  ![1](assets/1.png)\n\nIn [81]: plt.figure(figsize=(10, 6))\n         plt.plot(hours, success, 'ro')\n         plt.plot(hours, np.polyval(reg, hours), 'b')  ![2](assets/2.png)\n         plt.ylim(-0.2, 1.2);\n```", "```py\nIn [82]: lm = linear_model.LogisticRegression(solver='lbfgs')  ![1](assets/1.png)\n\nIn [83]: hrs = hours.reshape(1, -1).T  ![2](assets/2.png)\n\nIn [84]: lm.fit(hrs, success)  ![3](assets/3.png)\nOut[84]: LogisticRegression()\n\nIn [85]: prediction = lm.predict(hrs)  ![4](assets/4.png)\n\nIn [86]: plt.figure(figsize=(10, 6))\n         plt.plot(hours, success, 'ro', label='data')\n         plt.plot(hours, prediction, 'b', label='prediction')\n         plt.legend(loc=0)\n         plt.ylim(-0.2, 1.2);\n```", "```py\nIn [87]: prob = lm.predict_proba(hrs)  ![1](assets/1.png)\n\nIn [88]: plt.figure(figsize=(10, 6))\n         plt.plot(hours, success, 'ro')\n         plt.plot(hours, prediction, 'b')\n         plt.plot(hours, prob.T[0], 'm--',\n                  label='$p(h)$ for zero')  ![2](assets/2.png)\n         plt.plot(hours, prob.T[1], 'g-.',\n                  label='$p(h)$ for one')  ![3](assets/3.png)\n         plt.ylim(-0.2, 1.2)\n         plt.legend(loc=0);\n```", "```py\nIn [89]: symbol = 'GLD'\n\nIn [90]: data = pd.DataFrame(raw[symbol])\n\nIn [91]: data.rename(columns={symbol: 'price'}, inplace=True)\n\nIn [92]: data['return'] = np.log(data['price'] / data['price'].shift(1))\n\nIn [93]: data.dropna(inplace=True)\n\nIn [94]: lags = 3\n\nIn [95]: cols = []  ![1](assets/1.png)\n         for lag in range(1, lags + 1):\n             col = 'lag_{}'.format(lag)  ![2](assets/2.png)\n             data[col] = data['return'].shift(lag)  ![3](assets/3.png)\n             cols.append(col)  ![4](assets/4.png)\n\nIn [96]: data.dropna(inplace=True)  ![5](assets/5.png)\n```", "```py\nIn [97]: from sklearn.metrics import accuracy_score\n\nIn [98]: lm = linear_model.LogisticRegression(C=1e7, solver='lbfgs',\n                                              multi_class='auto',\n                                              max_iter=1000)  ![1](assets/1.png)\n\nIn [99]: lm.fit(data[cols], np.sign(data['return']))  ![2](assets/2.png)\nOut[99]: LogisticRegression(C=10000000.0, max_iter=1000)\n\nIn [100]: data['prediction'] = lm.predict(data[cols])  ![3](assets/3.png)\n\nIn [101]: data['prediction'].value_counts()  ![4](assets/4.png)\nOut[101]:  1.0    1983\n          -1.0     529\n          Name: prediction, dtype: int64\n\nIn [102]: hits = np.sign(data['return'].iloc[lags:] *\n                         data['prediction'].iloc[lags:]\n                        ).value_counts()  ![5](assets/5.png)\n\nIn [103]: hits\nOut[103]:  1.0    1338\n          -1.0    1159\n           0.0      12\n          dtype: int64\n\nIn [104]: accuracy_score(data['prediction'],\n                         np.sign(data['return']))  ![6](assets/6.png)\nOut[104]: 0.5338375796178344\n\nIn [105]: data['strategy'] = data['prediction'] * data['return']  ![7](assets/7.png)\n\nIn [106]: data[['return', 'strategy']].sum().apply(np.exp)  ![7](assets/7.png)\nOut[106]: return      1.289478\n          strategy    2.458716\n          dtype: float64\n\nIn [107]: data[['return', 'strategy']].cumsum().apply(np.exp).plot(\n                                                  figsize=(10, 6));  ![8](assets/8.png)\n```", "```py\nIn [108]: data = pd.DataFrame(raw[symbol])\n\nIn [109]: data.rename(columns={symbol: 'price'}, inplace=True)\n\nIn [110]: data['return'] = np.log(data['price'] / data['price'].shift(1))\n\nIn [111]: lags = 5\n\nIn [112]: cols = []\n          for lag in range(1, lags + 1):\n              col = 'lag_%d' % lag\n              data[col] = data['price'].shift(lag)  ![1](assets/1.png)\n              cols.append(col)\n\nIn [113]: data.dropna(inplace=True)\n\nIn [114]: lm.fit(data[cols], np.sign(data['return']))  ![2](assets/2.png)\nOut[114]: LogisticRegression(C=10000000.0, max_iter=1000)\n\nIn [115]: data['prediction'] = lm.predict(data[cols])\n\nIn [116]: data['prediction'].value_counts()  ![3](assets/3.png)\nOut[116]:  1.0    2047\n          -1.0     464\n          Name: prediction, dtype: int64\n\nIn [117]: hits = np.sign(data['return'].iloc[lags:] *\n                         data['prediction'].iloc[lags:]\n                        ).value_counts()\n\nIn [118]: hits\nOut[118]:  1.0    1331\n          -1.0    1163\n           0.0      12\n          dtype: int64\n\nIn [119]: accuracy_score(data['prediction'],\n                         np.sign(data['return']))  ![4](assets/4.png)\nOut[119]: 0.5312624452409399\n\nIn [120]: data['strategy'] = data['prediction'] * data['return']  ![5](assets/5.png)\n\nIn [121]: data[['return', 'strategy']].sum().apply(np.exp)  ![5](assets/5.png)\nOut[121]: return      1.283110\n          strategy    2.656833\n          dtype: float64\n\nIn [122]: data[['return', 'strategy']].cumsum().apply(np.exp).plot(\n                                                  figsize=(10, 6));\n```", "```py\nIn [123]: import ScikitVectorBacktester as SCI\n\nIn [124]: scibt = SCI.ScikitVectorBacktester('EUR=',\n                                             '2010-1-1', '2019-12-31',\n                                             10000, 0.0, 'logistic')\n\nIn [125]: scibt.run_strategy('2015-1-1', '2019-12-31',\n                             '2015-1-1', '2019-12-31', lags=15)\nOut[125]: (12192.18, 2189.5)\n\nIn [126]: scibt.run_strategy('2016-1-1', '2018-12-31',\n                             '2019-1-1', '2019-12-31', lags=15)\nOut[126]: (10580.54, 729.93)\n\nIn [127]: scibt.plot_results()\n```", "```py\nIn [128]: scibt = SCI.ScikitVectorBacktester('GDX',\n                                             '2010-1-1', '2019-12-31',\n                                             10000, 0.00, 'logistic')\n\nIn [129]: scibt.run_strategy('2013-1-1', '2017-12-31',\n                             '2018-1-1', '2018-12-31', lags=10)\nOut[129]: (12686.81, 4032.73)\n\nIn [130]: scibt.plot_results()\n```", "```py\nIn [131]: scibt = SCI.ScikitVectorBacktester('GDX',\n                                             '2010-1-1', '2019-12-31',\n                                             10000, 0.0025, 'logistic')\n\nIn [132]: scibt.run_strategy('2013-1-1', '2017-12-31',\n                             '2018-1-1', '2018-12-31', lags=10)\nOut[132]: (9588.48, 934.4)\n\nIn [133]: scibt.plot_results()\n```", "```py\nIn [134]: hours = np.array([0.5, 0.75, 1., 1.25, 1.5, 1.75, 1.75, 2.,\n                            2.25, 2.5, 2.75, 3., 3.25, 3.5, 4., 4.25,\n                            4.5, 4.75, 5., 5.5])\n\nIn [135]: success = np.array([0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n                              0, 1, 1, 1, 1, 1, 1])\n\nIn [136]: data = pd.DataFrame({'hours': hours, 'success': success})  ![1](assets/1.png)\n\nIn [137]: data.info()  ![2](assets/2.png)\n          <class 'pandas.core.frame.DataFrame'>\n          RangeIndex: 20 entries, 0 to 19\n          Data columns (total 2 columns):\n           #   Column   Non-Null Count  Dtype\n          ---  ------   --------------  -----\n           0   hours    20 non-null     float64\n           1   success  20 non-null     int64\n          dtypes: float64(1), int64(1)\n          memory usage: 448.0 bytes\n```", "```py\nIn [138]: from sklearn.neural_network import MLPClassifier  ![1](assets/1.png)\n\nIn [139]: model = MLPClassifier(hidden_layer_sizes=[32],\n                               max_iter=1000, random_state=100)  ![2](assets/2.png)\n```", "```py\nIn [140]: model.fit(data['hours'].values.reshape(-1, 1), data['success'])  ![1](assets/1.png)\nOut[140]: MLPClassifier(hidden_layer_sizes=[32], max_iter=1000,\n           random_state=100)\n\nIn [141]: data['prediction'] = model.predict(data['hours'].values.reshape(-1, 1)) ![2](assets/2.png)\n\nIn [142]: data.tail()\nOut[142]:     hours  success  prediction\n          15   4.25        1           1\n          16   4.50        1           1\n          17   4.75        1           1\n          18   5.00        1           1\n          19   5.50        1           1\n\nIn [143]: data.plot(x='hours', y=['success', 'prediction'],\n                    style=['ro', 'b-'], ylim=[-.1, 1.1],\n                    figsize=(10, 6));  ![3](assets/3.png)\n```", "```py\nIn [144]: symbol = 'EUR='  ![1](assets/1.png)\n\nIn [145]: data = pd.DataFrame(raw[symbol])  ![2](assets/2.png)\n\nIn [146]: data.rename(columns={symbol: 'price'}, inplace=True)  ![3](assets/3.png)\n\nIn [147]: data['return'] = np.log(data['price'] /\n                                   data['price'].shift(1))   ![4](assets/4.png)\n\nIn [148]: data['direction'] = np.where(data['return'] > 0, 1, 0)  ![4](assets/4.png)\n\nIn [149]: lags = 5\n\nIn [150]: cols = []\n          for lag in range(1, lags + 1): ![5](assets/5.png)\n              col = f'lag_{lag}'\n              data[col] = data['return'].shift(lag) ![6](assets/6.png)\n              cols.append(col)\n          data.dropna(inplace=True) ![7](assets/7.png)\n\nIn [151]: data.round(4).tail()  ![8](assets/8.png)\nOut[151]:\n                  price  return  direction   lag_1   lag_2   lag_3   lag_4   lag_5\n     Date\n     2019-12-24  1.1087  0.0001          1  0.0007 -0.0038  0.0008 -0.0034  0.0006\n     2019-12-26  1.1096  0.0008          1  0.0001  0.0007 -0.0038  0.0008 -0.0034\n     2019-12-27  1.1175  0.0071          1  0.0008  0.0001  0.0007 -0.0038  0.0008\n     2019-12-30  1.1197  0.0020          1  0.0071  0.0008  0.0001  0.0007 -0.0038\n     2019-12-31  1.1210  0.0012          1  0.0020  0.0071  0.0008  0.0001  0.0007\n```", "```py\nIn [152]: import tensorflow as tf  ![1](assets/1.png)\n          from keras.models import Sequential  ![2](assets/2.png)\n          from keras.layers import Dense  ![3](assets/3.png)\n          from keras.optimizers import Adam, RMSprop\n\nIn [153]: optimizer = Adam(learning_rate=0.0001)\n\nIn [154]: def set_seeds(seed=100):\n              random.seed(seed)\n              np.random.seed(seed)\n              tf.random.set_seed(100)\n\nIn [155]: set_seeds()\n          model = Sequential()  ![4](assets/4.png)\n          model.add(Dense(64, activation='relu',\n                  input_shape=(lags,)))  ![5](assets/5.png)\n          model.add(Dense(64, activation='relu'))  ![5](assets/5.png)\n          model.add(Dense(1, activation='sigmoid')) ![5](assets/5.png)\n          model.compile(optimizer=optimizer,\n                        loss='binary_crossentropy',\n                        metrics=['accuracy'])  ![6](assets/6.png)\n\nIn [156]: cutoff = '2017-12-31'  ![7](assets/7.png)\n\nIn [157]: training_data = data[data.index < cutoff].copy()  ![8](assets/8.png)\n\nIn [158]: mu, std = training_data.mean(), training_data.std()  ![9](assets/9.png)\n\nIn [159]: training_data_ = (training_data - mu) / std  ![9](assets/9.png)\n\nIn [160]: test_data = data[data.index >= cutoff].copy()  ![8](assets/8.png)\n\nIn [161]: test_data_ = (test_data - mu) / std  ![9](assets/9.png)\n\nIn [162]: %%time\n          model.fit(training_data[cols],\n                    training_data['direction'],\n                    epochs=50, verbose=False,\n                    validation_split=0.2, shuffle=False)  ![10](assets/10.png)\n          CPU times: user 4.86 s, sys: 989 ms, total: 5.85 s\n          Wall time: 3.34 s\n\nOut[162]: <tensorflow.python.keras.callbacks.History at 0x7f996a0a2880>\n\nIn [163]: res = pd.DataFrame(model.history.history)\n\nIn [164]: res[['accuracy', 'val_accuracy']].plot(figsize=(10, 6), style='--');\n```", "```py\nIn [165]: model.evaluate(training_data_[cols], training_data['direction'])\n          63/63 [==============================] - 0s 586us/step - loss: 0.7556 -\n           accuracy: 0.5152\n\nOut[165]: [0.7555528879165649, 0.5151968002319336]\n\nIn [166]: pred = np.where(model.predict(training_data_[cols]) > 0.5, 1, 0)  ![1](assets/1.png)\n\nIn [167]: pred[:30].flatten()  ![1](assets/1.png)\nOut[167]: array([0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n           0, 0, 0, 1, 0, 1, 0, 1, 0, 0])\n\nIn [168]: training_data['prediction'] = np.where(pred > 0, 1, -1)  ![2](assets/2.png)\n\nIn [169]: training_data['strategy'] = (training_data['prediction'] *\n                                      training_data['return'])  ![3](assets/3.png)\n\nIn [170]: training_data[['return', 'strategy']].sum().apply(np.exp)\nOut[170]: return      0.826569\n          strategy    1.317303\n          dtype: float64\n\nIn [171]: training_data[['return', 'strategy']].cumsum(\n                          ).apply(np.exp).plot(figsize=(10, 6));  ![4](assets/4.png)\n```", "```py\nIn [172]: model.evaluate(test_data_[cols], test_data['direction'])\n          16/16 [==============================] - 0s 676us/step - loss: 0.7292 -\n           accuracy: 0.5050\n\nOut[172]: [0.7292129993438721, 0.5049701929092407]\n\nIn [173]: pred = np.where(model.predict(test_data_[cols]) > 0.5, 1, 0)\n\nIn [174]: test_data['prediction'] = np.where(pred > 0, 1, -1)\n\nIn [175]: test_data['prediction'].value_counts()\nOut[175]: -1    368\n           1    135\n          Name: prediction, dtype: int64\n\nIn [176]: test_data['strategy'] = (test_data['prediction'] *\n                                  test_data['return'])\n\nIn [177]: test_data[['return', 'strategy']].sum().apply(np.exp)\nOut[177]: return      0.934478\n          strategy    1.109065\n          dtype: float64\n\nIn [178]: test_data[['return', 'strategy']].cumsum(\n                          ).apply(np.exp).plot(figsize=(10, 6));\n```", "```py\nIn [179]: data['momentum'] = data['return'].rolling(5).mean().shift(1)  ![1](assets/1.png)\n\nIn [180]: data['volatility'] = data['return'].rolling(20).std().shift(1)  ![2](assets/2.png)\n\nIn [181]: data['distance'] = (data['price'] -\n                              data['price'].rolling(50).mean()).shift(1)  ![3](assets/3.png)\n\nIn [182]: data.dropna(inplace=True)\n\nIn [183]: cols.extend(['momentum', 'volatility', 'distance'])\n\nIn [184]: print(data.round(4).tail())\n\n                 price  return  direction   lag_1   lag_2   lag_3   lag_4    lag_5\n    Date\n\n    2019-12-24  1.1087  0.0001          1  0.0007 -0.0038  0.0008 -0.0034   0.0006\n    2019-12-26  1.1096  0.0008          1  0.0001  0.0007 -0.0038  0.0008  -0.0034\n    2019-12-27  1.1175  0.0071          1  0.0008  0.0001  0.0007 -0.0038   0.0008\n    2019-12-30  1.1197  0.0020          1  0.0071  0.0008  0.0001  0.0007  -0.0038\n    2019-12-31  1.1210  0.0012          1  0.0020  0.0071  0.0008  0.0001   0.0007\n\n                      momentum  volatility  distance\n          Date\n          2019-12-24   -0.0010      0.0024    0.0005\n          2019-12-26   -0.0011      0.0024    0.0004\n          2019-12-27   -0.0003      0.0024    0.0012\n          2019-12-30    0.0010      0.0028    0.0089\n          2019-12-31    0.0021      0.0028    0.0110\n```", "```py\nIn [185]: training_data = data[data.index < cutoff].copy()\n\nIn [186]: mu, std = training_data.mean(), training_data.std()\n\nIn [187]: training_data_ = (training_data - mu) / std\n\nIn [188]: test_data = data[data.index >= cutoff].copy()\n\nIn [189]: test_data_ = (test_data - mu) / std\n\nIn [190]: set_seeds()\n          model = Sequential()\n          model.add(Dense(32, activation='relu',\n                          input_shape=(len(cols),)))  ![1](assets/1.png)\n          model.add(Dense(32, activation='relu'))\n          model.add(Dense(1, activation='sigmoid'))\n          model.compile(optimizer=optimizer,\n                        loss='binary_crossentropy',\n                        metrics=['accuracy'])\n```", "```py\nIn [191]: %%time\n          model.fit(training_data_[cols], training_data['direction'],\n                    verbose=False, epochs=25)\n          CPU times: user 2.32 s, sys: 577 ms, total: 2.9 s\n          Wall time: 1.48 s\n\nOut[191]: <tensorflow.python.keras.callbacks.History at 0x7f996d35c100>\n\nIn [192]: model.evaluate(training_data_[cols], training_data['direction'])\n          62/62 [==============================] - 0s 649us/step - loss: 0.6816 -\n           accuracy: 0.5646\n\nOut[192]: [0.6816270351409912, 0.5646397471427917]\n\nIn [193]: pred = np.where(model.predict(training_data_[cols]) > 0.5, 1, 0)\n\nIn [194]: training_data['prediction'] = np.where(pred > 0, 1, -1)\n\nIn [195]: training_data['strategy'] = (training_data['prediction'] *\n                                       training_data['return'])\n\nIn [196]: training_data[['return', 'strategy']].sum().apply(np.exp)\nOut[196]: return      0.901074\n          strategy    2.703377\n          dtype: float64\n\nIn [197]: training_data[['return', 'strategy']].cumsum(\n                          ).apply(np.exp).plot(figsize=(10, 6));\n```", "```py\nIn [198]: model.evaluate(test_data_[cols], test_data['direction'])\n          16/16 [==============================] - 0s 800us/step - loss: 0.6931 -\n           accuracy: 0.5507\n\nOut[198]: [0.6931276321411133, 0.5506958365440369]\n\nIn [199]: pred = np.where(model.predict(test_data_[cols]) > 0.5, 1, 0)\n\nIn [200]: test_data['prediction'] = np.where(pred > 0, 1, -1)\n\nIn [201]: test_data['prediction'].value_counts()\nOut[201]: -1    335\n           1    168\n          Name: prediction, dtype: int64\n\nIn [202]: test_data['strategy'] = (test_data['prediction'] *\n                                   test_data['return'])\n\nIn [203]: test_data[['return', 'strategy']].sum().apply(np.exp)\nOut[203]: return      0.934478\n          strategy    1.144385\n          dtype: float64\n\nIn [204]: test_data[['return', 'strategy']].cumsum(\n                          ).apply(np.exp).plot(figsize=(10, 6));\n```", "```py\n#\n# Python Module with Class\n# for Vectorized Backtesting\n# of Linear Regression-Based Strategies\n#\n# Python for Algorithmic Trading\n# (c) Dr. Yves J. Hilpisch\n# The Python Quants GmbH\n#\nimport numpy as np\nimport pandas as pd\n\nclass LRVectorBacktester(object):\n    ''' Class for the vectorized backtesting of\n linear regression-based trading strategies.\n\n Attributes\n ==========\n symbol: str\n TR RIC (financial instrument) to work with\n start: str\n start date for data selection\n end: str\n end date for data selection\n amount: int, float\n amount to be invested at the beginning\n tc: float\n proportional transaction costs (e.g., 0.5% = 0.005) per trade\n\n Methods\n =======\n get_data:\n retrieves and prepares the base data set\n select_data:\n selects a sub-set of the data\n prepare_lags:\n prepares the lagged data for the regression\n fit_model:\n implements the regression step\n run_strategy:\n runs the backtest for the regression-based strategy\n plot_results:\n plots the performance of the strategy compared to the symbol\n '''\n\n    def __init__(self, symbol, start, end, amount, tc):\n        self.symbol = symbol\n        self.start = start\n        self.end = end\n        self.amount = amount\n        self.tc = tc\n        self.results = None\n        self.get_data()\n\n    def get_data(self):\n        ''' Retrieves and prepares the data.\n '''\n        raw = pd.read_csv('http://hilpisch.com/pyalgo_eikon_eod_data.csv',\n                          index_col=0, parse_dates=True).dropna()\n        raw = pd.DataFrame(raw[self.symbol])\n        raw = raw.loc[self.start:self.end]\n        raw.rename(columns={self.symbol: 'price'}, inplace=True)\n        raw['returns'] = np.log(raw / raw.shift(1))\n        self.data = raw.dropna()\n\n    def select_data(self, start, end):\n        ''' Selects sub-sets of the financial data.\n '''\n        data = self.data[(self.data.index >= start) &\n                         (self.data.index <= end)].copy()\n        return data\n\n    def prepare_lags(self, start, end):\n        ''' Prepares the lagged data for the regression and prediction steps.\n '''\n        data = self.select_data(start, end)\n        self.cols = []\n        for lag in range(1, self.lags + 1):\n            col = f'lag_{lag}'\n            data[col] = data['returns'].shift(lag)\n            self.cols.append(col)\n        data.dropna(inplace=True)\n        self.lagged_data = data\n\n    def fit_model(self, start, end):\n        ''' Implements the regression step.\n '''\n        self.prepare_lags(start, end)\n        reg = np.linalg.lstsq(self.lagged_data[self.cols],\n                              np.sign(self.lagged_data['returns']),\n                              rcond=None)[0]\n        self.reg = reg\n\n    def run_strategy(self, start_in, end_in, start_out, end_out, lags=3):\n        ''' Backtests the trading strategy.\n '''\n        self.lags = lags\n        self.fit_model(start_in, end_in)\n        self.results = self.select_data(start_out, end_out).iloc[lags:]\n        self.prepare_lags(start_out, end_out)\n        prediction = np.sign(np.dot(self.lagged_data[self.cols], self.reg))\n        self.results['prediction'] = prediction\n        self.results['strategy'] = self.results['prediction'] * \\\n                                   self.results['returns']\n        # determine when a trade takes place\n        trades = self.results['prediction'].diff().fillna(0) != 0\n        # subtract transaction costs from return when trade takes place\n        self.results['strategy'][trades] -= self.tc\n        self.results['creturns'] = self.amount * \\\n                        self.results['returns'].cumsum().apply(np.exp)\n        self.results['cstrategy'] = self.amount * \\\n                        self.results['strategy'].cumsum().apply(np.exp)\n        # gross performance of the strategy\n        aperf = self.results['cstrategy'].iloc[-1]\n        # out-/underperformance of strategy\n        operf = aperf - self.results['creturns'].iloc[-1]\n        return round(aperf, 2), round(operf, 2)\n\n    def plot_results(self):\n        ''' Plots the cumulative performance of the trading strategy\n compared to the symbol.\n '''\n        if self.results is None:\n            print('No results to plot yet. Run a strategy.')\n        title = '%s | TC = %.4f' % (self.symbol, self.tc)\n        self.results[['creturns', 'cstrategy']].plot(title=title,\n                                                     figsize=(10, 6))\n\nif __name__ == '__main__':\n    lrbt = LRVectorBacktester('.SPX', '2010-1-1', '2018-06-29', 10000, 0.0)\n    print(lrbt.run_strategy('2010-1-1', '2019-12-31',\n                            '2010-1-1', '2019-12-31'))\n    print(lrbt.run_strategy('2010-1-1', '2015-12-31',\n                            '2016-1-1', '2019-12-31'))\n    lrbt = LRVectorBacktester('GDX', '2010-1-1', '2019-12-31', 10000, 0.001)\n    print(lrbt.run_strategy('2010-1-1', '2019-12-31',\n                            '2010-1-1', '2019-12-31', lags=5))\n    print(lrbt.run_strategy('2010-1-1', '2016-12-31',\n                            '2017-1-1', '2019-12-31', lags=5))\n```", "```py\n#\n# Python Module with Class\n# for Vectorized Backtesting\n# of Machine Learning-Based Strategies\n#\n# Python for Algorithmic Trading\n# (c) Dr. Yves J. Hilpisch\n# The Python Quants GmbH\n#\nimport numpy as np\nimport pandas as pd\nfrom sklearn import linear_model\n\nclass ScikitVectorBacktester(object):\n    ''' Class for the vectorized backtesting of\n machine learning-based trading strategies.\n\n Attributes\n ==========\n symbol: str\n TR RIC (financial instrument) to work with\n start: str\n start date for data selection\n end: str\n end date for data selection\n amount: int, float\n amount to be invested at the beginning\n tc: float\n proportional transaction costs (e.g., 0.5% = 0.005) per trade\n model: str\n either 'regression' or 'logistic'\n\n Methods\n =======\n get_data:\n retrieves and prepares the base data set\n select_data:\n selects a sub-set of the data\n prepare_features:\n prepares the features data for the model fitting\n fit_model:\n implements the fitting step\n run_strategy:\n runs the backtest for the regression-based strategy\n plot_results:\n plots the performance of the strategy compared to the symbol\n '''\n\n    def __init__(self, symbol, start, end, amount, tc, model):\n        self.symbol = symbol\n        self.start = start\n        self.end = end\n        self.amount = amount\n        self.tc = tc\n        self.results = None\n        if model == 'regression':\n            self.model = linear_model.LinearRegression()\n        elif model == 'logistic':\n            self.model = linear_model.LogisticRegression(C=1e6,\n                solver='lbfgs', multi_class='ovr', max_iter=1000)\n        else:\n            raise ValueError('Model not known or not yet implemented.')\n        self.get_data()\n\n    def get_data(self):\n        ''' Retrieves and prepares the data.\n '''\n        raw = pd.read_csv('http://hilpisch.com/pyalgo_eikon_eod_data.csv',\n                          index_col=0, parse_dates=True).dropna()\n        raw = pd.DataFrame(raw[self.symbol])\n        raw = raw.loc[self.start:self.end]\n        raw.rename(columns={self.symbol: 'price'}, inplace=True)\n        raw['returns'] = np.log(raw / raw.shift(1))\n        self.data = raw.dropna()\n\n    def select_data(self, start, end):\n        ''' Selects sub-sets of the financial data.\n '''\n        data = self.data[(self.data.index >= start) &\n                         (self.data.index <= end)].copy()\n        return data\n\n    def prepare_features(self, start, end):\n        ''' Prepares the feature columns for the regression and prediction steps.\n '''\n        self.data_subset = self.select_data(start, end)\n        self.feature_columns = []\n        for lag in range(1, self.lags + 1):\n            col = 'lag_{}'.format(lag)\n            self.data_subset[col] = self.data_subset['returns'].shift(lag)\n            self.feature_columns.append(col)\n        self.data_subset.dropna(inplace=True)\n\n    def fit_model(self, start, end):\n        ''' Implements the fitting step.\n '''\n        self.prepare_features(start, end)\n        self.model.fit(self.data_subset[self.feature_columns],\n                       np.sign(self.data_subset['returns']))\n\n    def run_strategy(self, start_in, end_in, start_out, end_out, lags=3):\n        ''' Backtests the trading strategy.\n '''\n        self.lags = lags\n        self.fit_model(start_in, end_in)\n        # data = self.select_data(start_out, end_out)\n        self.prepare_features(start_out, end_out)\n        prediction = self.model.predict(\n            self.data_subset[self.feature_columns])\n        self.data_subset['prediction'] = prediction\n        self.data_subset['strategy'] = (self.data_subset['prediction'] *\n                                        self.data_subset['returns'])\n        # determine when a trade takes place\n        trades = self.data_subset['prediction'].diff().fillna(0) != 0\n        # subtract transaction costs from return when trade takes place\n        self.data_subset['strategy'][trades] -= self.tc\n        self.data_subset['creturns'] = (self.amount *\n                        self.data_subset['returns'].cumsum().apply(np.exp))\n        self.data_subset['cstrategy'] = (self.amount *\n                        self.data_subset['strategy'].cumsum().apply(np.exp))\n        self.results = self.data_subset\n        # absolute performance of the strategy\n        aperf = self.results['cstrategy'].iloc[-1]\n        # out-/underperformance of strategy\n        operf = aperf - self.results['creturns'].iloc[-1]\n        return round(aperf, 2), round(operf, 2)\n\n    def plot_results(self):\n        ''' Plots the cumulative performance of the trading strategy\n compared to the symbol.\n '''\n        if self.results is None:\n            print('No results to plot yet. Run a strategy.')\n        title = '%s | TC = %.4f' % (self.symbol, self.tc)\n        self.results[['creturns', 'cstrategy']].plot(title=title,\n                                                     figsize=(10, 6))\n\nif __name__ == '__main__':\n    scibt = ScikitVectorBacktester('.SPX', '2010-1-1', '2019-12-31',\n                                   10000, 0.0, 'regression')\n    print(scibt.run_strategy('2010-1-1', '2019-12-31',\n                             '2010-1-1', '2019-12-31'))\n    print(scibt.run_strategy('2010-1-1', '2016-12-31',\n                             '2017-1-1', '2019-12-31'))\n    scibt = ScikitVectorBacktester('.SPX', '2010-1-1', '2019-12-31',\n                                   10000, 0.0, 'logistic')\n    print(scibt.run_strategy('2010-1-1', '2019-12-31',\n                             '2010-1-1', '2019-12-31'))\n    print(scibt.run_strategy('2010-1-1', '2016-12-31',\n                             '2017-1-1', '2019-12-31'))\n    scibt = ScikitVectorBacktester('.SPX', '2010-1-1', '2019-12-31',\n                                   10000, 0.001, 'logistic')\n    print(scibt.run_strategy('2010-1-1', '2019-12-31',\n                             '2010-1-1', '2019-12-31', lags=15))\n    print(scibt.run_strategy('2010-1-1', '2013-12-31',\n                             '2014-1-1', '2019-12-31', lags=15))\n```"]