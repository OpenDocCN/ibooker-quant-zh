<html><head></head><body><div id="sbo-rt-content"><section data-type="chapter" epub:type="chapter" data-pdf-bookmark="Chapter 8. Recurrent Neural Networks"><div class="chapter" id="recurrent_networks">
<h1><span class="label">Chapter 8. </span>Recurrent Neural Networks</h1>

<blockquote>
<p class="align_me_right">History never repeats itself, but it rhymes.</p>
<p data-type="attribution">Mark Twain (probably)</p>
</blockquote>
<blockquote>
<p class="align_me_right">My life seemed to be a series of events and accidents. Yet when I look back, I see a pattern.</p>
<p data-type="attribution">Bernoît Mandelbrot</p>
</blockquote>

<p><a data-type="indexterm" data-primary="statistical inefficiencies" data-secondary="RNNs" id="ix_stat_ineffic_RNNs_ch8"/><a data-type="indexterm" data-primary="RNNs (recurrent neural networks)" id="ix_RNNs_ch8"/>This chapter is about <em>recurrent neural networks</em> (RNNs). This type of network is specifically designed to learn about sequential data, such as text or time series data. The discussion in this chapter takes, as before, a practical approach and relies mainly on worked-out Python examples, making use of <code>Keras</code>.<sup><a data-type="noteref" id="idm45625292780216-marker" href="ch08.xhtml#idm45625292780216">1</a></sup></p>

<p><a data-type="xref" href="#rnn_first">“First Example”</a> and <a data-type="xref" href="#rnn_second">“Second Example”</a> introduce RNNs on the basis of two simple examples with sample numerical data. The application of RNNs to predict sequential data is illustrated. <a data-type="xref" href="#rnn_fin_price_series">“Financial Price Series”</a> then works with financial price series data and applies the RNN approach to predict such a series directly via estimation. <a data-type="xref" href="#rnn_fin_ret_series">“Financial Return Series”</a> then works with returns data to predict the future direction of the price of a financial instrument also via an estimation approach. <a data-type="xref" href="#rnn_fin_features">“Financial Features”</a> adds financial features to the mix—in addition to price and return data—to predict the market direction. Three different approaches are illustrated in this section: prediction via a shallow RNN for both estimation and classification, as well as prediction via a deep RNN for classification.</p>

<p>The chapter shows that the application of RNNs to financial time series data can achieve a prediction accuracy of well above 60% out-of-sample in the context of directional market predictions. However, the results obtained cannot fully keep up with those seen in <a data-type="xref" href="ch07.xhtml#dense_networks">Chapter 7</a>. This might come as a surprise, since RNNs are meant to work well with financial time series data, which is the primary focus of this book.</p>






<section data-type="sect1" data-pdf-bookmark="First Example"><div class="sect1" id="rnn_first">
<h1>First Example</h1>

<p><a data-type="indexterm" data-primary="RNNs (recurrent neural networks)" data-secondary="first example" id="ix_RNNs_firstex"/>To illustrate the training and usage of RNNs, consider a simple example based on a sequence of integers. First, some imports and configurations:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">import</code><code> </code><code class="nn">os</code><code>
</code><code>        </code><code class="kn">import</code><code> </code><code class="nn">random</code><code>
</code><code>        </code><code class="kn">import</code><code> </code><code class="nn">numpy</code><code> </code><code class="kn">as</code><code> </code><code class="nn">np</code><code>
</code><code>        </code><code class="kn">import</code><code> </code><code class="nn">pandas</code><code> </code><code class="kn">as</code><code> </code><code class="nn">pd</code><code>
</code><code>        </code><code class="kn">import</code><code> </code><code class="nn">tensorflow</code><code> </code><code class="kn">as</code><code> </code><code class="nn">tf</code><code>
</code><code>        </code><code class="kn">from</code><code> </code><code class="nn">pprint</code><code> </code><code class="kn">import</code><code> </code><code class="n">pprint</code><code>
</code><code>        </code><code class="kn">from</code><code> </code><code class="nn">pylab</code><code> </code><code class="kn">import</code><code> </code><code class="n">plt</code><code class="p">,</code><code> </code><code class="n">mpl</code><code>
</code><code>        </code><code class="n">plt</code><code class="o">.</code><code class="n">style</code><code class="o">.</code><code class="n">use</code><code class="p">(</code><code class="s1">'</code><code class="s1">seaborn</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>        </code><code class="n">mpl</code><code class="o">.</code><code class="n">rcParams</code><code class="p">[</code><code class="s1">'</code><code class="s1">savefig.dpi</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="mi">300</code><code>
</code><code>        </code><code class="n">mpl</code><code class="o">.</code><code class="n">rcParams</code><code class="p">[</code><code class="s1">'</code><code class="s1">font.family</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">serif</code><code class="s1">'</code><code>
</code><code>        </code><code class="n">pd</code><code class="o">.</code><code class="n">set_option</code><code class="p">(</code><code class="s1">'</code><code class="s1">precision</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="mi">4</code><code class="p">)</code><code>
</code><code>        </code><code class="n">np</code><code class="o">.</code><code class="n">set_printoptions</code><code class="p">(</code><code class="n">suppress</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code> </code><code class="n">precision</code><code class="o">=</code><code class="mi">4</code><code class="p">)</code><code>
</code><code>        </code><code class="n">os</code><code class="o">.</code><code class="n">environ</code><code class="p">[</code><code class="s1">'</code><code class="s1">PYTHONHASHSEED</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">0</code><code class="s1">'</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">2</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">set_seeds</code><code class="p">(</code><code class="n">seed</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code><code class="p">:</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO1-1" href="#callout_recurrent_neural_networks_CO1-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>            </code><code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">(</code><code class="n">seed</code><code class="p">)</code><code>
</code><code>            </code><code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">seed</code><code class="p">(</code><code class="n">seed</code><code class="p">)</code><code>
</code><code>            </code><code class="n">tf</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">set_seed</code><code class="p">(</code><code class="n">seed</code><code class="p">)</code><code>
</code><code>        </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO1-2" href="#callout_recurrent_neural_networks_CO1-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO1-1" href="#co_recurrent_neural_networks_CO1-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Function to set all seed values</p></dd>
</dl>

<p>Second is the simple data set that is transformed into an appropriate shape:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">3</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">a</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">arange</code><code class="p">(</code><code class="mi">100</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO2-1" href="#callout_recurrent_neural_networks_CO2-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>        </code><code class="n">a</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">3</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code> </code><code class="mi">0</code><code class="p">,</code><code>  </code><code class="mi">1</code><code class="p">,</code><code>  </code><code class="mi">2</code><code class="p">,</code><code>  </code><code class="mi">3</code><code class="p">,</code><code>  </code><code class="mi">4</code><code class="p">,</code><code>  </code><code class="mi">5</code><code class="p">,</code><code>  </code><code class="mi">6</code><code class="p">,</code><code>  </code><code class="mi">7</code><code class="p">,</code><code>  </code><code class="mi">8</code><code class="p">,</code><code>  </code><code class="mi">9</code><code class="p">,</code><code> </code><code class="mi">10</code><code class="p">,</code><code> </code><code class="mi">11</code><code class="p">,</code><code> </code><code class="mi">12</code><code class="p">,</code><code> </code><code class="mi">13</code><code class="p">,</code><code> </code><code class="mi">14</code><code class="p">,</code><code> </code><code class="mi">15</code><code class="p">,</code><code> </code><code class="mi">16</code><code class="p">,</code><code>
</code><code>               </code><code class="mi">17</code><code class="p">,</code><code> </code><code class="mi">18</code><code class="p">,</code><code> </code><code class="mi">19</code><code class="p">,</code><code> </code><code class="mi">20</code><code class="p">,</code><code> </code><code class="mi">21</code><code class="p">,</code><code> </code><code class="mi">22</code><code class="p">,</code><code> </code><code class="mi">23</code><code class="p">,</code><code> </code><code class="mi">24</code><code class="p">,</code><code> </code><code class="mi">25</code><code class="p">,</code><code> </code><code class="mi">26</code><code class="p">,</code><code> </code><code class="mi">27</code><code class="p">,</code><code> </code><code class="mi">28</code><code class="p">,</code><code> </code><code class="mi">29</code><code class="p">,</code><code> </code><code class="mi">30</code><code class="p">,</code><code> </code><code class="mi">31</code><code class="p">,</code><code> </code><code class="mi">32</code><code class="p">,</code><code> </code><code class="mi">33</code><code class="p">,</code><code>
</code><code>               </code><code class="mi">34</code><code class="p">,</code><code> </code><code class="mi">35</code><code class="p">,</code><code> </code><code class="mi">36</code><code class="p">,</code><code> </code><code class="mi">37</code><code class="p">,</code><code> </code><code class="mi">38</code><code class="p">,</code><code> </code><code class="mi">39</code><code class="p">,</code><code> </code><code class="mi">40</code><code class="p">,</code><code> </code><code class="mi">41</code><code class="p">,</code><code> </code><code class="mi">42</code><code class="p">,</code><code> </code><code class="mi">43</code><code class="p">,</code><code> </code><code class="mi">44</code><code class="p">,</code><code> </code><code class="mi">45</code><code class="p">,</code><code> </code><code class="mi">46</code><code class="p">,</code><code> </code><code class="mi">47</code><code class="p">,</code><code> </code><code class="mi">48</code><code class="p">,</code><code> </code><code class="mi">49</code><code class="p">,</code><code> </code><code class="mi">50</code><code class="p">,</code><code>
</code><code>               </code><code class="mi">51</code><code class="p">,</code><code> </code><code class="mi">52</code><code class="p">,</code><code> </code><code class="mi">53</code><code class="p">,</code><code> </code><code class="mi">54</code><code class="p">,</code><code> </code><code class="mi">55</code><code class="p">,</code><code> </code><code class="mi">56</code><code class="p">,</code><code> </code><code class="mi">57</code><code class="p">,</code><code> </code><code class="mi">58</code><code class="p">,</code><code> </code><code class="mi">59</code><code class="p">,</code><code> </code><code class="mi">60</code><code class="p">,</code><code> </code><code class="mi">61</code><code class="p">,</code><code> </code><code class="mi">62</code><code class="p">,</code><code> </code><code class="mi">63</code><code class="p">,</code><code> </code><code class="mi">64</code><code class="p">,</code><code> </code><code class="mi">65</code><code class="p">,</code><code> </code><code class="mi">66</code><code class="p">,</code><code> </code><code class="mi">67</code><code class="p">,</code><code>
</code><code>               </code><code class="mi">68</code><code class="p">,</code><code> </code><code class="mi">69</code><code class="p">,</code><code> </code><code class="mi">70</code><code class="p">,</code><code> </code><code class="mi">71</code><code class="p">,</code><code> </code><code class="mi">72</code><code class="p">,</code><code> </code><code class="mi">73</code><code class="p">,</code><code> </code><code class="mi">74</code><code class="p">,</code><code> </code><code class="mi">75</code><code class="p">,</code><code> </code><code class="mi">76</code><code class="p">,</code><code> </code><code class="mi">77</code><code class="p">,</code><code> </code><code class="mi">78</code><code class="p">,</code><code> </code><code class="mi">79</code><code class="p">,</code><code> </code><code class="mi">80</code><code class="p">,</code><code> </code><code class="mi">81</code><code class="p">,</code><code> </code><code class="mi">82</code><code class="p">,</code><code> </code><code class="mi">83</code><code class="p">,</code><code> </code><code class="mi">84</code><code class="p">,</code><code>
</code><code>               </code><code class="mi">85</code><code class="p">,</code><code> </code><code class="mi">86</code><code class="p">,</code><code> </code><code class="mi">87</code><code class="p">,</code><code> </code><code class="mi">88</code><code class="p">,</code><code> </code><code class="mi">89</code><code class="p">,</code><code> </code><code class="mi">90</code><code class="p">,</code><code> </code><code class="mi">91</code><code class="p">,</code><code> </code><code class="mi">92</code><code class="p">,</code><code> </code><code class="mi">93</code><code class="p">,</code><code> </code><code class="mi">94</code><code class="p">,</code><code> </code><code class="mi">95</code><code class="p">,</code><code> </code><code class="mi">96</code><code class="p">,</code><code> </code><code class="mi">97</code><code class="p">,</code><code> </code><code class="mi">98</code><code class="p">,</code><code> </code><code class="mi">99</code><code class="p">]</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">4</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">a</code><code> </code><code class="o">=</code><code> </code><code class="n">a</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">a</code><code class="p">)</code><code class="p">,</code><code> </code><code class="o">-</code><code class="mi">1</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO2-2" href="#callout_recurrent_neural_networks_CO2-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">5</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">a</code><code class="o">.</code><code class="n">shape</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO2-3" href="#callout_recurrent_neural_networks_CO2-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">5</code><code class="p">]</code><code class="p">:</code><code> </code><code class="p">(</code><code class="mi">100</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">6</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">a</code><code class="p">[</code><code class="p">:</code><code class="mi">5</code><code class="p">]</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO2-4" href="#callout_recurrent_neural_networks_CO2-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">6</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">,</code><code>
</code><code>               </code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">,</code><code>
</code><code>               </code><code class="p">[</code><code class="mi">2</code><code class="p">]</code><code class="p">,</code><code>
</code><code>               </code><code class="p">[</code><code class="mi">3</code><code class="p">]</code><code class="p">,</code><code>
</code><code>               </code><code class="p">[</code><code class="mi">4</code><code class="p">]</code><code class="p">]</code><code class="p">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO2-1" href="#co_recurrent_neural_networks_CO2-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Sample data</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO2-2" href="#co_recurrent_neural_networks_CO2-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Reshaping to two dimensions</p></dd>
</dl>

<p><a data-type="indexterm" data-primary="TimeseriesGenerator (RNN)" id="idm45625289239192"/>Using the <code>TimeseriesGenerator</code>, the raw data can be transformed into an object suited for the training of an RNN. The idea is to use a certain number of lags of the original data to train the model to predict the next value in the sequence. For example, <code>0, 1, 2</code> are the three lagged values (features) used to predict the value <code>3</code> (label). In the same way, <code>1, 2, 3</code> are used to predict <code>4</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">7</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">keras.preprocessing.sequence</code><code> </code><code class="kn">import</code><code> </code><code class="n">TimeseriesGenerator</code><code>
</code><code>        </code><code class="n">Using</code><code> </code><code class="n">TensorFlow</code><code> </code><code class="n">backend</code><code class="o">.</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">8</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">lags</code><code> </code><code class="o">=</code><code> </code><code class="mi">3</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">9</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">g</code><code> </code><code class="o">=</code><code> </code><code class="n">TimeseriesGenerator</code><code class="p">(</code><code class="n">a</code><code class="p">,</code><code> </code><code class="n">a</code><code class="p">,</code><code> </code><code class="n">length</code><code class="o">=</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">batch_size</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO3-1" href="#callout_recurrent_neural_networks_CO3-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">10</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">pprint</code><code class="p">(</code><code class="nb">list</code><code class="p">(</code><code class="n">g</code><code class="p">)</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO3-2" href="#callout_recurrent_neural_networks_CO3-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>         </code><code class="p">(</code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code class="p">[</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                 </code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                 </code><code class="p">[</code><code class="mi">2</code><code class="p">]</code><code class="p">]</code><code class="p">,</code><code>
</code><code>
</code><code>                </code><code class="p">[</code><code class="p">[</code><code class="mi">1</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                 </code><code class="p">[</code><code class="mi">2</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                 </code><code class="p">[</code><code class="mi">3</code><code class="p">]</code><code class="p">]</code><code class="p">,</code><code>
</code><code>
</code><code>                </code><code class="p">[</code><code class="p">[</code><code class="mi">2</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                 </code><code class="p">[</code><code class="mi">3</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                 </code><code class="p">[</code><code class="mi">4</code><code class="p">]</code><code class="p">]</code><code class="p">,</code><code>
</code><code>
</code><code>                </code><code class="p">[</code><code class="p">[</code><code class="mi">3</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                 </code><code class="p">[</code><code class="mi">4</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                 </code><code class="p">[</code><code class="mi">5</code><code class="p">]</code><code class="p">]</code><code class="p">,</code><code>
</code><code>
</code><code>                </code><code class="p">[</code><code class="p">[</code><code class="mi">4</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                 </code><code class="p">[</code><code class="mi">5</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                 </code><code class="p">[</code><code class="mi">6</code><code class="p">]</code><code class="p">]</code><code class="p">]</code><code class="p">)</code><code class="p">,</code><code>
</code><code>          </code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code class="p">[</code><code class="mi">3</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                </code><code class="p">[</code><code class="mi">4</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                </code><code class="p">[</code><code class="mi">5</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                </code><code class="p">[</code><code class="mi">6</code><code class="p">]</code><code class="p">,</code><code>
</code><code>                </code><code class="p">[</code><code class="mi">7</code><code class="p">]</code><code class="p">]</code><code class="p">)</code><code class="p">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO3-1" href="#co_recurrent_neural_networks_CO3-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p><code>TimeseriesGenerator</code> creates batches of lagged sequential data.</p></dd>
</dl>

<p>The creation of the RNN model is similar to DNNs. <a data-type="indexterm" data-primary="SimpleRNN layer" id="idm45625292532952"/>The following Python code uses a single hidden layer of type <code>SimpleRNN</code> (Chollet 2017, ch. 6; also see <a href="https://oreil.ly/kpuqA">Keras recurrent layers</a>). Even with relatively few hidden units, the number of trainable parameters is quite large. <a data-type="indexterm" data-primary=".fit_generator() method" data-primary-sortas="fit generator method" id="idm45625289261784"/>The <code>.fit_generator()</code> method takes as input generator objects such as those created with <code>TimeseriesGenerator</code>:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">11</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">keras.models</code><code> </code><code class="kn">import</code><code> </code><code class="n">Sequential</code><code>
</code><code>         </code><code class="kn">from</code><code> </code><code class="nn">keras.layers</code><code> </code><code class="kn">import</code><code> </code><code class="n">SimpleRNN</code><code class="p">,</code><code> </code><code class="n">LSTM</code><code class="p">,</code><code> </code><code class="n">Dense</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">12</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">Sequential</code><code class="p">(</code><code class="p">)</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">SimpleRNN</code><code class="p">(</code><code class="mi">100</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                             </code><code class="n">input_shape</code><code class="o">=</code><code class="p">(</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO4-1" href="#callout_recurrent_neural_networks_CO4-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">linear</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">optimizer</code><code class="o">=</code><code class="s1">'</code><code class="s1">adagrad</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">loss</code><code class="o">=</code><code class="s1">'</code><code class="s1">mse</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                       </code><code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="s1">'</code><code class="s1">mae</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">13</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">summary</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO4-2" href="#callout_recurrent_neural_networks_CO4-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>         </code><code class="n">Model</code><code class="p">:</code><code> </code><code class="s2">"</code><code class="s2">sequential_1</code><code class="s2">"</code><code>
</code><code>         </code><code class="n">_________________________________________________________________</code><code>
</code><code>         </code><code class="n">Layer</code><code> </code><code class="p">(</code><code class="nb">type</code><code class="p">)</code><code>                 </code><code class="n">Output</code><code> </code><code class="n">Shape</code><code>              </code><code class="n">Param</code><code> </code><code class="c1">#</code><code>
</code><code>         </code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">=</code><code>
</code><code>         </code><code class="n">simple_rnn_1</code><code> </code><code class="p">(</code><code class="n">SimpleRNN</code><code class="p">)</code><code>     </code><code class="p">(</code><code class="bp">None</code><code class="p">,</code><code> </code><code class="mi">100</code><code class="p">)</code><code>               </code><code class="mi">10200</code><code>
</code><code>         </code><code class="n">_________________________________________________________________</code><code>
</code><code>         </code><code class="n">dense_1</code><code> </code><code class="p">(</code><code class="n">Dense</code><code class="p">)</code><code>              </code><code class="p">(</code><code class="bp">None</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">)</code><code>                 </code><code class="mi">101</code><code>
</code><code>         </code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">==</code><code class="o">=</code><code>
</code><code>         </code><code class="n">Total</code><code> </code><code class="n">params</code><code class="p">:</code><code> </code><code class="mi">10</code><code class="p">,</code><code class="mi">301</code><code>
</code><code>         </code><code class="n">Trainable</code><code> </code><code class="n">params</code><code class="p">:</code><code> </code><code class="mi">10</code><code class="p">,</code><code class="mi">301</code><code>
</code><code>         </code><code class="n">Non</code><code class="o">-</code><code class="n">trainable</code><code> </code><code class="n">params</code><code class="p">:</code><code> </code><code class="mi">0</code><code>
</code><code>         </code><code class="n">_________________________________________________________________</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">14</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">fit_generator</code><code class="p">(</code><code class="n">g</code><code class="p">,</code><code> </code><code class="n">epochs</code><code class="o">=</code><code class="mi">1000</code><code class="p">,</code><code> </code><code class="n">steps_per_epoch</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code><code>
</code><code>                             </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO4-3" href="#callout_recurrent_neural_networks_CO4-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">17.4</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mf">3.9</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">21.3</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">30.8</code><code> </code><code class="n">s</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">14</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7f7f079058d0</code><code class="o">&gt;</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO4-1" href="#co_recurrent_neural_networks_CO4-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>The single hidden layer is of type <code>SimpleRNN</code>.</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO4-2" href="#co_recurrent_neural_networks_CO4-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>The summary of the shallow RNN.</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO4-3" href="#co_recurrent_neural_networks_CO4-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>The fitting of the RNN based on the generator object.</p></dd>
</dl>
<div style="page-break-after: always;"/>

<p>The performance metrics might show relatively erratic behavior when training RNNs (see <a data-type="xref" href="#figure_rnn_01">Figure 8-1</a>):</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">15</code><code class="p">]:</code> <code class="n">res</code> <code class="o">=</code> <code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">history</code><code class="o">.</code><code class="n">history</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">16</code><code class="p">]:</code> <code class="n">res</code><code class="o">.</code><code class="n">tail</code><code class="p">(</code><code class="mi">3</code><code class="p">)</code>
<code class="n">Out</code><code class="p">[</code><code class="mi">16</code><code class="p">]:</code>        <code class="n">loss</code>     <code class="n">mae</code>
         <code class="mi">997</code>  <code class="mf">0.0001</code>  <code class="mf">0.0109</code>
         <code class="mi">998</code>  <code class="mf">0.0007</code>  <code class="mf">0.0211</code>
         <code class="mi">999</code>  <code class="mf">0.0001</code>  <code class="mf">0.0101</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">17</code><code class="p">]:</code> <code class="n">res</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="mi">10</code><code class="p">:]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code> <code class="n">style</code><code class="o">=</code><code class="p">[</code><code class="s1">'--'</code><code class="p">,</code> <code class="s1">'--'</code><code class="p">]);</code></pre>

<figure class="thumb"><div id="figure_rnn_01" class="figure">
<img src="Images/aiif_0801.png" alt="aiif 0801" width="2379" height="1421"/>
<h6><span class="label">Figure 8-1. </span>Performance metrics during RNN training</h6>
</div></figure>

<p>Having a trained RNN available, the following Python code generates in-sample and out-of-sample predictions:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">18</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">x</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code class="mi">21</code><code class="p">,</code><code> </code><code class="mi">22</code><code class="p">,</code><code> </code><code class="mi">23</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">lags</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">y</code><code> </code><code class="o">=</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO5-1" href="#callout_recurrent_neural_networks_CO5-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>         </code><code class="nb">int</code><code class="p">(</code><code class="nb">round</code><code class="p">(</code><code class="n">y</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">18</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mi">24</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">19</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">x</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code class="mi">87</code><code class="p">,</code><code> </code><code class="mi">88</code><code class="p">,</code><code> </code><code class="mi">89</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">lags</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">y</code><code> </code><code class="o">=</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO5-2" href="#callout_recurrent_neural_networks_CO5-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>         </code><code class="nb">int</code><code class="p">(</code><code class="nb">round</code><code class="p">(</code><code class="n">y</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">19</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mi">90</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">20</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">x</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code class="mi">187</code><code class="p">,</code><code> </code><code class="mi">188</code><code class="p">,</code><code> </code><code class="mi">189</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">lags</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">y</code><code> </code><code class="o">=</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO5-3" href="#callout_recurrent_neural_networks_CO5-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>         </code><code class="nb">int</code><code class="p">(</code><code class="nb">round</code><code class="p">(</code><code class="n">y</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">20</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mi">190</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">21</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">x</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code class="mi">1187</code><code class="p">,</code><code> </code><code class="mi">1188</code><code class="p">,</code><code> </code><code class="mi">1189</code><code class="p">]</code><code class="p">)</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">lags</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">y</code><code> </code><code class="o">=</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO5-4" href="#callout_recurrent_neural_networks_CO5-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>         </code><code class="nb">int</code><code class="p">(</code><code class="nb">round</code><code class="p">(</code><code class="n">y</code><code class="p">[</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">]</code><code class="p">)</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">21</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mi">1194</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO5-1" href="#co_recurrent_neural_networks_CO5-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>In-sample prediction</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO5-2" href="#co_recurrent_neural_networks_CO5-3"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Out-of-sample prediction</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO5-3" href="#co_recurrent_neural_networks_CO5-4"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>Far-out-of-sample prediction</p></dd>
</dl>

<p>Even for far-out-of-sample predictions, the results are good in general in this simple case. However, the problem at hand could, for example, be perfectly solved by the application of OLS regression. Therefore, the effort involved for the training of an RNN for such a problem is quite high given the performance of the RNN.<a data-type="indexterm" data-primary="" data-startref="ix_RNNs_firstex" id="idm45625289413976"/></p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Second Example"><div class="sect1" id="rnn_second">
<h1>Second Example</h1>

<p><a data-type="indexterm" data-primary="RNNs (recurrent neural networks)" data-secondary="second example" id="ix_RNNs_secondex"/>The first example illustrates the training of an RNN for a simple problem that is easy to solve not only by OLS regression but also by a human being inspecting the data. The second example is a bit more challenging. The input data is transformed by a quadratic term and a trigonometric term, as well as by adding white noise to it. <a data-type="xref" href="#figure_rnn_02">Figure 8-2</a> shows the resulting sequence for the interval <math alttext="left-bracket minus 2 pi comma 2 pi">
  <mrow>
    <mo>[</mo>
    <mo>-</mo>
    <mn>2</mn>
    <mi>π</mi>
    <mo>,</mo>
    <mn>2</mn>
    <mi>π</mi>
  </mrow>
</math>]:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">22</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">transform</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code class="p">:</code><code>
</code><code>             </code><code class="n">y</code><code> </code><code class="o">=</code><code> </code><code class="mf">0.05</code><code> </code><code class="o">*</code><code> </code><code class="n">x</code><code> </code><code class="o">*</code><code class="o">*</code><code> </code><code class="mi">2</code><code> </code><code class="o">+</code><code> </code><code class="mf">0.2</code><code> </code><code class="o">*</code><code> </code><code class="n">x</code><code> </code><code class="o">+</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">sin</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code> </code><code class="o">+</code><code> </code><code class="mi">5</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO6-1" href="#callout_recurrent_neural_networks_CO6-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">y</code><code> </code><code class="o">+</code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">random</code><code class="o">.</code><code class="n">standard_normal</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code class="p">)</code><code> </code><code class="o">*</code><code> </code><code class="mf">0.2</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO6-2" href="#callout_recurrent_neural_networks_CO6-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>             </code><code class="k">return</code><code> </code><code class="n">y</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">23</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">x</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">linspace</code><code class="p">(</code><code class="o">-</code><code class="mi">2</code><code> </code><code class="o">*</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">pi</code><code class="p">,</code><code> </code><code class="mi">2</code><code> </code><code class="o">*</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">pi</code><code class="p">,</code><code> </code><code class="mi">500</code><code class="p">)</code><code>
</code><code>         </code><code class="n">a</code><code> </code><code class="o">=</code><code> </code><code class="n">transform</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">24</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code> </code><code class="mi">6</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">x</code><code class="p">,</code><code> </code><code class="n">a</code><code class="p">)</code><code class="p">;</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO6-1" href="#co_recurrent_neural_networks_CO6-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Deterministic transformation</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO6-2" href="#co_recurrent_neural_networks_CO6-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Stochastic transformation</p></dd>
</dl>

<figure class="thumb"><div id="figure_rnn_02" class="figure">
<img src="Images/aiif_0802.png" alt="aiif 0802" width="2379" height="1420"/>
<h6><span class="label">Figure 8-2. </span>Sample sequence data</h6>
</div></figure>

<p><a data-type="indexterm" data-primary="TimeseriesGenerator (RNN)" id="idm45625288569944"/>As before, the raw data is reshaped, <code>TimeseriesGenerator</code> is applied, and the RNN with a single hidden layer is trained:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">25</code><code class="p">]:</code> <code class="n">a</code> <code class="o">=</code> <code class="n">a</code><code class="o">.</code><code class="n">reshape</code><code class="p">((</code><code class="nb">len</code><code class="p">(</code><code class="n">a</code><code class="p">),</code> <code class="o">-</code><code class="mi">1</code><code class="p">))</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">26</code><code class="p">]:</code> <code class="n">a</code><code class="p">[:</code><code class="mi">5</code><code class="p">]</code>
<code class="n">Out</code><code class="p">[</code><code class="mi">26</code><code class="p">]:</code> <code class="n">array</code><code class="p">([[</code><code class="mf">5.6736</code><code class="p">],</code>
                <code class="p">[</code><code class="mf">5.68</code>  <code class="p">],</code>
                <code class="p">[</code><code class="mf">5.3127</code><code class="p">],</code>
                <code class="p">[</code><code class="mf">5.645</code> <code class="p">],</code>
                <code class="p">[</code><code class="mf">5.7118</code><code class="p">]])</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">27</code><code class="p">]:</code> <code class="n">lags</code> <code class="o">=</code> <code class="mi">5</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">28</code><code class="p">]:</code> <code class="n">g</code> <code class="o">=</code> <code class="n">TimeseriesGenerator</code><code class="p">(</code><code class="n">a</code><code class="p">,</code> <code class="n">a</code><code class="p">,</code> <code class="n">length</code><code class="o">=</code><code class="n">lags</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">29</code><code class="p">]:</code> <code class="n">model</code> <code class="o">=</code> <code class="n">Sequential</code><code class="p">()</code>
         <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">SimpleRNN</code><code class="p">(</code><code class="mi">500</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'relu'</code><code class="p">,</code> <code class="n">input_shape</code><code class="o">=</code><code class="p">(</code><code class="n">lags</code><code class="p">,</code> <code class="mi">1</code><code class="p">)))</code>
         <code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code> <code class="n">activation</code><code class="o">=</code><code class="s1">'linear'</code><code class="p">))</code>
         <code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">optimizer</code><code class="o">=</code><code class="s1">'rmsprop'</code><code class="p">,</code> <code class="n">loss</code><code class="o">=</code><code class="s1">'mse'</code><code class="p">,</code> <code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="s1">'mae'</code><code class="p">])</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">30</code><code class="p">]:</code> <code class="n">model</code><code class="o">.</code><code class="n">summary</code><code class="p">()</code>
         <code class="n">Model</code><code class="p">:</code> <code class="s2">"sequential_2"</code>
         <code class="n">_________________________________________________________________</code>
         <code class="n">Layer</code> <code class="p">(</code><code class="nb">type</code><code class="p">)</code>                 <code class="n">Output</code> <code class="n">Shape</code>              <code class="n">Param</code> <code class="c1">#</code>
         <code class="o">=================================================================</code>
         <code class="n">simple_rnn_2</code> <code class="p">(</code><code class="n">SimpleRNN</code><code class="p">)</code>     <code class="p">(</code><code class="bp">None</code><code class="p">,</code> <code class="mi">500</code><code class="p">)</code>               <code class="mi">251000</code>
         <code class="n">_________________________________________________________________</code>
         <code class="n">dense_2</code> <code class="p">(</code><code class="n">Dense</code><code class="p">)</code>              <code class="p">(</code><code class="bp">None</code><code class="p">,</code> <code class="mi">1</code><code class="p">)</code>                 <code class="mi">501</code>
         <code class="o">=================================================================</code>
         <code class="n">Total</code> <code class="n">params</code><code class="p">:</code> <code class="mi">251</code><code class="p">,</code><code class="mi">501</code>
         <code class="n">Trainable</code> <code class="n">params</code><code class="p">:</code> <code class="mi">251</code><code class="p">,</code><code class="mi">501</code>
         <code class="n">Non</code><code class="o">-</code><code class="n">trainable</code> <code class="n">params</code><code class="p">:</code> <code class="mi">0</code>
         <code class="n">_________________________________________________________________</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">31</code><code class="p">]:</code> <code class="o">%%</code><code class="n">time</code>
         <code class="n">model</code><code class="o">.</code><code class="n">fit_generator</code><code class="p">(</code><code class="n">g</code><code class="p">,</code> <code class="n">epochs</code><code class="o">=</code><code class="mi">500</code><code class="p">,</code>
                             <code class="n">steps_per_epoch</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code>
                             <code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code>
         <code class="n">CPU</code> <code class="n">times</code><code class="p">:</code> <code class="n">user</code> <code class="mi">1</code><code class="nb">min</code> <code class="mi">6</code><code class="n">s</code><code class="p">,</code> <code class="n">sys</code><code class="p">:</code> <code class="mf">14.6</code> <code class="n">s</code><code class="p">,</code> <code class="n">total</code><code class="p">:</code> <code class="mi">1</code><code class="nb">min</code> <code class="mi">20</code><code class="n">s</code>
         <code class="n">Wall</code> <code class="n">time</code><code class="p">:</code> <code class="mf">23.1</code> <code class="n">s</code>

<code class="n">Out</code><code class="p">[</code><code class="mi">31</code><code class="p">]:</code> <code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code> <code class="n">at</code> <code class="mh">0x7f7f09c11810</code><code class="o">&gt;</code></pre>

<p>The following Python code predicts sequence values for the interval <math alttext="left-bracket minus 6 pi comma 6 pi">
  <mrow>
    <mo>[</mo>
    <mo>-</mo>
    <mn>6</mn>
    <mi>π</mi>
    <mo>,</mo>
    <mn>6</mn>
    <mi>π</mi>
  </mrow>
</math>]. This interval is three times the size of the training interval and contains out-of-sample predictions both on the left-hand side and on the right-hand side of the training interval. <a data-type="xref" href="#figure_rnn_03">Figure 8-3</a> shows that the model performs quite well, even out-of-sample:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">32</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">x</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">linspace</code><code class="p">(</code><code class="o">-</code><code class="mi">6</code><code> </code><code class="o">*</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">pi</code><code class="p">,</code><code> </code><code class="mi">6</code><code> </code><code class="o">*</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">pi</code><code class="p">,</code><code> </code><code class="mi">1000</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO7-1" href="#callout_recurrent_neural_networks_CO7-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>         </code><code class="n">d</code><code> </code><code class="o">=</code><code> </code><code class="n">transform</code><code class="p">(</code><code class="n">x</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">33</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">g_</code><code> </code><code class="o">=</code><code> </code><code class="n">TimeseriesGenerator</code><code class="p">(</code><code class="n">d</code><code class="p">,</code><code> </code><code class="n">d</code><code class="p">,</code><code> </code><code class="n">length</code><code class="o">=</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">batch_size</code><code class="o">=</code><code class="nb">len</code><code class="p">(</code><code class="n">d</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO7-2" href="#callout_recurrent_neural_networks_CO7-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">34</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">f</code><code> </code><code class="o">=</code><code> </code><code class="nb">list</code><code class="p">(</code><code class="n">g_</code><code class="p">)</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="p">[</code><code class="mi">0</code><code class="p">]</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">d</code><code class="p">)</code><code> </code><code class="o">-</code><code> </code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">lags</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO7-3" href="#callout_recurrent_neural_networks_CO7-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">35</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">y</code><code> </code><code class="o">=</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">f</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO7-4" href="#callout_recurrent_neural_networks_CO7-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">36</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">plt</code><code class="o">.</code><code class="n">figure</code><code class="p">(</code><code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code> </code><code class="mi">6</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">x</code><code class="p">[</code><code class="n">lags</code><code class="p">:</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">d</code><code class="p">[</code><code class="n">lags</code><code class="p">:</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">label</code><code class="o">=</code><code class="s1">'</code><code class="s1">data</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">alpha</code><code class="o">=</code><code class="mf">0.75</code><code class="p">)</code><code>
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code><code class="n">x</code><code class="p">[</code><code class="n">lags</code><code class="p">:</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">y</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">r.</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">label</code><code class="o">=</code><code class="s1">'</code><code class="s1">pred</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">ms</code><code class="o">=</code><code class="mi">3</code><code class="p">)</code><code>
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">axvline</code><code class="p">(</code><code class="o">-</code><code class="mi">2</code><code> </code><code class="o">*</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">pi</code><code class="p">,</code><code> </code><code class="n">c</code><code class="o">=</code><code class="s1">'</code><code class="s1">g</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">ls</code><code class="o">=</code><code class="s1">'</code><code class="s1">--</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">axvline</code><code class="p">(</code><code class="mi">2</code><code> </code><code class="o">*</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">pi</code><code class="p">,</code><code> </code><code class="n">c</code><code class="o">=</code><code class="s1">'</code><code class="s1">g</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">ls</code><code class="o">=</code><code class="s1">'</code><code class="s1">--</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">text</code><code class="p">(</code><code class="o">-</code><code class="mi">15</code><code class="p">,</code><code> </code><code class="mi">22</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">out-of-sample</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">text</code><code class="p">(</code><code class="o">-</code><code class="mi">2</code><code class="p">,</code><code> </code><code class="mi">22</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">in-sample</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">text</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code><code> </code><code class="mi">22</code><code class="p">,</code><code> </code><code class="s1">'</code><code class="s1">out-of-sample</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>         </code><code class="n">plt</code><code class="o">.</code><code class="n">legend</code><code class="p">(</code><code class="p">)</code><code class="p">;</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO7-1" href="#co_recurrent_neural_networks_CO7-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Enlarges the sample data set</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO7-2" href="#co_recurrent_neural_networks_CO7-4"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>In-sample <em>and</em> out-of-sample prediction</p></dd>
</dl>
<div data-type="note" epub:type="note"><h1>Simplicity of Examples</h1>
<p><a data-type="indexterm" data-primary="OLS (ordinary least-squares) regression" data-secondary="versus neural networks" data-secondary-sortas="neural networks" id="idm45625288119672"/>The first two examples are deliberately chosen to be simple. Both problems posed in the examples can be solved more efficiently with OLS regression, for example, by allowing for trigonometric basis functions in the second example. However, the training of RNNs for nontrivial sequence data, such as financial time series data, is basically the same. In such a context, OLS regression, for instance, can in general not keep up with the capabilities of RNNs.<a data-type="indexterm" data-primary="" data-startref="ix_RNNs_secondex" id="idm45625288074104"/></p>
</div>

<figure class="thumb"><div id="figure_rnn_03" class="figure">
<img src="Images/aiif_0803.png" alt="aiif 0803" width="2404" height="1421"/>
<h6><span class="label">Figure 8-3. </span>In-sample and out-of-sample predictions of the RNN</h6>
</div></figure>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Financial Price Series"><div class="sect1" id="rnn_fin_price_series">
<h1>Financial Price Series</h1>

<p><a data-type="indexterm" data-primary="RNNs (recurrent neural networks)" data-secondary="financial price series" id="ix_RNNs_finpriceseries"/><a data-type="indexterm" data-primary="FX (foreign exchange)" id="ix_FX_RNNs_ch8"/><a data-type="indexterm" data-primary="financial price series, with RNN" id="ix_fin_price_RNNs"/>As a first application of RNNs to financial time series data, consider intraday EUR/USD quotes. With the approach introduced in the previous two sections, the training of the RNN on the financial time series is straightforward. First, the data is imported and resampled. The data is also normalized and transformed into the appropriate <code>ndarray</code> object:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">37</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">url</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">http://hilpisch.com/aiif_eikon_id_eur_usd.csv</code><code class="s1">'</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">38</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">symbol</code><code> </code><code class="o">=</code><code> </code><code class="s1">'</code><code class="s1">EUR_USD</code><code class="s1">'</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">39</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">raw</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">read_csv</code><code class="p">(</code><code class="n">url</code><code class="p">,</code><code> </code><code class="n">index_col</code><code class="o">=</code><code class="mi">0</code><code class="p">,</code><code> </code><code class="n">parse_dates</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">40</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">generate_data</code><code class="p">(</code><code class="p">)</code><code class="p">:</code><code>
</code><code>             </code><code class="n">data</code><code> </code><code class="o">=</code><code> </code><code class="n">pd</code><code class="o">.</code><code class="n">DataFrame</code><code class="p">(</code><code class="n">raw</code><code class="p">[</code><code class="s1">'</code><code class="s1">CLOSE</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO8-1" href="#callout_recurrent_neural_networks_CO8-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">data</code><code class="o">.</code><code class="n">columns</code><code> </code><code class="o">=</code><code> </code><code class="p">[</code><code class="n">symbol</code><code class="p">]</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO8-2" href="#callout_recurrent_neural_networks_CO8-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>             </code><code class="n">data</code><code> </code><code class="o">=</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">resample</code><code class="p">(</code><code class="s1">'</code><code class="s1">30min</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">label</code><code class="o">=</code><code class="s1">'</code><code class="s1">right</code><code class="s1">'</code><code class="p">)</code><code class="o">.</code><code class="n">last</code><code class="p">(</code><code class="p">)</code><code class="o">.</code><code class="n">ffill</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO8-3" href="#callout_recurrent_neural_networks_CO8-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>             </code><code class="k">return</code><code> </code><code class="n">data</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">41</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">data</code><code> </code><code class="o">=</code><code> </code><code class="n">generate_data</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">42</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">data</code><code> </code><code class="o">=</code><code> </code><code class="p">(</code><code class="n">data</code><code> </code><code class="o">-</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="p">)</code><code class="p">)</code><code> </code><code class="o">/</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">std</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO8-4" href="#callout_recurrent_neural_networks_CO8-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">43</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">p</code><code> </code><code class="o">=</code><code> </code><code class="n">data</code><code class="p">[</code><code class="n">symbol</code><code class="p">]</code><code class="o">.</code><code class="n">values</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO8-5" href="#callout_recurrent_neural_networks_CO8-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">44</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">p</code><code> </code><code class="o">=</code><code> </code><code class="n">p</code><code class="o">.</code><code class="n">reshape</code><code class="p">(</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">p</code><code class="p">)</code><code class="p">,</code><code> </code><code class="o">-</code><code class="mi">1</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO8-6" href="#callout_recurrent_neural_networks_CO8-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a></pre>
<div style="page-break-after: always;"/>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO8-1" href="#co_recurrent_neural_networks_CO8-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Selects a single column</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO8-2" href="#co_recurrent_neural_networks_CO8-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Renames the column</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO8-3" href="#co_recurrent_neural_networks_CO8-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>Resamples the data</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO8-4" href="#co_recurrent_neural_networks_CO8-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a></dt>
<dd><p>Applies Gaussian normalization</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO8-5" href="#co_recurrent_neural_networks_CO8-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a></dt>
<dd><p>Reshapes the data set to two dimensions</p></dd>
</dl>

<p><a data-type="indexterm" data-primary="create_rnn_model() function" id="idm45625287818520"/><a data-type="indexterm" data-primary="LSTM (long-short term memory) layer" id="idm45625287588312"/><a data-type="indexterm" data-primary="SimpleRNN layer" id="idm45625287587624"/>Second, the RNN is trained based on the generator object. The function 
<span class="keep-together"><code>create_rnn_model()</code></span> allows the creation of an RNN with a <code>SimpleRNN</code> or an <code>LSTM</code> (<em>long short-term memory</em>) layer (Chollet 2017, ch. 6; also see <a href="https://oreil.ly/kpuqA">Keras recurrent layers</a>).</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">45</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">lags</code><code> </code><code class="o">=</code><code> </code><code class="mi">5</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">46</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">g</code><code> </code><code class="o">=</code><code> </code><code class="n">TimeseriesGenerator</code><code class="p">(</code><code class="n">p</code><code class="p">,</code><code> </code><code class="n">p</code><code class="p">,</code><code> </code><code class="n">length</code><code class="o">=</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">batch_size</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">47</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">create_rnn_model</code><code class="p">(</code><code class="n">hu</code><code class="o">=</code><code class="mi">100</code><code class="p">,</code><code> </code><code class="n">lags</code><code class="o">=</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">layer</code><code class="o">=</code><code class="s1">'</code><code class="s1">SimpleRNN</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                                    </code><code class="n">features</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">algorithm</code><code class="o">=</code><code class="s1">'</code><code class="s1">estimation</code><code class="s1">'</code><code class="p">)</code><code class="p">:</code><code>
</code><code>             </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">Sequential</code><code class="p">(</code><code class="p">)</code><code>
</code><code>             </code><code class="k">if</code><code> </code><code class="n">layer</code><code> </code><code class="ow">is</code><code> </code><code class="s1">'</code><code class="s1">SimpleRNN</code><code class="s1">'</code><code class="p">:</code><code>
</code><code>                 </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">SimpleRNN</code><code class="p">(</code><code class="n">hu</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                                     </code><code class="n">input_shape</code><code class="o">=</code><code class="p">(</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">features</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO9-1" href="#callout_recurrent_neural_networks_CO9-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>             </code><code class="k">else</code><code class="p">:</code><code>
</code><code>                 </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">LSTM</code><code class="p">(</code><code class="n">hu</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">relu</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                                </code><code class="n">input_shape</code><code class="o">=</code><code class="p">(</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">features</code><code class="p">)</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO9-2" href="#callout_recurrent_neural_networks_CO9-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>             </code><code class="k">if</code><code> </code><code class="n">algorithm</code><code> </code><code class="o">==</code><code> </code><code class="s1">'</code><code class="s1">estimation</code><code class="s1">'</code><code class="p">:</code><code>
</code><code>                 </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">linear</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO9-3" href="#callout_recurrent_neural_networks_CO9-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>                 </code><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">optimizer</code><code class="o">=</code><code class="s1">'</code><code class="s1">adam</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">loss</code><code class="o">=</code><code class="s1">'</code><code class="s1">mse</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="s1">'</code><code class="s1">mae</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>             </code><code class="k">else</code><code class="p">:</code><code>
</code><code>                 </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">sigmoid</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO9-4" href="#callout_recurrent_neural_networks_CO9-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>                 </code><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">optimizer</code><code class="o">=</code><code class="s1">'</code><code class="s1">adam</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">loss</code><code class="o">=</code><code class="s1">'</code><code class="s1">mse</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="s1">'</code><code class="s1">accuracy</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>             </code><code class="k">return</code><code> </code><code class="n">model</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">48</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">create_rnn_model</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">49</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">fit_generator</code><code class="p">(</code><code class="n">g</code><code class="p">,</code><code> </code><code class="n">epochs</code><code class="o">=</code><code class="mi">500</code><code class="p">,</code><code> </code><code class="n">steps_per_epoch</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code><code>
</code><code>                             </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">20.8</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mf">4.66</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">25.5</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">11.2</code><code> </code><code class="n">s</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">49</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7f7ef6716590</code><code class="o">&gt;</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO9-1" href="#co_recurrent_neural_networks_CO9-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Adds a <code>SimpleRNN</code> layer or <code>LSTM</code> layer</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO9-2" href="#co_recurrent_neural_networks_CO9-3"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Adds an output layer for <em>estimation</em> or <em>classification</em></p></dd>
</dl>

<p>Third, the in-sample prediction is generated. As <a data-type="xref" href="#figure_rnn_04">Figure 8-4</a> illustrates, the RNN is capable of capturing the structure of the normalized financial time series data. Based on this visualization, the prediction accuracy seems quite good:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">50</code><code class="p">]:</code> <code class="n">y</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">g</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">51</code><code class="p">]:</code> <code class="n">data</code><code class="p">[</code><code class="s1">'pred'</code><code class="p">]</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">nan</code>
         <code class="n">data</code><code class="p">[</code><code class="s1">'pred'</code><code class="p">]</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">lags</code><code class="p">:]</code> <code class="o">=</code> <code class="n">y</code><code class="o">.</code><code class="n">flatten</code><code class="p">()</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">52</code><code class="p">]:</code> <code class="n">data</code><code class="p">[[</code><code class="n">symbol</code><code class="p">,</code> <code class="s1">'pred'</code><code class="p">]]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code>
                     <code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code> <code class="n">style</code><code class="o">=</code><code class="p">[</code><code class="s1">'b'</code><code class="p">,</code> <code class="s1">'r-.'</code><code class="p">],</code>
                     <code class="n">alpha</code><code class="o">=</code><code class="mf">0.75</code><code class="p">);</code></pre>

<figure class="thumb"><div id="figure_rnn_04" class="figure">
<img src="Images/aiif_0804.png" alt="aiif 0804" width="2411" height="1528"/>
<h6><span class="label">Figure 8-4. </span>In-sample prediction for financial price series by the RNN (whole data set)</h6>
</div></figure>

<p>However, the visualization suggests a result that does not hold up upon closer inspection. <a data-type="xref" href="#figure_rnn_05">Figure 8-5</a> zooms in and only shows 50 data points from the original data set and of the prediction. It becomes clear that the prediction values from the RNN are basically just the most previous lag, shifted by one time interval. Visually speaking, the prediction line is the financial time series itself, moved one time interval to the right:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">53</code><code class="p">]:</code> <code class="n">data</code><code class="p">[[</code><code class="n">symbol</code><code class="p">,</code> <code class="s1">'pred'</code><code class="p">]]</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="mi">50</code><code class="p">:</code><code class="mi">100</code><code class="p">]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code>
                     <code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code> <code class="n">style</code><code class="o">=</code><code class="p">[</code><code class="s1">'b'</code><code class="p">,</code> <code class="s1">'r-.'</code><code class="p">],</code>
                     <code class="n">alpha</code><code class="o">=</code><code class="mf">0.75</code><code class="p">);</code></pre>

<figure class="thumb"><div id="figure_rnn_05" class="figure">
<img src="Images/aiif_0805.png" alt="aiif 0805" width="2451" height="1528"/>
<h6><span class="label">Figure 8-5. </span>In-sample prediction for financial price series by the RNN (data sub-set)</h6>
</div></figure>
<div data-type="note" epub:type="note"><h1>RNNs and Efficient Markets</h1>
<p><a data-type="indexterm" data-primary="OLS (ordinary least-squares) regression" data-secondary="versus neural networks" data-secondary-sortas="neural networks" id="idm45625287519192"/>The results for the prediction of a financial price series based on an RNN are in line with the OLS regression approach used in <a data-type="xref" href="ch06.xhtml#ai_first_finance">Chapter 6</a> to illustrate the EMH. There, it is illustrated that, in a least-squares sense, today’s price is the best predictor for tomorrow’s price. The application of an RNN to price data does not yield any other insight.<a data-type="indexterm" data-primary="" data-startref="ix_fin_price_RNNs" id="idm45625287516664"/><a data-type="indexterm" data-primary="" data-startref="ix_FX_RNNs_ch8" id="idm45625287515720"/><a data-type="indexterm" data-primary="" data-startref="ix_RNNs_finpriceseries" id="idm45625287514776"/></p>
</div>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Financial Return Series"><div class="sect1" id="rnn_fin_ret_series">
<h1>Financial Return Series</h1>

<p><a data-type="indexterm" data-primary="returns" data-secondary="basing market prediction on" id="ix_returns_market_predict"/><a data-type="indexterm" data-primary="RNNs (recurrent neural networks)" data-secondary="financial return series" id="ix_RNNs_fin_return"/><a data-type="indexterm" data-primary="market prediction" data-secondary="with RNNs" data-secondary-sortas="RNNs" id="ix_market_predict_RNNs"/><a data-type="indexterm" data-primary="market prediction" data-secondary="returns data as basis for" id="ix_returns_data_predict"/><a data-type="indexterm" data-primary="AI-first finance" data-secondary="returns data as basis for market prediction" id="ix_AI-firstfin_returns_data"/>As previous analyses have shown, it might be easier to predict returns instead of prices. Therefore, the following Python code repeats the preceding analysis based on log returns:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">54</code><code class="p">]:</code> <code class="n">data</code> <code class="o">=</code> <code class="n">generate_data</code><code class="p">()</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">55</code><code class="p">]:</code> <code class="n">data</code><code class="p">[</code><code class="s1">'r'</code><code class="p">]</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">log</code><code class="p">(</code><code class="n">data</code> <code class="o">/</code> <code class="n">data</code><code class="o">.</code><code class="n">shift</code><code class="p">(</code><code class="mi">1</code><code class="p">))</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">56</code><code class="p">]:</code> <code class="n">data</code><code class="o">.</code><code class="n">dropna</code><code class="p">(</code><code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">57</code><code class="p">]:</code> <code class="n">data</code> <code class="o">=</code> <code class="p">(</code><code class="n">data</code> <code class="o">-</code> <code class="n">data</code><code class="o">.</code><code class="n">mean</code><code class="p">())</code> <code class="o">/</code> <code class="n">data</code><code class="o">.</code><code class="n">std</code><code class="p">()</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">58</code><code class="p">]:</code> <code class="n">r</code> <code class="o">=</code> <code class="n">data</code><code class="p">[</code><code class="s1">'r'</code><code class="p">]</code><code class="o">.</code><code class="n">values</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">59</code><code class="p">]:</code> <code class="n">r</code> <code class="o">=</code> <code class="n">r</code><code class="o">.</code><code class="n">reshape</code><code class="p">((</code><code class="nb">len</code><code class="p">(</code><code class="n">r</code><code class="p">),</code> <code class="o">-</code><code class="mi">1</code><code class="p">))</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">60</code><code class="p">]:</code> <code class="n">g</code> <code class="o">=</code> <code class="n">TimeseriesGenerator</code><code class="p">(</code><code class="n">r</code><code class="p">,</code> <code class="n">r</code><code class="p">,</code> <code class="n">length</code><code class="o">=</code><code class="n">lags</code><code class="p">,</code> <code class="n">batch_size</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">61</code><code class="p">]:</code> <code class="n">model</code> <code class="o">=</code> <code class="n">create_rnn_model</code><code class="p">()</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">62</code><code class="p">]:</code> <code class="o">%%</code><code class="n">time</code>
         <code class="n">model</code><code class="o">.</code><code class="n">fit_generator</code><code class="p">(</code><code class="n">g</code><code class="p">,</code> <code class="n">epochs</code><code class="o">=</code><code class="mi">500</code><code class="p">,</code> <code class="n">steps_per_epoch</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code>
                             <code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code>
         <code class="n">CPU</code> <code class="n">times</code><code class="p">:</code> <code class="n">user</code> <code class="mf">20.4</code> <code class="n">s</code><code class="p">,</code> <code class="n">sys</code><code class="p">:</code> <code class="mf">4.2</code> <code class="n">s</code><code class="p">,</code> <code class="n">total</code><code class="p">:</code> <code class="mf">24.6</code> <code class="n">s</code>
         <code class="n">Wall</code> <code class="n">time</code><code class="p">:</code> <code class="mf">11.3</code> <code class="n">s</code>

<code class="n">Out</code><code class="p">[</code><code class="mi">62</code><code class="p">]:</code> <code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code> <code class="n">at</code> <code class="mh">0x7f7ef47a8dd0</code><code class="o">&gt;</code></pre>

<p>As <a data-type="xref" href="#figure_rnn_06">Figure 8-6</a> shows, the RNN’s predictions are not too good in absolute terms. However, they seem to get the market direction (sign of the return) somehow right:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">63</code><code class="p">]:</code> <code class="n">y</code> <code class="o">=</code> <code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">g</code><code class="p">,</code> <code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">64</code><code class="p">]:</code> <code class="n">data</code><code class="p">[</code><code class="s1">'pred'</code><code class="p">]</code> <code class="o">=</code> <code class="n">np</code><code class="o">.</code><code class="n">nan</code>
         <code class="n">data</code><code class="p">[</code><code class="s1">'pred'</code><code class="p">]</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">lags</code><code class="p">:]</code> <code class="o">=</code> <code class="n">y</code><code class="o">.</code><code class="n">flatten</code><code class="p">()</code>
         <code class="n">data</code><code class="o">.</code><code class="n">dropna</code><code class="p">(</code><code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">65</code><code class="p">]:</code> <code class="n">data</code><code class="p">[[</code><code class="s1">'r'</code><code class="p">,</code> <code class="s1">'pred'</code><code class="p">]]</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="mi">50</code><code class="p">:</code><code class="mi">100</code><code class="p">]</code><code class="o">.</code><code class="n">plot</code><code class="p">(</code>
                     <code class="n">figsize</code><code class="o">=</code><code class="p">(</code><code class="mi">10</code><code class="p">,</code> <code class="mi">6</code><code class="p">),</code> <code class="n">style</code><code class="o">=</code><code class="p">[</code><code class="s1">'b'</code><code class="p">,</code> <code class="s1">'r-.'</code><code class="p">],</code>
                     <code class="n">alpha</code><code class="o">=</code><code class="mf">0.75</code><code class="p">);</code>
         <code class="n">plt</code><code class="o">.</code><code class="n">axhline</code><code class="p">(</code><code class="mi">0</code><code class="p">,</code> <code class="n">c</code><code class="o">=</code><code class="s1">'grey'</code><code class="p">,</code> <code class="n">ls</code><code class="o">=</code><code class="s1">'--'</code><code class="p">)</code></pre>

<figure class="thumb"><div id="figure_rnn_06" class="figure">
<img src="Images/aiif_0806.png" alt="aiif 0806" width="2411" height="1528"/>
<h6><span class="label">Figure 8-6. </span>In-sample prediction for financial return series by the RNN (data sub-set)</h6>
</div></figure>

<p>While <a data-type="xref" href="#figure_rnn_06">Figure 8-6</a> only provides an indication, the relatively high accuracy score supports the assumption that the RNN might perform better on a return than on a price series:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code> <code class="p">[</code><code class="mi">66</code><code class="p">]:</code> <code class="kn">from</code> <code class="nn">sklearn.metrics</code> <code class="kn">import</code> <code class="n">accuracy_score</code>

<code class="n">In</code> <code class="p">[</code><code class="mi">67</code><code class="p">]:</code> <code class="n">accuracy_score</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">sign</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="s1">'r'</code><code class="p">]),</code> <code class="n">np</code><code class="o">.</code><code class="n">sign</code><code class="p">(</code><code class="n">data</code><code class="p">[</code><code class="s1">'pred'</code><code class="p">]))</code>
<code class="n">Out</code><code class="p">[</code><code class="mi">67</code><code class="p">]:</code> <code class="mf">0.6806532093445226</code></pre>

<p>However, to get a realistic picture, a train-test split is in order. The accuracy score out-of-sample is not as high as the one seen for the whole data set in-sample, but it is still high for the problem at hand:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">68</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">split</code><code> </code><code class="o">=</code><code> </code><code class="nb">int</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">r</code><code class="p">)</code><code> </code><code class="o">*</code><code> </code><code class="mf">0.8</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO10-1" href="#callout_recurrent_neural_networks_CO10-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">69</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">train</code><code> </code><code class="o">=</code><code> </code><code class="n">r</code><code class="p">[</code><code class="p">:</code><code class="n">split</code><code class="p">]</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO10-2" href="#callout_recurrent_neural_networks_CO10-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">70</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">test</code><code> </code><code class="o">=</code><code> </code><code class="n">r</code><code class="p">[</code><code class="n">split</code><code class="p">:</code><code class="p">]</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO10-3" href="#callout_recurrent_neural_networks_CO10-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">71</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">g</code><code> </code><code class="o">=</code><code> </code><code class="n">TimeseriesGenerator</code><code class="p">(</code><code class="n">train</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">,</code><code> </code><code class="n">length</code><code class="o">=</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">batch_size</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO10-4" href="#callout_recurrent_neural_networks_CO10-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">72</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>
</code><code>         </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">create_rnn_model</code><code class="p">(</code><code class="n">hu</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">73</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">fit_generator</code><code class="p">(</code><code class="n">g</code><code class="p">,</code><code> </code><code class="n">epochs</code><code class="o">=</code><code class="mi">100</code><code class="p">,</code><code> </code><code class="n">steps_per_epoch</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code><code> </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO10-5" href="#callout_recurrent_neural_networks_CO10-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">5.67</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mf">1.09</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">6.75</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">2.95</code><code> </code><code class="n">s</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">73</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7f7ef5482dd0</code><code class="o">&gt;</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">74</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">g_</code><code> </code><code class="o">=</code><code> </code><code class="n">TimeseriesGenerator</code><code class="p">(</code><code class="n">test</code><code class="p">,</code><code> </code><code class="n">test</code><code class="p">,</code><code> </code><code class="n">length</code><code class="o">=</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">batch_size</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO10-6" href="#callout_recurrent_neural_networks_CO10-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">75</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">y</code><code> </code><code class="o">=</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">g_</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO10-7" href="#callout_recurrent_neural_networks_CO10-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">76</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">accuracy_score</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">sign</code><code class="p">(</code><code class="n">test</code><code class="p">[</code><code class="n">lags</code><code class="p">:</code><code class="p">]</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">sign</code><code class="p">(</code><code class="n">y</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO10-8" href="#callout_recurrent_neural_networks_CO10-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">76</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">0.6708428246013668</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO10-1" href="#co_recurrent_neural_networks_CO10-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Splits the data into train and test data sub-sets</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO10-2" href="#co_recurrent_neural_networks_CO10-4"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Fits the model on the training data</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO10-3" href="#co_recurrent_neural_networks_CO10-6"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>Tests the model on the testing data<a data-type="indexterm" data-primary="" data-startref="ix_AI-firstfin_returns_data" id="idm45625286298520"/><a data-type="indexterm" data-primary="" data-startref="ix_returns_data_predict" id="idm45625286229784"/><a data-type="indexterm" data-primary="" data-startref="ix_market_predict_RNNs" id="idm45625286228840"/><a data-type="indexterm" data-primary="" data-startref="ix_returns_market_predict" id="idm45625286227896"/><a data-type="indexterm" data-primary="" data-startref="ix_RNNs_fin_return" id="idm45625286226984"/></p></dd>
</dl>
</div></section>













<section data-type="sect1" data-pdf-bookmark="Financial Features"><div class="sect1" id="rnn_fin_features">
<h1>Financial Features</h1>

<p><a data-type="indexterm" data-primary="RNNs (recurrent neural networks)" data-secondary="financial features" id="ix_RNNs_fin_features"/>The application of RNNs is not restricted to the raw price or return data. Additional features can also be included to improve the prediction of the RNN. The following Python code adds typical financial features to the data set:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">77</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">data</code><code> </code><code class="o">=</code><code> </code><code class="n">generate_data</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">78</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">data</code><code class="p">[</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">log</code><code class="p">(</code><code class="n">data</code><code> </code><code class="o">/</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">shift</code><code class="p">(</code><code class="mi">1</code><code class="p">)</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">79</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">window</code><code> </code><code class="o">=</code><code> </code><code class="mi">20</code><code>
</code><code>         </code><code class="n">data</code><code class="p">[</code><code class="s1">'</code><code class="s1">mom</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">data</code><code class="p">[</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">rolling</code><code class="p">(</code><code class="n">window</code><code class="p">)</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO11-1" href="#callout_recurrent_neural_networks_CO11-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>         </code><code class="n">data</code><code class="p">[</code><code class="s1">'</code><code class="s1">vol</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">=</code><code> </code><code class="n">data</code><code class="p">[</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">rolling</code><code class="p">(</code><code class="n">window</code><code class="p">)</code><code class="o">.</code><code class="n">std</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO11-2" href="#callout_recurrent_neural_networks_CO11-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">80</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">dropna</code><code class="p">(</code><code class="n">inplace</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO11-1" href="#co_recurrent_neural_networks_CO11-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p><a data-type="indexterm" data-primary="momentum feature" id="idm45625286055544"/>Adds a time series <em>momentum</em> feature</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO11-2" href="#co_recurrent_neural_networks_CO11-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p><a data-type="indexterm" data-primary="rolling volatility feature" id="idm45625286052008"/><a data-type="indexterm" data-primary="volatility" data-secondary="rolling volatility feature" id="idm45625286051336"/>Adds a rolling <em>volatility</em> feature</p></dd>
</dl>








<section data-type="sect2" data-pdf-bookmark="Estimation"><div class="sect2" id="idm45625286049624">
<h2>Estimation</h2>

<p><a data-type="indexterm" data-primary="neural networks" data-secondary="in estimation task" data-secondary-sortas="estimation task" id="ix_neuralnet_estim_task_ch8"/><a data-type="indexterm" data-primary="estimation task" data-secondary="neural networks applied to" id="ix_estim_task_nn_app_ch8"/>The out-of-sample accuracy, maybe somewhat surprisingly, drops significantly in the estimation case. In other words, there is no improvement observed from adding financial features in this particular case:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">81</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">split</code><code> </code><code class="o">=</code><code> </code><code class="nb">int</code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">data</code><code class="p">)</code><code> </code><code class="o">*</code><code> </code><code class="mf">0.8</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">82</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">train</code><code> </code><code class="o">=</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="p">:</code><code class="n">split</code><code class="p">]</code><code class="o">.</code><code class="n">copy</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">83</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">mu</code><code class="p">,</code><code> </code><code class="n">std</code><code> </code><code class="o">=</code><code> </code><code class="n">train</code><code class="o">.</code><code class="n">mean</code><code class="p">(</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">train</code><code class="o">.</code><code class="n">std</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO12-1" href="#callout_recurrent_neural_networks_CO12-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">84</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">train</code><code> </code><code class="o">=</code><code> </code><code class="p">(</code><code class="n">train</code><code> </code><code class="o">-</code><code> </code><code class="n">mu</code><code class="p">)</code><code> </code><code class="o">/</code><code> </code><code class="n">std</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO12-2" href="#callout_recurrent_neural_networks_CO12-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">85</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">test</code><code> </code><code class="o">=</code><code> </code><code class="n">data</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">split</code><code class="p">:</code><code class="p">]</code><code class="o">.</code><code class="n">copy</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">86</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">test</code><code> </code><code class="o">=</code><code> </code><code class="p">(</code><code class="n">test</code><code> </code><code class="o">-</code><code> </code><code class="n">mu</code><code class="p">)</code><code> </code><code class="o">/</code><code> </code><code class="n">std</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO12-3" href="#callout_recurrent_neural_networks_CO12-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">87</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">g</code><code> </code><code class="o">=</code><code> </code><code class="n">TimeseriesGenerator</code><code class="p">(</code><code class="n">train</code><code class="o">.</code><code class="n">values</code><code class="p">,</code><code> </code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">values</code><code class="p">,</code><code>
</code><code>                                 </code><code class="n">length</code><code class="o">=</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">batch_size</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO12-4" href="#callout_recurrent_neural_networks_CO12-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">88</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>
</code><code>         </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">create_rnn_model</code><code class="p">(</code><code class="n">hu</code><code class="o">=</code><code class="mi">100</code><code class="p">,</code><code> </code><code class="n">features</code><code class="o">=</code><code class="nb">len</code><code class="p">(</code><code class="n">data</code><code class="o">.</code><code class="n">columns</code><code class="p">)</code><code class="p">,</code><code>
</code><code>                                  </code><code class="n">layer</code><code class="o">=</code><code class="s1">'</code><code class="s1">SimpleRNN</code><code class="s1">'</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">89</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">fit_generator</code><code class="p">(</code><code class="n">g</code><code class="p">,</code><code> </code><code class="n">epochs</code><code class="o">=</code><code class="mi">100</code><code class="p">,</code><code> </code><code class="n">steps_per_epoch</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code><code>
</code><code>                             </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO12-5" href="#callout_recurrent_neural_networks_CO12-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">5.24</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mf">1.08</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">6.32</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">2.73</code><code> </code><code class="n">s</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">89</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7f7ef313c950</code><code class="o">&gt;</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">90</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">g_</code><code> </code><code class="o">=</code><code> </code><code class="n">TimeseriesGenerator</code><code class="p">(</code><code class="n">test</code><code class="o">.</code><code class="n">values</code><code class="p">,</code><code> </code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">values</code><code class="p">,</code><code>
</code><code>                                  </code><code class="n">length</code><code class="o">=</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">batch_size</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO12-6" href="#callout_recurrent_neural_networks_CO12-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">91</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">y</code><code> </code><code class="o">=</code><code> </code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">g_</code><code class="p">)</code><code class="o">.</code><code class="n">flatten</code><code class="p">(</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO12-7" href="#callout_recurrent_neural_networks_CO12-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">92</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">accuracy_score</code><code class="p">(</code><code class="n">np</code><code class="o">.</code><code class="n">sign</code><code class="p">(</code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">]</code><code class="o">.</code><code class="n">iloc</code><code class="p">[</code><code class="n">lags</code><code class="p">:</code><code class="p">]</code><code class="p">)</code><code class="p">,</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">sign</code><code class="p">(</code><code class="n">y</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO12-8" href="#callout_recurrent_neural_networks_CO12-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">92</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">0.37299771167048057</code></pre>
<div style="page-break-after: always;"/>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO12-1" href="#co_recurrent_neural_networks_CO12-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>Calculates the first and second moment of the training data</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO12-2" href="#co_recurrent_neural_networks_CO12-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Applies Gaussian normalization to the training data</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO12-3" href="#co_recurrent_neural_networks_CO12-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>Applies Gaussian normalization to the testing data—based on the statistics from the training data</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO12-4" href="#co_recurrent_neural_networks_CO12-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a></dt>
<dd><p>Fits the model on the training data</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO12-5" href="#co_recurrent_neural_networks_CO12-6"><img src="Images/5.png" alt="5" width="12" height="12"/></a></dt>
<dd><p>Tests the model on the testing data<a data-type="indexterm" data-primary="" data-startref="ix_estim_task_nn_app_ch8" id="idm45625285594344"/><a data-type="indexterm" data-primary="" data-startref="ix_neuralnet_estim_task_ch8" id="idm45625285593400"/></p></dd>
</dl>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Classification"><div class="sect2" id="idm45625285563384">
<h2>Classification</h2>

<p><a data-type="indexterm" data-primary="neural networks" data-secondary="in classification task" data-secondary-sortas="classification task" id="idm45625285591464"/><a data-type="indexterm" data-primary="classification task" data-secondary="neural networks applied to" id="idm45625285589992"/>The analyses so far use a <code>Keras</code> RNN model for <em>estimation</em> to predict the future direction of the price of the financial instrument. The problem at hand is probably better cast directly into a <em>classification</em> setting. The following Python code works with binary labels data and predicts the direction of the price movement directly. <a data-type="indexterm" data-primary="LSTM (long-short term memory) layer" id="idm45625285587416"/>It also works this time with an LSTM layer. The out-of-sample accuracy is quite high even for a relatively small number of hidden units and only a few training epochs. The approach again takes class imbalance into account by adjusting the class weights appropriately. The prediction accuracy is quite high in this case with around 65%:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">93</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>
</code><code>         </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">create_rnn_model</code><code class="p">(</code><code class="n">hu</code><code class="o">=</code><code class="mi">50</code><code class="p">,</code><code>
</code><code>                     </code><code class="n">features</code><code class="o">=</code><code class="nb">len</code><code class="p">(</code><code class="n">data</code><code class="o">.</code><code class="n">columns</code><code class="p">)</code><code class="p">,</code><code>
</code><code>                     </code><code class="n">layer</code><code class="o">=</code><code class="s1">'</code><code class="s1">LSTM</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                     </code><code class="n">algorithm</code><code class="o">=</code><code class="s1">'</code><code class="s1">classification</code><code class="s1">'</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO13-1" href="#callout_recurrent_neural_networks_CO13-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">94</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">train_y</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">train</code><code class="p">[</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">&gt;</code><code> </code><code class="mi">0</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO13-2" href="#callout_recurrent_neural_networks_CO13-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">95</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">bincount</code><code class="p">(</code><code class="n">train_y</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO13-3" href="#callout_recurrent_neural_networks_CO13-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">95</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code class="mi">2374</code><code class="p">,</code><code> </code><code class="mi">1142</code><code class="p">]</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">96</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">cw</code><code class="p">(</code><code class="n">a</code><code class="p">)</code><code class="p">:</code><code>
</code><code>             </code><code class="n">c0</code><code class="p">,</code><code> </code><code class="n">c1</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">bincount</code><code class="p">(</code><code class="n">a</code><code class="p">)</code><code>
</code><code>             </code><code class="n">w0</code><code> </code><code class="o">=</code><code> </code><code class="p">(</code><code class="mi">1</code><code> </code><code class="o">/</code><code> </code><code class="n">c0</code><code class="p">)</code><code> </code><code class="o">*</code><code> </code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">a</code><code class="p">)</code><code class="p">)</code><code> </code><code class="o">/</code><code> </code><code class="mi">2</code><code>
</code><code>             </code><code class="n">w1</code><code> </code><code class="o">=</code><code> </code><code class="p">(</code><code class="mi">1</code><code> </code><code class="o">/</code><code> </code><code class="n">c1</code><code class="p">)</code><code> </code><code class="o">*</code><code> </code><code class="p">(</code><code class="nb">len</code><code class="p">(</code><code class="n">a</code><code class="p">)</code><code class="p">)</code><code> </code><code class="o">/</code><code> </code><code class="mi">2</code><code>
</code><code>             </code><code class="k">return</code><code> </code><code class="p">{</code><code class="mi">0</code><code class="p">:</code><code> </code><code class="n">w0</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">:</code><code> </code><code class="n">w1</code><code class="p">}</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">97</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">g</code><code> </code><code class="o">=</code><code> </code><code class="n">TimeseriesGenerator</code><code class="p">(</code><code class="n">train</code><code class="o">.</code><code class="n">values</code><code class="p">,</code><code> </code><code class="n">train_y</code><code class="p">,</code><code>
</code><code>                                 </code><code class="n">length</code><code class="o">=</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">batch_size</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">98</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>         </code><code class="n">model</code><code class="o">.</code><code class="n">fit_generator</code><code class="p">(</code><code class="n">g</code><code class="p">,</code><code> </code><code class="n">epochs</code><code class="o">=</code><code class="mi">5</code><code class="p">,</code><code> </code><code class="n">steps_per_epoch</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code><code>
</code><code>                             </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code> </code><code class="n">class_weight</code><code class="o">=</code><code class="n">cw</code><code class="p">(</code><code class="n">train_y</code><code class="p">)</code><code class="p">)</code><code>
</code><code>         </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">1.25</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mi">159</code><code> </code><code class="n">ms</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">1.41</code><code> </code><code class="n">s</code><code>
</code><code>         </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mi">947</code><code> </code><code class="n">ms</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">98</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7f7ef43baf90</code><code class="o">&gt;</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">99</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">test_y</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">test</code><code class="p">[</code><code class="s1">'</code><code class="s1">r</code><code class="s1">'</code><code class="p">]</code><code> </code><code class="o">&gt;</code><code> </code><code class="mi">0</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO13-4" href="#callout_recurrent_neural_networks_CO13-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">100</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">g_</code><code> </code><code class="o">=</code><code> </code><code class="n">TimeseriesGenerator</code><code class="p">(</code><code class="n">test</code><code class="o">.</code><code class="n">values</code><code class="p">,</code><code> </code><code class="n">test_y</code><code class="p">,</code><code>
</code><code>                                   </code><code class="n">length</code><code class="o">=</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">batch_size</code><code class="o">=</code><code class="mi">5</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">101</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">y</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">g_</code><code class="p">,</code><code> </code><code class="n">batch_size</code><code class="o">=</code><code class="bp">None</code><code class="p">)</code><code> </code><code class="o">&gt;</code><code> </code><code class="mf">0.5</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">)</code><code class="o">.</code><code class="n">flatten</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">102</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">bincount</code><code class="p">(</code><code class="n">y</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">102</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code class="mi">492</code><code class="p">,</code><code> </code><code class="mi">382</code><code class="p">]</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">103</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">accuracy_score</code><code class="p">(</code><code class="n">test_y</code><code class="p">[</code><code class="n">lags</code><code class="p">:</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">y</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">103</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">0.6498855835240275</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO13-1" href="#co_recurrent_neural_networks_CO13-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>RNN model for classification</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO13-2" href="#co_recurrent_neural_networks_CO13-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>Binary training labels</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO13-3" href="#co_recurrent_neural_networks_CO13-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>Class frequency for training labels</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO13-4" href="#co_recurrent_neural_networks_CO13-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a></dt>
<dd><p>Binary testing labels</p></dd>
</dl>
</div></section>













<section data-type="sect2" data-pdf-bookmark="Deep RNNs"><div class="sect2" id="idm45625285307688">
<h2>Deep RNNs</h2>

<p><a data-type="indexterm" data-primary="overfitting of data, avoiding" id="idm45625285306600"/><a data-type="indexterm" data-primary="deep RNNs" id="idm45625285305736"/><a data-type="indexterm" data-primary="RNNs (recurrent neural networks)" data-secondary="dropout" id="idm45625285305032"/>Finally, consider deep RNNs, which are RNNs with multiple hidden layers. They are as easily created as deep DNNs. The only requirement is that for the nonfinal hidden layers, the parameter <code>return_sequences</code> is set to <code>True</code>. <a data-type="indexterm" data-primary="dropout, managing" data-secondary="RNNs" id="idm45625285294936"/>The following Python function to create a deep RNN also allows for the addition of <code>Dropout</code> layers to potentially avoid overfitting. The prediction accuracy is comparable to the one seen in the previous sub-section:</p>

<pre data-type="programlisting" data-code-language="python"><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">104</code><code class="p">]</code><code class="p">:</code><code> </code><code class="kn">from</code><code> </code><code class="nn">keras.layers</code><code> </code><code class="kn">import</code><code> </code><code class="n">Dropout</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">105</code><code class="p">]</code><code class="p">:</code><code> </code><code class="k">def</code><code> </code><code class="nf">create_deep_rnn_model</code><code class="p">(</code><code class="n">hl</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">100</code><code class="p">,</code><code> </code><code class="n">layer</code><code class="o">=</code><code class="s1">'</code><code class="s1">SimpleRNN</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                                    </code><code class="n">optimizer</code><code class="o">=</code><code class="s1">'</code><code class="s1">rmsprop</code><code class="s1">'</code><code class="p">,</code><code> </code><code class="n">features</code><code class="o">=</code><code class="mi">1</code><code class="p">,</code><code>
</code><code>                                    </code><code class="n">dropout</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code> </code><code class="n">rate</code><code class="o">=</code><code class="mf">0.3</code><code class="p">,</code><code> </code><code class="n">seed</code><code class="o">=</code><code class="mi">100</code><code class="p">)</code><code class="p">:</code><code>
</code><code>              </code><code class="k">if</code><code> </code><code class="n">hl</code><code> </code><code class="o">&lt;</code><code class="o">=</code><code> </code><code class="mi">2</code><code class="p">:</code><code> </code><code class="n">hl</code><code> </code><code class="o">=</code><code> </code><code class="mi">2</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO14-1" href="#callout_recurrent_neural_networks_CO14-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>              </code><code class="k">if</code><code> </code><code class="n">layer</code><code> </code><code class="o">==</code><code> </code><code class="s1">'</code><code class="s1">SimpleRNN</code><code class="s1">'</code><code class="p">:</code><code>
</code><code>                  </code><code class="n">layer</code><code> </code><code class="o">=</code><code> </code><code class="n">SimpleRNN</code><code>
</code><code>              </code><code class="k">else</code><code class="p">:</code><code>
</code><code>                  </code><code class="n">layer</code><code> </code><code class="o">=</code><code> </code><code class="n">LSTM</code><code>
</code><code>              </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">Sequential</code><code class="p">(</code><code class="p">)</code><code>
</code><code>              </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">layer</code><code class="p">(</code><code class="n">hu</code><code class="p">,</code><code> </code><code class="n">input_shape</code><code class="o">=</code><code class="p">(</code><code class="n">lags</code><code class="p">,</code><code> </code><code class="n">features</code><code class="p">)</code><code class="p">,</code><code>
</code><code>                               </code><code class="n">return_sequences</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code>
</code><code>                              </code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO14-2" href="#callout_recurrent_neural_networks_CO14-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a><code>
</code><code>              </code><code class="k">if</code><code> </code><code class="n">dropout</code><code class="p">:</code><code>
</code><code>                  </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dropout</code><code class="p">(</code><code class="n">rate</code><code class="p">,</code><code> </code><code class="n">seed</code><code class="o">=</code><code class="n">seed</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO14-3" href="#callout_recurrent_neural_networks_CO14-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>              </code><code class="k">for</code><code> </code><code class="n">_</code><code> </code><code class="ow">in</code><code> </code><code class="nb">range</code><code class="p">(</code><code class="mi">2</code><code class="p">,</code><code> </code><code class="n">hl</code><code class="p">)</code><code class="p">:</code><code>
</code><code>                  </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">layer</code><code class="p">(</code><code class="n">hu</code><code class="p">,</code><code> </code><code class="n">return_sequences</code><code class="o">=</code><code class="bp">True</code><code class="p">)</code><code class="p">)</code><code>
</code><code>                  </code><code class="k">if</code><code> </code><code class="n">dropout</code><code class="p">:</code><code>
</code><code>                      </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dropout</code><code class="p">(</code><code class="n">rate</code><code class="p">,</code><code> </code><code class="n">seed</code><code class="o">=</code><code class="n">seed</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO14-4" href="#callout_recurrent_neural_networks_CO14-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a><code>
</code><code>              </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">layer</code><code class="p">(</code><code class="n">hu</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO14-5" href="#callout_recurrent_neural_networks_CO14-4"><img src="Images/4.png" alt="4" width="12" height="12"/></a><code>
</code><code>              </code><code class="n">model</code><code class="o">.</code><code class="n">add</code><code class="p">(</code><code class="n">Dense</code><code class="p">(</code><code class="mi">1</code><code class="p">,</code><code> </code><code class="n">activation</code><code class="o">=</code><code class="s1">'</code><code class="s1">sigmoid</code><code class="s1">'</code><code class="p">)</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO14-6" href="#callout_recurrent_neural_networks_CO14-5"><img src="Images/5.png" alt="5" width="12" height="12"/></a><code>
</code><code>              </code><code class="n">model</code><code class="o">.</code><code class="n">compile</code><code class="p">(</code><code class="n">optimizer</code><code class="o">=</code><code class="n">optimizer</code><code class="p">,</code><code>
</code><code>                            </code><code class="n">loss</code><code class="o">=</code><code class="s1">'</code><code class="s1">binary_crossentropy</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                            </code><code class="n">metrics</code><code class="o">=</code><code class="p">[</code><code class="s1">'</code><code class="s1">accuracy</code><code class="s1">'</code><code class="p">]</code><code class="p">)</code><code>
</code><code>              </code><code class="k">return</code><code> </code><code class="n">model</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">106</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">set_seeds</code><code class="p">(</code><code class="p">)</code><code>
</code><code>          </code><code class="n">model</code><code> </code><code class="o">=</code><code> </code><code class="n">create_deep_rnn_model</code><code class="p">(</code><code>
</code><code>                      </code><code class="n">hl</code><code class="o">=</code><code class="mi">2</code><code class="p">,</code><code> </code><code class="n">hu</code><code class="o">=</code><code class="mi">50</code><code class="p">,</code><code> </code><code class="n">layer</code><code class="o">=</code><code class="s1">'</code><code class="s1">SimpleRNN</code><code class="s1">'</code><code class="p">,</code><code>
</code><code>                      </code><code class="n">features</code><code class="o">=</code><code class="nb">len</code><code class="p">(</code><code class="n">data</code><code class="o">.</code><code class="n">columns</code><code class="p">)</code><code class="p">,</code><code>
</code><code>                      </code><code class="n">dropout</code><code class="o">=</code><code class="bp">True</code><code class="p">,</code><code> </code><code class="n">rate</code><code class="o">=</code><code class="mf">0.3</code><code class="p">)</code><code>  </code><a class="co" id="co_recurrent_neural_networks_CO14-7" href="#callout_recurrent_neural_networks_CO14-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">107</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">%</code><code class="o">%</code><code class="n">time</code><code>
</code><code>          </code><code class="n">model</code><code class="o">.</code><code class="n">fit_generator</code><code class="p">(</code><code class="n">g</code><code class="p">,</code><code> </code><code class="n">epochs</code><code class="o">=</code><code class="mi">200</code><code class="p">,</code><code> </code><code class="n">steps_per_epoch</code><code class="o">=</code><code class="mi">10</code><code class="p">,</code><code>
</code><code>                              </code><code class="n">verbose</code><code class="o">=</code><code class="bp">False</code><code class="p">,</code><code> </code><code class="n">class_weight</code><code class="o">=</code><code class="n">cw</code><code class="p">(</code><code class="n">train_y</code><code class="p">)</code><code class="p">)</code><code>
</code><code>          </code><code class="n">CPU</code><code> </code><code class="n">times</code><code class="p">:</code><code> </code><code class="n">user</code><code> </code><code class="mf">14.2</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">sys</code><code class="p">:</code><code> </code><code class="mf">2.85</code><code> </code><code class="n">s</code><code class="p">,</code><code> </code><code class="n">total</code><code class="p">:</code><code> </code><code class="mf">17.1</code><code> </code><code class="n">s</code><code>
</code><code>          </code><code class="n">Wall</code><code> </code><code class="n">time</code><code class="p">:</code><code> </code><code class="mf">7.09</code><code> </code><code class="n">s</code><code>
</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">107</code><code class="p">]</code><code class="p">:</code><code> </code><code class="o">&lt;</code><code class="n">keras</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">callbacks</code><code class="o">.</code><code class="n">History</code><code> </code><code class="n">at</code><code> </code><code class="mh">0x7f7ef6428790</code><code class="o">&gt;</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">108</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">y</code><code> </code><code class="o">=</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">where</code><code class="p">(</code><code class="n">model</code><code class="o">.</code><code class="n">predict</code><code class="p">(</code><code class="n">g_</code><code class="p">,</code><code> </code><code class="n">batch_size</code><code class="o">=</code><code class="bp">None</code><code class="p">)</code><code> </code><code class="o">&gt;</code><code> </code><code class="mf">0.5</code><code class="p">,</code><code> </code><code class="mi">1</code><code class="p">,</code><code> </code><code class="mi">0</code><code class="p">)</code><code class="o">.</code><code class="n">flatten</code><code class="p">(</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">109</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">np</code><code class="o">.</code><code class="n">bincount</code><code class="p">(</code><code class="n">y</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">109</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">array</code><code class="p">(</code><code class="p">[</code><code class="mi">550</code><code class="p">,</code><code> </code><code class="mi">324</code><code class="p">]</code><code class="p">)</code><code>
</code><code>
</code><code class="n">In</code><code> </code><code class="p">[</code><code class="mi">110</code><code class="p">]</code><code class="p">:</code><code> </code><code class="n">accuracy_score</code><code class="p">(</code><code class="n">test_y</code><code class="p">[</code><code class="n">lags</code><code class="p">:</code><code class="p">]</code><code class="p">,</code><code> </code><code class="n">y</code><code class="p">)</code><code>
</code><code class="n">Out</code><code class="p">[</code><code class="mi">110</code><code class="p">]</code><code class="p">:</code><code> </code><code class="mf">0.6430205949656751</code></pre>
<dl class="calloutlist">
<dt><a class="co" id="callout_recurrent_neural_networks_CO14-1" href="#co_recurrent_neural_networks_CO14-1"><img src="Images/1.png" alt="1" width="12" height="12"/></a></dt>
<dd><p>A minimum of two hidden layers is ensured.</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO14-2" href="#co_recurrent_neural_networks_CO14-2"><img src="Images/2.png" alt="2" width="12" height="12"/></a></dt>
<dd><p>The first hidden layer.</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO14-3" href="#co_recurrent_neural_networks_CO14-3"><img src="Images/3.png" alt="3" width="12" height="12"/></a></dt>
<dd><p>The <code>Dropout</code> layers.</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO14-4" href="#co_recurrent_neural_networks_CO14-5"><img src="Images/4.png" alt="4" width="12" height="12"/></a></dt>
<dd><p>The final hidden layer.</p></dd>
<dt><a class="co" id="callout_recurrent_neural_networks_CO14-5" href="#co_recurrent_neural_networks_CO14-6"><img src="Images/5.png" alt="5" width="12" height="12"/></a></dt>
<dd><p>The model is built for classification.<a data-type="indexterm" data-primary="" data-startref="ix_RNNs_ch8" id="idm45625284675640"/><a data-type="indexterm" data-primary="" data-startref="ix_stat_ineffic_RNNs_ch8" id="idm45625284674776"/><a data-type="indexterm" data-primary="" data-startref="ix_RNNs_fin_features" id="idm45625284673864"/></p></dd>
</dl>
</div></section>





</div></section>













<section data-type="sect1" data-pdf-bookmark="Conclusions"><div class="sect1" id="idm45625286225736">
<h1>Conclusions</h1>

<p>This chapter introduces RNNs with <code>Keras</code> and illustrates the application of such neural networks to financial time series data. On the Python level, working with RNNs is not too different from working with DNNs. One major difference is that the training and test data must necessarily be presented in a sequential form to the respective methods. However, this is made easy by the application of the <code>TimeseriesGenerator</code> function, which transforms sequential data into a generator object that <code>Keras</code> RNNs can work with.</p>

<p>The examples in this chapter work with both financial price series and financial return series. In addition, financial features, such as time series momentum, can also be added easily. The functions presented for model creation allow, among other things, for one to use <code>SimpleRNN</code> or <code>LSTM</code> layers as well as different optimizers. They also allow one to model estimation and classification problems in the context of shallow and deep neural networks.</p>

<p>The out-of-sample prediction accuracy, when predicting market direction, is relatively high for the classification examples—but it’s not that high and can even be quite low for the estimation examples.</p>
</div></section>













<section data-type="sect1" data-pdf-bookmark="References"><div class="sect1" id="idm45625284899912">
<h1>References</h1>

<p>Books and papers cited in this chapter:</p>

<ul class="author-date-bib">
<li>
<p>Chollet, François. 2017. <em>Deep Learning with Python</em>. Shelter Island: Manning.</p>
</li>
<li>
<p>Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. 2016. <em>Deep Learning</em>. Cambridge: MIT Press. <a href="http://deeplearningbook.org"><em class="hyperlink">http://deeplearningbook.org</em></a>.</p>
</li>
</ul>
</div></section>







<div data-type="footnotes"><p data-type="footnote" id="idm45625292780216"><sup><a href="ch08.xhtml#idm45625292780216-marker">1</a></sup> For technical details of RNNs, refer to Goodfellow et al. (2016, ch. 10). For the practical implementation, refer to Chollet (2017, ch. 6).</p></div></div></section></div>



  </body></html>